
@article{saha_intra-_2020,
	title = {Intra- and {Inter}-subject {Variability} in {EEG}-{Based} {Sensorimotor} {Brain} {Computer} {Interface}: {A} {Review}},
	volume = {13},
	issn = {1662-5188},
	shorttitle = {Intra- and {Inter}-subject {Variability} in {EEG}-{Based} {Sensorimotor} {Brain} {Computer} {Interface}},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2019.00087},
	abstract = {Brain computer interfaces (BCI) for the rehabilitation of motor impairments exploit sensorimotor rhythms (SMR) in the electroencephalogram (EEG). However, the neurophysiological processes underpinning the SMR often vary over time and across subjects. Inherent intra- and inter-subject variability causes covariate shift in data distributions that impede the transferability of model parameters amongst sessions/subjects. Transfer learning includes machine learning-based methods to compensate for inter-subject and inter-session (intra-subject) variability manifested in EEG-derived feature distributions as a covariate shift for BCI. Besides transfer learning approaches, recent studies have explored psychological and neurophysiological predictors as well as inter-subject associativity assessment, which may augment transfer learning in EEG-based BCI. Here, we highlight the importance of measuring inter-session/subject performance predictors for generalized BCI frameworks for both normal and motor-impaired people, reducing the necessity for tedious and annoying calibration sessions and BCI training.},
	urldate = {2024-01-03},
	journal = {Frontiers in Computational Neuroscience},
	author = {Saha, Simanto and Baumert, Mathias},
	year = {2020},
	keywords = {EEG, Review, Variability},
	file = {Full Text PDF:C\:\\Users\\s.velut\\Zotero\\storage\\NYCF2ZI3\\Saha et Baumert - 2020 - Intra- and Inter-subject Variability in EEG-Based .pdf:application/pdf},
}

@article{cabrera_castillos_burst_2023,
	title = {Burst c-{VEP} {Based} {BCI}: {Optimizing} stimulus design for enhanced classification with minimal calibration data and improved user experience},
	volume = {284},
	issn = {1053-8119},
	shorttitle = {Burst c-{VEP} {Based} {BCI}},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811923005979},
	doi = {10.1016/j.neuroimage.2023.120446},
	abstract = {The utilization of aperiodic flickering visual stimuli under the form of code-modulated Visual Evoked Potentials (c-VEP) represents a pivotal advancement in the field of reactive Brain–Computer Interface (rBCI). A major advantage of the c-VEP approach is that the training of the model is independent of the number and complexity of targets, which helps reduce calibration time. Nevertheless, the existing designs of c-VEP stimuli can be further improved in terms of visual user experience but also to achieve a higher signal-to-noise ratio, while shortening the selection time and calibration process. In this study, we introduce an innovative variant of code-VEP, referred to as “Burst c-VEP”. This original approach involves the presentation of short bursts of aperiodic visual flashes at a deliberately slow rate, typically ranging from two to four flashes per second. The rationale behind this design is to leverage the sensitivity of the primary visual cortex to transient changes in low-level stimuli features to reliably elicit distinctive series of visual evoked potentials. In comparison to other types of faster-paced code sequences, burst c-VEP exhibit favorable properties to achieve high bitwise decoding performance using convolutional neural networks (CNN), which yields potential to attain faster selection time with the need for less calibration data. Furthermore, our investigation focuses on reducing the perceptual saliency of c-VEP through the attenuation of visual stimuli contrast and intensity to significantly improve users’ visual comfort. The proposed solutions were tested through an offline 4-classes c-VEP protocol involving 12 participants. Following a factorial design, participants were instructed to focus on c-VEP targets whose pattern (burst and maximum-length sequences) and amplitude (100\% or 40\% amplitude depth modulations) were manipulated across experimental conditions. Firstly, the full amplitude burst c-VEP sequences exhibited higher accuracy, ranging from 90.5\% (with 17.6s of calibration data) to 95.6\% (with 52.8s of calibration data), compared to its m-sequence counterpart (71.4\% to 85.0\%). The mean selection time for both types of codes (1.5 s) compared favorably to reports from previous studies. Secondly, our findings revealed that lowering the intensity of the stimuli only slightly decreased the accuracy of the burst code sequences to 94.2\% while leading to substantial improvements in terms of user experience. Taken together, these results demonstrate the high potential of the proposed burst codes to advance reactive BCI both in terms of performance and usability. The collected dataset, along with the proposed CNN architecture implementation, are shared through open-access repositories.},
	urldate = {2024-01-03},
	journal = {NeuroImage},
	author = {Cabrera Castillos, Kalou and Ladouce, Simon and Darmet, Ludovic and Dehais, Frédéric},
	month = dec,
	year = {2023},
	keywords = {Amplitude depth reduction, CNN, Code-VEP, Reactive BCI, Visual comfort},
	pages = {120446},
	file = {ScienceDirect Snapshot:C\:\\Users\\s.velut\\Zotero\\storage\\KKNL6MDC\\S1053811923005979.html:text/html;Version soumise:C\:\\Users\\s.velut\\Zotero\\storage\\I64SG9GA\\Cabrera Castillos et al. - 2023 - Burst c-VEP Based BCI Optimizing stimulus design .pdf:application/pdf},
}

@article{martinez-cagigal_brain-computer_2021,
	title = {Brain-computer interfaces based on code-modulated visual evoked potentials (c-{VEP}): a literature review},
	volume = {18},
	issn = {1741-2552},
	shorttitle = {Brain-computer interfaces based on code-modulated visual evoked potentials (c-{VEP})},
	doi = {10.1088/1741-2552/ac38cf},
	abstract = {Objective.Code-modulated visual evoked potentials (c-VEP) have been consolidated in recent years as robust control signals capable of providing non-invasive brain-computer interfaces (BCIs) for reliable, high-speed communication. Their usefulness for communication and control purposes has been reflected in an exponential increase of related articles in the last decade. The aim of this review is to provide a comprehensive overview of the literature to gain understanding of the existing research on c-VEP-based BCIs, since its inception (1984) until today (2021), as well as to identify promising future research lines.Approach.The literature review was conducted according to the Preferred Reporting Items for Systematic reviews and Meta-Analysis guidelines. After assessing the eligibility of journal manuscripts, conferences, book chapters and non-indexed documents, a total of 70 studies were included. A comprehensive analysis of the main characteristics and design choices of c-VEP-based BCIs was discussed, including stimulation paradigms, signal processing, modeling responses, applications, etc.Main results.The literature review showed that state-of-the-art c-VEP-based BCIs are able to provide an accurate control of the system with a large number of commands, high selection speeds and even without calibration. In general, a lack of validation in real setups was observed, especially regarding the validation with disabled populations. Future work should be focused toward developing self-paced c-VEP-based portable BCIs applied in real-world environments that could exploit the unique benefits of c-VEP paradigms. Some aspects such as asynchrony, unsupervised training, or code optimization still require further research and development.Significance.Despite the growing popularity of c-VEP-based BCIs, to the best of our knowledge, this is the first literature review on the topic. In addition to providing a joint discussion of the advances in the field, some future lines of research are suggested to contribute to the development of reliable plug-and-play c-VEP-based BCIs.},
	language = {eng},
	number = {6},
	journal = {Journal of Neural Engineering},
	author = {Martínez-Cagigal, Víctor and Thielen, Jordy and Santamaría-Vázquez, Eduardo and Pérez-Velasco, Sergio and Desain, Peter and Hornero, Roberto},
	month = nov,
	year = {2021},
	pmid = {34763331},
	keywords = {Brain-Computer Interfaces, brain–computer interface (BCI), code-modulated VEP (c-VEP), EEG, Evoked Potentials, Visual, Language, literature review, Signal Processing, Computer-Assisted, visual evoked potential (VEP)},
	file = {Martínez-Cagigal et al. - 2021 - Brain-computer interfaces based on code-modulated .pdf:C\:\\Users\\s.velut\\Zotero\\storage\\F86J9SEQ\\Martínez-Cagigal et al. - 2021 - Brain-computer interfaces based on code-modulated .pdf:application/pdf},
}

@article{thielen_full_2021,
	title = {From full calibration to zero training for a code-modulated visual evoked potentials for brain–computer interface},
	volume = {18},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2552/abecef},
	doi = {10.1088/1741-2552/abecef},
	abstract = {Objective. Typically, a brain–computer interface (BCI) is calibrated using user- and session-specific data because of the individual idiosyncrasies and the non-stationary signal properties of the electroencephalogram (EEG). Therefore, it is normal for BCIs to undergo a time-consuming passive training stage that prevents users from directly operating them. In this study, we systematically reduce the training data set in a stepwise fashion, to ultimately arrive at a calibration-free method for a code-modulated visually evoked potential (cVEP)-based BCI to fully eliminate the tedious training stage. Approach. In an extensive offline analysis, we compare our sophisticated encoding model with a traditional event-related potential (ERP) technique. We calibrate the encoding model in a standard way, with data limited to a single class while generalizing to all others and without any data. In addition, we investigate the feasibility of the zero-training cVEP BCI in an online setting. Main results. By adopting the encoding model, the training data can be reduced substantially, while maintaining both the classification performance as well as the explained variance of the ERP method. Moreover, with data from only one class or even no data at all, it still shows excellent performance. In addition, the zero-training cVEP BCI achieved high communication rates in an online spelling task, proving its feasibility for practical use. Significance. To date, this is the fastest zero-training cVEP BCI in the field, allowing high communication speeds without calibration while using only a few non-invasive water-based EEG electrodes. This allows us to skip the training stage altogether and spend all the valuable time on direct operation. This minimizes the session time and opens up new exciting directions for practical plug-and-play BCI. Fundamentally, these results validate that the adopted neural encoding model compresses data into event responses without the loss of explanatory power compared to using full ERPs as a template.},
	language = {en},
	number = {5},
	urldate = {2024-01-03},
	journal = {Journal of Neural Engineering},
	author = {Thielen, J. and Marsman, P. and Farquhar, J. and Desain, P.},
	month = apr,
	year = {2021},
	note = {Publisher: IOP Publishing},
	keywords = {0-train, CVEP, EEG, Transfer learning},
	pages = {056007},
	file = {IOP Full Text PDF:C\:\\Users\\s.velut\\Zotero\\storage\\EG5VJGW3\\Thielen et al. - 2021 - From full calibration to zero training for a code-.pdf:application/pdf},
}

@article{ying_riemannian_2022,
	title = {Riemannian geometry-based transfer learning for reducing training time in c-{VEP} {BCIs}},
	volume = {12},
	copyright = {2022 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-14026-y},
	doi = {10.1038/s41598-022-14026-y},
	abstract = {One of the main problems that a brain-computer interface (BCI) face is that a training stage is required for acquiring training data to calibrate its classification model just before every use. Transfer learning is a promising method for addressing the problem. In this paper, we propose a Riemannian geometry-based transfer learning algorithm for code modulated visual evoked potential (c-VEP)-based BCIs, which can effectively reduce the calibration time without sacrificing the classification accuracy. The algorithm includes the main procedures of log-Euclidean data alignment (LEDA), super-trial construction, covariance matrix estimation, training accuracy-based subject selection (TSS) and minimum distance to mean classification. Among them, the LEDA reduces the difference in data distribution between subjects, whereas the TSS promotes the similarity between a target subject and the source subjects. The resulting performance of transfer learning is improved significantly. Sixteen subjects participated in a c-VEP BCI experiment and the recorded data were used in offline analysis. Leave-one subject-out (LOSO) cross-validation was used to evaluate the proposed algorithm on the data set. The results showed that the algorithm achieved much higher classification accuracy than the subject-specific (baseline) algorithm with the same number of training trials. Equivalently, the algorithm reduces the training time of the BCI at the same performance level and thus facilitates its application in real world.},
	language = {en},
	number = {1},
	urldate = {2024-01-03},
	journal = {Scientific Reports},
	author = {Ying, Jiahui and Wei, Qingguo and Zhou, Xichen},
	month = jun,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Biomedical engineering, CVEP, Data aligment, EEG, Extracellular recording, Riemannian geometry, Transfer learning},
	pages = {9818},
	file = {Full Text PDF:C\:\\Users\\s.velut\\Zotero\\storage\\XW2DVEEK\\Ying et al. - 2022 - Riemannian geometry-based transfer learning for re.pdf:application/pdf},
}

@article{coelho_rodrigues_riemannian_2018,
	title = {Riemannian {Procrustes} {Analysis} : {Transfer} {Learning} for {Brain}-{Computer} {Interfaces}},
	volume = {66},
	shorttitle = {Riemannian {Procrustes} {Analysis}},
	url = {https://hal.science/hal-01971856},
	doi = {10.1109/TBME.2018.2889705},
	abstract = {Objective: This paper presents a Transfer Learning approach for dealing with the statistical variability of EEG signals recorded on different sessions and/or from different subjects. This is a common problem faced by Brain-Computer Interfaces (BCI) and poses a challenge for systems that try to reuse data from previous recordings to avoid a calibration phase for new users or new sessions for the same user. Method: We propose a method based on Procrustes analysis for matching the statistical distributions of two datasets using simple geometrical transformations (translation, scaling and rotation) over the data points. We use symmetric positive definite matrices (SPD) as statistical features for describing the EEG signals, so the geometrical operations on the data points respect the intrinsic geometry of the SPD manifold. Because of its geometry-aware nature, we call our method the Riemannian Procrustes Analysis (RPA). We assess the improvement in Transfer Learning via RPA by performing classification tasks on simulated data and on eight publicly available BCI datasets covering three experimental paradigms (243 subjects in total). Results: Our results show that the classification accuracy with RPA is superior in comparison to other geometry-aware methods proposed in the literature. We also observe improvements in ensemble classification strategies when the statistics of the datasets are matched via RPA. Conclusion and significance: We present a simple yet powerful method for matching the statistical distributions of two datasets, thus paving the way to BCI systems capable of reusing data from previous sessions and avoid the need of a calibration procedure.},
	number = {8},
	urldate = {2024-01-03},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Coelho Rodrigues, Pedro Luiz and Jutten, Christian and Congedo, Marco},
	month = dec,
	year = {2018},
	note = {Publisher: Institute of Electrical and Electronics Engineers},
	keywords = {Brain-Computer Interface, Covariance Matrices, Data aligment, EEG, Riemannian geometry, Transfer Learning},
	pages = {2390 -- 2401},
	file = {HAL PDF Full Text:C\:\\Users\\s.velut\\Zotero\\storage\\WXBCCBGH\\Coelho Rodrigues et al. - 2018 - Riemannian Procrustes Analysis  Transfer Learning.pdf:application/pdf},
}
