{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6de10f24-829d-4847-b79b-7d4d282eb5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# from _utils import make_preds_accumul_aggresive, make_preds_pvalue\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "#from tensorflow import keras\n",
    "import mne\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "575c7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 60\n",
    "sfreq = 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e15184-3fcf-463d-89b7-97e4e6db7a95",
   "metadata": {},
   "source": [
    "## Path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "12c5a06b-e9fd-42d7-bf0c-83d8d68b707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 500\n",
    "\n",
    "participant = 'P12'\n",
    "path = '/'.join(['C:\\\\Users\\\\s.velut\\\\Documents\\\\These\\\\Protheus_PHD\\\\Class4\\\\', participant])\n",
    "# path = '/home/dcas/k.cabrera/Data/SETNOP2'\n",
    "n_class=4\n",
    "fps = 60\n",
    "window_size = 0.3\n",
    "\n",
    "# file_name = '_'.join([participant, 'mseq40.set'])\n",
    "#file_name = '_'.join([participant, 'mseq100.set'])\n",
    "# file_name = '_'.join([participant, 'burst40.set'])\n",
    "file_name = '_'.join([participant, 'burst100.set'])\n",
    "# file_name = '/'.join([path,  participant+'_whitemseq.set'])\n",
    "# file_name = '_'.join([participant, 'burst', 'oi_1.set'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f830cb-fdc0-4d83-b0e3-3107ac016368",
   "metadata": {},
   "source": [
    "#### Load channel positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ede9c-040e-4590-94b2-577a62a9b026",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the raw data and small pre-process\n",
    "1. Drop the ACC channels and the shitty channels near ears\n",
    "2. Average re-referencing\n",
    "4. Extract 2.2s epochs using events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b8df747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_eeglab(path+\"\\\\\"+file_name, preload=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "388b5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a4b45",
   "metadata": {},
   "source": [
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "raw.set_montage(montage)\n",
    "raw.plot_sensors(show_names=True)\n",
    "raw.plot_psd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e02a0323-b237-4b92-b5ed-ded4930f3cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'F9', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'P9', 'O1', 'Oz', 'O2', 'P10', 'P8', 'P4', 'CP2', 'CP6', 'T8', 'C4', 'Cz', 'FC2', 'FC6', 'F10', 'F8', 'F4', 'Fp2']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : 32\n",
      "<Info | 9 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, Fz, F3, F7, F9, FC5, FC1, C3, T7, CP5, CP1, Pz, P3, P7, P9, ...\n",
      " chs: 32 EEG\n",
      " custom_ref_applied: True\n",
      " dig: 32 items (32 EEG)\n",
      " highpass: 1.0 Hz\n",
      " lowpass: 20.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 32\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      ">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(raw.ch_names)\n",
    "# to_drop = [\"P9\", \"P10\", \"TP9\", \"TP10\", \"10\", \"21\"]\n",
    "# raw = raw.drop_channels([ch for ch in raw.ch_names if ch in to_drop])\n",
    "# # raw = raw.drop_channels([\"10\", \"21\"])\n",
    "#keep = [\"O1\", \"O2\", \"Oz\", \"P7\", \"P3\", \"P4\", \"P8\", \"Pz\",\"P9\"]\n",
    "# keep = [\"16\", \"18\", \"17\", \"15\", \"14\", \"19\", \"20\", \"13\"] # electrodes to keep\n",
    "#raw = raw.drop_channels([i for i in raw.ch_names if i not in keep])\n",
    "\n",
    "# raw = raw.filter(l_freq=50.1, h_freq=49.9, method=\"iir\", verbose=True)\n",
    "raw = raw.filter(l_freq=1,h_freq=20,  method=\"fir\", verbose=True)\n",
    "# raw = raw.filter(l_freq=1,h_freq=8,  method=\"fir\", verbose=True)\n",
    "#raw.resample(250, npad='auto')\n",
    "# Average re-referencing\n",
    "mne.set_eeg_reference(raw, 'average', copy=False, verbose=False)\n",
    "\n",
    "n_channels = len(raw.ch_names)\n",
    "print(\"Channels :\", n_channels)\n",
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9e70fa4b-2e51-42fe-a41a-0b7c29ea6bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# Strip the annotations that were script to make them easier to process\n",
    "events, event_id = mne.events_from_annotations(raw, event_id='auto', verbose=False)\n",
    "to_remove = []\n",
    "for idx in range(len(raw.annotations.description)):\n",
    "    if (('collects' in raw.annotations.description[idx]) or\n",
    "        ('iti' in raw.annotations.description[idx]) or\n",
    "        (raw.annotations.description[idx] == '[]')):\n",
    "        to_remove.append(idx)\n",
    "    else:\n",
    "        code = raw.annotations.description[idx].split('_')[0]\n",
    "        lab = raw.annotations.description[idx].split('_')[1]\n",
    "        code = code.replace('\\n', '')\n",
    "        code = code.replace('[', '')\n",
    "        code = code.replace(']', '')\n",
    "        code = code.replace(' ', '')\n",
    "        raw.annotations.description[idx] = code + '_' + lab\n",
    "\n",
    "to_remove = np.array(to_remove)\n",
    "if len(to_remove) > 0:\n",
    "    raw.annotations.delete(to_remove)\n",
    "# Get the events\n",
    "events, event_id = mne.events_from_annotations(raw, event_id='auto', verbose=False)\n",
    "#print(events.shape)\n",
    "shift = 0.0\n",
    "# Epoch the data following event\n",
    "epochs = mne.Epochs(raw, events, event_id=event_id, tmin=shift, \\\n",
    "            tmax=2.2+shift, baseline=(None, None), preload=False, verbose=False)\n",
    "labels = epochs.events[..., -1]+1\n",
    "labels -= np.min(labels)\n",
    "#print(epochs.events[..., -1])\n",
    "data = epochs.get_data()\n",
    "info_ep = epochs.info\n",
    "#print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b29ac",
   "metadata": {},
   "source": [
    "evoke1 = epochs[\"111111111111110000111100001111000011001111001100001100111111000000110011111100001100110000001111001100000011001100001100000000001100_1\"].average()\n",
    "evoke2 = epochs[\"000011110000000011111111110000000000001111000011001100110011110011000000110000001111110011001111111111000011000000111100001100111111_2\"].average()\n",
    "evoke3 = epochs[\"111100000000110000111100000000000011001111001100110011000000111111001111110011001111000000111100111111000000000011111100001100110011_3\"].average()\n",
    "evoke4 = epochs[\"111100111100111100111100000011111100000011111111110000110011000011110000000011000000001111111111110011001100001111000011000000110011_4\"].average()\n",
    "\n",
    "evoke1.plot(picks=\"eeg\", spatial_colors=True, gfp=True)\n",
    "# evoke1.plot_topomap()\n",
    "# evoke1.plot_joint()\n",
    "evoke2.plot(picks=\"eeg\", spatial_colors=True, gfp=True)\n",
    "evoke3.plot(picks=\"eeg\", spatial_colors=True, gfp=True)\n",
    "evoke4.plot(picks=\"eeg\", spatial_colors=True, gfp=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec5d54-21ce-4a3e-9974-dff0d81efe65",
   "metadata": {},
   "source": [
    "### Transform a code in `str` to a code in np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8d886a37-bc66-490c-a290-f84b2502c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code2array(code):\n",
    "    tmp = []\n",
    "    for idx, c in enumerate(code[:-2]):\n",
    "        if c == '5' or c == '.':\n",
    "            continue\n",
    "        elif c == '0':\n",
    "            if code[idx+2] == '5':\n",
    "                tmp.append(0.5)\n",
    "            else:\n",
    "                tmp.append(0)\n",
    "        else:\n",
    "            tmp.append(1)\n",
    "    if code[-1] == '.':\n",
    "        if code[-2] == '0':\n",
    "            tmp.append(0)\n",
    "        else:\n",
    "            tmp.append(1)\n",
    "    return np.array(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f02ea8-255b-4d46-9f64-8263ef253089",
   "metadata": {},
   "source": [
    "### Build a dictionnary that contains all the code in the np.array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7e221464-c67a-468d-bedc-1cb4592d032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "codes = OrderedDict()\n",
    "for k, v in event_id.items():\n",
    "    code = k.split('_')[0]\n",
    "    code = code.replace('.','').replace('2','')\n",
    "    idx = k.split('_')[1]\n",
    "    if 'randomslowwhite' in file_name:\n",
    "        codes[v-1] = code2array(code)\n",
    "    else:\n",
    "        codes[v-1] = np.array(list(map(int, code)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f84de91-a554-4326-8c67-f1ad891597d5",
   "metadata": {},
   "source": [
    "### Define train/test split and windows size\n",
    "Here we use only the first 7 blocks as calibrition and 8 others would be used as testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "11e5d7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0,\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "                     1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     1, 1, 1, 1, 0, 0, 0, 0])),\n",
       "             (1,\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "                     1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             (2,\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "                     1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 1, 1, 1])),\n",
       "             (3,\n",
       "              array([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "                     1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "                     0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0]))])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9b1c4257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 32, 1101)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e12df7eb-a999-4f84-8b58-6c5503e5feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = int(epochs.info['sfreq'])\n",
    "n_samples_windows = int(window_size*sfreq)\n",
    "n_trial_per_class = int(len(data)/n_class)\n",
    "\n",
    "n_cal = 7\n",
    "\n",
    "data_train = data[:n_class*n_cal]\n",
    "labels_train = labels[:n_class*n_cal]\n",
    "data_test = data[n_class*n_cal:]\n",
    "labels_test = labels[n_class*n_cal:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c34c29-78b0-4da1-ac2c-b18150cb175e",
   "metadata": {},
   "source": [
    "### Slice the epoch in windows\n",
    "The network is not processing full epochs but windows of 250ms. So each epoch is cut into window and the following code (`0` or `1`) is associated as label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ec58decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_window_old(data, labels):\n",
    "    length = int((2.2-window_size)*sfreq)\n",
    "    X = np.empty(shape=((length)*data.shape[0], n_channels, n_samples_windows))\n",
    "    y = np.empty(shape=((length)*data.shape[0]), dtype=int)\n",
    "    print(length)\n",
    "    print(n_samples_windows)\n",
    "    count = 0\n",
    "    for trial_nb, trial in enumerate(data):\n",
    "        lab = labels[trial_nb]\n",
    "        c = codes[lab]\n",
    "        code_pos = 0\n",
    "        for idx in range(length):\n",
    "            X[count] = trial[:, idx:idx+n_samples_windows]\n",
    "            if idx/sfreq >= (code_pos+1)/fps:\n",
    "                code_pos += 1 \n",
    "            y[count] = int(c[code_pos])\n",
    "            count += 1\n",
    "\n",
    "    # X = np.expand_dims(X, 1)\n",
    "    X = X.astype(np.float32)\n",
    "    y_pred = np.vstack((y,np.abs(1-y))).T\n",
    "    y = np.array([1 if (y >= 0.5) else 0 for y in y_pred[:,0]])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b888b955-2c47-4dcd-b51f-438442a0d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_window(data, labels, win_size, data_freq, code_freq, offset=0,\n",
    "              focus_rising=None, pre_rising=0, post_rising=0,\n",
    "              focus_falling=None, pre_falling=0, post_falling=0):\n",
    "    length = int((2.2-win_size)*data_freq)\n",
    "    X = np.empty(shape=((length)*data.shape[0], n_channels, n_samples_windows))\n",
    "    Y = np.empty(shape=((length)*data.shape[0]), dtype=int)\n",
    "    for trial_nb, trial in enumerate(data):\n",
    "        lab = labels[trial_nb]\n",
    "        c = codes[lab]\n",
    "        labels_upsampled = np.repeat(c, sfreq//code_freq)\n",
    "        labels_upsampled = np.concatenate((np.zeros(int(offset*data_freq), dtype=int), np.array(labels_upsampled)))\n",
    "        if (focus_rising is not None) or (focus_falling is not None):\n",
    "            hi_indices = []\n",
    "            low_indices = []\n",
    "            for idx in range(1, len(labels_upsampled)):\n",
    "                if (focus_rising is not None) and (labels_upsampled[idx-1] == 0) and (labels_upsampled[idx] == 1):\n",
    "                    hi_indices.append(idx)\n",
    "                elif (focus_falling is not None) and (labels_upsampled[idx-1] == 1) and (labels_upsampled[idx] == 0):\n",
    "                    low_indices.append(idx)\n",
    "            focused_labels = np.zeros(length)\n",
    "            pre_rising_frames = int(sfreq*pre_rising)\n",
    "            post_rising_frames = int(sfreq*post_rising)\n",
    "            pre_falling_frames = int(sfreq*pre_falling)\n",
    "            post_falling_frames = int(sfreq*post_falling)\n",
    "            for idx in hi_indices:\n",
    "                focused_labels[idx-pre_rising_frames:idx+post_rising_frames+1] = 1\n",
    "            for idx in low_indices:\n",
    "                focused_labels[idx-pre_falling_frames:idx+post_falling_frames+1] = 1\n",
    "        else:\n",
    "            focused_labels = labels_upsampled.copy()\n",
    "            \n",
    "        for idx in range(length):\n",
    "            # print('Xidx:', trial_nb*length+idx, \"Tidxm:\", idx, 'TidxM:', idx +\n",
    "            #       n_samples_windows, 'Ltrial', trial[:, idx:idx+n_samples_windows].shape)\n",
    "            X[trial_nb*length+idx] = trial[:, idx:idx+n_samples_windows]\n",
    "            Y[trial_nb*length+idx] = focused_labels[idx]\n",
    "    # X = np.expand_dims(X, 1)\n",
    "    X = X.astype(np.float32)\n",
    "    y_pred = np.vstack((Y,np.abs(1-Y))).T\n",
    "    Y = [1 if (Y >= 0.5) else 0 for Y in y_pred[:,0]]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "23dc6e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 32, 1101)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "50bfe6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950\n",
      "150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "#window_size = 0.40\n",
    "# X, Y = to_window_old(np.array(data_train[:1]), labels_train[:1])\n",
    "# X_train, Y_train = to_window_old(data_train, labels_train)\n",
    "# X_test, Y_test = to_window_old(data_test, labels_test)\n",
    "# print(Y[:,0])\n",
    "X_train, Y_train = to_window_old(data_train, labels_train)#, 0.25, sfreq, 60)\n",
    "X_test, Y_test = to_window_old(data_test, labels_test)#, 0.25, sfreq, 60)\n",
    "# print(codes[labels_test[0]])\n",
    "# print(np.array(Y_train[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "cca97a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_train = mne.EpochsArray(X_train,info_ep)\n",
    "# epochs_train.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e74ca2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_test = mne.EpochsArray(X_test,info_ep)\n",
    "# epochs_test.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d7b89-7b58-44f9-ab45-3b1ef1ea713e",
   "metadata": {},
   "source": [
    "### Normalization using stats from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e2ab8195-3775-47c4-8a16-953fac6636a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = X_train.std(axis=0)\n",
    "X_train /= X_std + 1e-8\n",
    "X_std = X_test.std(axis=0)\n",
    "X_test /= X_std + 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e1ba06-f21d-4ecf-9cd5-8387736a4508",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Balance classes\n",
    "Our classes are unbalanced, there are more `1` than `0` in the train set (the stimulation is more often ON than OFF).  \n",
    "We will use a random under sampler to make it balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "692240c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26600, 32, 150)\n",
      "(30400, 32, 150)\n",
      "(26600,)\n",
      "4501\n",
      "(30400,)\n",
      "5144\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(len(Y_train[Y_train[:] == 1]))\n",
    "print(Y_test.shape)\n",
    "print(len(Y_test[Y_test[:] == 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "44030563-1570-4eb3-b112-6b630d449e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rus = RandomUnderSampler()\n",
    "counter=np.array(range(0,len(Y_train))).reshape(-1,1)\n",
    "index,_ = rus.fit_resample(counter,Y_train[:])\n",
    "X_train = np.squeeze(X_train[index,:,:], axis=1)\n",
    "Y_train = np.squeeze(Y_train[index])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "44336b40-3e06-4c69-9858-2b696853ea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9002, 32, 150)\n",
      "(9002,)\n",
      "(30400, 32, 150)\n",
      "(30400,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "38de3569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4501\n",
      "4501\n",
      "25256\n",
      "5144\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train[Y_train[:] == 0]))\n",
    "print(len(Y_train[Y_train[:] == 1]))\n",
    "print(len(Y_test[Y_test[:] == 0]))\n",
    "print(len(Y_test[Y_test[:] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37542174-788c-4128-ae21-94cf344b15d1",
   "metadata": {},
   "source": [
    "### Pick an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c0727580-c7d6-498a-a90c-467e07da91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "clf = make_pipeline(XdawnCovariances(nfilter=4, estimator=\"lwf\", xdawn_estimator=\"lwf\"),MDM())\n",
    "clf2 = make_pipeline(XdawnCovariances(nfilter=4, estimator=\"lwf\", xdawn_estimator=\"lwf\"),\n",
    "    TangentSpace(),\n",
    "    LDA(solver=\"lsqr\", shrinkage=\"auto\"))\n",
    "clf3 = make_pipeline(XdawnCovariances(nfilter=4, estimator=\"lwf\", xdawn_estimator=\"lwf\"),\n",
    "    TangentSpace(),\n",
    "    svm.SVC())\n",
    "clf4 = make_pipeline(XdawnCovariances(estimator='lwf'), TangentSpace(), LogisticRegression(max_iter=10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e22a2512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('xdawncovariances',\n",
      "                 XdawnCovariances(estimator='lwf', xdawn_estimator='lwf')),\n",
      "                ('tangentspace', TangentSpace()), ('svc', SVC())])\n"
     ]
    }
   ],
   "source": [
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(Y_test.shape)\n",
    "\n",
    "print(clf3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5099b32-1a52-4758-a20b-0a2c759d9cbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cut the train in train and valid\n",
    "Also set some HP of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "6f8a5ecf-8400-4722-86bc-317d15a2b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ad9011-e499-4c2a-9163-d968ba4d0153",
   "metadata": {},
   "source": [
    "### Attach an optimizer and train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3bb97b",
   "metadata": {},
   "source": [
    "res_X_train=[]\n",
    "for i in range(len(X_train)):\n",
    "    res_X_train.append(np.array(X_train[i:i+1]).reshape(n_samples_windows, n_channels, 1))\n",
    "res_X_val=[]\n",
    "for i in range(len(x_val)):\n",
    "    res_X_val.append(np.array(x_val[i:i+1]).reshape(n_samples_windows, n_channels, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1a142",
   "metadata": {},
   "source": [
    "np.array(res_X_val).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9861b",
   "metadata": {},
   "source": [
    "np.array(res_X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "29716ea1-43fe-4060-b7e2-7685be9c2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 1e-3\n",
    "# weight_decay = 1e-4\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=lr, amsgrad=True)\n",
    "# clf.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "# X_trainp = xdawn.fit_transform(X_train,y_train)\n",
    "# X_valp = xdawn.fit_transform(x_val,y_val)\n",
    "# X_testp = xdawn.fit_trans form(X_test,Y_test)\n",
    "history = clf.fit(np.array(x_train), y_train)\n",
    "history2 = clf2.fit(np.array(x_train), y_train)\n",
    "history3 = clf3.fit(np.array(x_train), y_train)\n",
    "history4 = clf4.fit(np.array(x_train), y_train)\n",
    "\n",
    "#keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "c179b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RG+MDM\n",
      "0.7880849881960839\n",
      "0.7812326485285952\n",
      "0.7756907894736842\n",
      "RG+LDA\n",
      "0.8273850854048049\n",
      "0.7945585785674625\n",
      "0.8033552631578947\n",
      "RG+SVC\n",
      "0.977780863768921\n",
      "0.9711271515824542\n",
      "0.8185197368421052\n",
      "RG+TS+Reg\n",
      "0.8193306485210388\n",
      "0.8167684619655747\n",
      "0.7843421052631578\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"RG+MDM\")\n",
    "print(history.score(x_train,y_train))\n",
    "print(history.score(x_val,y_val))\n",
    "print(history.score(X_test,Y_test))\n",
    "\n",
    "print(\"RG+LDA\")\n",
    "print(history2.score(x_train,y_train))\n",
    "print(history2.score(x_val,y_val))\n",
    "print(history2.score(X_test,Y_test))\n",
    "\n",
    "print(\"RG+SVC\")\n",
    "print(history3.score(x_train,y_train))\n",
    "print(history3.score(x_val,y_val))\n",
    "print(history3.score(X_test,Y_test))\n",
    "\n",
    "print(\"RG+TS+Reg\")\n",
    "print(history4.score(x_train,y_train))\n",
    "print(history4.score(x_val,y_val))\n",
    "print(history4.score(X_test,Y_test))\n",
    "\n",
    "# print(history.predict(X_trainp)==y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b597e6e-6eb6-4314-bfcf-a4f405d6d0f1",
   "metadata": {},
   "source": [
    "### Model and accuracy and loss\n",
    "Just check that the model learnt something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c91070-aab2-451f-b011-4ad2eb23f0ca",
   "metadata": {},
   "source": [
    "filename = ''\n",
    "np.save(filename + \"std_from_calibration\", X_std)\n",
    "model_filename = os.path.join(os.getcwd(), filename + '0.7' + \"trainedmodel\")\n",
    "# Save the model if calibration was done\n",
    "clf.save(model_filename)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2ae4c-9865-42a3-bc95-45ad496308c4",
   "metadata": {},
   "source": [
    "## Vizualize learned filters\n",
    "### Raw vizualiation of 1D convolutinal kernel of the first layer --> spatial filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be1554-eb6d-4001-8c2d-a421db9a5841",
   "metadata": {},
   "source": [
    "### Viz of the corresponding topo maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ca7e0-dd11-40e9-90e6-f162e290aa06",
   "metadata": {},
   "source": [
    "### Predict on the test set\n",
    "The predictions are made on windows to regress the code.  \n",
    "Here we divide the prediction in 10 fold to avoid OOM from the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "17f599ad-7a5f-469d-9680-876e7438cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = clf2.predict(X_test)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aefccb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "cf375061",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "y_test_norm = np.array([0 if y == 0 else 1 for y in Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b72c1d1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 2093\n",
      "True negatives: 22329\n",
      "False positives: 2927\n",
      "False negatives: 3051\n",
      "Accuracy: 0.8033552631578947\n",
      "Sensitivity: 0.4068818040435459\n",
      "Precision: 0.41693227091633467\n",
      "Fowlkes-Mallows: 0.41187638261304893\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "import math\n",
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "print(\"True positives:\", tp)\n",
    "print(\"True negatives:\", tn)\n",
    "print(\"False positives:\", fp)\n",
    "print(\"False negatives:\", fn)\n",
    "print(\"Accuracy:\", (tp+tn)/len(y_test_norm))\n",
    "print(\"Sensitivity:\", sen:=tp/(tp+fn))\n",
    "print(\"Precision:\", pre:=tp/(tp+fp))\n",
    "print(\"Fowlkes-Mallows:\", math.sqrt(sen*pre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "92944dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30400,)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6b90c-103f-4762-8d56-c820dfbf9129",
   "metadata": {},
   "source": [
    "### Convert prediction on windows (regressed code) to label prediction\n",
    "\n",
    "It is offline and synchronous, so we will:\n",
    "1. First create a `code_buffer` that contains the regressed code on the full epoch (2.2s - the last window)\n",
    "    - The refresh rate of the EEG device (500 Hz) is faster than the refress rate of the screen (60Hz), so we average predictions (500/60~8 samples) so they correspond to each flip of the screen.\n",
    "2. Starting from `min_len` (in number of samples), we compute Pearson correalation with the bank of templates code to find the closest one\n",
    "    - If the most correlated code has a significantely bigger correlation compared to the second one (50% bigger) and the p_value is significative then the trial is classified and we move to the next one\n",
    "    - If the thresholds are not reached, then we add samples (with a step of 3) to have a longer trial and re-do the computation\n",
    "    - The thresholds can never been reached in 2.2s, then the trial is not classified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d7e07-f107-48dd-9530-0d58f533aafd",
   "metadata": {},
   "source": [
    "### Compute accuracy score and accuracy score when a prediction is made (discard not classified trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c000d2-8ad2-4fce-8519-3197a7397513",
   "metadata": {},
   "source": [
    "### Other classification method\n",
    "Same as before but the classification method is different. Instead of thresholds to reach, if when increasing trial lengt a code correllated the most 40 times in a row then the trial is labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4fd82787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'make_preds_accumul_aggresive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\s.velut\\Documents\\These\\Protheus_PHD\\Scripts\\single_subject_other_classif.ipynb Cell 59\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/single_subject_other_classif.ipynb#Y112sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m cons \u001b[39min\u001b[39;00m [\u001b[39m15\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m25\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m35\u001b[39m, \u001b[39m40\u001b[39m, \u001b[39m45\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m55\u001b[39m, \u001b[39m60\u001b[39m]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/single_subject_other_classif.ipynb#Y112sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(cons)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/single_subject_other_classif.ipynb#Y112sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     labels_pred_accumul, _, mean_long_accumul \u001b[39m=\u001b[39m make_preds_accumul_aggresive(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/single_subject_other_classif.ipynb#Y112sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         y_pred_norm, codes, min_len\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, sfreq\u001b[39m=\u001b[39msfreq, consecutive\u001b[39m=\u001b[39mcons, window_size\u001b[39m=\u001b[39mwindow_size\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/single_subject_other_classif.ipynb#Y112sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/single_subject_other_classif.ipynb#Y112sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(labels_pred_accumul[labels_pred_accumul \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/single_subject_other_classif.ipynb#Y112sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(y_pred_norm))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_preds_accumul_aggresive' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "acc_best_score=0\n",
    "acc_best_ratio=0\n",
    "acc_best_acc=0\n",
    "acc_best_value = 0\n",
    "# for minlen in np.linspace(10, 60, 10):\n",
    "for cons in [15, 20, 25, 30, 35, 40, 45, 50, 55, 60]:\n",
    "    print(cons)\n",
    "    labels_pred_accumul, _, mean_long_accumul = make_preds_accumul_aggresive(\n",
    "        y_pred_norm, codes, min_len=30, sfreq=sfreq, consecutive=cons, window_size=window_size\n",
    "    )\n",
    "    print(labels_pred_accumul[labels_pred_accumul != -1])\n",
    "    print(len(y_pred_norm))\n",
    "    ratio = np.round(len(labels_pred_accumul[labels_pred_accumul != -1])/len(labels_pred_accumul), 2)\n",
    "    accuracy = np.round(accuracy_score(labels_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    score = np.round(ratio*accuracy,2)\n",
    "    print(\"==========\", cons, ':', ratio, '--', accuracy,\n",
    "        '--', score, '--', np.mean(mean_long_accumul))\n",
    "    if accuracy > acc_best_acc:\n",
    "        acc_best_score = score\n",
    "        acc_best_value = cons\n",
    "        acc_best_acc = accuracy\n",
    "        acc_best_ratio = ratio\n",
    "\n",
    "print(\"Best accuracy\", acc_best_acc)\n",
    "print(\"Best ratio\", acc_best_ratio)\n",
    "print(\"Best score\", acc_best_score)\n",
    "print(\"Best values\", acc_best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ab636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_accumul, aaaaa, mean_long_accumul = make_preds_accumul_aggresive(\n",
    "        y_pred_norm, codes, min_len=30, sfreq=sfreq, consecutive=15, window_size=window_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f451353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(labels_pred_accumul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb4b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5269678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca169b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1433e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd80b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ac3a953833c090f146e4ba605ec310f853a691b325db82e974886e3abb928d6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
