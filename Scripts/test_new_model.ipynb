{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\moabb\\pipelines\\__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from EEG2CodeKeras import (basearchi,\n",
    "                           basearchitest_batchnorm,\n",
    "                           basearchi_patchembedding,\n",
    "                           basearchi_patchembeddingdilation,\n",
    "                           trueVanilliaEEG2Code,\n",
    "                           vanilliaEEG2Code,\n",
    "                           vanilliaEEG2Code2,\n",
    "                           EEGnet_Inception)\n",
    "from _utils import make_preds_accumul_aggresive, make_preds_pvalue\n",
    "\n",
    "from utils import prepare_data, get_BVEP_data, balance\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import balanced_accuracy_score,confusion_matrix\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import keras\n",
    "\n",
    "\n",
    "from pyriemann.estimation import XdawnCovariances, Xdawn\n",
    "from sklearn.manifold import TSNE\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.utils.distance import distance_riemann, distance\n",
    "from pyriemann.utils.utils import check_weights\n",
    "from pyriemann.utils.base import powm\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from mne.decoding import Vectorizer\n",
    "from pyriemann.transfer import (\n",
    "    decode_domains,\n",
    "    encode_domains,\n",
    "    TLCenter,\n",
    "    TLStretch,\n",
    "    TLRotate,\n",
    ")\n",
    "\n",
    "from tensorflow import keras\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "import mne\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s.velut\\Documents\\These\\Protheus_PHD\\Scripts\\DNorm_CLF\\DNorm_SPD\\optimizer\\riemannian_adam.py:128: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_compile is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n"
     ]
    }
   ],
   "source": [
    "from moabb.paradigms import CVEP\n",
    "from SPDNet.tensorflow.spd_net_2_tensorflow import SPDNet_AJD\n",
    "from SPDNet.tensorflow.spd_net_tensorflow import SPDNet_Tensorflow\n",
    "# from SPDNet.tensorflow.optimizer import riemannian_adam\n",
    "from SPDNet.torch.optimizers import riemannian_adam as torch_riemannian_adam\n",
    "from SPDNet.torch.spd_net_bn_torch import SPDNetBN_Torch, SPDNetBN_Module,CNNSPDNetBN_Module\n",
    "from DNorm_CLF.DNorm_SPD.DNorm_SPD import BNSPD_Net\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "sys.path.insert(0,\"C:\\\\Users\\\\s.velut\\\\Documents\\\\These\\\\moabb\\\\moabb\\\\datasets\")\n",
    "sys.path.insert(0,\"C:\\\\Users\\\\s.velut\\\\Documents\\\\These\\\\moabb\\\\moabb\\\\paradigms\")\n",
    "sys.path.insert(0,\"C:\\\\Users\\\\s.velut\\\\Documents\\\\These\\\\Protheus_PHD\\\\Scripts\\\\SPDNet\")\n",
    "sys.path.insert(0,\"C:\\\\Users\\\\s.velut\\\\Documents\\\\These\\\\riemannian_tSNE\")\n",
    "from R_TSNE import R_TSNE\n",
    "from castillos2023 import CasitllosCVEP100,CasitllosCVEP40,CasitllosBurstVEP100,CasitllosBurstVEP40\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=0.25\n",
    "n_class=4\n",
    "sfreq = 500\n",
    "fps = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n"
     ]
    }
   ],
   "source": [
    "subjects = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "# subjects = [1,2,3]\n",
    "n_channels = 32\n",
    "on_frame = False\n",
    "tospd = False\n",
    "recenter = True\n",
    "normalise = False\n",
    "if on_frame:\n",
    "    freq = fps\n",
    "else:\n",
    "    freq = sfreq\n",
    "\n",
    "raw_data,labels,codes,labels_codes = get_BVEP_data(subjects,on_frame)\n",
    "X_parent,Y_parent,domains_parent = prepare_data(subjects,raw_data,labels,on_frame,tospd,recenter,codes=codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6944585834729912\n",
      "Epoch 2, Loss: 0.5538793123006814\n",
      "Epoch 3, Loss: 0.4291010735444135\n",
      "Epoch 4, Loss: 0.35639989878538864\n",
      "Epoch 5, Loss: 0.31818655786797156\n",
      "Epoch 6, Loss: 0.2979181310311357\n",
      "Epoch 7, Loss: 0.277120313782002\n",
      "Epoch 8, Loss: 0.2668423019211832\n",
      "Epoch 9, Loss: 0.2549846105058366\n",
      "Epoch 10, Loss: 0.24095147769406752\n",
      "Epoch 11, Loss: 0.2326553807756013\n",
      "Epoch 12, Loss: 0.22620270569760453\n",
      "Epoch 13, Loss: 0.21972339399086088\n",
      "Epoch 14, Loss: 0.21952193174158685\n",
      "Epoch 15, Loss: 0.21610366727937289\n",
      "Epoch 16, Loss: 0.2024741565439152\n",
      "Epoch 17, Loss: 0.20901847885702446\n",
      "Epoch 18, Loss: 0.19118114578634288\n",
      "Epoch 19, Loss: 0.19096887021093514\n",
      "Epoch 20, Loss: 0.19683055049177375\n",
      "Training finished!\n",
      "Validation Accuracy: 0.9236740210403273\n",
      "Test Accuracy: 0.8225257019994665\n",
      "getting accuracy of participant  0\n",
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:277: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "TL to the participant :  1\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7053466121644038\n",
      "Epoch 2, Loss: 0.569629180684965\n",
      "Epoch 3, Loss: 0.4996024740718688\n",
      "Epoch 4, Loss: 0.44662166881592286\n",
      "Epoch 5, Loss: 0.4113372326379351\n",
      "Epoch 6, Loss: 0.38329968668597697\n",
      "Epoch 7, Loss: 0.36569728624843106\n",
      "Epoch 8, Loss: 0.3467595614960599\n",
      "Epoch 9, Loss: 0.34218282563199437\n",
      "Epoch 10, Loss: 0.32396380360650584\n",
      "Epoch 11, Loss: 0.3131950656556799\n",
      "Epoch 12, Loss: 0.31610235760252503\n",
      "Epoch 13, Loss: 0.29960281725587035\n",
      "Epoch 14, Loss: 0.30463305608740116\n",
      "Epoch 15, Loss: 0.2935693343716462\n",
      "Epoch 16, Loss: 0.29070969610583136\n",
      "Epoch 17, Loss: 0.294869719419857\n",
      "Epoch 18, Loss: 0.2794969149571946\n",
      "Epoch 19, Loss: 0.2732529854310174\n",
      "Epoch 20, Loss: 0.2739236008591929\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8572915715459776\n",
      "Test Accuracy: 0.6329756560517579\n",
      "getting accuracy of participant  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  2\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6089175089580071\n",
      "Epoch 2, Loss: 0.40532228520371383\n",
      "Epoch 3, Loss: 0.33366999959739896\n",
      "Epoch 4, Loss: 0.3028602772043272\n",
      "Epoch 5, Loss: 0.28264925289253684\n",
      "Epoch 6, Loss: 0.2644562651968652\n",
      "Epoch 7, Loss: 0.25492864772315604\n",
      "Epoch 8, Loss: 0.2457273748200802\n",
      "Epoch 9, Loss: 0.2392385746082766\n",
      "Epoch 10, Loss: 0.23726030278736057\n",
      "Epoch 11, Loss: 0.226144069289147\n",
      "Epoch 12, Loss: 0.2221934774891392\n",
      "Epoch 13, Loss: 0.2208465063164683\n",
      "Epoch 14, Loss: 0.2123982309048172\n",
      "Epoch 15, Loss: 0.21529391809145876\n",
      "Epoch 16, Loss: 0.2088198176569065\n",
      "Epoch 17, Loss: 0.20835771683859108\n",
      "Epoch 18, Loss: 0.20391879441323518\n",
      "Epoch 19, Loss: 0.20131233226748427\n",
      "Epoch 20, Loss: 0.19165491821565006\n",
      "Training finished!\n",
      "Validation Accuracy: 0.9329609449279602\n",
      "Test Accuracy: 0.8088148038699828\n",
      "getting accuracy of participant  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  3\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6387841367938223\n",
      "Epoch 2, Loss: 0.4986293820271304\n",
      "Epoch 3, Loss: 0.4176959047531361\n",
      "Epoch 4, Loss: 0.3677853627625593\n",
      "Epoch 5, Loss: 0.33602066822302906\n",
      "Epoch 6, Loss: 0.3138773883975892\n",
      "Epoch 7, Loss: 0.293397057568426\n",
      "Epoch 8, Loss: 0.2869163280829963\n",
      "Epoch 9, Loss: 0.265244901502658\n",
      "Epoch 10, Loss: 0.25920052826156814\n",
      "Epoch 11, Loss: 0.25690051368139827\n",
      "Epoch 12, Loss: 0.23648418452797934\n",
      "Epoch 13, Loss: 0.23358811821060335\n",
      "Epoch 14, Loss: 0.22651925583999202\n",
      "Epoch 15, Loss: 0.22815976908480923\n",
      "Epoch 16, Loss: 0.21046135010391814\n",
      "Epoch 17, Loss: 0.20905428431570455\n",
      "Epoch 18, Loss: 0.2166762476149154\n",
      "Epoch 19, Loss: 0.20687310845027718\n",
      "Epoch 20, Loss: 0.2023017041532847\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8677083333333333\n",
      "Test Accuracy: 0.7434163232940061\n",
      "getting accuracy of participant  3\n",
      "TL to the participant :  4\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6587709659551041\n",
      "Epoch 2, Loss: 0.5187182282557415\n",
      "Epoch 3, Loss: 0.39378288423185054\n",
      "Epoch 4, Loss: 0.3140967597458111\n",
      "Epoch 5, Loss: 0.27068522431577485\n",
      "Epoch 6, Loss: 0.24601708944369388\n",
      "Epoch 7, Loss: 0.22688527677757725\n",
      "Epoch 8, Loss: 0.2151982772396756\n",
      "Epoch 9, Loss: 0.2135807524713489\n",
      "Epoch 10, Loss: 0.19564849481870086\n",
      "Epoch 11, Loss: 0.18761178249685204\n",
      "Epoch 12, Loss: 0.18926718831260475\n",
      "Epoch 13, Loss: 0.17524304767465385\n",
      "Epoch 14, Loss: 0.17792338935680843\n",
      "Epoch 15, Loss: 0.16703891752798644\n",
      "Epoch 16, Loss: 0.16728703196793088\n",
      "Epoch 17, Loss: 0.16224560740811056\n",
      "Epoch 18, Loss: 0.15593201881079466\n",
      "Epoch 19, Loss: 0.16454581547508637\n",
      "Epoch 20, Loss: 0.16051358218107278\n",
      "Training finished!\n",
      "Validation Accuracy: 0.9551282051282051\n",
      "Test Accuracy: 0.8125097268334618\n",
      "getting accuracy of participant  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  5\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7143024300565736\n",
      "Epoch 2, Loss: 0.6439851578403999\n",
      "Epoch 3, Loss: 0.5973106816838986\n",
      "Epoch 4, Loss: 0.5582810553502852\n",
      "Epoch 5, Loss: 0.5156728739697951\n",
      "Epoch 6, Loss: 0.481730128965034\n",
      "Epoch 7, Loss: 0.460086785196504\n",
      "Epoch 8, Loss: 0.43243027615057017\n",
      "Epoch 9, Loss: 0.41664127709276716\n",
      "Epoch 10, Loss: 0.411861476190676\n",
      "Epoch 11, Loss: 0.40520119813250427\n",
      "Epoch 12, Loss: 0.3872365579516413\n",
      "Epoch 13, Loss: 0.3783460864992094\n",
      "Epoch 14, Loss: 0.3698342621408192\n",
      "Epoch 15, Loss: 0.3671555073336065\n",
      "Epoch 16, Loss: 0.3617675722386224\n",
      "Epoch 17, Loss: 0.34814806796615794\n",
      "Epoch 18, Loss: 0.3408165960917443\n",
      "Epoch 19, Loss: 0.33601722817997437\n",
      "Epoch 20, Loss: 0.33830852620824625\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8453393603177864\n",
      "Test Accuracy: 0.5724467293754076\n",
      "getting accuracy of participant  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  6\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6522476598578004\n",
      "Epoch 2, Loss: 0.4755119483627702\n",
      "Epoch 3, Loss: 0.3587372824545708\n",
      "Epoch 4, Loss: 0.297693321061047\n",
      "Epoch 5, Loss: 0.26246268638929204\n",
      "Epoch 6, Loss: 0.24271734841654694\n",
      "Epoch 7, Loss: 0.22115377406763448\n",
      "Epoch 8, Loss: 0.21149258591802345\n",
      "Epoch 9, Loss: 0.21041101196720022\n",
      "Epoch 10, Loss: 0.19464598383400186\n",
      "Epoch 11, Loss: 0.18615249939593698\n",
      "Epoch 12, Loss: 0.18675313059515097\n",
      "Epoch 13, Loss: 0.17735481112940396\n",
      "Epoch 14, Loss: 0.18270591824241542\n",
      "Epoch 15, Loss: 0.1703293914844542\n",
      "Epoch 16, Loss: 0.1668283682427504\n",
      "Epoch 17, Loss: 0.16638093090975836\n",
      "Epoch 18, Loss: 0.16597517482950358\n",
      "Epoch 19, Loss: 0.16305182049595873\n",
      "Epoch 20, Loss: 0.15555419209965057\n",
      "Training finished!\n",
      "Validation Accuracy: 0.9598810546125596\n",
      "Test Accuracy: 0.7637731961818937\n",
      "getting accuracy of participant  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  7\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6558465084941975\n",
      "Epoch 2, Loss: 0.49122979921936755\n",
      "Epoch 3, Loss: 0.37172540324016545\n",
      "Epoch 4, Loss: 0.29593381155622145\n",
      "Epoch 5, Loss: 0.256321954908761\n",
      "Epoch 6, Loss: 0.23226105000635547\n",
      "Epoch 7, Loss: 0.21912009422165127\n",
      "Epoch 8, Loss: 0.2070649889897685\n",
      "Epoch 9, Loss: 0.20137462895762173\n",
      "Epoch 10, Loss: 0.1851124343991244\n",
      "Epoch 11, Loss: 0.18402342994041318\n",
      "Epoch 12, Loss: 0.17545141912820744\n",
      "Epoch 13, Loss: 0.1707611516792191\n",
      "Epoch 14, Loss: 0.16800904133423814\n",
      "Epoch 15, Loss: 0.16365729826522707\n",
      "Epoch 16, Loss: 0.16158167482466065\n",
      "Epoch 17, Loss: 0.15490858866108367\n",
      "Epoch 18, Loss: 0.1610291502962304\n",
      "Epoch 19, Loss: 0.1536070464907282\n",
      "Epoch 20, Loss: 0.14976355149241916\n",
      "Training finished!\n",
      "Validation Accuracy: 0.9438908551204476\n",
      "Test Accuracy: 0.8684548832409438\n",
      "getting accuracy of participant  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  8\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.686091600393944\n",
      "Epoch 2, Loss: 0.6095383973909609\n",
      "Epoch 3, Loss: 0.5315235120245024\n",
      "Epoch 4, Loss: 0.4784147548449771\n",
      "Epoch 5, Loss: 0.44093059249035554\n",
      "Epoch 6, Loss: 0.4108569510197191\n",
      "Epoch 7, Loss: 0.39948849639989986\n",
      "Epoch 8, Loss: 0.388276860247337\n",
      "Epoch 9, Loss: 0.3812336554993763\n",
      "Epoch 10, Loss: 0.34823199172285435\n",
      "Epoch 11, Loss: 0.3447057662617531\n",
      "Epoch 12, Loss: 0.33655680198193594\n",
      "Epoch 13, Loss: 0.3254195201513525\n",
      "Epoch 14, Loss: 0.3231670288518646\n",
      "Epoch 15, Loss: 0.32913705698460705\n",
      "Epoch 16, Loss: 0.318533251900905\n",
      "Epoch 17, Loss: 0.31485218812291954\n",
      "Epoch 18, Loss: 0.3116477575689802\n",
      "Epoch 19, Loss: 0.31179510551687095\n",
      "Epoch 20, Loss: 0.29944238559536734\n",
      "Training finished!\n",
      "Validation Accuracy: 0.9277695277695278\n",
      "Test Accuracy: 0.6610264542079207\n",
      "getting accuracy of participant  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  9\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.4755443377614996\n",
      "Epoch 2, Loss: 0.23896264601007958\n",
      "Epoch 3, Loss: 0.17894376774903886\n",
      "Epoch 4, Loss: 0.14666856194228448\n",
      "Epoch 5, Loss: 0.1299241162150527\n",
      "Epoch 6, Loss: 0.12024325813908902\n",
      "Epoch 7, Loss: 0.11076336739179644\n",
      "Epoch 8, Loss: 0.10355339091992877\n",
      "Epoch 9, Loss: 0.09565281163319313\n",
      "Epoch 10, Loss: 0.08918611420835314\n",
      "Epoch 11, Loss: 0.09117001838952837\n",
      "Epoch 12, Loss: 0.08363024666469683\n",
      "Epoch 13, Loss: 0.0863496537779668\n",
      "Epoch 14, Loss: 0.08233874957994113\n",
      "Epoch 15, Loss: 0.07610422070448952\n",
      "Epoch 16, Loss: 0.07776269514310578\n",
      "Epoch 17, Loss: 0.08258037855050442\n",
      "Epoch 18, Loss: 0.0779208525217385\n",
      "Epoch 19, Loss: 0.07741501022307638\n",
      "Epoch 20, Loss: 0.07389803608285202\n",
      "Training finished!\n",
      "Validation Accuracy: 0.9818032809339658\n",
      "Test Accuracy: 0.9572688626459951\n",
      "getting accuracy of participant  9\n",
      "TL to the participant :  10\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6527422824862542\n",
      "Epoch 2, Loss: 0.5276674208920774\n",
      "Epoch 3, Loss: 0.43840596707365953\n",
      "Epoch 4, Loss: 0.37428407546238707\n",
      "Epoch 5, Loss: 0.34181916291840614\n",
      "Epoch 6, Loss: 0.3091899464739906\n",
      "Epoch 7, Loss: 0.28428418786280485\n",
      "Epoch 8, Loss: 0.2645427187312977\n",
      "Epoch 9, Loss: 0.25713709212731795\n",
      "Epoch 10, Loss: 0.24111043836816853\n",
      "Epoch 11, Loss: 0.24134747148516023\n",
      "Epoch 12, Loss: 0.22879027312515735\n",
      "Epoch 13, Loss: 0.2262930550875195\n",
      "Epoch 14, Loss: 0.21464210975107262\n",
      "Epoch 15, Loss: 0.21382763584583678\n",
      "Epoch 16, Loss: 0.20519143420250985\n",
      "Epoch 17, Loss: 0.20410498881721947\n",
      "Epoch 18, Loss: 0.19670062444966904\n",
      "Epoch 19, Loss: 0.2018836192136586\n",
      "Epoch 20, Loss: 0.19763028087244927\n",
      "Training finished!\n",
      "Validation Accuracy: 0.9508547008547008\n",
      "Test Accuracy: 0.7330992794732317\n",
      "getting accuracy of participant  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  11\n",
      "(27300, 32, 125)\n",
      "(31200, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6988589993596271\n",
      "Epoch 2, Loss: 0.6316084550181587\n",
      "Epoch 3, Loss: 0.5676488655577747\n",
      "Epoch 4, Loss: 0.5178162628427988\n",
      "Epoch 5, Loss: 0.4723283810763644\n",
      "Epoch 6, Loss: 0.4444703937010373\n",
      "Epoch 7, Loss: 0.4204618234359164\n",
      "Epoch 8, Loss: 0.4007349701106623\n",
      "Epoch 9, Loss: 0.39097634345085813\n",
      "Epoch 10, Loss: 0.37553006662433996\n",
      "Epoch 11, Loss: 0.3559364430087989\n",
      "Epoch 12, Loss: 0.34972863752088507\n",
      "Epoch 13, Loss: 0.32834511773004044\n",
      "Epoch 14, Loss: 0.3240028661197094\n",
      "Epoch 15, Loss: 0.3167406407839553\n",
      "Epoch 16, Loss: 0.31306491096586736\n",
      "Epoch 17, Loss: 0.30993571644063683\n",
      "Epoch 18, Loss: 0.3074419455129964\n",
      "Epoch 19, Loss: 0.3008260238105924\n",
      "Epoch 20, Loss: 0.2966516059031771\n",
      "Training finished!\n",
      "Validation Accuracy: 0.9086363947674817\n",
      "Test Accuracy: 0.638233009537855\n",
      "getting accuracy of participant  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8225257  0.63297566 0.8088148  0.74341632 0.81250973 0.57244673\n",
      " 0.7637732  0.86845488 0.66102645 0.95726886 0.73309928 0.63823301]\n",
      "[183.87130761 183.95863271 184.72878742 135.65179062 122.35824776\n",
      " 124.8109901  162.6724081  129.6378696  225.1806252  250.03609228\n",
      " 221.30211592 240.05810714]\n",
      "[17.17922807 17.14903259 16.96914411 10.0809536  10.59220839 10.04147959\n",
      " 17.01987076 10.97256446 26.2461462  19.94112277 20.36900353 25.13798428]\n",
      "[0.94 0.75 0.97 0.91 1.   0.59 0.91 0.94 0.72 1.   0.91 0.72]\n"
     ]
    }
   ],
   "source": [
    "n_cal = 7\n",
    "n_class = 4\n",
    "nb_fold = 1\n",
    "spdbn_accuracy_code_perso = np.zeros((nb_fold,12))\n",
    "spdbn_tps_train_code_perso = np.zeros((nb_fold,12))\n",
    "spdbn_tps_test_code_perso = np.zeros((nb_fold,12))\n",
    "spdbn_accuracy_perso = np.zeros((nb_fold,12))\n",
    "\n",
    "for k in range(nb_fold):\n",
    "    for i in range(12):\n",
    "        print(\"TL to the participant : \", i)\n",
    "        X = X_parent.copy()\n",
    "        Y = Y_parent.copy()\n",
    "        domains = domains_parent.copy()\n",
    "        nb_sample_cal = int(n_class*n_cal*(2.2-window_size)*freq)\n",
    "\n",
    "        X_train = X[i][:nb_sample_cal]\n",
    "        Y_train = Y[i][:nb_sample_cal]\n",
    "        X_test = X[i][nb_sample_cal:]\n",
    "        Y_test = Y[i][nb_sample_cal:]\n",
    "        labels_code_test = labels_codes[i][(n_class*n_cal):]\n",
    "\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        # X_std = X_train.std(axis=0)\n",
    "        # X_train /= X_std + 1e-8\n",
    "        # X_std = X_test.std(axis=0)\n",
    "        # X_test /= X_std + 1e-8\n",
    "\n",
    "        print(\"balancing the number of ones and zeros\")\n",
    "        X_train, Y_train, domains_train = balance(X_train,Y_train,domains[i][:nb_sample_cal])\n",
    "\n",
    "        print(\"Creating the different pipelines\")\n",
    "        clf = CNNSPDNetBN_Module(32,0.25)\n",
    "\n",
    "        print(\"Fitting\")\n",
    "        start = time.time()\n",
    "        weight_decay = 1e-4\n",
    "        \n",
    "        x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "        # Convert data into PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(x_train, dtype=torch.float64)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "        X_val_tensor = torch.tensor(x_val, dtype=torch.float64)\n",
    "        y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float64)\n",
    "        y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "        # Create DataLoader for train, validation, and test sets\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = torch.nn.CrossEntropyLoss().float()\n",
    "        optimizer = torch_riemannian_adam.RiemannianAdam(clf.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        num_epochs = 20\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_dataloader:\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = clf(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_dataloader)}\")\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "        spdbn_tps_train_code_perso[k][i] = time.time() - start\n",
    "\n",
    "        # Validation\n",
    "        clf.eval()\n",
    "        val_correct = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                outputs = clf(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_pred.append(np.array(predicted))\n",
    "                y_true.append(np.array(labels)) \n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = balanced_accuracy_score(np.concatenate(y_true),np.concatenate(y_pred))\n",
    "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "        # Testing\n",
    "        start = time.time()\n",
    "        test_correct = 0\n",
    "        y_pred= []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                outputs = clf(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_pred.append(np.array(predicted))\n",
    "                y_true.append(np.array(labels)) \n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        test_accuracy = balanced_accuracy_score(np.concatenate(y_true),np.concatenate(y_pred))\n",
    "        print(f\"Test Accuracy: {test_accuracy}\")\n",
    "        \n",
    "        print(\"getting accuracy of participant \", i)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "        y_test_norm = np.array([0 if y == 0 else 1 for y in np.concatenate(y_true)])\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "        spdbn_accuracy_perso[k][i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "        labels_pred_accumul, _, mean_long_accumul = make_preds_accumul_aggresive(\n",
    "            y_pred_norm, codes, min_len=30, sfreq=freq, consecutive=50, window_size=window_size\n",
    "        )\n",
    "        spdbn_tps_test_code_perso[k][i] = time.time() - start\n",
    "        spdbn_accuracy_code_perso[k][i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "spdbn_accuracy_perso = np.mean(spdbn_accuracy_perso,axis=0)\n",
    "spdbn_tps_train_code_perso = np.mean(spdbn_tps_train_code_perso,axis=0)\n",
    "spdbn_tps_test_code_perso = np.mean(spdbn_tps_test_code_perso,axis=0)\n",
    "spdbn_accuracy_code_perso = np.mean(spdbn_accuracy_code_perso,axis=0)\n",
    "\n",
    "print(spdbn_accuracy_perso)\n",
    "print(spdbn_tps_train_code_perso)\n",
    "print(spdbn_tps_test_code_perso)\n",
    "print(spdbn_accuracy_code_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/CNNSPD/score/WO_score\",spdbn_accuracy_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/CNNSPD/score_code/WO_score_code\",spdbn_tps_train_code_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/CNNSPD/temps_code/WO_tps_train_code\",spdbn_tps_test_code_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/CNNSPD/temps_code/WO_tps_test_code\",spdbn_accuracy_code_perso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOO the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(643500, 32, 125)\n",
      "(58500, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5277659098280294\n",
      "Epoch 2, Loss: 0.4841184514596053\n",
      "Epoch 3, Loss: 0.47832595402633277\n",
      "Epoch 4, Loss: 0.47431327800346434\n",
      "Epoch 5, Loss: 0.47307354526412176\n",
      "Epoch 6, Loss: 0.46983986987853216\n",
      "Epoch 7, Loss: 0.469540729996048\n",
      "Epoch 8, Loss: 0.467504229511115\n",
      "Epoch 9, Loss: 0.466709942542084\n",
      "Epoch 10, Loss: 0.46533458289430524\n",
      "Epoch 11, Loss: 0.4654226899812408\n",
      "Epoch 12, Loss: 0.4646671213304908\n",
      "Epoch 13, Loss: 0.46413536576486686\n",
      "Epoch 14, Loss: 0.4640318215520198\n",
      "Epoch 15, Loss: 0.46360225276941125\n",
      "Epoch 16, Loss: 0.463363304505864\n",
      "Epoch 17, Loss: 0.4618279601328525\n",
      "Epoch 18, Loss: 0.46237815643406865\n",
      "Epoch 19, Loss: 0.4618663814736231\n",
      "Epoch 20, Loss: 0.4623452462479358\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8076190407044691\n",
      "Test Accuracy: 0.8263275429339341\n",
      "getting accuracy of participant  0\n",
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:277: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "TL to the participant :  1\n",
      "(643500, 32, 125)\n",
      "(58500, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.513253789746171\n",
      "Epoch 2, Loss: 0.4728649203665809\n",
      "Epoch 3, Loss: 0.4657882227568898\n",
      "Epoch 4, Loss: 0.462134321689101\n",
      "Epoch 5, Loss: 0.4597709352308286\n",
      "Epoch 6, Loss: 0.4578779061722081\n",
      "Epoch 7, Loss: 0.45604842306390375\n",
      "Epoch 8, Loss: 0.4553864021557888\n",
      "Epoch 9, Loss: 0.4545465334552933\n",
      "Epoch 10, Loss: 0.4533265323164503\n",
      "Epoch 11, Loss: 0.4531286495658521\n",
      "Epoch 12, Loss: 0.45181513595907546\n",
      "Epoch 13, Loss: 0.45210765759939736\n",
      "Epoch 14, Loss: 0.45026820642324095\n",
      "Epoch 15, Loss: 0.4505847792871611\n",
      "Epoch 16, Loss: 0.4497398875819785\n",
      "Epoch 17, Loss: 0.44951026408774286\n",
      "Epoch 18, Loss: 0.4479078587732351\n",
      "Epoch 19, Loss: 0.4495728930154951\n",
      "Epoch 20, Loss: 0.44797585173285837\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8147060485502573\n",
      "Test Accuracy: 0.7274783971660639\n",
      "getting accuracy of participant  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  2\n",
      "(643500, 32, 125)\n",
      "(58500, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5203625199106414\n",
      "Epoch 2, Loss: 0.48177368665286074\n",
      "Epoch 3, Loss: 0.4749256106405472\n",
      "Epoch 4, Loss: 0.47272641160351186\n",
      "Epoch 5, Loss: 0.47011318851483624\n",
      "Epoch 6, Loss: 0.4685026138482137\n",
      "Epoch 7, Loss: 0.46778867794458856\n",
      "Epoch 8, Loss: 0.4657345656287458\n",
      "Epoch 9, Loss: 0.4652122970461063\n"
     ]
    }
   ],
   "source": [
    "n_cal = 7\n",
    "n_class = 4\n",
    "nb_fold = 1\n",
    "spdbn_accuracy_code_perso = np.zeros((nb_fold,12))\n",
    "spdbn_tps_train_code_perso = np.zeros((nb_fold,12))\n",
    "spdbn_tps_test_code_perso = np.zeros((nb_fold,12))\n",
    "spdbn_accuracy_perso = np.zeros((nb_fold,12))\n",
    "\n",
    "for k in range(nb_fold):\n",
    "    for i in range(12):\n",
    "        print(\"TL to the participant : \", i)\n",
    "        ind2take = [j for j in range(12) if j!=i]\n",
    "        X = X_parent.copy()\n",
    "        Y = Y_parent.copy()\n",
    "        domains = domains_parent.copy()\n",
    "        \n",
    "        X_train = np.concatenate(X[ind2take]).reshape(-1,X.shape[-2],X.shape[-1])\n",
    "        Y_train = np.concatenate(Y[ind2take]).reshape(-1)\n",
    "        domains_train = domains[ind2take].reshape(-1)\n",
    "        X_test = X[i]\n",
    "        Y_test = Y[i]\n",
    "        labels_code_test = labels_codes[i]\n",
    "\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        # X_std = X_train.std(axis=0)\n",
    "        # X_train /= X_std + 1e-8\n",
    "        # X_std = X_test.std(axis=0)\n",
    "        # X_test /= X_std + 1e-8\n",
    "\n",
    "        print(\"balancing the number of ones and zeros\")\n",
    "        X_train, Y_train, domains_train = balance(X_train,Y_train,domains_train)\n",
    "\n",
    "        print(\"Creating the different pipelines\")\n",
    "        clf = CNNSPDNetBN_Module(32,0.25)\n",
    "\n",
    "        print(\"Fitting\")\n",
    "        start = time.time()\n",
    "        weight_decay = 1e-4\n",
    "        \n",
    "        x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "        # Convert data into PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(x_train, dtype=torch.float64)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "        X_val_tensor = torch.tensor(x_val, dtype=torch.float64)\n",
    "        y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float64)\n",
    "        y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "        # Create DataLoader for train, validation, and test sets\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = torch.nn.CrossEntropyLoss().float()\n",
    "        optimizer = torch_riemannian_adam.RiemannianAdam(clf.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        num_epochs = 20\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_dataloader:\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = clf(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_dataloader)}\")\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "        spdbn_tps_train_code_perso[k][i] = time.time() - start\n",
    "\n",
    "        # Validation\n",
    "        clf.eval()\n",
    "        val_correct = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                outputs = clf(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_pred.append(np.array(predicted))\n",
    "                y_true.append(np.array(labels)) \n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = balanced_accuracy_score(np.concatenate(y_true),np.concatenate(y_pred))\n",
    "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "        # Testing\n",
    "        start = time.time()\n",
    "        test_correct = 0\n",
    "        y_pred= []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                outputs = clf(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_pred.append(np.array(predicted))\n",
    "                y_true.append(np.array(labels)) \n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        test_accuracy = balanced_accuracy_score(np.concatenate(y_true),np.concatenate(y_pred))\n",
    "        print(f\"Test Accuracy: {test_accuracy}\")\n",
    "        \n",
    "        print(\"getting accuracy of participant \", i)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "        y_test_norm = np.array([0 if y == 0 else 1 for y in np.concatenate(y_true)])\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "        spdbn_accuracy_perso[k][i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "        labels_pred_accumul, _, mean_long_accumul = make_preds_accumul_aggresive(\n",
    "            y_pred_norm, codes, min_len=30, sfreq=freq, consecutive=50, window_size=window_size\n",
    "        )\n",
    "        spdbn_tps_test_code_perso[k][i] = time.time() - start\n",
    "        spdbn_accuracy_code_perso[k][i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "spdbn_accuracy_perso = np.mean(spdbn_accuracy_perso,axis=0)\n",
    "spdbn_tps_train_code_perso = np.mean(spdbn_tps_train_code_perso,axis=0)\n",
    "spdbn_tps_test_code_perso = np.mean(spdbn_tps_test_code_perso,axis=0)\n",
    "spdbn_accuracy_code_perso = np.mean(spdbn_accuracy_code_perso,axis=0)\n",
    "\n",
    "print(spdbn_accuracy_perso)\n",
    "print(spdbn_tps_train_code_perso)\n",
    "print(spdbn_tps_test_code_perso)\n",
    "print(spdbn_accuracy_code_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/CNNSPD/score/LOO_score\",spdbn_accuracy_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/CNNSPD/score_code/LOO_score_code\",spdbn_tps_train_code_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/CNNSPD/temps_code/LOO_tps_train_code\",spdbn_tps_test_code_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/CNNSPD/temps_code/LOO_tps_test_code\",spdbn_accuracy_code_perso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
