{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6de10f24-829d-4847-b79b-7d4d282eb5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\moabb\\pipelines\\__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from EEG2CodeKeras import (basearchi,\n",
    "                           basearchitest_batchnorm,\n",
    "                           basearchi_patchembedding,\n",
    "                           basearchi_patchembeddingdilation,\n",
    "                           trueVanilliaEEG2Code,\n",
    "                           vanilliaEEG2Code,\n",
    "                           vanilliaEEG2Code2,\n",
    "                           EEGnet_Inception)\n",
    "from _utils import make_preds_accumul_aggresive, make_preds_pvalue\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from pyriemann.estimation import XdawnCovariances, Xdawn\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from tensorflow import keras\n",
    "import mne\n",
    "from mne.decoding import Vectorizer\n",
    "from mne.decoding import CSP\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from utils import balance\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from SPDNet.torch.spd_net_bn_torch import SPDNetBN_Module\n",
    "from SPDNet.torch.optimizers import riemannian_adam as torch_riemannian_adam\n",
    "\n",
    "from Alignments.riemannian import compute_riemannian_alignment\n",
    "from utils import Euc2SPD\n",
    "from SPDNet.tensorflow.spd_net_tensorflow import SPDNet_Tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cbff77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "575c7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 60\n",
    "sfreq = 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e15184-3fcf-463d-89b7-97e4e6db7a95",
   "metadata": {},
   "source": [
    "## Path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c5a06b-e9fd-42d7-bf0c-83d8d68b707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = ['P1','P2','P3','P4','P5','P6','P7','P8','P9','P10',\n",
    "                'P11','P12','P13','P14','P15','P16','P17','P18','P19','P20',\n",
    "                'P21','P22','P23','P24']\n",
    "path = 'C:\\\\Users\\\\s.velut\\\\Documents\\\\These\\\\Protheus_PHD\\\\Data\\\\Dry_Ricker'\n",
    "# path = '/home/dcas/k.cabrera/Data/SETNOP2'\n",
    "n_class=5\n",
    "window_size = 0.25\n",
    "\n",
    "\n",
    "\n",
    "# file_name = '_'.join([participant, 'mseq40.set'])\n",
    "# file_name = '_'.join([participant, 'mseq100.set'])\n",
    "# file_name = '_'.join([participant, 'burst40.set'])\n",
    "# file_name = '_'.join([participant, 'dryburst100.set'])\n",
    "# file_name = '/'.join([path,  participant+'_whitemseq.set'])\n",
    "# file_name = '_'.join([participant, 'burst', 'oi_1.set'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ede9c-040e-4590-94b2-577a62a9b026",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the raw data and small pre-process\n",
    "1. Drop the ACC channels and the shitty channels near ears\n",
    "2. Average re-referencing\n",
    "4. Extract 2.2s epochs using events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib Qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8df747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 500.0, returning unmodified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_9712\\4146463880.py:2: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n"
     ]
    }
   ],
   "source": [
    "sfreq = 500\n",
    "raw_eeglab = [mne.io.read_raw_eeglab(os.path.join(path, '_'.join([participants[i], 'dryburst100.set'])), preload=True, verbose=False).resample(sfreq=sfreq)\n",
    "               for i in range(len(participants))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e02a0323-b237-4b92-b5ed-ded4930f3cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Channels : ['EEG 000', 'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007']\n"
     ]
    }
   ],
   "source": [
    "# to_drop = [\"P9\", \"P10\", \"TP9\", \"TP10\", \"10\", \"21\"]\n",
    "# keep = [\"O1\", \"O2\", \"Oz\", \"P7\", \"P3\", \"P4\", \"P8\", \"Pz\"]\n",
    "# keep = [\"16\", \"18\", \"17\", \"15\", \"14\", \"19\", \"20\", \"13\"] # electrodes to keep\n",
    "\n",
    "for ind_i,i in enumerate(participants):\n",
    "    # raw = raw.drop_channels([ch for ch in raw.ch_names if ch in to_drop])\n",
    "    # raw = raw.drop_channels([i for i in raw.ch_names if i not in keep])\n",
    "\n",
    "    raw_eeglab[ind_i] = raw_eeglab[ind_i].filter(l_freq=1, h_freq=25, method=\"fir\", verbose=True)\n",
    "\n",
    "    # mne.set_eeg_reference(raw_eeglab[ind_i], 'average', copy=False, verbose=False)\n",
    "    n_channels = len(raw_eeglab[ind_i].ch_names)\n",
    "    print(\"Channels :\", raw_eeglab[ind_i].ch_names)\n",
    "    # print(raw_eeglab[ind_i].info)\n",
    "\n",
    "\n",
    "\n",
    "# raw = raw.filter(l_freq=50.1, h_freq=49.9, method=\"iir\", verbose=True)\n",
    "# raw = mne.filter.resample(raw,2)\n",
    "# raw.resample(480, npad='auto')\n",
    "# Average re-referencing\n",
    "#raw = raw.filter(l_freq=5, h_freq=45, method=\"fir\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['000000000000000000001000000000000000000000100000000000000000000010000000000000000000001000000000000000000000100000000000000000000010_1', '000000000000000010000000000000000000001000000000000000000000100000000000000000000010000000000000000000001000000000000000000000100000_3', '000000000010000000000000000000001000000000000000000000100000000000000000000010000000000000000000001000000000000000000000100000000000_2', '000000001000000000000000000000100000000000000000000010000000000000000000001000000000000000000000100000000000000000000010000000000000_5', '100000000000000000000010000000000000000000001000000000000000000000100000000000000000000010000000000000000000001000000000000000000000_4', 'BURST_1', 'BURST_2', 'BURST_3', 'BURST_4', 'BURST_5', 'boundary']\n",
      "{'000000000000000000001000000000000000000000100000000000000000000010000000000000000000001000000000000000000000100000000000000000000010_1': 1, '000000000000000010000000000000000000001000000000000000000000100000000000000000000010000000000000000000001000000000000000000000100000_3': 2, '000000000010000000000000000000001000000000000000000000100000000000000000000010000000000000000000001000000000000000000000100000000000_2': 3, '000000001000000000000000000000100000000000000000000010000000000000000000001000000000000000000000100000000000000000000010000000000000_5': 4, '100000000000000000000010000000000000000000001000000000000000000000100000000000000000000010000000000000000000001000000000000000000000_4': 5, 'BURST_1': 6, 'BURST_2': 7, 'BURST_3': 8, 'BURST_4': 9, 'BURST_5': 10, 'boundary': 11} [[    6     0    11]\n",
      " [  102     0     4]\n",
      " [  138     0    10]\n",
      " [  230     0    10]\n",
      " [  322     0    10]\n",
      " [  413     0    10]\n",
      " [  505     0    10]\n",
      " [  596     0    10]\n",
      " [  952     0     1]\n",
      " [ 1036     0     6]\n",
      " [ 1127     0     6]\n",
      " [ 1219     0     6]\n",
      " [ 1310     0     6]\n",
      " [ 1402     0     6]\n",
      " [ 1494     0     6]\n",
      " [ 1802     0     2]\n",
      " [ 1870     0     8]\n",
      " [ 1962     0     8]\n",
      " [ 2054     0     8]\n",
      " [ 2145     0     8]\n",
      " [ 2237     0     8]\n",
      " [ 2328     0     8]\n",
      " [ 2652     0     3]\n",
      " [ 2694     0     7]\n",
      " [ 2786     0     7]\n",
      " [ 2878     0     7]\n",
      " [ 2970     0     7]\n",
      " [ 3061     0     7]\n",
      " [ 3153     0     7]\n",
      " [ 3502     0     5]\n",
      " [ 3504     0     9]\n",
      " [ 3596     0     9]\n",
      " [ 3688     0     9]\n",
      " [ 3779     0     9]\n",
      " [ 3870     0     9]\n",
      " [ 3962     0     9]\n",
      " [ 4768     0     4]\n",
      " [ 4804     0    10]\n",
      " [ 4896     0    10]\n",
      " [ 4988     0    10]\n",
      " [ 5080     0    10]\n",
      " [ 5172     0    10]\n",
      " [ 5263     0    10]\n",
      " [ 5618     0     1]\n",
      " [ 5702     0     6]\n",
      " [ 5794     0     6]\n",
      " [ 5886     0     6]\n",
      " [ 5977     0     6]\n",
      " [ 6068     0     6]\n",
      " [ 6160     0     6]\n",
      " [ 6468     0     5]\n",
      " [ 6470     0     9]\n",
      " [ 6562     0     9]\n",
      " [ 6654     0     9]\n",
      " [ 6746     0     9]\n",
      " [ 6838     0     9]\n",
      " [ 6929     0     9]\n",
      " [ 7318     0     2]\n",
      " [ 7386     0     8]\n",
      " [ 7478     0     8]\n",
      " [ 7570     0     8]\n",
      " [ 7662     0     8]\n",
      " [ 7753     0     8]\n",
      " [ 7845     0     8]\n",
      " [ 8168     0     3]\n",
      " [ 8211     0     7]\n",
      " [ 8302     0     7]\n",
      " [ 8394     0     7]\n",
      " [ 8486     0     7]\n",
      " [ 8578     0     7]\n",
      " [ 8669     0     7]\n",
      " [ 9426     0     1]\n",
      " [ 9510     0     6]\n",
      " [ 9602     0     6]\n",
      " [ 9694     0     6]\n",
      " [ 9785     0     6]\n",
      " [ 9877     0     6]\n",
      " [ 9968     0     6]\n",
      " [10276     0     5]\n",
      " [10279     0     9]\n",
      " [10370     0     9]\n",
      " [10462     0     9]\n",
      " [10554     0     9]\n",
      " [10646     0     9]\n",
      " [10737     0     9]\n",
      " [11126     0     2]\n",
      " [11194     0     8]\n",
      " [11286     0     8]\n",
      " [11378     0     8]\n",
      " [11470     0     8]\n",
      " [11562     0     8]\n",
      " [11653     0     8]\n",
      " [11976     0     4]\n",
      " [12012     0    10]\n",
      " [12104     0    10]\n",
      " [12196     0    10]\n",
      " [12288     0    10]\n",
      " [12380     0    10]\n",
      " [12471     0    10]\n",
      " [12826     0     3]\n",
      " [12869     0     7]\n",
      " [12960     0     7]\n",
      " [13052     0     7]\n",
      " [13144     0     7]\n",
      " [13236     0     7]\n",
      " [13328     0     7]\n",
      " [14530     0     2]\n",
      " [14598     0     8]\n",
      " [14690     0     8]\n",
      " [14782     0     8]\n",
      " [14874     0     8]\n",
      " [14966     0     8]\n",
      " [15057     0     8]\n",
      " [15380     0     4]\n",
      " [15416     0    10]\n",
      " [15508     0    10]\n",
      " [15600     0    10]\n",
      " [15692     0    10]\n",
      " [15784     0    10]\n",
      " [15875     0    10]\n",
      " [16230     0     1]\n",
      " [16314     0     6]\n",
      " [16406     0     6]\n",
      " [16498     0     6]\n",
      " [16589     0     6]\n",
      " [16680     0     6]\n",
      " [16772     0     6]\n",
      " [17080     0     3]\n",
      " [17123     0     7]\n",
      " [17214     0     7]\n",
      " [17306     0     7]\n",
      " [17398     0     7]\n",
      " [17490     0     7]\n",
      " [17582     0     7]\n",
      " [17930     0     5]\n",
      " [17932     0     9]\n",
      " [18024     0     9]\n",
      " [18116     0     9]\n",
      " [18208     0     9]\n",
      " [18299     0     9]\n",
      " [18391     0     9]\n",
      " [19350     0     1]\n",
      " [19434     0     6]\n",
      " [19526     0     6]\n",
      " [19618     0     6]\n",
      " [19710     0     6]\n",
      " [19802     0     6]\n",
      " [19893     0     6]\n",
      " [20200     0     4]\n",
      " [20238     0    10]\n",
      " [20329     0    10]\n",
      " [20420     0    10]\n",
      " [20512     0    10]\n",
      " [20604     0    10]\n",
      " [20696     0    10]\n",
      " [21050     0     2]\n",
      " [21119     0     8]\n",
      " [21211     0     8]\n",
      " [21302     0     8]\n",
      " [21394     0     8]\n",
      " [21486     0     8]\n",
      " [21578     0     8]\n",
      " [21900     0     3]\n",
      " [21944     0     7]\n",
      " [22035     0     7]\n",
      " [22127     0     7]\n",
      " [22218     0     7]\n",
      " [22310     0     7]\n",
      " [22402     0     7]\n",
      " [22750     0     5]\n",
      " [22753     0     9]\n",
      " [22845     0     9]\n",
      " [22936     0     9]\n",
      " [23028     0     9]\n",
      " [23120     0     9]\n",
      " [23212     0     9]\n",
      " [23992     0     5]\n",
      " [23995     0     9]\n",
      " [24086     0     9]\n",
      " [24178     0     9]\n",
      " [24270     0     9]\n",
      " [24362     0     9]\n",
      " [24453     0     9]\n",
      " [24842     0     4]\n",
      " [24878     0    10]\n",
      " [24970     0    10]\n",
      " [25062     0    10]\n",
      " [25154     0    10]\n",
      " [25246     0    10]\n",
      " [25337     0    10]\n",
      " [25692     0     2]\n",
      " [25760     0     8]\n",
      " [25852     0     8]\n",
      " [25944     0     8]\n",
      " [26036     0     8]\n",
      " [26128     0     8]\n",
      " [26219     0     8]\n",
      " [26542     0     3]\n",
      " [26585     0     7]\n",
      " [26676     0     7]\n",
      " [26768     0     7]\n",
      " [26860     0     7]\n",
      " [26952     0     7]\n",
      " [27044     0     7]\n",
      " [27392     0     1]\n",
      " [27476     0     6]\n",
      " [27568     0     6]\n",
      " [27659     0     6]\n",
      " [27751     0     6]\n",
      " [27842     0     6]\n",
      " [27934     0     6]\n",
      " [28792     0     1]\n",
      " [28876     0     6]\n",
      " [28968     0     6]\n",
      " [29059     0     6]\n",
      " [29151     0     6]\n",
      " [29242     0     6]\n",
      " [29334     0     6]\n",
      " [29642     0     4]\n",
      " [29678     0    10]\n",
      " [29770     0    10]\n",
      " [29862     0    10]\n",
      " [29954     0    10]\n",
      " [30045     0    10]\n",
      " [30137     0    10]\n",
      " [30492     0     5]\n",
      " [30494     0     9]\n",
      " [30586     0     9]\n",
      " [30678     0     9]\n",
      " [30770     0     9]\n",
      " [30861     0     9]\n",
      " [30952     0     9]\n",
      " [31342     0     2]\n",
      " [31410     0     8]\n",
      " [31502     0     8]\n",
      " [31594     0     8]\n",
      " [31686     0     8]\n",
      " [31777     0     8]\n",
      " [31868     0     8]\n",
      " [32191     0     3]\n",
      " [32234     0     7]\n",
      " [32327     0     7]\n",
      " [32418     0     7]\n",
      " [32510     0     7]\n",
      " [32602     0     7]\n",
      " [32693     0     7]\n",
      " [33504     0     5]\n",
      " [33507     0     9]\n",
      " [33598     0     9]\n",
      " [33690     0     9]\n",
      " [33782     0     9]\n",
      " [33874     0     9]\n",
      " [33965     0     9]\n",
      " [34354     0     2]\n",
      " [34423     0     8]\n",
      " [34514     0     8]\n",
      " [34606     0     8]\n",
      " [34698     0     8]\n",
      " [34790     0     8]\n",
      " [34881     0     8]\n",
      " [35204     0     4]\n",
      " [35240     0    10]\n",
      " [35332     0    10]\n",
      " [35424     0    10]\n",
      " [35516     0    10]\n",
      " [35608     0    10]\n",
      " [35699     0    10]\n",
      " [36054     0     3]\n",
      " [36097     0     7]\n",
      " [36188     0     7]\n",
      " [36280     0     7]\n",
      " [36372     0     7]\n",
      " [36464     0     7]\n",
      " [36556     0     7]\n",
      " [36904     0     1]\n",
      " [36988     0     6]\n",
      " [37080     0     6]\n",
      " [37172     0     6]\n",
      " [37263     0     6]\n",
      " [37354     0     6]\n",
      " [37446     0     6]\n",
      " [38196     0     3]\n",
      " [38238     0     7]\n",
      " [38330     0     7]\n",
      " [38422     0     7]\n",
      " [38514     0     7]\n",
      " [38605     0     7]\n",
      " [38697     0     7]\n",
      " [39046     0     1]\n",
      " [39130     0     6]\n",
      " [39221     0     6]\n",
      " [39313     0     6]\n",
      " [39404     0     6]\n",
      " [39496     0     6]\n",
      " [39588     0     6]\n",
      " [39896     0     5]\n",
      " [39898     0     9]\n",
      " [39990     0     9]\n",
      " [40082     0     9]\n",
      " [40173     0     9]\n",
      " [40265     0     9]\n",
      " [40356     0     9]\n",
      " [40746     0     4]\n",
      " [40782     0    10]\n",
      " [40874     0    10]\n",
      " [40966     0    10]\n",
      " [41057     0    10]\n",
      " [41149     0    10]\n",
      " [41240     0    10]\n",
      " [41596     0     2]\n",
      " [41664     0     8]\n",
      " [41756     0     8]\n",
      " [41848     0     8]\n",
      " [41939     0     8]\n",
      " [42030     0     8]\n",
      " [42122     0     8]\n",
      " [42920     0     4]\n",
      " [42957     0    10]\n",
      " [43048     0    10]\n",
      " [43140     0    10]\n",
      " [43232     0    10]\n",
      " [43324     0    10]\n",
      " [43416     0    10]\n",
      " [43770     0     1]\n",
      " [43854     0     6]\n",
      " [43946     0     6]\n",
      " [44038     0     6]\n",
      " [44130     0     6]\n",
      " [44221     0     6]\n",
      " [44312     0     6]\n",
      " [44620     0     5]\n",
      " [44623     0     9]\n",
      " [44714     0     9]\n",
      " [44806     0     9]\n",
      " [44898     0     9]\n",
      " [44990     0     9]\n",
      " [45082     0     9]\n",
      " [45470     0     3]\n",
      " [45513     0     7]\n",
      " [45605     0     7]\n",
      " [45696     0     7]\n",
      " [45788     0     7]\n",
      " [45880     0     7]\n",
      " [45972     0     7]\n",
      " [46320     0     2]\n",
      " [46389     0     8]\n",
      " [46480     0     8]\n",
      " [46572     0     8]\n",
      " [46664     0     8]\n",
      " [46756     0     8]\n",
      " [46847     0     8]\n",
      " [47620     0     1]\n",
      " [47704     0     6]\n",
      " [47796     0     6]\n",
      " [47888     0     6]\n",
      " [47979     0     6]\n",
      " [48070     0     6]\n",
      " [48162     0     6]\n",
      " [48470     0     5]\n",
      " [48472     0     9]\n",
      " [48564     0     9]\n",
      " [48656     0     9]\n",
      " [48748     0     9]\n",
      " [48840     0     9]\n",
      " [48931     0     9]\n",
      " [49320     0     4]\n",
      " [49356     0    10]\n",
      " [49448     0    10]\n",
      " [49540     0    10]\n",
      " [49632     0    10]\n",
      " [49724     0    10]\n",
      " [49815     0    10]\n",
      " [50170     0     2]\n",
      " [50238     0     8]\n",
      " [50330     0     8]\n",
      " [50422     0     8]\n",
      " [50514     0     8]\n",
      " [50606     0     8]\n",
      " [50697     0     8]\n",
      " [51020     0     3]\n",
      " [51063     0     7]\n",
      " [51154     0     7]\n",
      " [51246     0     7]\n",
      " [51338     0     7]\n",
      " [51430     0     7]\n",
      " [51522     0     7]\n",
      " [52282     0     2]\n",
      " [52351     0     8]\n",
      " [52442     0     8]\n",
      " [52534     0     8]\n",
      " [52626     0     8]\n",
      " [52718     0     8]\n",
      " [52810     0     8]\n",
      " [53132     0     4]\n",
      " [53169     0    10]\n",
      " [53260     0    10]\n",
      " [53352     0    10]\n",
      " [53444     0    10]\n",
      " [53536     0    10]\n",
      " [53628     0    10]\n",
      " [53982     0     5]\n",
      " [53985     0     9]\n",
      " [54076     0     9]\n",
      " [54168     0     9]\n",
      " [54260     0     9]\n",
      " [54352     0     9]\n",
      " [54444     0     9]\n",
      " [54832     0     1]\n",
      " [54916     0     6]\n",
      " [55008     0     6]\n",
      " [55100     0     6]\n",
      " [55191     0     6]\n",
      " [55283     0     6]\n",
      " [55374     0     6]\n",
      " [55682     0     3]\n",
      " [55725     0     7]\n",
      " [55817     0     7]\n",
      " [55908     0     7]\n",
      " [56000     0     7]\n",
      " [56092     0     7]\n",
      " [56184     0     7]\n",
      " [57249     0     5]\n",
      " [57252     0     9]\n",
      " [57343     0     9]\n",
      " [57435     0     9]\n",
      " [57526     0     9]\n",
      " [57618     0     9]\n",
      " [57710     0     9]\n",
      " [58098     0     1]\n",
      " [58183     0     6]\n",
      " [58274     0     6]\n",
      " [58366     0     6]\n",
      " [58458     0     6]\n",
      " [58550     0     6]\n",
      " [58641     0     6]\n",
      " [58948     0     2]\n",
      " [59018     0     8]\n",
      " [59109     0     8]\n",
      " [59200     0     8]\n",
      " [59292     0     8]\n",
      " [59384     0     8]\n",
      " [59476     0     8]\n",
      " [59798     0     3]\n",
      " [59842     0     7]\n",
      " [59934     0     7]\n",
      " [60025     0     7]\n",
      " [60116     0     7]\n",
      " [60208     0     7]\n",
      " [60300     0     7]\n",
      " [60648     0     4]\n",
      " [60686     0    10]\n",
      " [60777     0    10]\n",
      " [60869     0    10]\n",
      " [60960     0    10]\n",
      " [61052     0    10]\n",
      " [61144     0    10]\n",
      " [61886     0     3]\n",
      " [61929     0     7]\n",
      " [62021     0     7]\n",
      " [62112     0     7]\n",
      " [62204     0     7]\n",
      " [62296     0     7]\n",
      " [62388     0     7]\n",
      " [62736     0     1]\n",
      " [62820     0     6]\n",
      " [62912     0     6]\n",
      " [63004     0     6]\n",
      " [63095     0     6]\n",
      " [63186     0     6]\n",
      " [63278     0     6]\n",
      " [63586     0     5]\n",
      " [63588     0     9]\n",
      " [63680     0     9]\n",
      " [63772     0     9]\n",
      " [63864     0     9]\n",
      " [63956     0     9]\n",
      " [64047     0     9]\n",
      " [64436     0     4]\n",
      " [64472     0    10]\n",
      " [64564     0    10]\n",
      " [64656     0    10]\n",
      " [64748     0    10]\n",
      " [64840     0    10]\n",
      " [64931     0    10]\n",
      " [65286     0     2]\n",
      " [65354     0     8]\n",
      " [65446     0     8]\n",
      " [65538     0     8]\n",
      " [65630     0     8]\n",
      " [65722     0     8]\n",
      " [65813     0     8]\n",
      " [66598     0     3]\n",
      " [66642     0     7]\n",
      " [66733     0     7]\n",
      " [66824     0     7]\n",
      " [66916     0     7]\n",
      " [67008     0     7]\n",
      " [67100     0     7]\n",
      " [67448     0     5]\n",
      " [67451     0     9]\n",
      " [67542     0     9]\n",
      " [67634     0     9]\n",
      " [67726     0     9]\n",
      " [67818     0     9]\n",
      " [67910     0     9]\n",
      " [68298     0     2]\n",
      " [68367     0     8]\n",
      " [68458     0     8]\n",
      " [68550     0     8]\n",
      " [68642     0     8]\n",
      " [68734     0     8]\n",
      " [68825     0     8]\n",
      " [69148     0     1]\n",
      " [69232     0     6]\n",
      " [69324     0     6]\n",
      " [69416     0     6]\n",
      " [69507     0     6]\n",
      " [69599     0     6]\n",
      " [69690     0     6]\n",
      " [69998     0     4]\n",
      " [70035     0    10]\n",
      " [70126     0    10]\n",
      " [70218     0    10]\n",
      " [70310     0    10]\n",
      " [70402     0    10]\n",
      " [70493     0    10]\n",
      " [70781     0    11]]\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Setting baseline interval to [-0.008, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Setting baseline interval to [-0.008, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Setting baseline interval to [-0.008, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Setting baseline interval to [-0.008, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Setting baseline interval to [-0.008, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "p=1\n",
    "window_size=0.5\n",
    "events, event_id = mne.events_from_annotations(raw_eeglab[p])\n",
    "print(event_id,events)\n",
    "epochs = mne.Epochs(raw_eeglab[p], events, event_id=event_id, tmin=0, \\\n",
    "            tmax=0.6, baseline=(None, None), preload=False, verbose=False)\n",
    "\n",
    "epochs_train1 = mne.Epochs(raw_eeglab[p],events, 6,tmin=-0.01,tmax=window_size)\n",
    "epochs_train2 = mne.Epochs(raw_eeglab[p],events, 7,tmin=-0.01,tmax=window_size)\n",
    "epochs_train3 = mne.Epochs(raw_eeglab[p],events, 8,tmin=-0.01,tmax=window_size)\n",
    "epochs_train4 = mne.Epochs(raw_eeglab[p],events, 9,tmin=-0.01,tmax=window_size)\n",
    "epochs_train5 = mne.Epochs(raw_eeglab[p],events, 10,tmin=-0.01,tmax=window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_20788\\3746502456.py:8: RuntimeWarning: Only 1 channel in \"picks\"; cannot combine by method \"mean\".\n",
      "  mne.viz.plot_compare_evokeds(evokeds, combine=\"mean\", picks=\"EEG 000\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\AppData\\Local\\Temp\\ipykernel_20788\\3746502456.py:8: RuntimeWarning: Cannot find channel coordinates in the supplied Evokeds. Not showing channel locations.\n",
      "  mne.viz.plot_compare_evokeds(evokeds, combine=\"mean\", picks=\"EEG 000\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 1000x750 with 1 Axes>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_1 = list(epochs_train1.iter_evoked())\n",
    "evoked_2 = list(epochs_train2.iter_evoked())\n",
    "evoked_3 = list(epochs_train3.iter_evoked())\n",
    "evoked_4 = list(epochs_train4.iter_evoked())\n",
    "evoked_5 = list(epochs_train5.iter_evoked())\n",
    "\n",
    "evokeds = dict(one=evoked_1,two=evoked_2,three=evoked_3,four=evoked_4,five=evoked_5)\n",
    "mne.viz.plot_compare_evokeds(evokeds, combine=\"mean\", picks=\"EEG 000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e70fa4b-2e51-42fe-a41a-0b7c29ea6bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 75 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs_list = []\n",
    "events_list = []\n",
    "events_id_list = []\n",
    "onset_code_list = []\n",
    "data_list = []\n",
    "labels_code_list = []\n",
    "for ind_i, i in enumerate(participants): \n",
    "    # Strip the annotations that were script to make them easier to process\n",
    "    events, event_id = mne.events_from_annotations(raw_eeglab[ind_i], event_id='auto', verbose=False)\n",
    "    to_remove = []\n",
    "    for idx in range(len(raw_eeglab[ind_i].annotations.description)):\n",
    "        if (('boundary' in raw_eeglab[ind_i].annotations.description[idx]) or\n",
    "            ('BURST' in raw_eeglab[ind_i].annotations.description[idx])):\n",
    "            to_remove.append(idx)\n",
    "\n",
    "    to_remove = np.array(to_remove)\n",
    "    if len(to_remove) > 0:\n",
    "        raw_eeglab[ind_i].annotations.delete(to_remove)\n",
    "    # Get the events\n",
    "    temp_event,temp_event_id = mne.events_from_annotations(raw_eeglab[ind_i], event_id='auto', verbose=False)\n",
    "    events_list.append(temp_event)\n",
    "    events_id_list.append(temp_event_id)\n",
    "    shift = 0.0\n",
    "    # Epoch the data following event\n",
    "    epochs_list.append(mne.Epochs(raw_eeglab[ind_i], events_list[ind_i], event_id=events_id_list[ind_i], tmin=shift, \\\n",
    "                tmax=2.2+shift, baseline=(None, None), preload=False, verbose=False))\n",
    "    # print(events_list[ind_i])\n",
    "\n",
    "    labels_code_list.append(epochs_list[ind_i].events[..., -1])\n",
    "    labels_code_list[ind_i] -= np.min(labels_code_list[ind_i])\n",
    "    # print(epochs.events[..., -1])\n",
    "    data_list.append(epochs_list[ind_i].get_data())\n",
    "    info_ep = epochs_list[ind_i].info\n",
    "    # print(epochs)\n",
    "    onset_code_list.append(epochs_list[ind_i].events[..., 0])\n",
    "data_list = np.array(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec5d54-21ce-4a3e-9974-dff0d81efe65",
   "metadata": {},
   "source": [
    "### Transform a code in `str` to a code in np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8d886a37-bc66-490c-a290-f84b2502c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code2array(code):\n",
    "    tmp = []\n",
    "    for idx, c in enumerate(code[:-2]):\n",
    "        if c == '5' or c == '.':\n",
    "            continue\n",
    "        elif c == '0':\n",
    "            if code[idx+2] == '5':\n",
    "                tmp.append(0.5)\n",
    "            else:\n",
    "                tmp.append(0)\n",
    "        else:\n",
    "            tmp.append(1)\n",
    "    if code[-1] == '.':\n",
    "        if code[-2] == '0':\n",
    "            tmp.append(0)\n",
    "        else:\n",
    "            tmp.append(1)\n",
    "    return np.array(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f02ea8-255b-4d46-9f64-8263ef253089",
   "metadata": {},
   "source": [
    "### Build a dictionnary that contains all the code in the np.array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e221464-c67a-468d-bedc-1cb4592d032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "codes = OrderedDict()\n",
    "for k, v in events_id_list[0].items():\n",
    "    code = k.split('_')[0]\n",
    "    code = code.replace('.','').replace('2','')\n",
    "    idx = k.split('_')[1]\n",
    "    codes[v-1] = np.array(list(map(int, code)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f84de91-a554-4326-8c67-f1ad891597d5",
   "metadata": {},
   "source": [
    "### Define train/test split and windows size\n",
    "Here we use only the first 7 blocks as calibrition and 8 others would be used as testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(codes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 75, 8, 1101)\n"
     ]
    }
   ],
   "source": [
    "print(data_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c34c29-78b0-4da1-ac2c-b18150cb175e",
   "metadata": {},
   "source": [
    "### Slice the epoch in windows\n",
    "The network is not processing full epochs but windows of 250ms. So each epoch is cut into window and the following code (`0` or `1`) is associated as label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b888b955-2c47-4dcd-b51f-438442a0d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_window_cov(data, labels,length,n_samples_windows,codes,normalise=False,window_size=0.25,sfreq=500,fps=60,n_channels=8):\n",
    "    X = np.empty(shape=((length)*data.shape[0], data.shape[1], n_samples_windows))\n",
    "    y = np.empty(shape=((length)*data.shape[0]), dtype=int)\n",
    "    count = 0\n",
    "    for trial_nb, trial in enumerate(data):\n",
    "        lab = labels[trial_nb]\n",
    "        c = codes[lab]\n",
    "        code_pos = 0\n",
    "        for idx in range(length):\n",
    "            X[count] = trial[:, idx:idx+n_samples_windows]\n",
    "            if idx/sfreq >= (code_pos+1)/fps:\n",
    "                code_pos += 1 \n",
    "            y[count] = int(c[code_pos])\n",
    "            count += 1\n",
    "    if normalise:\n",
    "        X_std = X.std(axis=0)\n",
    "        X /= X_std + 1e-8\n",
    "    xdawncov = XdawnCovariances(estimator=\"lwf\",xdawn_estimator=\"lwf\",nfilter=8)\n",
    "    X = xdawncov.fit_transform(X,y)\n",
    "    # X = X.astype(np.float32)\n",
    "    y_pred = np.vstack((y,np.abs(1-y))).T\n",
    "    y = np.array([1 if (y >= 0.5) else 0 for y in y_pred[:,0]])\n",
    "    return X, y\n",
    "\n",
    "def to_window_old(data, labels,length,n_samples_windows,codes,window_size=0.25,normalise=True,sfreq=500,fps=60,n_channels=8):\n",
    "    \n",
    "    X = np.empty(shape=((length)*data.shape[0], n_channels, n_samples_windows))\n",
    "    idx_taken = []\n",
    "    y = np.empty(shape=((length)*data.shape[0]), dtype=int)\n",
    "    count = 0\n",
    "    for trial_nb, trial in enumerate(data):\n",
    "        lab = labels[trial_nb]\n",
    "        c = codes[lab]\n",
    "        code_pos = 0\n",
    "        for idx in range(length):\n",
    "            X[count] = trial[:, idx:idx+n_samples_windows]\n",
    "            if idx/sfreq >= (code_pos+1)/fps:\n",
    "                code_pos += 1 \n",
    "            y[count] = int(c[code_pos])\n",
    "            count += 1\n",
    "        \n",
    "        for idx in range(length):\n",
    "            # print('Xidx:', trial_nb*length+idx, \"Tidxm:\", idx, 'TidxM:', idx +\n",
    "            #       n_samples_windows, 'Ltrial', trial[:, idx:idx+n_samples_windows].shape)\n",
    "            idx_taken.append(trial_nb*length+idx)\n",
    "    # if normalise:\n",
    "    #     X_std = X.std(axis=0)\n",
    "    #     X /= X_std + 1e-8\n",
    "    y_pred = np.vstack((y,np.abs(1-y))).T\n",
    "    y = np.array([1 if (y >= 0.5) else 0 for y in y_pred[:,0]])\n",
    "\n",
    "    return X, y, np.array(idx_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "50bfe6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 8775)\n",
      "(24, 8775, 8, 125)\n",
      "(24, 8775)\n",
      "(24, 8775, 8, 125)\n"
     ]
    }
   ],
   "source": [
    "window_size = 0.25\n",
    "n_samples_windows = int(window_size*sfreq)\n",
    "# length = int((2.2-window_size)*sfreq)\n",
    "length = int((2.2-window_size)*fps)\n",
    "X = np.zeros((data_list.shape[0],length*data_list.shape[1],data_list.shape[2],n_samples_windows))\n",
    "y = np.zeros((data_list.shape[0],length*data_list.shape[1]))\n",
    "idx_taken = np.zeros((data_list.shape[0],length*data_list.shape[1]))\n",
    "domains = []\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "for ind_i,i in enumerate(participants):\n",
    "    # X[ind_i],y[ind_i],idx_taken[ind_i] = to_window_old(data_list[ind_i],labels_code_list[ind_i],length,n_samples_windows,codes,window_size=window_size,sfreq=sfreq)\n",
    "    X[ind_i],y[ind_i],idx_taken[ind_i] = to_window_old(data_list[ind_i],labels_code_list[ind_i],length,n_samples_windows,codes,window_size=window_size,sfreq=fps)\n",
    "    domains.append([\"Source_sub_{}\".format(ind_i+1),]*len(y[ind_i]))\n",
    "\n",
    "# print(codes[labels_test[0]])\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "domains = np.array(domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onset_anno(onset_window,label_window,onset_code,nb_seq_min,nb_seq_max,code_freq,sfreq,win_size):\n",
    "    assert(sfreq!=0)\n",
    "    new_onset = []\n",
    "    new_onset_0 = []\n",
    "    current_code = 0\n",
    "    onset_code = np.ceil(onset_code*code_freq/sfreq)\n",
    "    nb_seq_min-=1\n",
    "    onset_shift = onset_code[current_code+nb_seq_min]\n",
    "    time_trial = (2.2-win_size)\n",
    "    # onset_window = np.arange(0,time_trial*code_freq*(nb_seq_max-nb_seq_min)-1,1,dtype=int)\n",
    "    for i,o in enumerate(onset_window):\n",
    "        if label_window[i]==1:\n",
    "            # print(i)\n",
    "            if current_code==nb_seq_max-1-nb_seq_min:\n",
    "                new_onset.append(o+onset_shift)\n",
    "            else:\n",
    "                if o+onset_shift >= onset_code[current_code+nb_seq_min]+time_trial*code_freq:\n",
    "                    current_code+=1\n",
    "                    onset_shift = onset_code[current_code+nb_seq_min]-time_trial*code_freq*current_code\n",
    "                new_onset.append(o+onset_shift)\n",
    "        else:\n",
    "            if current_code==nb_seq_max-1-nb_seq_min:\n",
    "                new_onset_0.append(o+onset_shift)\n",
    "            else:\n",
    "                if o+onset_shift >= onset_code[current_code+nb_seq_min]+time_trial*code_freq:\n",
    "                    current_code+=1\n",
    "                    onset_shift = onset_code[current_code+nb_seq_min]-time_trial*code_freq*current_code\n",
    "                new_onset_0.append(o+onset_shift)\n",
    "    \n",
    "    # modified_onset_code = [onset_code[i]-time_trial*sfreq*i for i in range(nb_seq_min,nb_seq_max)]\n",
    "    # new_onset_0 = np.concatenate([np.arange(onset_code[i],onset_code[i]+time_trial*sfreq,sfreq//60) for i in range(nb_seq_min,nb_seq_max)])\n",
    "    new_onset_0 = np.array(list(filter(lambda i: i not in new_onset, new_onset_0)))\n",
    "    # print(new_onset_0.shape)\n",
    "    return np.array(new_onset)/code_freq, np.array(new_onset_0)/code_freq\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y_train)\n",
    "# print(np.where(Y_train==1)[0]*sfreq//60)\n",
    "# print(frame_train)\n",
    "for ind_i,i in enumerate(participants):\n",
    "    onset,onset_0 = onset_anno(idx_taken[ind_i],y[ind_i],onset_code_list[ind_i],1,n_class*15,60,500,window_size)\n",
    "    # print(onset,onset_0)\n",
    "    anno = mne.Annotations(onset,0.001*sfreq//60,\"1\")\n",
    "    anno.append(onset_0,0.001*sfreq//60,\"0\")\n",
    "\n",
    "    raw_eeglab[ind_i] = raw_eeglab[ind_i].set_annotations(anno)\n",
    "# events, event_id = mne.events_from_annotations(raw)\n",
    "# print(event_id,events)\n",
    "# epochs = mne.Epochs(raw, events, event_id=event_id, tmin=0, \\\n",
    "#             tmax=0.6, baseline=(None, None), preload=False, verbose=False)\n",
    "\n",
    "# epochs_train1 = mne.Epochs(raw,events, 2,tmin=-0.01,tmax=window_size)\n",
    "# epochs_train0 = mne.Epochs(raw,events, 1,tmin=-0.01,tmax=window_size)\n",
    "\n",
    "# evoked_1 = list(epochs_train1.iter_evoked())\n",
    "# # evoked_1.plot(picks=\"Oz\")\n",
    "# evoked_0 = list(epochs_train0.iter_evoked())\n",
    "# # evoked_0.plot(picks=\"Oz\")\n",
    "# evokeds = dict(one=evoked_1,zero=evoked_0)\n",
    "# mne.viz.plot_compare_evokeds(evokeds, combine=\"mean\", picks=\"EEG 001\")\n",
    "# raw.plot(n_channels=15, duration=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 5\n",
    "plt.plot(np.mean(X[p][np.where(Y[p]==1)],axis=0),color='r')\n",
    "plt.plot(np.mean(X[p][np.where(Y[p]==0)],axis=0),color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpaa(y_pred, codes, min_len=30, sfreq=60, consecutive=30, window_size=0.25):\n",
    "    length = int((2.2-window_size)*sfreq)\n",
    "    y_pred = np.array(y_pred)\n",
    "    rez_acc = []\n",
    "\n",
    "    code_buffer = []\n",
    "    labels_pred = []\n",
    "    code_pos = 0\n",
    "    y_tmp = [] \n",
    "    mean_long = []\n",
    "\n",
    "    for trial in range(int(len(y_pred)/length)):   \n",
    "        # Retrieve a trial\n",
    "        tmp_code = y_pred[trial*length:(trial+1)*length]\n",
    "        code_pos = 0\n",
    "\n",
    "        # Do an average over the prdata, codes, labels, fps\n",
    "        code_buffer = []\n",
    "        for idx in range(len(tmp_code)):\n",
    "            y_tmp.append(tmp_code[idx])\n",
    "            if (idx+1)/sfreq >= (code_pos+1)/60:\n",
    "                code_pred = np.mean(y_tmp) \n",
    "                code_pred = int(np.rint(code_pred))\n",
    "                code_buffer.append(code_pred) \n",
    "                y_tmp = []\n",
    "                code_pos += 1\n",
    "        # Find the code that correlate the most\n",
    "        corr = -2\n",
    "        pred_lab = -1\n",
    "        # print(\"buffer:\",code_buffer)\n",
    "        out = 0\n",
    "        for long in np.arange(min_len, len(code_buffer) -1 , step=1):\n",
    "            dtw_values = []\n",
    "            for key, values in codes.items():\n",
    "                dtw_values.append(np.corrcoef(code_buffer[:long], values[:long])[0,1])\n",
    "                # print((code_buffer[:long], values[:long]))\n",
    "            dtw_values = np.array(dtw_values)\n",
    "            # print(\"corr values;\",dtw_values)\n",
    "            max_dtw = list(codes.keys())[np.argmax(dtw_values)] \n",
    "            # print(max_dtw)\n",
    "            if (max_dtw == pred_lab):\n",
    "                out += 1\n",
    "                corr = np.max(dtw_values)\n",
    "            else:\n",
    "                pred_lab = max_dtw\n",
    "                out = 0\n",
    "            if out == consecutive:\n",
    "                mean_long.append((long)/60)\n",
    "                break\n",
    "        labels_pred.append(pred_lab)\n",
    "    labels_pred = np.array(labels_pred)\n",
    "    return labels_pred, code_buffer, mean_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dim(X):\n",
    "    X_temp = []\n",
    "    Y_temp = []\n",
    "    for i in range(X.shape[0]):\n",
    "        # print(i)\n",
    "        X_temp.append(np.expand_dims(X[i],1))\n",
    "    return np.array(X_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((X.shape[0],length*data_list.shape[1],data_list.shape[2],int(window_size*sfreq)))\n",
    "y = np.zeros((data_list.shape[0],length*data_list.shape[1]))\n",
    "for ind_i,i in enumerate(participants):\n",
    "    events, event_id = mne.events_from_annotations(raw_eeglab[ind_i])\n",
    "    # print(event_id)\n",
    "    epochs = mne.Epochs(raw_eeglab[ind_i],events,event_id,tmin=0.0,tmax=window_size,baseline=(0,0))\n",
    "    temp_X = epochs.get_data()[:,:,:-1]\n",
    "    y[ind_i] = epochs.events[...,-1]-1\n",
    "    X[ind_i] = compute_riemannian_alignment(temp_X, mean=None, dtype='real')\n",
    "    # X[ind_i] = temp_X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "6/6 [==============================] - 2s 87ms/step - loss: 0.7866 - accuracy: 0.5352 - val_loss: 0.6493 - val_accuracy: 0.7027\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6697 - accuracy: 0.6116 - val_loss: 0.5670 - val_accuracy: 0.7568\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5636 - accuracy: 0.7523 - val_loss: 0.5205 - val_accuracy: 0.7568\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4914 - accuracy: 0.7798 - val_loss: 0.5007 - val_accuracy: 0.8108\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4215 - accuracy: 0.8318 - val_loss: 0.5305 - val_accuracy: 0.8108\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3862 - accuracy: 0.8349 - val_loss: 0.5653 - val_accuracy: 0.8108\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3479 - accuracy: 0.8502 - val_loss: 0.5998 - val_accuracy: 0.8108\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3390 - accuracy: 0.8593 - val_loss: 0.6037 - val_accuracy: 0.8378\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3053 - accuracy: 0.8869 - val_loss: 0.6270 - val_accuracy: 0.8108\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2741 - accuracy: 0.8991 - val_loss: 0.6110 - val_accuracy: 0.8108\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2645 - accuracy: 0.8930 - val_loss: 0.6474 - val_accuracy: 0.8108\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2766 - accuracy: 0.8960 - val_loss: 0.7079 - val_accuracy: 0.7838\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2510 - accuracy: 0.8991 - val_loss: 0.6992 - val_accuracy: 0.8108\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2560 - accuracy: 0.8899 - val_loss: 0.6918 - val_accuracy: 0.8108\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2489 - accuracy: 0.8716 - val_loss: 0.7027 - val_accuracy: 0.8108\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2390 - accuracy: 0.9205 - val_loss: 0.6842 - val_accuracy: 0.8108\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2321 - accuracy: 0.9144 - val_loss: 0.6157 - val_accuracy: 0.8378\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1962 - accuracy: 0.9144 - val_loss: 0.5862 - val_accuracy: 0.8378\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2421 - accuracy: 0.8869 - val_loss: 0.6118 - val_accuracy: 0.8378\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2150 - accuracy: 0.9144 - val_loss: 0.6440 - val_accuracy: 0.8378\n",
      "getting accuracy of participant  0\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.343939393939394\n",
      "TL to the participant :  1\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 84ms/step - loss: 0.7680 - accuracy: 0.5505 - val_loss: 0.7060 - val_accuracy: 0.6486\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7532 - accuracy: 0.5627 - val_loss: 0.7170 - val_accuracy: 0.5405\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7271 - accuracy: 0.5657 - val_loss: 0.6946 - val_accuracy: 0.6216\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7045 - accuracy: 0.6086 - val_loss: 0.6665 - val_accuracy: 0.6486\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6786 - accuracy: 0.6269 - val_loss: 0.6485 - val_accuracy: 0.6216\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6478 - accuracy: 0.6453 - val_loss: 0.6258 - val_accuracy: 0.6757\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6158 - accuracy: 0.6728 - val_loss: 0.6109 - val_accuracy: 0.6757\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6123 - accuracy: 0.6728 - val_loss: 0.5952 - val_accuracy: 0.7297\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5991 - accuracy: 0.6850 - val_loss: 0.5816 - val_accuracy: 0.7297\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5678 - accuracy: 0.7278 - val_loss: 0.5686 - val_accuracy: 0.7297\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5532 - accuracy: 0.7187 - val_loss: 0.5528 - val_accuracy: 0.7027\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4999 - accuracy: 0.7554 - val_loss: 0.5413 - val_accuracy: 0.7027\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4905 - accuracy: 0.7615 - val_loss: 0.5444 - val_accuracy: 0.6757\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5127 - accuracy: 0.7462 - val_loss: 0.5367 - val_accuracy: 0.7027\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5101 - accuracy: 0.7768 - val_loss: 0.5307 - val_accuracy: 0.7027\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5254 - accuracy: 0.7523 - val_loss: 0.5288 - val_accuracy: 0.7568\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4437 - accuracy: 0.8287 - val_loss: 0.5130 - val_accuracy: 0.7838\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4324 - accuracy: 0.8073 - val_loss: 0.5088 - val_accuracy: 0.7838\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3919 - accuracy: 0.8287 - val_loss: 0.4976 - val_accuracy: 0.7838\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4488 - accuracy: 0.8043 - val_loss: 0.4936 - val_accuracy: 0.7838\n",
      "getting accuracy of participant  1\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.3686868686868687\n",
      "TL to the participant :  2\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 80ms/step - loss: 0.8258 - accuracy: 0.4954 - val_loss: 0.6883 - val_accuracy: 0.5676\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7520 - accuracy: 0.5352 - val_loss: 0.6841 - val_accuracy: 0.5946\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7408 - accuracy: 0.5443 - val_loss: 0.6954 - val_accuracy: 0.5946\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7218 - accuracy: 0.5474 - val_loss: 0.6995 - val_accuracy: 0.5135\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7198 - accuracy: 0.5657 - val_loss: 0.7066 - val_accuracy: 0.5135\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7195 - accuracy: 0.5505 - val_loss: 0.7016 - val_accuracy: 0.4865\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7193 - accuracy: 0.5902 - val_loss: 0.7107 - val_accuracy: 0.4865\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7042 - accuracy: 0.5810 - val_loss: 0.7268 - val_accuracy: 0.5135\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6881 - accuracy: 0.5963 - val_loss: 0.7142 - val_accuracy: 0.5405\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7004 - accuracy: 0.5810 - val_loss: 0.6923 - val_accuracy: 0.5676\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6624 - accuracy: 0.6116 - val_loss: 0.6943 - val_accuracy: 0.5676\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6639 - accuracy: 0.6300 - val_loss: 0.6938 - val_accuracy: 0.5135\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6690 - accuracy: 0.6208 - val_loss: 0.6878 - val_accuracy: 0.5676\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6912 - accuracy: 0.6086 - val_loss: 0.6875 - val_accuracy: 0.5946\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6512 - accuracy: 0.6239 - val_loss: 0.6921 - val_accuracy: 0.5676\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6290 - accuracy: 0.6361 - val_loss: 0.6998 - val_accuracy: 0.5405\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6032 - accuracy: 0.6789 - val_loss: 0.7019 - val_accuracy: 0.5946\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6267 - accuracy: 0.6636 - val_loss: 0.6950 - val_accuracy: 0.5676\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5853 - accuracy: 0.6942 - val_loss: 0.6586 - val_accuracy: 0.5676\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5948 - accuracy: 0.6483 - val_loss: 0.6457 - val_accuracy: 0.5676\n",
      "getting accuracy of participant  2\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4727272727272727\n",
      "TL to the participant :  3\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 80ms/step - loss: 0.8104 - accuracy: 0.5076 - val_loss: 0.6606 - val_accuracy: 0.7027\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7344 - accuracy: 0.5749 - val_loss: 0.6379 - val_accuracy: 0.6757\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6832 - accuracy: 0.6086 - val_loss: 0.6017 - val_accuracy: 0.7297\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6417 - accuracy: 0.6697 - val_loss: 0.5683 - val_accuracy: 0.7027\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6387 - accuracy: 0.6453 - val_loss: 0.5375 - val_accuracy: 0.7297\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5629 - accuracy: 0.7248 - val_loss: 0.5141 - val_accuracy: 0.7568\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5521 - accuracy: 0.7859 - val_loss: 0.4839 - val_accuracy: 0.7838\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5201 - accuracy: 0.7554 - val_loss: 0.4311 - val_accuracy: 0.8378\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4648 - accuracy: 0.7982 - val_loss: 0.3976 - val_accuracy: 0.8108\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4479 - accuracy: 0.7890 - val_loss: 0.3790 - val_accuracy: 0.8378\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3857 - accuracy: 0.8349 - val_loss: 0.3613 - val_accuracy: 0.8378\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3764 - accuracy: 0.8471 - val_loss: 0.3484 - val_accuracy: 0.8378\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3188 - accuracy: 0.8563 - val_loss: 0.3556 - val_accuracy: 0.8649\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3213 - accuracy: 0.8777 - val_loss: 0.3575 - val_accuracy: 0.8378\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3475 - accuracy: 0.8563 - val_loss: 0.3396 - val_accuracy: 0.8378\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2924 - accuracy: 0.8930 - val_loss: 0.3246 - val_accuracy: 0.8108\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3048 - accuracy: 0.8746 - val_loss: 0.3274 - val_accuracy: 0.8378\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3033 - accuracy: 0.8716 - val_loss: 0.3434 - val_accuracy: 0.8649\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2860 - accuracy: 0.8930 - val_loss: 0.3512 - val_accuracy: 0.8378\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2970 - accuracy: 0.8716 - val_loss: 0.3470 - val_accuracy: 0.8649\n",
      "getting accuracy of participant  3\n",
      "143/143 [==============================] - 1s 5ms/step\n",
      "meannnnnn long 1.3761904761904766\n",
      "TL to the participant :  4\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 67ms/step - loss: 0.8143 - accuracy: 0.5138 - val_loss: 0.6691 - val_accuracy: 0.5676\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7531 - accuracy: 0.5535 - val_loss: 0.6958 - val_accuracy: 0.5946\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7080 - accuracy: 0.5872 - val_loss: 0.6342 - val_accuracy: 0.6486\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6695 - accuracy: 0.5963 - val_loss: 0.6083 - val_accuracy: 0.6216\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6348 - accuracy: 0.6575 - val_loss: 0.6148 - val_accuracy: 0.6486\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6559 - accuracy: 0.6483 - val_loss: 0.5951 - val_accuracy: 0.6757\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5953 - accuracy: 0.7278 - val_loss: 0.5315 - val_accuracy: 0.7297\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6258 - accuracy: 0.6758 - val_loss: 0.4928 - val_accuracy: 0.8108\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5763 - accuracy: 0.6911 - val_loss: 0.4714 - val_accuracy: 0.8649\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5844 - accuracy: 0.7278 - val_loss: 0.4323 - val_accuracy: 0.8919\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5546 - accuracy: 0.7339 - val_loss: 0.4066 - val_accuracy: 0.8919\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5091 - accuracy: 0.7615 - val_loss: 0.3787 - val_accuracy: 0.8919\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5157 - accuracy: 0.7584 - val_loss: 0.3603 - val_accuracy: 0.8919\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4902 - accuracy: 0.7370 - val_loss: 0.3409 - val_accuracy: 0.8649\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4545 - accuracy: 0.7859 - val_loss: 0.3176 - val_accuracy: 0.9189\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5115 - accuracy: 0.7554 - val_loss: 0.3067 - val_accuracy: 0.9189\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4299 - accuracy: 0.8043 - val_loss: 0.2971 - val_accuracy: 0.9459\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4671 - accuracy: 0.8165 - val_loss: 0.2877 - val_accuracy: 0.9189\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4342 - accuracy: 0.7890 - val_loss: 0.2820 - val_accuracy: 0.9189\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4120 - accuracy: 0.8532 - val_loss: 0.2769 - val_accuracy: 0.9189\n",
      "getting accuracy of participant  4\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.3862745098039218\n",
      "TL to the participant :  5\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 81ms/step - loss: 0.8125 - accuracy: 0.5321 - val_loss: 0.6635 - val_accuracy: 0.6216\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7848 - accuracy: 0.5260 - val_loss: 0.6618 - val_accuracy: 0.7297\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7291 - accuracy: 0.5810 - val_loss: 0.6630 - val_accuracy: 0.6757\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.7092 - accuracy: 0.5749 - val_loss: 0.6489 - val_accuracy: 0.6757\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6459 - accuracy: 0.6330 - val_loss: 0.6298 - val_accuracy: 0.7027\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5917 - accuracy: 0.6972 - val_loss: 0.6263 - val_accuracy: 0.7027\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5555 - accuracy: 0.7615 - val_loss: 0.6065 - val_accuracy: 0.5946\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5447 - accuracy: 0.7829 - val_loss: 0.5785 - val_accuracy: 0.7027\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5332 - accuracy: 0.7523 - val_loss: 0.5690 - val_accuracy: 0.7027\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4785 - accuracy: 0.7676 - val_loss: 0.5654 - val_accuracy: 0.6486\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4850 - accuracy: 0.7676 - val_loss: 0.5577 - val_accuracy: 0.7297\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4725 - accuracy: 0.8135 - val_loss: 0.5479 - val_accuracy: 0.7568\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4161 - accuracy: 0.8349 - val_loss: 0.5429 - val_accuracy: 0.7568\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4187 - accuracy: 0.7982 - val_loss: 0.5310 - val_accuracy: 0.7838\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4233 - accuracy: 0.8257 - val_loss: 0.5315 - val_accuracy: 0.7568\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4193 - accuracy: 0.8410 - val_loss: 0.5264 - val_accuracy: 0.7568\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3873 - accuracy: 0.8379 - val_loss: 0.5285 - val_accuracy: 0.7297\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4221 - accuracy: 0.8287 - val_loss: 0.5199 - val_accuracy: 0.7838\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3971 - accuracy: 0.8471 - val_loss: 0.5103 - val_accuracy: 0.7568\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3440 - accuracy: 0.8685 - val_loss: 0.4901 - val_accuracy: 0.7838\n",
      "getting accuracy of participant  5\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4257575757575758\n",
      "TL to the participant :  6\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 83ms/step - loss: 0.7841 - accuracy: 0.5107 - val_loss: 0.6856 - val_accuracy: 0.5946\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7370 - accuracy: 0.5352 - val_loss: 0.6866 - val_accuracy: 0.5135\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7429 - accuracy: 0.5382 - val_loss: 0.6740 - val_accuracy: 0.5946\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6950 - accuracy: 0.5627 - val_loss: 0.6666 - val_accuracy: 0.5405\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7005 - accuracy: 0.5810 - val_loss: 0.6823 - val_accuracy: 0.6216\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6916 - accuracy: 0.5872 - val_loss: 0.6827 - val_accuracy: 0.5135\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6466 - accuracy: 0.6269 - val_loss: 0.6676 - val_accuracy: 0.5405\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6467 - accuracy: 0.6361 - val_loss: 0.6547 - val_accuracy: 0.5676\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6432 - accuracy: 0.6330 - val_loss: 0.6272 - val_accuracy: 0.6216\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6159 - accuracy: 0.6422 - val_loss: 0.6094 - val_accuracy: 0.6486\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6207 - accuracy: 0.6972 - val_loss: 0.6039 - val_accuracy: 0.6757\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6071 - accuracy: 0.7034 - val_loss: 0.5832 - val_accuracy: 0.7027\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5842 - accuracy: 0.7370 - val_loss: 0.5570 - val_accuracy: 0.7838\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5493 - accuracy: 0.7462 - val_loss: 0.5442 - val_accuracy: 0.8108\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5663 - accuracy: 0.7187 - val_loss: 0.5573 - val_accuracy: 0.7027\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6142 - accuracy: 0.6942 - val_loss: 0.5290 - val_accuracy: 0.8378\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5016 - accuracy: 0.7554 - val_loss: 0.4968 - val_accuracy: 0.8649\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5048 - accuracy: 0.7584 - val_loss: 0.4738 - val_accuracy: 0.8378\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5224 - accuracy: 0.7431 - val_loss: 0.4579 - val_accuracy: 0.8649\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4612 - accuracy: 0.7920 - val_loss: 0.4496 - val_accuracy: 0.8378\n",
      "getting accuracy of participant  6\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4354166666666668\n",
      "TL to the participant :  7\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 82ms/step - loss: 0.7991 - accuracy: 0.5596 - val_loss: 0.6349 - val_accuracy: 0.7297\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6903 - accuracy: 0.6177 - val_loss: 0.5724 - val_accuracy: 0.8108\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6272 - accuracy: 0.6575 - val_loss: 0.5152 - val_accuracy: 0.8919\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6324 - accuracy: 0.6483 - val_loss: 0.4628 - val_accuracy: 0.8919\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5585 - accuracy: 0.7217 - val_loss: 0.4149 - val_accuracy: 0.8378\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5436 - accuracy: 0.7492 - val_loss: 0.3706 - val_accuracy: 0.8649\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4501 - accuracy: 0.7798 - val_loss: 0.3474 - val_accuracy: 0.9189\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4431 - accuracy: 0.7982 - val_loss: 0.3285 - val_accuracy: 0.8919\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4539 - accuracy: 0.7829 - val_loss: 0.3278 - val_accuracy: 0.8919\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4284 - accuracy: 0.8043 - val_loss: 0.3274 - val_accuracy: 0.8649\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4238 - accuracy: 0.8073 - val_loss: 0.2872 - val_accuracy: 0.8649\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4067 - accuracy: 0.8257 - val_loss: 0.2723 - val_accuracy: 0.9189\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4143 - accuracy: 0.8349 - val_loss: 0.2831 - val_accuracy: 0.9189\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3566 - accuracy: 0.8624 - val_loss: 0.3065 - val_accuracy: 0.9189\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3668 - accuracy: 0.8440 - val_loss: 0.3348 - val_accuracy: 0.8649\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3589 - accuracy: 0.8563 - val_loss: 0.3378 - val_accuracy: 0.8649\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3120 - accuracy: 0.8807 - val_loss: 0.3173 - val_accuracy: 0.9189\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3277 - accuracy: 0.8685 - val_loss: 0.3020 - val_accuracy: 0.9189\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3831 - accuracy: 0.8563 - val_loss: 0.3161 - val_accuracy: 0.9189\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3137 - accuracy: 0.8685 - val_loss: 0.3109 - val_accuracy: 0.9189\n",
      "getting accuracy of participant  7\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.409313725490196\n",
      "TL to the participant :  8\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 56ms/step - loss: 0.7841 - accuracy: 0.4985 - val_loss: 0.7724 - val_accuracy: 0.4595\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7304 - accuracy: 0.5413 - val_loss: 0.7218 - val_accuracy: 0.5405\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7357 - accuracy: 0.5321 - val_loss: 0.7007 - val_accuracy: 0.5405\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6852 - accuracy: 0.5841 - val_loss: 0.7039 - val_accuracy: 0.5135\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7059 - accuracy: 0.5505 - val_loss: 0.7111 - val_accuracy: 0.4595\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6839 - accuracy: 0.5994 - val_loss: 0.6986 - val_accuracy: 0.4595\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7098 - accuracy: 0.5657 - val_loss: 0.6956 - val_accuracy: 0.4324\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7203 - accuracy: 0.5535 - val_loss: 0.6920 - val_accuracy: 0.5405\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6833 - accuracy: 0.6330 - val_loss: 0.6978 - val_accuracy: 0.5405\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6598 - accuracy: 0.6116 - val_loss: 0.6953 - val_accuracy: 0.5135\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6633 - accuracy: 0.6024 - val_loss: 0.6787 - val_accuracy: 0.5946\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6692 - accuracy: 0.6239 - val_loss: 0.6472 - val_accuracy: 0.5946\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6070 - accuracy: 0.6850 - val_loss: 0.6430 - val_accuracy: 0.7027\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6606 - accuracy: 0.6453 - val_loss: 0.6486 - val_accuracy: 0.7027\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6246 - accuracy: 0.6086 - val_loss: 0.6315 - val_accuracy: 0.7297\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5810 - accuracy: 0.6820 - val_loss: 0.6189 - val_accuracy: 0.7027\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6061 - accuracy: 0.6972 - val_loss: 0.6065 - val_accuracy: 0.7568\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5860 - accuracy: 0.6850 - val_loss: 0.5925 - val_accuracy: 0.7838\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5613 - accuracy: 0.7156 - val_loss: 0.5726 - val_accuracy: 0.8649\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5636 - accuracy: 0.7156 - val_loss: 0.5416 - val_accuracy: 0.8378\n",
      "getting accuracy of participant  8\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4660493827160497\n",
      "TL to the participant :  9\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 77ms/step - loss: 0.8089 - accuracy: 0.4985 - val_loss: 0.6895 - val_accuracy: 0.5135\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.7385 - accuracy: 0.5260 - val_loss: 0.6754 - val_accuracy: 0.5135\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7322 - accuracy: 0.5291 - val_loss: 0.6922 - val_accuracy: 0.4865\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7647 - accuracy: 0.5107 - val_loss: 0.7083 - val_accuracy: 0.5946\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7175 - accuracy: 0.5260 - val_loss: 0.7200 - val_accuracy: 0.5676\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7300 - accuracy: 0.5199 - val_loss: 0.7296 - val_accuracy: 0.5676\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7337 - accuracy: 0.5321 - val_loss: 0.7080 - val_accuracy: 0.5405\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7292 - accuracy: 0.5291 - val_loss: 0.7115 - val_accuracy: 0.6216\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7492 - accuracy: 0.5138 - val_loss: 0.6912 - val_accuracy: 0.6216\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7338 - accuracy: 0.4954 - val_loss: 0.7461 - val_accuracy: 0.5946\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6938 - accuracy: 0.5413 - val_loss: 0.7639 - val_accuracy: 0.5405\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7337 - accuracy: 0.5199 - val_loss: 0.7367 - val_accuracy: 0.4865\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6919 - accuracy: 0.5291 - val_loss: 0.7482 - val_accuracy: 0.4595\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7004 - accuracy: 0.5291 - val_loss: 0.7187 - val_accuracy: 0.4865\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7317 - accuracy: 0.5382 - val_loss: 0.6701 - val_accuracy: 0.5405\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7145 - accuracy: 0.5719 - val_loss: 0.6898 - val_accuracy: 0.5135\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7433 - accuracy: 0.5535 - val_loss: 0.7538 - val_accuracy: 0.5135\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7364 - accuracy: 0.5933 - val_loss: 0.7776 - val_accuracy: 0.4865\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6980 - accuracy: 0.5688 - val_loss: 0.8021 - val_accuracy: 0.5676\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6808 - accuracy: 0.5382 - val_loss: 0.8717 - val_accuracy: 0.5676\n",
      "getting accuracy of participant  9\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.5633333333333332\n",
      "TL to the participant :  10\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 78ms/step - loss: 0.7752 - accuracy: 0.5505 - val_loss: 0.6226 - val_accuracy: 0.7568\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7693 - accuracy: 0.5382 - val_loss: 0.6148 - val_accuracy: 0.7027\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7324 - accuracy: 0.5535 - val_loss: 0.6085 - val_accuracy: 0.7297\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6802 - accuracy: 0.5688 - val_loss: 0.5968 - val_accuracy: 0.7297\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6267 - accuracy: 0.6483 - val_loss: 0.5792 - val_accuracy: 0.7568\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5987 - accuracy: 0.6850 - val_loss: 0.5561 - val_accuracy: 0.7838\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5863 - accuracy: 0.7064 - val_loss: 0.5304 - val_accuracy: 0.7568\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5448 - accuracy: 0.7370 - val_loss: 0.5052 - val_accuracy: 0.7568\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4889 - accuracy: 0.7920 - val_loss: 0.4994 - val_accuracy: 0.7027\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4545 - accuracy: 0.8104 - val_loss: 0.4949 - val_accuracy: 0.7297\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4944 - accuracy: 0.7982 - val_loss: 0.4750 - val_accuracy: 0.7838\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4863 - accuracy: 0.7829 - val_loss: 0.4536 - val_accuracy: 0.7838\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4271 - accuracy: 0.8073 - val_loss: 0.4478 - val_accuracy: 0.7838\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4508 - accuracy: 0.8196 - val_loss: 0.4541 - val_accuracy: 0.7838\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3967 - accuracy: 0.8073 - val_loss: 0.4543 - val_accuracy: 0.7838\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3694 - accuracy: 0.8349 - val_loss: 0.4595 - val_accuracy: 0.8108\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3652 - accuracy: 0.8379 - val_loss: 0.4619 - val_accuracy: 0.7838\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3951 - accuracy: 0.8196 - val_loss: 0.4762 - val_accuracy: 0.8108\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3646 - accuracy: 0.8471 - val_loss: 0.4799 - val_accuracy: 0.7568\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3688 - accuracy: 0.8410 - val_loss: 0.4684 - val_accuracy: 0.7568\n",
      "getting accuracy of participant  10\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.3892473118279576\n",
      "TL to the participant :  11\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 79ms/step - loss: 0.7687 - accuracy: 0.5382 - val_loss: 0.6610 - val_accuracy: 0.6486\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7161 - accuracy: 0.5596 - val_loss: 0.6330 - val_accuracy: 0.7027\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6791 - accuracy: 0.6147 - val_loss: 0.6146 - val_accuracy: 0.7838\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7048 - accuracy: 0.6361 - val_loss: 0.6226 - val_accuracy: 0.7027\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6433 - accuracy: 0.6483 - val_loss: 0.5983 - val_accuracy: 0.7838\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6394 - accuracy: 0.6606 - val_loss: 0.5859 - val_accuracy: 0.8108\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6314 - accuracy: 0.6667 - val_loss: 0.6165 - val_accuracy: 0.6216\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5783 - accuracy: 0.6820 - val_loss: 0.6059 - val_accuracy: 0.6486\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6053 - accuracy: 0.6758 - val_loss: 0.5602 - val_accuracy: 0.7027\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6029 - accuracy: 0.7187 - val_loss: 0.5365 - val_accuracy: 0.7838\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5460 - accuracy: 0.7584 - val_loss: 0.5247 - val_accuracy: 0.7027\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5609 - accuracy: 0.7645 - val_loss: 0.5440 - val_accuracy: 0.7297\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5191 - accuracy: 0.7615 - val_loss: 0.5039 - val_accuracy: 0.7568\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5412 - accuracy: 0.7401 - val_loss: 0.4806 - val_accuracy: 0.8108\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5508 - accuracy: 0.7431 - val_loss: 0.4752 - val_accuracy: 0.8108\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5319 - accuracy: 0.7370 - val_loss: 0.4803 - val_accuracy: 0.8108\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4868 - accuracy: 0.7584 - val_loss: 0.4863 - val_accuracy: 0.7838\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4560 - accuracy: 0.8104 - val_loss: 0.4803 - val_accuracy: 0.7838\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4747 - accuracy: 0.7676 - val_loss: 0.4882 - val_accuracy: 0.7568\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5387 - accuracy: 0.7584 - val_loss: 0.5348 - val_accuracy: 0.7297\n",
      "getting accuracy of participant  11\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.468333333333333\n",
      "TL to the participant :  12\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 167ms/step - loss: 0.8165 - accuracy: 0.5046 - val_loss: 0.7291 - val_accuracy: 0.5135\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7506 - accuracy: 0.5321 - val_loss: 0.6913 - val_accuracy: 0.5405\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7667 - accuracy: 0.5046 - val_loss: 0.6931 - val_accuracy: 0.6216\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7289 - accuracy: 0.5382 - val_loss: 0.6801 - val_accuracy: 0.6486\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7093 - accuracy: 0.5413 - val_loss: 0.6734 - val_accuracy: 0.7027\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6922 - accuracy: 0.5505 - val_loss: 0.6577 - val_accuracy: 0.5946\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6821 - accuracy: 0.6086 - val_loss: 0.6452 - val_accuracy: 0.6216\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6437 - accuracy: 0.6300 - val_loss: 0.6372 - val_accuracy: 0.6216\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6726 - accuracy: 0.6024 - val_loss: 0.6040 - val_accuracy: 0.6486\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6838 - accuracy: 0.5872 - val_loss: 0.5883 - val_accuracy: 0.7027\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6482 - accuracy: 0.6024 - val_loss: 0.5873 - val_accuracy: 0.7297\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6389 - accuracy: 0.6575 - val_loss: 0.5785 - val_accuracy: 0.7838\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6163 - accuracy: 0.6606 - val_loss: 0.5590 - val_accuracy: 0.8108\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6077 - accuracy: 0.6300 - val_loss: 0.5343 - val_accuracy: 0.8108\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6044 - accuracy: 0.6636 - val_loss: 0.5214 - val_accuracy: 0.8108\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6002 - accuracy: 0.6728 - val_loss: 0.5021 - val_accuracy: 0.8649\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5530 - accuracy: 0.7339 - val_loss: 0.4861 - val_accuracy: 0.8649\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5508 - accuracy: 0.7187 - val_loss: 0.4566 - val_accuracy: 0.8649\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5444 - accuracy: 0.7125 - val_loss: 0.4279 - val_accuracy: 0.8649\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5494 - accuracy: 0.7584 - val_loss: 0.4044 - val_accuracy: 0.9189\n",
      "getting accuracy of participant  12\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4568181818181813\n",
      "TL to the participant :  13\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 74ms/step - loss: 0.8433 - accuracy: 0.5138 - val_loss: 0.7273 - val_accuracy: 0.4865\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7311 - accuracy: 0.5596 - val_loss: 0.7031 - val_accuracy: 0.5135\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6906 - accuracy: 0.5872 - val_loss: 0.7006 - val_accuracy: 0.5405\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7204 - accuracy: 0.5596 - val_loss: 0.6995 - val_accuracy: 0.5135\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6638 - accuracy: 0.6269 - val_loss: 0.7006 - val_accuracy: 0.5405\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6885 - accuracy: 0.5963 - val_loss: 0.6933 - val_accuracy: 0.5676\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6599 - accuracy: 0.6239 - val_loss: 0.6785 - val_accuracy: 0.5405\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6410 - accuracy: 0.6575 - val_loss: 0.6464 - val_accuracy: 0.5405\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6386 - accuracy: 0.6391 - val_loss: 0.6180 - val_accuracy: 0.5135\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6291 - accuracy: 0.6636 - val_loss: 0.6141 - val_accuracy: 0.5946\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6316 - accuracy: 0.6361 - val_loss: 0.6120 - val_accuracy: 0.6216\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6097 - accuracy: 0.6850 - val_loss: 0.5970 - val_accuracy: 0.6486\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6001 - accuracy: 0.6881 - val_loss: 0.5780 - val_accuracy: 0.6486\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5512 - accuracy: 0.7339 - val_loss: 0.5677 - val_accuracy: 0.6757\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5893 - accuracy: 0.7217 - val_loss: 0.5703 - val_accuracy: 0.6757\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5914 - accuracy: 0.7156 - val_loss: 0.5731 - val_accuracy: 0.6757\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5759 - accuracy: 0.7003 - val_loss: 0.5681 - val_accuracy: 0.7027\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5588 - accuracy: 0.6881 - val_loss: 0.5544 - val_accuracy: 0.6486\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6023 - accuracy: 0.6820 - val_loss: 0.5448 - val_accuracy: 0.7297\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5399 - accuracy: 0.7278 - val_loss: 0.5432 - val_accuracy: 0.7838\n",
      "getting accuracy of participant  13\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.3946428571428575\n",
      "TL to the participant :  14\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 79ms/step - loss: 0.8113 - accuracy: 0.4954 - val_loss: 0.7116 - val_accuracy: 0.4595\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7348 - accuracy: 0.5535 - val_loss: 0.7065 - val_accuracy: 0.5946\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7940 - accuracy: 0.5046 - val_loss: 0.6883 - val_accuracy: 0.4595\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7745 - accuracy: 0.4862 - val_loss: 0.6846 - val_accuracy: 0.4865\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7201 - accuracy: 0.5291 - val_loss: 0.6743 - val_accuracy: 0.4865\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6991 - accuracy: 0.5657 - val_loss: 0.7431 - val_accuracy: 0.6216\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7292 - accuracy: 0.5688 - val_loss: 0.7187 - val_accuracy: 0.6486\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6970 - accuracy: 0.5688 - val_loss: 0.7085 - val_accuracy: 0.5946\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7053 - accuracy: 0.5413 - val_loss: 0.6934 - val_accuracy: 0.5405\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6706 - accuracy: 0.6086 - val_loss: 0.6893 - val_accuracy: 0.5135\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7061 - accuracy: 0.5596 - val_loss: 0.7039 - val_accuracy: 0.5676\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7118 - accuracy: 0.5933 - val_loss: 0.7028 - val_accuracy: 0.5405\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6864 - accuracy: 0.5810 - val_loss: 0.7402 - val_accuracy: 0.6216\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6679 - accuracy: 0.6300 - val_loss: 0.7773 - val_accuracy: 0.6216\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6435 - accuracy: 0.6575 - val_loss: 0.7706 - val_accuracy: 0.6216\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6414 - accuracy: 0.6453 - val_loss: 0.7655 - val_accuracy: 0.6216\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6461 - accuracy: 0.6422 - val_loss: 0.7651 - val_accuracy: 0.6216\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6651 - accuracy: 0.6300 - val_loss: 0.7588 - val_accuracy: 0.5676\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6407 - accuracy: 0.6300 - val_loss: 0.7700 - val_accuracy: 0.6216\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6654 - accuracy: 0.6453 - val_loss: 0.7599 - val_accuracy: 0.5946\n",
      "getting accuracy of participant  14\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.5346153846153843\n",
      "TL to the participant :  15\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 81ms/step - loss: 0.7981 - accuracy: 0.5168 - val_loss: 0.6993 - val_accuracy: 0.5676\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7368 - accuracy: 0.5352 - val_loss: 0.6887 - val_accuracy: 0.5676\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7005 - accuracy: 0.5688 - val_loss: 0.6676 - val_accuracy: 0.5405\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6618 - accuracy: 0.6239 - val_loss: 0.6518 - val_accuracy: 0.6216\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6573 - accuracy: 0.6116 - val_loss: 0.6413 - val_accuracy: 0.6486\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6475 - accuracy: 0.6758 - val_loss: 0.6174 - val_accuracy: 0.6486\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6028 - accuracy: 0.6881 - val_loss: 0.5879 - val_accuracy: 0.7568\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5739 - accuracy: 0.6820 - val_loss: 0.5698 - val_accuracy: 0.7838\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5328 - accuracy: 0.7431 - val_loss: 0.5476 - val_accuracy: 0.7838\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5418 - accuracy: 0.7187 - val_loss: 0.5296 - val_accuracy: 0.7568\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5155 - accuracy: 0.7554 - val_loss: 0.5039 - val_accuracy: 0.7568\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4989 - accuracy: 0.7615 - val_loss: 0.4829 - val_accuracy: 0.7568\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4402 - accuracy: 0.8165 - val_loss: 0.4503 - val_accuracy: 0.7568\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4146 - accuracy: 0.7920 - val_loss: 0.4443 - val_accuracy: 0.7568\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4526 - accuracy: 0.7920 - val_loss: 0.4480 - val_accuracy: 0.7838\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3699 - accuracy: 0.8502 - val_loss: 0.4458 - val_accuracy: 0.7838\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4332 - accuracy: 0.8012 - val_loss: 0.4105 - val_accuracy: 0.7838\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.4223 - accuracy: 0.8043 - val_loss: 0.4013 - val_accuracy: 0.7838\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3823 - accuracy: 0.8379 - val_loss: 0.3944 - val_accuracy: 0.8108\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3560 - accuracy: 0.8716 - val_loss: 0.3656 - val_accuracy: 0.8108\n",
      "getting accuracy of participant  15\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.3600000000000003\n",
      "TL to the participant :  16\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 82ms/step - loss: 0.8407 - accuracy: 0.4954 - val_loss: 0.6956 - val_accuracy: 0.5946\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7325 - accuracy: 0.5657 - val_loss: 0.6861 - val_accuracy: 0.6216\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6848 - accuracy: 0.6697 - val_loss: 0.6748 - val_accuracy: 0.6757\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6346 - accuracy: 0.6544 - val_loss: 0.6868 - val_accuracy: 0.6757\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6001 - accuracy: 0.6972 - val_loss: 0.6618 - val_accuracy: 0.7297\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5179 - accuracy: 0.7554 - val_loss: 0.6589 - val_accuracy: 0.7838\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5298 - accuracy: 0.7462 - val_loss: 0.6299 - val_accuracy: 0.7568\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4631 - accuracy: 0.8073 - val_loss: 0.5320 - val_accuracy: 0.8108\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4406 - accuracy: 0.8073 - val_loss: 0.4596 - val_accuracy: 0.8108\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4343 - accuracy: 0.8012 - val_loss: 0.4431 - val_accuracy: 0.8378\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4123 - accuracy: 0.8318 - val_loss: 0.4298 - val_accuracy: 0.8108\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.3921 - accuracy: 0.8318 - val_loss: 0.4227 - val_accuracy: 0.8378\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3515 - accuracy: 0.8532 - val_loss: 0.4147 - val_accuracy: 0.8378\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3573 - accuracy: 0.8654 - val_loss: 0.4002 - val_accuracy: 0.8378\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3279 - accuracy: 0.8838 - val_loss: 0.3855 - val_accuracy: 0.8378\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3242 - accuracy: 0.8654 - val_loss: 0.3682 - val_accuracy: 0.8649\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2464 - accuracy: 0.9358 - val_loss: 0.3473 - val_accuracy: 0.8649\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2683 - accuracy: 0.9174 - val_loss: 0.3278 - val_accuracy: 0.8919\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2765 - accuracy: 0.8869 - val_loss: 0.3251 - val_accuracy: 0.8649\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2428 - accuracy: 0.9052 - val_loss: 0.3338 - val_accuracy: 0.8649\n",
      "getting accuracy of participant  16\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.3703703703703707\n",
      "TL to the participant :  17\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 82ms/step - loss: 0.7883 - accuracy: 0.4954 - val_loss: 0.6982 - val_accuracy: 0.5676\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6786 - accuracy: 0.6391 - val_loss: 0.6986 - val_accuracy: 0.5946\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6992 - accuracy: 0.6177 - val_loss: 0.6943 - val_accuracy: 0.5946\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6976 - accuracy: 0.6055 - val_loss: 0.6730 - val_accuracy: 0.6486\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6837 - accuracy: 0.6177 - val_loss: 0.6826 - val_accuracy: 0.5676\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6665 - accuracy: 0.6391 - val_loss: 0.7047 - val_accuracy: 0.5405\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6279 - accuracy: 0.6606 - val_loss: 0.6928 - val_accuracy: 0.5676\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6530 - accuracy: 0.6453 - val_loss: 0.7074 - val_accuracy: 0.5405\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5928 - accuracy: 0.6911 - val_loss: 0.7174 - val_accuracy: 0.5405\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5940 - accuracy: 0.6911 - val_loss: 0.7041 - val_accuracy: 0.4865\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5674 - accuracy: 0.7401 - val_loss: 0.6959 - val_accuracy: 0.5405\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5711 - accuracy: 0.7401 - val_loss: 0.6798 - val_accuracy: 0.5676\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5968 - accuracy: 0.7095 - val_loss: 0.6415 - val_accuracy: 0.6216\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5797 - accuracy: 0.6881 - val_loss: 0.6436 - val_accuracy: 0.6216\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.5676 - accuracy: 0.6942 - val_loss: 0.6522 - val_accuracy: 0.5946\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5658 - accuracy: 0.7309 - val_loss: 0.6531 - val_accuracy: 0.6216\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5157 - accuracy: 0.7523 - val_loss: 0.7018 - val_accuracy: 0.5405\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5665 - accuracy: 0.7187 - val_loss: 0.7084 - val_accuracy: 0.5946\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5098 - accuracy: 0.7584 - val_loss: 0.7351 - val_accuracy: 0.5405\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5395 - accuracy: 0.7462 - val_loss: 0.7693 - val_accuracy: 0.5405\n",
      "getting accuracy of participant  17\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4\n",
      "TL to the participant :  18\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 58ms/step - loss: 0.8053 - accuracy: 0.5382 - val_loss: 0.6712 - val_accuracy: 0.5946\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7298 - accuracy: 0.5566 - val_loss: 0.6644 - val_accuracy: 0.5946\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7165 - accuracy: 0.5657 - val_loss: 0.6558 - val_accuracy: 0.6757\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6986 - accuracy: 0.5963 - val_loss: 0.6375 - val_accuracy: 0.6757\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6336 - accuracy: 0.6514 - val_loss: 0.6126 - val_accuracy: 0.7027\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5967 - accuracy: 0.6483 - val_loss: 0.6051 - val_accuracy: 0.7568\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5820 - accuracy: 0.6728 - val_loss: 0.5961 - val_accuracy: 0.7568\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5482 - accuracy: 0.7217 - val_loss: 0.6168 - val_accuracy: 0.7297\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5666 - accuracy: 0.7095 - val_loss: 0.6371 - val_accuracy: 0.7297\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.5206 - accuracy: 0.7370 - val_loss: 0.6527 - val_accuracy: 0.7027\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4620 - accuracy: 0.7676 - val_loss: 0.6269 - val_accuracy: 0.7027\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5050 - accuracy: 0.7431 - val_loss: 0.6279 - val_accuracy: 0.7027\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4923 - accuracy: 0.7859 - val_loss: 0.6269 - val_accuracy: 0.7027\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4884 - accuracy: 0.7859 - val_loss: 0.6023 - val_accuracy: 0.7568\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4920 - accuracy: 0.7890 - val_loss: 0.6043 - val_accuracy: 0.7568\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.6004 - val_accuracy: 0.7838\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4973 - accuracy: 0.7768 - val_loss: 0.6112 - val_accuracy: 0.7838\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4328 - accuracy: 0.8104 - val_loss: 0.6215 - val_accuracy: 0.7568\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4761 - accuracy: 0.7829 - val_loss: 0.6318 - val_accuracy: 0.7568\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4384 - accuracy: 0.8012 - val_loss: 0.6434 - val_accuracy: 0.7297\n",
      "getting accuracy of participant  18\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4222222222222223\n",
      "TL to the participant :  19\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 80ms/step - loss: 0.7788 - accuracy: 0.5138 - val_loss: 0.6914 - val_accuracy: 0.4865\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7620 - accuracy: 0.5168 - val_loss: 0.6692 - val_accuracy: 0.5405\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7138 - accuracy: 0.5749 - val_loss: 0.6700 - val_accuracy: 0.5405\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7309 - accuracy: 0.5810 - val_loss: 0.6613 - val_accuracy: 0.5405\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7044 - accuracy: 0.5780 - val_loss: 0.6468 - val_accuracy: 0.6216\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7007 - accuracy: 0.5688 - val_loss: 0.6358 - val_accuracy: 0.6216\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6824 - accuracy: 0.5872 - val_loss: 0.6321 - val_accuracy: 0.6216\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6465 - accuracy: 0.6361 - val_loss: 0.6292 - val_accuracy: 0.6486\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7030 - accuracy: 0.5719 - val_loss: 0.6158 - val_accuracy: 0.7027\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6622 - accuracy: 0.6361 - val_loss: 0.6004 - val_accuracy: 0.7568\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6207 - accuracy: 0.6820 - val_loss: 0.5819 - val_accuracy: 0.8108\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6472 - accuracy: 0.6361 - val_loss: 0.5699 - val_accuracy: 0.7568\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6471 - accuracy: 0.6514 - val_loss: 0.5763 - val_accuracy: 0.7027\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6302 - accuracy: 0.6575 - val_loss: 0.5875 - val_accuracy: 0.7027\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6242 - accuracy: 0.6789 - val_loss: 0.5749 - val_accuracy: 0.7568\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6318 - accuracy: 0.6422 - val_loss: 0.5608 - val_accuracy: 0.7838\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6559 - accuracy: 0.6789 - val_loss: 0.5566 - val_accuracy: 0.7838\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6328 - accuracy: 0.6514 - val_loss: 0.5686 - val_accuracy: 0.7568\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6167 - accuracy: 0.6544 - val_loss: 0.5709 - val_accuracy: 0.7838\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6127 - accuracy: 0.6636 - val_loss: 0.5695 - val_accuracy: 0.7568\n",
      "getting accuracy of participant  19\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4606060606060607\n",
      "TL to the participant :  20\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 82ms/step - loss: 0.7976 - accuracy: 0.4954 - val_loss: 0.6531 - val_accuracy: 0.5946\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7152 - accuracy: 0.5933 - val_loss: 0.6037 - val_accuracy: 0.7568\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6321 - accuracy: 0.6361 - val_loss: 0.5848 - val_accuracy: 0.7838\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.6026 - accuracy: 0.7156 - val_loss: 0.5601 - val_accuracy: 0.8108\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.5949 - accuracy: 0.7003 - val_loss: 0.5510 - val_accuracy: 0.7568\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5601 - accuracy: 0.7523 - val_loss: 0.5343 - val_accuracy: 0.7838\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5287 - accuracy: 0.7309 - val_loss: 0.4972 - val_accuracy: 0.7838\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5235 - accuracy: 0.7523 - val_loss: 0.4732 - val_accuracy: 0.7568\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4457 - accuracy: 0.8104 - val_loss: 0.4526 - val_accuracy: 0.7568\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4231 - accuracy: 0.8196 - val_loss: 0.4203 - val_accuracy: 0.8378\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4416 - accuracy: 0.8012 - val_loss: 0.4156 - val_accuracy: 0.8649\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3979 - accuracy: 0.8287 - val_loss: 0.4163 - val_accuracy: 0.8649\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3737 - accuracy: 0.8624 - val_loss: 0.3836 - val_accuracy: 0.8649\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3112 - accuracy: 0.8532 - val_loss: 0.3818 - val_accuracy: 0.8649\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3540 - accuracy: 0.8624 - val_loss: 0.4114 - val_accuracy: 0.8649\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3317 - accuracy: 0.8471 - val_loss: 0.4301 - val_accuracy: 0.8649\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3169 - accuracy: 0.8654 - val_loss: 0.3986 - val_accuracy: 0.8649\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3479 - accuracy: 0.8502 - val_loss: 0.3917 - val_accuracy: 0.8649\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3267 - accuracy: 0.8563 - val_loss: 0.4014 - val_accuracy: 0.8649\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3257 - accuracy: 0.8654 - val_loss: 0.4463 - val_accuracy: 0.8378\n",
      "getting accuracy of participant  20\n",
      "143/143 [==============================] - 1s 5ms/step\n",
      "meannnnnn long 1.3935185185185186\n",
      "TL to the participant :  21\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 82ms/step - loss: 0.8237 - accuracy: 0.5015 - val_loss: 0.7124 - val_accuracy: 0.5946\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7787 - accuracy: 0.5107 - val_loss: 0.6957 - val_accuracy: 0.5676\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.7364 - accuracy: 0.5260 - val_loss: 0.6963 - val_accuracy: 0.5405\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.7445 - accuracy: 0.5352 - val_loss: 0.7248 - val_accuracy: 0.5405\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6977 - accuracy: 0.5902 - val_loss: 0.6906 - val_accuracy: 0.5405\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6861 - accuracy: 0.5749 - val_loss: 0.6631 - val_accuracy: 0.6216\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6496 - accuracy: 0.6606 - val_loss: 0.6745 - val_accuracy: 0.6757\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6633 - accuracy: 0.6177 - val_loss: 0.6761 - val_accuracy: 0.6486\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6368 - accuracy: 0.6636 - val_loss: 0.7081 - val_accuracy: 0.5946\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6575 - accuracy: 0.6239 - val_loss: 0.7191 - val_accuracy: 0.5405\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6527 - accuracy: 0.6361 - val_loss: 0.7301 - val_accuracy: 0.5946\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6332 - accuracy: 0.6606 - val_loss: 0.6952 - val_accuracy: 0.6757\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6051 - accuracy: 0.6575 - val_loss: 0.6705 - val_accuracy: 0.7027\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6049 - accuracy: 0.6606 - val_loss: 0.6584 - val_accuracy: 0.7027\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6045 - accuracy: 0.6697 - val_loss: 0.6600 - val_accuracy: 0.7027\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6008 - accuracy: 0.6820 - val_loss: 0.6759 - val_accuracy: 0.7027\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5843 - accuracy: 0.6789 - val_loss: 0.6684 - val_accuracy: 0.6757\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5267 - accuracy: 0.7462 - val_loss: 0.6534 - val_accuracy: 0.7027\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5930 - accuracy: 0.7064 - val_loss: 0.6383 - val_accuracy: 0.7568\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5249 - accuracy: 0.7645 - val_loss: 0.6358 - val_accuracy: 0.7297\n",
      "getting accuracy of participant  21\n",
      "143/143 [==============================] - 1s 5ms/step\n",
      "meannnnnn long 1.553333333333333\n",
      "TL to the participant :  22\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 81ms/step - loss: 0.8316 - accuracy: 0.4648 - val_loss: 0.6795 - val_accuracy: 0.6216\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7399 - accuracy: 0.5352 - val_loss: 0.6775 - val_accuracy: 0.5135\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6949 - accuracy: 0.6055 - val_loss: 0.6694 - val_accuracy: 0.5946\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7289 - accuracy: 0.5382 - val_loss: 0.6682 - val_accuracy: 0.6486\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.7356 - accuracy: 0.5168 - val_loss: 0.6555 - val_accuracy: 0.6757\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7259 - accuracy: 0.5688 - val_loss: 0.6457 - val_accuracy: 0.6757\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7252 - accuracy: 0.5872 - val_loss: 0.6436 - val_accuracy: 0.7027\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7078 - accuracy: 0.5413 - val_loss: 0.6447 - val_accuracy: 0.5946\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6569 - accuracy: 0.6177 - val_loss: 0.6352 - val_accuracy: 0.7568\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6738 - accuracy: 0.6361 - val_loss: 0.6287 - val_accuracy: 0.7568\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6934 - accuracy: 0.5902 - val_loss: 0.6207 - val_accuracy: 0.7568\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6331 - accuracy: 0.6544 - val_loss: 0.6110 - val_accuracy: 0.8108\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6403 - accuracy: 0.6330 - val_loss: 0.6049 - val_accuracy: 0.7838\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6156 - accuracy: 0.7003 - val_loss: 0.5952 - val_accuracy: 0.7568\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6214 - accuracy: 0.6758 - val_loss: 0.5868 - val_accuracy: 0.7838\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5903 - accuracy: 0.6911 - val_loss: 0.5797 - val_accuracy: 0.7568\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6042 - accuracy: 0.6697 - val_loss: 0.5696 - val_accuracy: 0.7568\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5937 - accuracy: 0.7217 - val_loss: 0.5646 - val_accuracy: 0.7568\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6015 - accuracy: 0.7095 - val_loss: 0.5612 - val_accuracy: 0.7568\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5731 - accuracy: 0.6789 - val_loss: 0.5555 - val_accuracy: 0.7838\n",
      "getting accuracy of participant  22\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4333333333333333\n",
      "TL to the participant :  23\n",
      "(3990, 1, 8, 150)\n",
      "(4560, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 62ms/step - loss: 0.7692 - accuracy: 0.5229 - val_loss: 0.6664 - val_accuracy: 0.5946\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7078 - accuracy: 0.5902 - val_loss: 0.6154 - val_accuracy: 0.6757\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6505 - accuracy: 0.6544 - val_loss: 0.5599 - val_accuracy: 0.7838\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5848 - accuracy: 0.7217 - val_loss: 0.5085 - val_accuracy: 0.8649\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5130 - accuracy: 0.7829 - val_loss: 0.4555 - val_accuracy: 0.8649\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.5009 - accuracy: 0.7462 - val_loss: 0.4018 - val_accuracy: 0.8919\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.4368 - accuracy: 0.8196 - val_loss: 0.3529 - val_accuracy: 0.9189\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.4015 - accuracy: 0.8287 - val_loss: 0.3185 - val_accuracy: 0.9189\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3886 - accuracy: 0.8073 - val_loss: 0.2917 - val_accuracy: 0.9189\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3539 - accuracy: 0.8410 - val_loss: 0.2623 - val_accuracy: 0.8919\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3380 - accuracy: 0.8746 - val_loss: 0.2408 - val_accuracy: 0.9189\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3521 - accuracy: 0.8532 - val_loss: 0.2261 - val_accuracy: 0.9189\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3273 - accuracy: 0.8624 - val_loss: 0.2126 - val_accuracy: 0.9189\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3079 - accuracy: 0.8685 - val_loss: 0.2003 - val_accuracy: 0.9459\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3052 - accuracy: 0.8899 - val_loss: 0.1876 - val_accuracy: 0.9459\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.3104 - accuracy: 0.8654 - val_loss: 0.1894 - val_accuracy: 0.9459\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3492 - accuracy: 0.8563 - val_loss: 0.1910 - val_accuracy: 0.9459\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3132 - accuracy: 0.8716 - val_loss: 0.1856 - val_accuracy: 0.9459\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2776 - accuracy: 0.8838 - val_loss: 0.1822 - val_accuracy: 0.9459\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3037 - accuracy: 0.8899 - val_loss: 0.1869 - val_accuracy: 0.9189\n",
      "getting accuracy of participant  23\n",
      "143/143 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.3716216216216217\n",
      "[0.89523826 0.8462599  0.69106158 0.8313154  0.84752368 0.8456501\n",
      " 0.7619662  0.86086857 0.70809177 0.56409962 0.80571267 0.70933788\n",
      " 0.7264918  0.77225325 0.57929157 0.85371889 0.869229   0.70058859\n",
      " 0.74224936 0.68108385 0.84816883 0.71599265 0.66564444 0.88469492]\n",
      "[4.78186965 5.22679114 5.14599991 5.35847068 4.29600048 5.18290138\n",
      " 5.20080042 5.13674784 4.72951531 4.93313622 5.07571769 4.95785356\n",
      " 5.50911522 4.78821564 5.14699841 5.14080095 5.21308017 5.13605857\n",
      " 4.26191449 5.08705473 5.23581696 5.25912786 5.15364885 4.87975502]\n",
      "[2.63643765 2.71768165 3.55500126 2.73500156 2.61099982 2.78719354\n",
      " 2.84727955 2.83912134 2.76054573 3.0132432  2.63436794 2.83299828\n",
      " 2.99292064 2.90574551 3.11433315 3.00209212 2.59699917 2.98012114\n",
      " 2.80716038 3.10320163 2.64702535 3.24332619 2.63038039 2.06823826]\n",
      "[0.98 0.85 0.75 0.85 0.95 0.98 0.72 0.95 0.75 0.38 0.9  0.8  0.82 0.88\n",
      " 0.4  0.95 0.92 0.75 0.78 0.55 1.   0.7  0.7  1.  ]\n"
     ]
    }
   ],
   "source": [
    "n_cal = 7\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "CNN_accuracy_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_train_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_test_code_perso = np.zeros(nb_part)\n",
    "CNN_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*60)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "\n",
    "    X_train = np.expand_dims(X[i][:nb_samples_windows],1)\n",
    "    Y_train = y[i][:nb_samples_windows]\n",
    "    # Y_train = np.vstack((Y_train,np.abs(1-Y_train))).T\n",
    "    domains_train = domains[i][:nb_samples_windows]\n",
    "    X_test = np.expand_dims(X[i][nb_samples_windows:],1)\n",
    "    Y_test = np.vstack((y[i][nb_samples_windows:],np.abs(1-y[i][nb_samples_windows:]))).T\n",
    "    labels_code_test = labels_code_list[i][n_cal*n_class:]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    X_std = X_train.std(axis=0)\n",
    "    X_train /= X_std + 1e-8\n",
    "    X_std = X_test.std(axis=0)\n",
    "    X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    X_train,Y_train,domains_train = balance(X_train,Y_train,domains_train)\n",
    "    Y_train = np.vstack((Y_train,np.abs(1-Y_train))).T\n",
    "    n_samples_windows = X_train.shape[-1]\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = basearchi(windows_size = n_samples_windows, n_channel_input = X_train.shape[2])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr, amsgrad=True)\n",
    "    clf.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "    history_list.append(clf.fit(np.array(x_train), y_train,\n",
    "                    batch_size=batchsize, epochs=epochs,\n",
    "                    validation_data=(np.array(x_val), y_val), shuffle=True))\n",
    "    CNN_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)[:,0]\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([0 if y[0] == 0 else 1 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    CNN_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, fps=60, consecutive=50, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    CNN_tps_test_code_perso[i] = time.time() - start\n",
    "    CNN_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(CNN_accuracy_perso)\n",
    "print(CNN_tps_train_code_perso)\n",
    "print(CNN_tps_test_code_perso)\n",
    "print(CNN_accuracy_code_perso)\n",
    "# pd.DataFrame(CNN_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score/SS_score.csv\")\n",
    "# pd.DataFrame(CNN_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score_code/SS_score_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_train_code/SS_tps_train_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_test_code/SS_tps_test_code.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.8045833333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7958333333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([0.98, 0.85, 0.75, 0.85, 0.95, 0.98, 0.72, 0.95, 0.75, 0.38, 0.9,  0.8,  0.82, 0.88,\n",
    " 0.4,  0.95, 0.92, 0.75, 0.78, 0.55, 1,0.7,  0.7,  1  ]))\n",
    "np.mean([1,0.98, 0.88, 0.85, 0.98, 0.9,  0.68, 0.92, 0.68, 0.52, 0.8,  0.65, 0.6,  0.88,\n",
    " 0.32, 0.92, 0.82, 0.9,  0.72, 0.65, 0.95, 0.9,  0.6,  1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 3ms/step\n",
      "0.9427549194991056\n",
      "(4095,)\n",
      "(35,)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "labels_pred_accumul,labels_code_test\n",
    "\n",
    "pred_train = clf.predict(X_train)[:,0]\n",
    "y_pred_train = np.array([1 if (y >= 0.5) else 0 for y in pred_train])\n",
    "y_train_norm = np.array([0 if y[0] == 0 else 1 for y in Y_train])\n",
    "\n",
    "print(balanced_accuracy_score(y_train_norm,y_pred_train))\n",
    "print(y_pred_train.shape)\n",
    "\n",
    "labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "    y_train_norm, codes, min_len=30, fps=60, consecutive=50, window_size=window_size\n",
    ")\n",
    "print(labels_pred_accumul.shape)\n",
    "print(np.round(accuracy_score(labels_code_list[i][:7*5][labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((np.array(codes[1]),y_pred_train[:117]))\n",
    "print((np.array(codes[0]),y_pred_train[117:117*2]))\n",
    "\n",
    "labels_code_list[i],labels_pred_accumul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 7s 17ms/step - loss: 0.6562 - accuracy: 0.6245 - val_loss: 0.5792 - val_accuracy: 0.7074\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5955 - accuracy: 0.6898 - val_loss: 0.5627 - val_accuracy: 0.7207\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5787 - accuracy: 0.7033 - val_loss: 0.5620 - val_accuracy: 0.7107\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5749 - accuracy: 0.7072 - val_loss: 0.5528 - val_accuracy: 0.7224\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5647 - accuracy: 0.7176 - val_loss: 0.5500 - val_accuracy: 0.7285\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.5579 - accuracy: 0.7222 - val_loss: 0.5513 - val_accuracy: 0.7285\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.5580 - accuracy: 0.7252 - val_loss: 0.5436 - val_accuracy: 0.7369\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.5553 - accuracy: 0.7211 - val_loss: 0.5454 - val_accuracy: 0.7285\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5551 - accuracy: 0.7250 - val_loss: 0.5439 - val_accuracy: 0.7336\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5495 - accuracy: 0.7290 - val_loss: 0.5385 - val_accuracy: 0.7330\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5492 - accuracy: 0.7274 - val_loss: 0.5409 - val_accuracy: 0.7414\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5503 - accuracy: 0.7303 - val_loss: 0.5388 - val_accuracy: 0.7363\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5459 - accuracy: 0.7329 - val_loss: 0.5384 - val_accuracy: 0.7402\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.5442 - accuracy: 0.7357 - val_loss: 0.5381 - val_accuracy: 0.7358\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.5436 - accuracy: 0.7332 - val_loss: 0.5315 - val_accuracy: 0.7480\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5419 - accuracy: 0.7335 - val_loss: 0.5310 - val_accuracy: 0.7486\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.5434 - accuracy: 0.7312 - val_loss: 0.5332 - val_accuracy: 0.7408\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5432 - accuracy: 0.7337 - val_loss: 0.5346 - val_accuracy: 0.7313\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5372 - accuracy: 0.7378 - val_loss: 0.5298 - val_accuracy: 0.7453\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5414 - accuracy: 0.7323 - val_loss: 0.5325 - val_accuracy: 0.7414\n",
      "getting accuracy of participant  0\n",
      "268/268 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.439236111111111\n",
      "TL to the participant :  1\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 7s 18ms/step - loss: 0.6643 - accuracy: 0.6220 - val_loss: 0.5649 - val_accuracy: 0.7269\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.6001 - accuracy: 0.6869 - val_loss: 0.5395 - val_accuracy: 0.7297\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5828 - accuracy: 0.7051 - val_loss: 0.5279 - val_accuracy: 0.7408\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5717 - accuracy: 0.7090 - val_loss: 0.5235 - val_accuracy: 0.7475\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.5706 - accuracy: 0.7149 - val_loss: 0.5242 - val_accuracy: 0.7508\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5668 - accuracy: 0.7199 - val_loss: 0.5175 - val_accuracy: 0.7553\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5649 - accuracy: 0.7127 - val_loss: 0.5190 - val_accuracy: 0.7553\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5628 - accuracy: 0.7186 - val_loss: 0.5234 - val_accuracy: 0.7570\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5590 - accuracy: 0.7211 - val_loss: 0.5119 - val_accuracy: 0.7570\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5579 - accuracy: 0.7237 - val_loss: 0.5147 - val_accuracy: 0.7514\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5546 - accuracy: 0.7224 - val_loss: 0.5097 - val_accuracy: 0.7575\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5554 - accuracy: 0.7253 - val_loss: 0.5118 - val_accuracy: 0.7586\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5517 - accuracy: 0.7279 - val_loss: 0.5081 - val_accuracy: 0.7536\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5547 - accuracy: 0.7249 - val_loss: 0.5117 - val_accuracy: 0.7631\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5506 - accuracy: 0.7291 - val_loss: 0.5098 - val_accuracy: 0.7592\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5530 - accuracy: 0.7238 - val_loss: 0.5082 - val_accuracy: 0.7547\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5458 - accuracy: 0.7310 - val_loss: 0.5092 - val_accuracy: 0.7559\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5506 - accuracy: 0.7263 - val_loss: 0.5132 - val_accuracy: 0.7592\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5520 - accuracy: 0.7276 - val_loss: 0.5078 - val_accuracy: 0.7564\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.5491 - accuracy: 0.7295 - val_loss: 0.5107 - val_accuracy: 0.7564\n",
      "getting accuracy of participant  1\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.425\n",
      "TL to the participant :  2\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 12ms/step - loss: 0.6625 - accuracy: 0.6113 - val_loss: 0.5947 - val_accuracy: 0.6945\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5799 - accuracy: 0.7034 - val_loss: 0.5578 - val_accuracy: 0.7230\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5649 - accuracy: 0.7178 - val_loss: 0.5512 - val_accuracy: 0.7246\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5555 - accuracy: 0.7262 - val_loss: 0.5393 - val_accuracy: 0.7313\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5495 - accuracy: 0.7286 - val_loss: 0.5395 - val_accuracy: 0.7330\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5491 - accuracy: 0.7307 - val_loss: 0.5364 - val_accuracy: 0.7386\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5421 - accuracy: 0.7339 - val_loss: 0.5342 - val_accuracy: 0.7336\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5375 - accuracy: 0.7380 - val_loss: 0.5375 - val_accuracy: 0.7302\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5358 - accuracy: 0.7389 - val_loss: 0.5364 - val_accuracy: 0.7363\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5370 - accuracy: 0.7389 - val_loss: 0.5365 - val_accuracy: 0.7369\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5354 - accuracy: 0.7396 - val_loss: 0.5302 - val_accuracy: 0.7391\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5314 - accuracy: 0.7438 - val_loss: 0.5313 - val_accuracy: 0.7419\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5339 - accuracy: 0.7411 - val_loss: 0.5366 - val_accuracy: 0.7369\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5295 - accuracy: 0.7446 - val_loss: 0.5345 - val_accuracy: 0.7352\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5288 - accuracy: 0.7440 - val_loss: 0.5318 - val_accuracy: 0.7369\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5272 - accuracy: 0.7443 - val_loss: 0.5261 - val_accuracy: 0.7425\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5302 - accuracy: 0.7427 - val_loss: 0.5302 - val_accuracy: 0.7397\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5260 - accuracy: 0.7439 - val_loss: 0.5282 - val_accuracy: 0.7441\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5262 - accuracy: 0.7451 - val_loss: 0.5290 - val_accuracy: 0.7363\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5269 - accuracy: 0.7432 - val_loss: 0.5261 - val_accuracy: 0.7453\n",
      "getting accuracy of participant  2\n",
      "268/268 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4095238095238098\n",
      "TL to the participant :  3\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6711 - accuracy: 0.5987 - val_loss: 0.5907 - val_accuracy: 0.7035\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.6007 - accuracy: 0.6863 - val_loss: 0.5718 - val_accuracy: 0.7124\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5834 - accuracy: 0.6981 - val_loss: 0.5779 - val_accuracy: 0.7107\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5774 - accuracy: 0.7074 - val_loss: 0.5611 - val_accuracy: 0.7207\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5691 - accuracy: 0.7116 - val_loss: 0.5664 - val_accuracy: 0.7185\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5666 - accuracy: 0.7141 - val_loss: 0.5653 - val_accuracy: 0.7202\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5634 - accuracy: 0.7204 - val_loss: 0.5600 - val_accuracy: 0.7191\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5617 - accuracy: 0.7227 - val_loss: 0.5624 - val_accuracy: 0.7269\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5563 - accuracy: 0.7239 - val_loss: 0.5552 - val_accuracy: 0.7252\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5583 - accuracy: 0.7220 - val_loss: 0.5633 - val_accuracy: 0.7219\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5528 - accuracy: 0.7271 - val_loss: 0.5551 - val_accuracy: 0.7319\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5501 - accuracy: 0.7288 - val_loss: 0.5536 - val_accuracy: 0.7219\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5527 - accuracy: 0.7271 - val_loss: 0.5504 - val_accuracy: 0.7235\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5514 - accuracy: 0.7252 - val_loss: 0.5508 - val_accuracy: 0.7280\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5498 - accuracy: 0.7262 - val_loss: 0.5460 - val_accuracy: 0.7274\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5492 - accuracy: 0.7276 - val_loss: 0.5431 - val_accuracy: 0.7302\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5471 - accuracy: 0.7310 - val_loss: 0.5424 - val_accuracy: 0.7313\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5468 - accuracy: 0.7289 - val_loss: 0.5462 - val_accuracy: 0.7347\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5440 - accuracy: 0.7266 - val_loss: 0.5466 - val_accuracy: 0.7336\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5449 - accuracy: 0.7327 - val_loss: 0.5439 - val_accuracy: 0.7263\n",
      "getting accuracy of participant  3\n",
      "268/268 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4499999999999997\n",
      "TL to the participant :  4\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6632 - accuracy: 0.6108 - val_loss: 0.5674 - val_accuracy: 0.7274\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5993 - accuracy: 0.6852 - val_loss: 0.5571 - val_accuracy: 0.7191\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5874 - accuracy: 0.6997 - val_loss: 0.5543 - val_accuracy: 0.7297\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5783 - accuracy: 0.7074 - val_loss: 0.5472 - val_accuracy: 0.7341\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5716 - accuracy: 0.7113 - val_loss: 0.5467 - val_accuracy: 0.7397\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5700 - accuracy: 0.7140 - val_loss: 0.5428 - val_accuracy: 0.7391\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5705 - accuracy: 0.7108 - val_loss: 0.5406 - val_accuracy: 0.7425\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5632 - accuracy: 0.7176 - val_loss: 0.5383 - val_accuracy: 0.7414\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5639 - accuracy: 0.7139 - val_loss: 0.5441 - val_accuracy: 0.7352\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5606 - accuracy: 0.7196 - val_loss: 0.5369 - val_accuracy: 0.7386\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5594 - accuracy: 0.7222 - val_loss: 0.5358 - val_accuracy: 0.7436\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5565 - accuracy: 0.7212 - val_loss: 0.5377 - val_accuracy: 0.7375\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5561 - accuracy: 0.7248 - val_loss: 0.5328 - val_accuracy: 0.7425\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5557 - accuracy: 0.7227 - val_loss: 0.5303 - val_accuracy: 0.7408\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5544 - accuracy: 0.7236 - val_loss: 0.5288 - val_accuracy: 0.7419\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5531 - accuracy: 0.7251 - val_loss: 0.5359 - val_accuracy: 0.7330\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5543 - accuracy: 0.7230 - val_loss: 0.5286 - val_accuracy: 0.7447\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5540 - accuracy: 0.7226 - val_loss: 0.5253 - val_accuracy: 0.7436\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5519 - accuracy: 0.7244 - val_loss: 0.5292 - val_accuracy: 0.7397\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5515 - accuracy: 0.7276 - val_loss: 0.5268 - val_accuracy: 0.7453\n",
      "getting accuracy of participant  4\n",
      "268/268 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.433333333333333\n",
      "TL to the participant :  5\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6746 - accuracy: 0.5956 - val_loss: 0.5847 - val_accuracy: 0.7124\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.6096 - accuracy: 0.6747 - val_loss: 0.5697 - val_accuracy: 0.7191\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5916 - accuracy: 0.6896 - val_loss: 0.5646 - val_accuracy: 0.7263\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5824 - accuracy: 0.7019 - val_loss: 0.5559 - val_accuracy: 0.7380\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5784 - accuracy: 0.7039 - val_loss: 0.5466 - val_accuracy: 0.7352\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5749 - accuracy: 0.7091 - val_loss: 0.5526 - val_accuracy: 0.7330\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5704 - accuracy: 0.7085 - val_loss: 0.5424 - val_accuracy: 0.7369\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5690 - accuracy: 0.7127 - val_loss: 0.5402 - val_accuracy: 0.7414\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5661 - accuracy: 0.7155 - val_loss: 0.5386 - val_accuracy: 0.7447\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5669 - accuracy: 0.7152 - val_loss: 0.5419 - val_accuracy: 0.7380\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5633 - accuracy: 0.7189 - val_loss: 0.5362 - val_accuracy: 0.7369\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5641 - accuracy: 0.7170 - val_loss: 0.5407 - val_accuracy: 0.7352\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5617 - accuracy: 0.7188 - val_loss: 0.5364 - val_accuracy: 0.7363\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5568 - accuracy: 0.7250 - val_loss: 0.5430 - val_accuracy: 0.7380\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5623 - accuracy: 0.7212 - val_loss: 0.5347 - val_accuracy: 0.7380\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5562 - accuracy: 0.7232 - val_loss: 0.5296 - val_accuracy: 0.7386\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5567 - accuracy: 0.7259 - val_loss: 0.5288 - val_accuracy: 0.7414\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5550 - accuracy: 0.7253 - val_loss: 0.5284 - val_accuracy: 0.7419\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5557 - accuracy: 0.7254 - val_loss: 0.5352 - val_accuracy: 0.7419\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5530 - accuracy: 0.7258 - val_loss: 0.5327 - val_accuracy: 0.7492\n",
      "getting accuracy of participant  5\n",
      "268/268 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4354938271604933\n",
      "TL to the participant :  6\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6557 - accuracy: 0.6231 - val_loss: 0.5715 - val_accuracy: 0.7163\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5989 - accuracy: 0.6874 - val_loss: 0.5518 - val_accuracy: 0.7213\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5838 - accuracy: 0.7012 - val_loss: 0.5486 - val_accuracy: 0.7336\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5694 - accuracy: 0.7118 - val_loss: 0.5380 - val_accuracy: 0.7397\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5687 - accuracy: 0.7108 - val_loss: 0.5336 - val_accuracy: 0.7414\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5636 - accuracy: 0.7197 - val_loss: 0.5268 - val_accuracy: 0.7402\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5612 - accuracy: 0.7243 - val_loss: 0.5321 - val_accuracy: 0.7425\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5591 - accuracy: 0.7222 - val_loss: 0.5295 - val_accuracy: 0.7347\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5558 - accuracy: 0.7251 - val_loss: 0.5269 - val_accuracy: 0.7414\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5547 - accuracy: 0.7250 - val_loss: 0.5279 - val_accuracy: 0.7425\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5547 - accuracy: 0.7236 - val_loss: 0.5158 - val_accuracy: 0.7520\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5533 - accuracy: 0.7276 - val_loss: 0.5271 - val_accuracy: 0.7397\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5475 - accuracy: 0.7290 - val_loss: 0.5227 - val_accuracy: 0.7436\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.5511 - accuracy: 0.7274 - val_loss: 0.5250 - val_accuracy: 0.7475\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5464 - accuracy: 0.7333 - val_loss: 0.5221 - val_accuracy: 0.7520\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5465 - accuracy: 0.7295 - val_loss: 0.5182 - val_accuracy: 0.7492\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5457 - accuracy: 0.7310 - val_loss: 0.5281 - val_accuracy: 0.7369\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.5495 - accuracy: 0.7301 - val_loss: 0.5193 - val_accuracy: 0.7570\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5427 - accuracy: 0.7319 - val_loss: 0.5254 - val_accuracy: 0.7425\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5438 - accuracy: 0.7310 - val_loss: 0.5161 - val_accuracy: 0.7520\n",
      "getting accuracy of participant  6\n",
      "268/268 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4246527777777775\n",
      "TL to the participant :  7\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 14ms/step - loss: 0.6878 - accuracy: 0.5816 - val_loss: 0.5946 - val_accuracy: 0.7029\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.6076 - accuracy: 0.6773 - val_loss: 0.5527 - val_accuracy: 0.7358\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5889 - accuracy: 0.6965 - val_loss: 0.5569 - val_accuracy: 0.7274\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5796 - accuracy: 0.7023 - val_loss: 0.5462 - val_accuracy: 0.7336\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5710 - accuracy: 0.7113 - val_loss: 0.5400 - val_accuracy: 0.7363\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5670 - accuracy: 0.7152 - val_loss: 0.5375 - val_accuracy: 0.7375\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5623 - accuracy: 0.7171 - val_loss: 0.5382 - val_accuracy: 0.7419\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5591 - accuracy: 0.7209 - val_loss: 0.5311 - val_accuracy: 0.7402\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5543 - accuracy: 0.7261 - val_loss: 0.5296 - val_accuracy: 0.7391\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5543 - accuracy: 0.7282 - val_loss: 0.5283 - val_accuracy: 0.7464\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5544 - accuracy: 0.7248 - val_loss: 0.5285 - val_accuracy: 0.7430\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5556 - accuracy: 0.7253 - val_loss: 0.5262 - val_accuracy: 0.7453\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5485 - accuracy: 0.7298 - val_loss: 0.5270 - val_accuracy: 0.7402\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5480 - accuracy: 0.7309 - val_loss: 0.5255 - val_accuracy: 0.7441\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5466 - accuracy: 0.7319 - val_loss: 0.5283 - val_accuracy: 0.7447\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5460 - accuracy: 0.7310 - val_loss: 0.5182 - val_accuracy: 0.7453\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5492 - accuracy: 0.7319 - val_loss: 0.5252 - val_accuracy: 0.7414\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5470 - accuracy: 0.7297 - val_loss: 0.5248 - val_accuracy: 0.7430\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5443 - accuracy: 0.7328 - val_loss: 0.5224 - val_accuracy: 0.7453\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5468 - accuracy: 0.7330 - val_loss: 0.5230 - val_accuracy: 0.7480\n",
      "getting accuracy of participant  7\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4005747126436778\n",
      "TL to the participant :  8\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 6s 15ms/step - loss: 0.6739 - accuracy: 0.6054 - val_loss: 0.5745 - val_accuracy: 0.7179\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5994 - accuracy: 0.6854 - val_loss: 0.5618 - val_accuracy: 0.7230\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5799 - accuracy: 0.7037 - val_loss: 0.5503 - val_accuracy: 0.7358\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5699 - accuracy: 0.7087 - val_loss: 0.5452 - val_accuracy: 0.7308\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5691 - accuracy: 0.7140 - val_loss: 0.5462 - val_accuracy: 0.7352\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5649 - accuracy: 0.7147 - val_loss: 0.5420 - val_accuracy: 0.7425\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5595 - accuracy: 0.7227 - val_loss: 0.5404 - val_accuracy: 0.7375\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5588 - accuracy: 0.7227 - val_loss: 0.5398 - val_accuracy: 0.7380\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5520 - accuracy: 0.7260 - val_loss: 0.5362 - val_accuracy: 0.7480\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.5550 - accuracy: 0.7266 - val_loss: 0.5375 - val_accuracy: 0.7419\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.5493 - accuracy: 0.7283 - val_loss: 0.5332 - val_accuracy: 0.7425\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.5507 - accuracy: 0.7268 - val_loss: 0.5331 - val_accuracy: 0.7397\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.5458 - accuracy: 0.7287 - val_loss: 0.5311 - val_accuracy: 0.7480\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.5432 - accuracy: 0.7331 - val_loss: 0.5271 - val_accuracy: 0.7453\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5461 - accuracy: 0.7292 - val_loss: 0.5305 - val_accuracy: 0.7453\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5449 - accuracy: 0.7297 - val_loss: 0.5266 - val_accuracy: 0.7492\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5448 - accuracy: 0.7296 - val_loss: 0.5260 - val_accuracy: 0.7514\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5445 - accuracy: 0.7313 - val_loss: 0.5270 - val_accuracy: 0.7469\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5390 - accuracy: 0.7332 - val_loss: 0.5281 - val_accuracy: 0.7480\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.5410 - accuracy: 0.7321 - val_loss: 0.5275 - val_accuracy: 0.7475\n",
      "getting accuracy of participant  8\n",
      "268/268 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.439492753623188\n",
      "TL to the participant :  9\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6977 - accuracy: 0.5578 - val_loss: 0.5995 - val_accuracy: 0.7007\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.6125 - accuracy: 0.6776 - val_loss: 0.5687 - val_accuracy: 0.7157\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5773 - accuracy: 0.7070 - val_loss: 0.5492 - val_accuracy: 0.7241\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5701 - accuracy: 0.7108 - val_loss: 0.5463 - val_accuracy: 0.7352\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5606 - accuracy: 0.7188 - val_loss: 0.5365 - val_accuracy: 0.7363\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.5599 - accuracy: 0.7227 - val_loss: 0.5341 - val_accuracy: 0.7386\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5503 - accuracy: 0.7282 - val_loss: 0.5253 - val_accuracy: 0.7453\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5531 - accuracy: 0.7249 - val_loss: 0.5298 - val_accuracy: 0.7464\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5479 - accuracy: 0.7322 - val_loss: 0.5283 - val_accuracy: 0.7447\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5446 - accuracy: 0.7342 - val_loss: 0.5288 - val_accuracy: 0.7475\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5417 - accuracy: 0.7345 - val_loss: 0.5331 - val_accuracy: 0.7402\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5439 - accuracy: 0.7330 - val_loss: 0.5268 - val_accuracy: 0.7408\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5393 - accuracy: 0.7375 - val_loss: 0.5291 - val_accuracy: 0.7469\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5390 - accuracy: 0.7378 - val_loss: 0.5259 - val_accuracy: 0.7559\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5406 - accuracy: 0.7327 - val_loss: 0.5224 - val_accuracy: 0.7514\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5373 - accuracy: 0.7365 - val_loss: 0.5215 - val_accuracy: 0.7525\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5355 - accuracy: 0.7404 - val_loss: 0.5282 - val_accuracy: 0.7486\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5334 - accuracy: 0.7417 - val_loss: 0.5238 - val_accuracy: 0.7514\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5358 - accuracy: 0.7362 - val_loss: 0.5194 - val_accuracy: 0.7575\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5345 - accuracy: 0.7382 - val_loss: 0.5227 - val_accuracy: 0.7547\n",
      "getting accuracy of participant  9\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4731060606060604\n",
      "TL to the participant :  10\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 11ms/step - loss: 0.6728 - accuracy: 0.6020 - val_loss: 0.5594 - val_accuracy: 0.7347\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5951 - accuracy: 0.6900 - val_loss: 0.5478 - val_accuracy: 0.7386\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5846 - accuracy: 0.7030 - val_loss: 0.5359 - val_accuracy: 0.7525\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5724 - accuracy: 0.7121 - val_loss: 0.5286 - val_accuracy: 0.7559\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5693 - accuracy: 0.7138 - val_loss: 0.5300 - val_accuracy: 0.7514\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5680 - accuracy: 0.7152 - val_loss: 0.5284 - val_accuracy: 0.7525\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5621 - accuracy: 0.7210 - val_loss: 0.5214 - val_accuracy: 0.7625\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5594 - accuracy: 0.7195 - val_loss: 0.5198 - val_accuracy: 0.7648\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5579 - accuracy: 0.7230 - val_loss: 0.5221 - val_accuracy: 0.7625\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5551 - accuracy: 0.7239 - val_loss: 0.5229 - val_accuracy: 0.7575\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5523 - accuracy: 0.7272 - val_loss: 0.5190 - val_accuracy: 0.7547\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5503 - accuracy: 0.7290 - val_loss: 0.5183 - val_accuracy: 0.7559\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5504 - accuracy: 0.7320 - val_loss: 0.5223 - val_accuracy: 0.7586\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5498 - accuracy: 0.7305 - val_loss: 0.5153 - val_accuracy: 0.7637\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5498 - accuracy: 0.7281 - val_loss: 0.5165 - val_accuracy: 0.7592\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5455 - accuracy: 0.7311 - val_loss: 0.5184 - val_accuracy: 0.7648\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5461 - accuracy: 0.7305 - val_loss: 0.5153 - val_accuracy: 0.7653\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5449 - accuracy: 0.7311 - val_loss: 0.5135 - val_accuracy: 0.7631\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5472 - accuracy: 0.7335 - val_loss: 0.5150 - val_accuracy: 0.7553\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5456 - accuracy: 0.7329 - val_loss: 0.5097 - val_accuracy: 0.7625\n",
      "getting accuracy of participant  10\n",
      "268/268 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4555555555555555\n",
      "TL to the participant :  11\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6573 - accuracy: 0.6316 - val_loss: 0.5751 - val_accuracy: 0.7230\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5893 - accuracy: 0.6958 - val_loss: 0.5471 - val_accuracy: 0.7447\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5731 - accuracy: 0.7095 - val_loss: 0.5540 - val_accuracy: 0.7213\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5670 - accuracy: 0.7175 - val_loss: 0.5383 - val_accuracy: 0.7514\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5575 - accuracy: 0.7210 - val_loss: 0.5340 - val_accuracy: 0.7514\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5548 - accuracy: 0.7229 - val_loss: 0.5304 - val_accuracy: 0.7430\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5514 - accuracy: 0.7258 - val_loss: 0.5327 - val_accuracy: 0.7430\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5504 - accuracy: 0.7285 - val_loss: 0.5259 - val_accuracy: 0.7503\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5480 - accuracy: 0.7320 - val_loss: 0.5267 - val_accuracy: 0.7531\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5465 - accuracy: 0.7309 - val_loss: 0.5243 - val_accuracy: 0.7542\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5449 - accuracy: 0.7304 - val_loss: 0.5222 - val_accuracy: 0.7553\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5459 - accuracy: 0.7308 - val_loss: 0.5230 - val_accuracy: 0.7514\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5437 - accuracy: 0.7315 - val_loss: 0.5235 - val_accuracy: 0.7492\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5411 - accuracy: 0.7334 - val_loss: 0.5208 - val_accuracy: 0.7559\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5405 - accuracy: 0.7341 - val_loss: 0.5171 - val_accuracy: 0.7520\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5405 - accuracy: 0.7349 - val_loss: 0.5148 - val_accuracy: 0.7586\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5369 - accuracy: 0.7367 - val_loss: 0.5216 - val_accuracy: 0.7503\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5375 - accuracy: 0.7378 - val_loss: 0.5162 - val_accuracy: 0.7547\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5386 - accuracy: 0.7367 - val_loss: 0.5148 - val_accuracy: 0.7531\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5376 - accuracy: 0.7370 - val_loss: 0.5168 - val_accuracy: 0.7575\n",
      "getting accuracy of participant  11\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.432882882882883\n",
      "TL to the participant :  12\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6630 - accuracy: 0.6188 - val_loss: 0.5663 - val_accuracy: 0.7224\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5931 - accuracy: 0.6935 - val_loss: 0.5476 - val_accuracy: 0.7235\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5800 - accuracy: 0.7057 - val_loss: 0.5465 - val_accuracy: 0.7330\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5684 - accuracy: 0.7142 - val_loss: 0.5366 - val_accuracy: 0.7347\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5666 - accuracy: 0.7166 - val_loss: 0.5313 - val_accuracy: 0.7525\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5619 - accuracy: 0.7241 - val_loss: 0.5341 - val_accuracy: 0.7397\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5584 - accuracy: 0.7211 - val_loss: 0.5317 - val_accuracy: 0.7419\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5569 - accuracy: 0.7216 - val_loss: 0.5233 - val_accuracy: 0.7458\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5557 - accuracy: 0.7200 - val_loss: 0.5167 - val_accuracy: 0.7492\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5510 - accuracy: 0.7271 - val_loss: 0.5230 - val_accuracy: 0.7542\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5473 - accuracy: 0.7282 - val_loss: 0.5202 - val_accuracy: 0.7559\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5517 - accuracy: 0.7275 - val_loss: 0.5219 - val_accuracy: 0.7536\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5481 - accuracy: 0.7305 - val_loss: 0.5167 - val_accuracy: 0.7586\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5440 - accuracy: 0.7326 - val_loss: 0.5161 - val_accuracy: 0.7469\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5452 - accuracy: 0.7333 - val_loss: 0.5183 - val_accuracy: 0.7486\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5448 - accuracy: 0.7305 - val_loss: 0.5157 - val_accuracy: 0.7492\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5435 - accuracy: 0.7319 - val_loss: 0.5184 - val_accuracy: 0.7503\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5409 - accuracy: 0.7352 - val_loss: 0.5130 - val_accuracy: 0.7542\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5433 - accuracy: 0.7291 - val_loss: 0.5132 - val_accuracy: 0.7559\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5446 - accuracy: 0.7341 - val_loss: 0.5156 - val_accuracy: 0.7475\n",
      "getting accuracy of participant  12\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.416287878787879\n",
      "TL to the participant :  13\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6597 - accuracy: 0.6137 - val_loss: 0.5737 - val_accuracy: 0.7185\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5894 - accuracy: 0.6947 - val_loss: 0.5564 - val_accuracy: 0.7230\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5779 - accuracy: 0.7039 - val_loss: 0.5486 - val_accuracy: 0.7397\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5726 - accuracy: 0.7146 - val_loss: 0.5440 - val_accuracy: 0.7436\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5640 - accuracy: 0.7178 - val_loss: 0.5341 - val_accuracy: 0.7436\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5623 - accuracy: 0.7186 - val_loss: 0.5305 - val_accuracy: 0.7425\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5593 - accuracy: 0.7216 - val_loss: 0.5319 - val_accuracy: 0.7486\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5567 - accuracy: 0.7249 - val_loss: 0.5357 - val_accuracy: 0.7447\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5546 - accuracy: 0.7258 - val_loss: 0.5306 - val_accuracy: 0.7425\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.5488 - accuracy: 0.7305 - val_loss: 0.5336 - val_accuracy: 0.7447\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5493 - accuracy: 0.7254 - val_loss: 0.5296 - val_accuracy: 0.7497\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.5494 - accuracy: 0.7296 - val_loss: 0.5308 - val_accuracy: 0.7419\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.5471 - accuracy: 0.7300 - val_loss: 0.5302 - val_accuracy: 0.7414\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.5472 - accuracy: 0.7327 - val_loss: 0.5329 - val_accuracy: 0.7402\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5450 - accuracy: 0.7339 - val_loss: 0.5306 - val_accuracy: 0.7469\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5469 - accuracy: 0.7292 - val_loss: 0.5256 - val_accuracy: 0.7447\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5453 - accuracy: 0.7328 - val_loss: 0.5290 - val_accuracy: 0.7430\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5429 - accuracy: 0.7340 - val_loss: 0.5276 - val_accuracy: 0.7447\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5422 - accuracy: 0.7310 - val_loss: 0.5302 - val_accuracy: 0.7469\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5420 - accuracy: 0.7357 - val_loss: 0.5249 - val_accuracy: 0.7414\n",
      "getting accuracy of participant  13\n",
      "268/268 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4098639455782311\n",
      "TL to the participant :  14\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 7s 15ms/step - loss: 0.6708 - accuracy: 0.6059 - val_loss: 0.5736 - val_accuracy: 0.6895\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5968 - accuracy: 0.6854 - val_loss: 0.5455 - val_accuracy: 0.7285\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5781 - accuracy: 0.7036 - val_loss: 0.5399 - val_accuracy: 0.7358\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5696 - accuracy: 0.7111 - val_loss: 0.5372 - val_accuracy: 0.7464\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5599 - accuracy: 0.7193 - val_loss: 0.5294 - val_accuracy: 0.7464\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5524 - accuracy: 0.7261 - val_loss: 0.5321 - val_accuracy: 0.7469\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5503 - accuracy: 0.7282 - val_loss: 0.5258 - val_accuracy: 0.7425\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5497 - accuracy: 0.7282 - val_loss: 0.5256 - val_accuracy: 0.7436\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5490 - accuracy: 0.7274 - val_loss: 0.5243 - val_accuracy: 0.7486\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5455 - accuracy: 0.7312 - val_loss: 0.5156 - val_accuracy: 0.7480\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5418 - accuracy: 0.7337 - val_loss: 0.5167 - val_accuracy: 0.7536\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5434 - accuracy: 0.7339 - val_loss: 0.5162 - val_accuracy: 0.7475\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5402 - accuracy: 0.7382 - val_loss: 0.5153 - val_accuracy: 0.7497\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5397 - accuracy: 0.7408 - val_loss: 0.5182 - val_accuracy: 0.7531\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5395 - accuracy: 0.7370 - val_loss: 0.5103 - val_accuracy: 0.7531\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5363 - accuracy: 0.7402 - val_loss: 0.5153 - val_accuracy: 0.7531\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5358 - accuracy: 0.7412 - val_loss: 0.5124 - val_accuracy: 0.7559\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5338 - accuracy: 0.7391 - val_loss: 0.5120 - val_accuracy: 0.7531\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5347 - accuracy: 0.7438 - val_loss: 0.5104 - val_accuracy: 0.7620\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5316 - accuracy: 0.7438 - val_loss: 0.5131 - val_accuracy: 0.7559\n",
      "getting accuracy of participant  14\n",
      "268/268 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4183760683760687\n",
      "TL to the participant :  15\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6629 - accuracy: 0.6169 - val_loss: 0.5745 - val_accuracy: 0.7258\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5974 - accuracy: 0.6878 - val_loss: 0.5553 - val_accuracy: 0.7425\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5818 - accuracy: 0.7000 - val_loss: 0.5513 - val_accuracy: 0.7380\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5724 - accuracy: 0.7080 - val_loss: 0.5429 - val_accuracy: 0.7475\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5677 - accuracy: 0.7134 - val_loss: 0.5369 - val_accuracy: 0.7453\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5652 - accuracy: 0.7172 - val_loss: 0.5364 - val_accuracy: 0.7436\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5627 - accuracy: 0.7202 - val_loss: 0.5349 - val_accuracy: 0.7514\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5561 - accuracy: 0.7205 - val_loss: 0.5385 - val_accuracy: 0.7453\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5552 - accuracy: 0.7217 - val_loss: 0.5368 - val_accuracy: 0.7453\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5529 - accuracy: 0.7258 - val_loss: 0.5328 - val_accuracy: 0.7492\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5544 - accuracy: 0.7238 - val_loss: 0.5383 - val_accuracy: 0.7441\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5524 - accuracy: 0.7291 - val_loss: 0.5338 - val_accuracy: 0.7486\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5471 - accuracy: 0.7290 - val_loss: 0.5285 - val_accuracy: 0.7475\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5495 - accuracy: 0.7290 - val_loss: 0.5309 - val_accuracy: 0.7508\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5482 - accuracy: 0.7301 - val_loss: 0.5304 - val_accuracy: 0.7542\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5466 - accuracy: 0.7305 - val_loss: 0.5290 - val_accuracy: 0.7514\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5483 - accuracy: 0.7302 - val_loss: 0.5275 - val_accuracy: 0.7497\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5452 - accuracy: 0.7336 - val_loss: 0.5267 - val_accuracy: 0.7525\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5443 - accuracy: 0.7326 - val_loss: 0.5229 - val_accuracy: 0.7497\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5448 - accuracy: 0.7329 - val_loss: 0.5257 - val_accuracy: 0.7458\n",
      "getting accuracy of participant  15\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4174999999999998\n",
      "TL to the participant :  16\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6572 - accuracy: 0.6233 - val_loss: 0.5770 - val_accuracy: 0.7163\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5905 - accuracy: 0.6891 - val_loss: 0.5558 - val_accuracy: 0.7319\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5797 - accuracy: 0.7057 - val_loss: 0.5533 - val_accuracy: 0.7302\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5648 - accuracy: 0.7158 - val_loss: 0.5462 - val_accuracy: 0.7297\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5640 - accuracy: 0.7161 - val_loss: 0.5474 - val_accuracy: 0.7447\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5622 - accuracy: 0.7196 - val_loss: 0.5430 - val_accuracy: 0.7425\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5537 - accuracy: 0.7279 - val_loss: 0.5361 - val_accuracy: 0.7475\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5526 - accuracy: 0.7224 - val_loss: 0.5362 - val_accuracy: 0.7414\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5534 - accuracy: 0.7220 - val_loss: 0.5345 - val_accuracy: 0.7397\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5487 - accuracy: 0.7282 - val_loss: 0.5319 - val_accuracy: 0.7380\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5469 - accuracy: 0.7305 - val_loss: 0.5285 - val_accuracy: 0.7447\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5459 - accuracy: 0.7297 - val_loss: 0.5300 - val_accuracy: 0.7414\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5434 - accuracy: 0.7326 - val_loss: 0.5256 - val_accuracy: 0.7441\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5454 - accuracy: 0.7327 - val_loss: 0.5320 - val_accuracy: 0.7386\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5459 - accuracy: 0.7315 - val_loss: 0.5257 - val_accuracy: 0.7475\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5424 - accuracy: 0.7324 - val_loss: 0.5302 - val_accuracy: 0.7386\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5436 - accuracy: 0.7347 - val_loss: 0.5274 - val_accuracy: 0.7486\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5415 - accuracy: 0.7359 - val_loss: 0.5220 - val_accuracy: 0.7436\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5429 - accuracy: 0.7315 - val_loss: 0.5235 - val_accuracy: 0.7480\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5440 - accuracy: 0.7347 - val_loss: 0.5225 - val_accuracy: 0.7480\n",
      "getting accuracy of participant  16\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4380116959064329\n",
      "TL to the participant :  17\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6692 - accuracy: 0.6022 - val_loss: 0.5906 - val_accuracy: 0.6923\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.6033 - accuracy: 0.6764 - val_loss: 0.5609 - val_accuracy: 0.7230\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5857 - accuracy: 0.6964 - val_loss: 0.5643 - val_accuracy: 0.7152\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5762 - accuracy: 0.7087 - val_loss: 0.5580 - val_accuracy: 0.7207\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5717 - accuracy: 0.7071 - val_loss: 0.5569 - val_accuracy: 0.7246\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5705 - accuracy: 0.7090 - val_loss: 0.5514 - val_accuracy: 0.7274\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5661 - accuracy: 0.7127 - val_loss: 0.5535 - val_accuracy: 0.7258\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5652 - accuracy: 0.7135 - val_loss: 0.5502 - val_accuracy: 0.7285\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5610 - accuracy: 0.7194 - val_loss: 0.5495 - val_accuracy: 0.7324\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5591 - accuracy: 0.7188 - val_loss: 0.5478 - val_accuracy: 0.7308\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5568 - accuracy: 0.7233 - val_loss: 0.5455 - val_accuracy: 0.7352\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5534 - accuracy: 0.7264 - val_loss: 0.5545 - val_accuracy: 0.7219\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5518 - accuracy: 0.7252 - val_loss: 0.5456 - val_accuracy: 0.7297\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5527 - accuracy: 0.7228 - val_loss: 0.5465 - val_accuracy: 0.7285\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5503 - accuracy: 0.7256 - val_loss: 0.5418 - val_accuracy: 0.7302\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5499 - accuracy: 0.7268 - val_loss: 0.5438 - val_accuracy: 0.7297\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5484 - accuracy: 0.7275 - val_loss: 0.5447 - val_accuracy: 0.7269\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5466 - accuracy: 0.7279 - val_loss: 0.5413 - val_accuracy: 0.7308\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5517 - accuracy: 0.7249 - val_loss: 0.5453 - val_accuracy: 0.7336\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5453 - accuracy: 0.7287 - val_loss: 0.5411 - val_accuracy: 0.7313\n",
      "getting accuracy of participant  17\n",
      "268/268 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3898809523809526\n",
      "TL to the participant :  18\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 13ms/step - loss: 0.6764 - accuracy: 0.5948 - val_loss: 0.5797 - val_accuracy: 0.7163\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5898 - accuracy: 0.6931 - val_loss: 0.5344 - val_accuracy: 0.7531\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5710 - accuracy: 0.7137 - val_loss: 0.5299 - val_accuracy: 0.7497\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5624 - accuracy: 0.7189 - val_loss: 0.5271 - val_accuracy: 0.7598\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5546 - accuracy: 0.7248 - val_loss: 0.5187 - val_accuracy: 0.7547\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5490 - accuracy: 0.7290 - val_loss: 0.5206 - val_accuracy: 0.7592\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5461 - accuracy: 0.7328 - val_loss: 0.5150 - val_accuracy: 0.7564\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5431 - accuracy: 0.7367 - val_loss: 0.5148 - val_accuracy: 0.7592\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5391 - accuracy: 0.7375 - val_loss: 0.5137 - val_accuracy: 0.7637\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5350 - accuracy: 0.7409 - val_loss: 0.5100 - val_accuracy: 0.7614\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5388 - accuracy: 0.7376 - val_loss: 0.5191 - val_accuracy: 0.7598\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5363 - accuracy: 0.7383 - val_loss: 0.5183 - val_accuracy: 0.7598\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5331 - accuracy: 0.7409 - val_loss: 0.5108 - val_accuracy: 0.7620\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5348 - accuracy: 0.7385 - val_loss: 0.5059 - val_accuracy: 0.7586\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5324 - accuracy: 0.7414 - val_loss: 0.5070 - val_accuracy: 0.7664\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5302 - accuracy: 0.7456 - val_loss: 0.5087 - val_accuracy: 0.7620\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5308 - accuracy: 0.7425 - val_loss: 0.5106 - val_accuracy: 0.7570\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5284 - accuracy: 0.7467 - val_loss: 0.5108 - val_accuracy: 0.7553\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5273 - accuracy: 0.7414 - val_loss: 0.5047 - val_accuracy: 0.7547\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5306 - accuracy: 0.7431 - val_loss: 0.5072 - val_accuracy: 0.7603\n",
      "getting accuracy of participant  18\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4244791666666665\n",
      "TL to the participant :  19\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 11ms/step - loss: 0.6621 - accuracy: 0.6212 - val_loss: 0.5651 - val_accuracy: 0.7179\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5936 - accuracy: 0.6950 - val_loss: 0.5572 - val_accuracy: 0.7280\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5785 - accuracy: 0.7057 - val_loss: 0.5429 - val_accuracy: 0.7324\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5703 - accuracy: 0.7120 - val_loss: 0.5372 - val_accuracy: 0.7347\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5624 - accuracy: 0.7197 - val_loss: 0.5364 - val_accuracy: 0.7336\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5593 - accuracy: 0.7225 - val_loss: 0.5332 - val_accuracy: 0.7414\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5558 - accuracy: 0.7242 - val_loss: 0.5413 - val_accuracy: 0.7397\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5513 - accuracy: 0.7285 - val_loss: 0.5339 - val_accuracy: 0.7285\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5561 - accuracy: 0.7230 - val_loss: 0.5307 - val_accuracy: 0.7358\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5510 - accuracy: 0.7287 - val_loss: 0.5323 - val_accuracy: 0.7319\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5494 - accuracy: 0.7285 - val_loss: 0.5256 - val_accuracy: 0.7380\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5501 - accuracy: 0.7287 - val_loss: 0.5253 - val_accuracy: 0.7341\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5440 - accuracy: 0.7368 - val_loss: 0.5245 - val_accuracy: 0.7336\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5476 - accuracy: 0.7321 - val_loss: 0.5265 - val_accuracy: 0.7347\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5443 - accuracy: 0.7345 - val_loss: 0.5271 - val_accuracy: 0.7280\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5422 - accuracy: 0.7384 - val_loss: 0.5285 - val_accuracy: 0.7313\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5441 - accuracy: 0.7344 - val_loss: 0.5285 - val_accuracy: 0.7347\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5398 - accuracy: 0.7336 - val_loss: 0.5233 - val_accuracy: 0.7341\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5407 - accuracy: 0.7345 - val_loss: 0.5217 - val_accuracy: 0.7319\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5362 - accuracy: 0.7430 - val_loss: 0.5214 - val_accuracy: 0.7330\n",
      "getting accuracy of participant  19\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4054487179487176\n",
      "TL to the participant :  20\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.6605 - accuracy: 0.6241 - val_loss: 0.5785 - val_accuracy: 0.7213\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5973 - accuracy: 0.6896 - val_loss: 0.5580 - val_accuracy: 0.7213\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 2s 9ms/step - loss: 0.5737 - accuracy: 0.7100 - val_loss: 0.5551 - val_accuracy: 0.7274\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5698 - accuracy: 0.7198 - val_loss: 0.5441 - val_accuracy: 0.7330\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5645 - accuracy: 0.7179 - val_loss: 0.5451 - val_accuracy: 0.7347\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5614 - accuracy: 0.7254 - val_loss: 0.5409 - val_accuracy: 0.7330\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5559 - accuracy: 0.7259 - val_loss: 0.5389 - val_accuracy: 0.7274\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5539 - accuracy: 0.7264 - val_loss: 0.5374 - val_accuracy: 0.7324\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5546 - accuracy: 0.7269 - val_loss: 0.5347 - val_accuracy: 0.7375\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5490 - accuracy: 0.7275 - val_loss: 0.5342 - val_accuracy: 0.7358\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5504 - accuracy: 0.7289 - val_loss: 0.5364 - val_accuracy: 0.7369\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5481 - accuracy: 0.7287 - val_loss: 0.5400 - val_accuracy: 0.7386\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5470 - accuracy: 0.7323 - val_loss: 0.5279 - val_accuracy: 0.7380\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5477 - accuracy: 0.7310 - val_loss: 0.5247 - val_accuracy: 0.7430\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5450 - accuracy: 0.7337 - val_loss: 0.5239 - val_accuracy: 0.7464\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5435 - accuracy: 0.7362 - val_loss: 0.5282 - val_accuracy: 0.7397\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5462 - accuracy: 0.7317 - val_loss: 0.5245 - val_accuracy: 0.7380\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5413 - accuracy: 0.7352 - val_loss: 0.5270 - val_accuracy: 0.7363\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5425 - accuracy: 0.7361 - val_loss: 0.5258 - val_accuracy: 0.7391\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5418 - accuracy: 0.7338 - val_loss: 0.5255 - val_accuracy: 0.7419\n",
      "getting accuracy of participant  20\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4250000000000003\n",
      "TL to the participant :  21\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.6567 - accuracy: 0.6241 - val_loss: 0.5765 - val_accuracy: 0.7096\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5914 - accuracy: 0.6970 - val_loss: 0.5599 - val_accuracy: 0.7269\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5753 - accuracy: 0.7098 - val_loss: 0.5549 - val_accuracy: 0.7347\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5660 - accuracy: 0.7180 - val_loss: 0.5556 - val_accuracy: 0.7308\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5623 - accuracy: 0.7209 - val_loss: 0.5455 - val_accuracy: 0.7352\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5604 - accuracy: 0.7251 - val_loss: 0.5454 - val_accuracy: 0.7341\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5577 - accuracy: 0.7246 - val_loss: 0.5442 - val_accuracy: 0.7336\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5536 - accuracy: 0.7271 - val_loss: 0.5413 - val_accuracy: 0.7330\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5534 - accuracy: 0.7292 - val_loss: 0.5413 - val_accuracy: 0.7352\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5500 - accuracy: 0.7315 - val_loss: 0.5381 - val_accuracy: 0.7363\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5495 - accuracy: 0.7326 - val_loss: 0.5371 - val_accuracy: 0.7386\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5486 - accuracy: 0.7297 - val_loss: 0.5375 - val_accuracy: 0.7380\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5467 - accuracy: 0.7344 - val_loss: 0.5422 - val_accuracy: 0.7363\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5452 - accuracy: 0.7341 - val_loss: 0.5296 - val_accuracy: 0.7408\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5453 - accuracy: 0.7344 - val_loss: 0.5372 - val_accuracy: 0.7347\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5445 - accuracy: 0.7347 - val_loss: 0.5411 - val_accuracy: 0.7330\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5445 - accuracy: 0.7334 - val_loss: 0.5316 - val_accuracy: 0.7425\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5441 - accuracy: 0.7347 - val_loss: 0.5338 - val_accuracy: 0.7408\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5439 - accuracy: 0.7319 - val_loss: 0.5328 - val_accuracy: 0.7453\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5461 - accuracy: 0.7315 - val_loss: 0.5341 - val_accuracy: 0.7386\n",
      "getting accuracy of participant  21\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4287037037037038\n",
      "TL to the participant :  22\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 11ms/step - loss: 0.6516 - accuracy: 0.6366 - val_loss: 0.5505 - val_accuracy: 0.7475\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5922 - accuracy: 0.6980 - val_loss: 0.5245 - val_accuracy: 0.7536\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5761 - accuracy: 0.7112 - val_loss: 0.5267 - val_accuracy: 0.7598\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5658 - accuracy: 0.7177 - val_loss: 0.5221 - val_accuracy: 0.7520\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5604 - accuracy: 0.7229 - val_loss: 0.5191 - val_accuracy: 0.7520\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5587 - accuracy: 0.7238 - val_loss: 0.5112 - val_accuracy: 0.7564\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5575 - accuracy: 0.7267 - val_loss: 0.5119 - val_accuracy: 0.7536\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5529 - accuracy: 0.7288 - val_loss: 0.5142 - val_accuracy: 0.7531\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5526 - accuracy: 0.7277 - val_loss: 0.5126 - val_accuracy: 0.7570\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5505 - accuracy: 0.7320 - val_loss: 0.5148 - val_accuracy: 0.7542\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5477 - accuracy: 0.7342 - val_loss: 0.5113 - val_accuracy: 0.7553\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5492 - accuracy: 0.7304 - val_loss: 0.5087 - val_accuracy: 0.7586\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5440 - accuracy: 0.7358 - val_loss: 0.5046 - val_accuracy: 0.7564\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5456 - accuracy: 0.7365 - val_loss: 0.5096 - val_accuracy: 0.7625\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5431 - accuracy: 0.7362 - val_loss: 0.5071 - val_accuracy: 0.7547\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5463 - accuracy: 0.7363 - val_loss: 0.5079 - val_accuracy: 0.7620\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5414 - accuracy: 0.7342 - val_loss: 0.5067 - val_accuracy: 0.7564\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5418 - accuracy: 0.7375 - val_loss: 0.5034 - val_accuracy: 0.7586\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5385 - accuracy: 0.7371 - val_loss: 0.5018 - val_accuracy: 0.7642\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5429 - accuracy: 0.7386 - val_loss: 0.4962 - val_accuracy: 0.7586\n",
      "getting accuracy of participant  22\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4932291666666666\n",
      "TL to the participant :  23\n",
      "(196650, 1, 8, 150)\n",
      "(196650,)\n",
      "(8550, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.6530 - accuracy: 0.6301 - val_loss: 0.5837 - val_accuracy: 0.7012\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5974 - accuracy: 0.6905 - val_loss: 0.5568 - val_accuracy: 0.7241\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5834 - accuracy: 0.7011 - val_loss: 0.5582 - val_accuracy: 0.7263\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5757 - accuracy: 0.7086 - val_loss: 0.5520 - val_accuracy: 0.7269\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5722 - accuracy: 0.7106 - val_loss: 0.5578 - val_accuracy: 0.7285\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5646 - accuracy: 0.7134 - val_loss: 0.5561 - val_accuracy: 0.7291\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5655 - accuracy: 0.7179 - val_loss: 0.5432 - val_accuracy: 0.7369\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5623 - accuracy: 0.7190 - val_loss: 0.5444 - val_accuracy: 0.7352\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5608 - accuracy: 0.7221 - val_loss: 0.5451 - val_accuracy: 0.7341\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5614 - accuracy: 0.7165 - val_loss: 0.5402 - val_accuracy: 0.7324\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5566 - accuracy: 0.7246 - val_loss: 0.5428 - val_accuracy: 0.7386\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5552 - accuracy: 0.7224 - val_loss: 0.5391 - val_accuracy: 0.7341\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5552 - accuracy: 0.7256 - val_loss: 0.5406 - val_accuracy: 0.7347\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5502 - accuracy: 0.7287 - val_loss: 0.5411 - val_accuracy: 0.7369\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5493 - accuracy: 0.7329 - val_loss: 0.5372 - val_accuracy: 0.7447\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5499 - accuracy: 0.7322 - val_loss: 0.5350 - val_accuracy: 0.7386\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5490 - accuracy: 0.7290 - val_loss: 0.5416 - val_accuracy: 0.7369\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5503 - accuracy: 0.7292 - val_loss: 0.5337 - val_accuracy: 0.7453\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5505 - accuracy: 0.7272 - val_loss: 0.5390 - val_accuracy: 0.7397\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 2s 10ms/step - loss: 0.5477 - accuracy: 0.7282 - val_loss: 0.5381 - val_accuracy: 0.7330\n",
      "getting accuracy of participant  23\n",
      "268/268 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4220125786163518\n",
      "[0.75253111 0.80924774 0.50869627 0.79303356 0.79546097 0.82008861\n",
      " 0.78279129 0.83575132 0.73404506 0.69766214 0.72292138 0.67870004\n",
      " 0.75815894 0.77284125 0.65290818 0.82480204 0.7900641  0.80614159\n",
      " 0.47295909 0.77252074 0.68555807 0.61411199 0.61377262 0.78842383]\n",
      "[84.82202506 83.17717719 63.02565145 64.00838208 63.80908012 64.02188158\n",
      " 65.56281018 67.27648544 69.07332826 65.54193664 62.63724828 65.38989687\n",
      " 61.58230066 66.46439767 65.28679943 62.63115501 61.82194519 61.92254758\n",
      " 58.13859391 51.15470529 50.19919229 50.10076618 50.64921904 49.99795079]\n",
      "[5.77399802 3.23318672 4.08260822 3.96539998 3.7212894  3.71795082\n",
      " 4.12644601 3.63859344 4.66775084 3.90560389 3.03074384 3.65781832\n",
      " 3.8712399  3.87999392 3.89565301 3.68327737 3.6592989  3.6627841\n",
      " 2.36515832 1.91634917 2.01043797 2.20118976 2.11044335 1.92543244]\n",
      "[0.89 0.91 0.24 0.95 0.93 0.93 0.92 0.93 0.77 0.69 0.8  0.65 0.84 0.91\n",
      " 0.53 0.95 0.92 0.92 0.13 0.83 0.68 0.4  0.49 0.87]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_cal = 4\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "CNN_accuracy_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_train_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_test_code_perso = np.zeros(nb_part)\n",
    "CNN_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*60)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "    ind2take = [j for j in range(nb_part) if j!=i]\n",
    "\n",
    "    X_train = np.expand_dims(np.concatenate(X[ind2take]).reshape(-1,X.shape[-2],X.shape[-1]),1)\n",
    "    Y_train = np.concatenate(y[ind2take]).reshape(-1)\n",
    "    domains_train = np.concatenate(domains[ind2take]).reshape(-1)\n",
    "    X_test = np.expand_dims(X[i],1)\n",
    "    Y_test = np.vstack((y[i],np.abs(1-y[i]))).T\n",
    "    labels_code_test = labels_code_list[i]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    X_std = X_train.std(axis=0)\n",
    "    X_train /= X_std + 1e-8\n",
    "    X_std = X_test.std(axis=0)\n",
    "    X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    X_train,Y_train,domains_train = balance(X_train,Y_train,domains_train)\n",
    "    Y_train = np.vstack((Y_train,np.abs(1-Y_train))).T\n",
    "    n_samples_windows = X_train.shape[-1]\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = basearchi(windows_size = n_samples_windows, n_channel_input = X_train.shape[2])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr, amsgrad=True)\n",
    "    clf.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "    history_list.append(clf.fit(np.array(x_train), y_train,\n",
    "                    batch_size=batchsize, epochs=epochs,\n",
    "                    validation_data=(np.array(x_val), y_val), shuffle=True))\n",
    "    CNN_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)[:,0]\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([0 if y[0] == 0 else 1 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    CNN_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, fps=60, consecutive=50, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    CNN_tps_test_code_perso[i] = time.time() - start\n",
    "    CNN_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(CNN_accuracy_perso)\n",
    "print(CNN_tps_train_code_perso)\n",
    "print(CNN_tps_test_code_perso)\n",
    "print(CNN_accuracy_code_perso)\n",
    "# pd.DataFrame(CNN_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score/DG_score.csv\")\n",
    "# pd.DataFrame(CNN_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score_code/DG_score_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_train_code/DG_tps_train_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_test_code/DG_tps_test_code.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.7533333333333333\n",
      "with 0.25s 0.7033333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([0.89, 0.91, 0.24, 0.95, 0.93, 0.93, 0.92, 0.93, 0.77, 0.69, 0.8,  0.65, 0.84, 0.91,\n",
    " 0.53, 0.95, 0.92, 0.92, 0.13, 0.83, 0.68, 0.4,  0.49, 0.87]))\n",
    "print(\"with 0.25s\",np.mean([0.49, 0.81, 0.25, 0.93, 0.75, 0.88, 0.81, 0.92, 0.84, 0.69, 0.76, 0.63, 0.73, 0.84,\n",
    " 0.47, 0.92, 0.89, 0.89, 0.2,  0.76, 0.71, 0.39, 0.41, 0.91]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.6607 - accuracy: 0.6143 - val_loss: 0.5705 - val_accuracy: 0.7036\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5938 - accuracy: 0.6953 - val_loss: 0.5520 - val_accuracy: 0.7240\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 2s 9ms/step - loss: 0.5763 - accuracy: 0.7079 - val_loss: 0.5348 - val_accuracy: 0.7383\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5705 - accuracy: 0.7160 - val_loss: 0.5336 - val_accuracy: 0.7317\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5698 - accuracy: 0.7172 - val_loss: 0.5343 - val_accuracy: 0.7388\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5643 - accuracy: 0.7201 - val_loss: 0.5362 - val_accuracy: 0.7410\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5596 - accuracy: 0.7211 - val_loss: 0.5326 - val_accuracy: 0.7416\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5549 - accuracy: 0.7261 - val_loss: 0.5277 - val_accuracy: 0.7410\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5553 - accuracy: 0.7282 - val_loss: 0.5237 - val_accuracy: 0.7477\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5532 - accuracy: 0.7271 - val_loss: 0.5259 - val_accuracy: 0.7388\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5527 - accuracy: 0.7311 - val_loss: 0.5205 - val_accuracy: 0.7399\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5543 - accuracy: 0.7267 - val_loss: 0.5266 - val_accuracy: 0.7455\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5547 - accuracy: 0.7274 - val_loss: 0.5226 - val_accuracy: 0.7361\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5476 - accuracy: 0.7332 - val_loss: 0.5234 - val_accuracy: 0.7427\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5486 - accuracy: 0.7313 - val_loss: 0.5217 - val_accuracy: 0.7433\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5494 - accuracy: 0.7304 - val_loss: 0.5199 - val_accuracy: 0.7488\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5465 - accuracy: 0.7316 - val_loss: 0.5192 - val_accuracy: 0.7449\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5447 - accuracy: 0.7356 - val_loss: 0.5184 - val_accuracy: 0.7350\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5457 - accuracy: 0.7340 - val_loss: 0.5173 - val_accuracy: 0.7460\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5440 - accuracy: 0.7320 - val_loss: 0.5168 - val_accuracy: 0.7455\n",
      "getting accuracy of participant  0\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4214285714285717\n",
      "TL to the participant :  1\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 11ms/step - loss: 0.6857 - accuracy: 0.5834 - val_loss: 0.5873 - val_accuracy: 0.7107\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.6114 - accuracy: 0.6770 - val_loss: 0.5554 - val_accuracy: 0.7300\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5894 - accuracy: 0.6945 - val_loss: 0.5491 - val_accuracy: 0.7322\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5746 - accuracy: 0.7114 - val_loss: 0.5442 - val_accuracy: 0.7295\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5745 - accuracy: 0.7108 - val_loss: 0.5448 - val_accuracy: 0.7328\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5682 - accuracy: 0.7174 - val_loss: 0.5379 - val_accuracy: 0.7377\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5632 - accuracy: 0.7198 - val_loss: 0.5360 - val_accuracy: 0.7394\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5569 - accuracy: 0.7205 - val_loss: 0.5283 - val_accuracy: 0.7383\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5582 - accuracy: 0.7233 - val_loss: 0.5317 - val_accuracy: 0.7394\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5578 - accuracy: 0.7215 - val_loss: 0.5301 - val_accuracy: 0.7444\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5535 - accuracy: 0.7267 - val_loss: 0.5277 - val_accuracy: 0.7543\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5524 - accuracy: 0.7277 - val_loss: 0.5205 - val_accuracy: 0.7438\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5514 - accuracy: 0.7285 - val_loss: 0.5264 - val_accuracy: 0.7477\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5519 - accuracy: 0.7307 - val_loss: 0.5215 - val_accuracy: 0.7449\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5512 - accuracy: 0.7268 - val_loss: 0.5261 - val_accuracy: 0.7499\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5480 - accuracy: 0.7283 - val_loss: 0.5243 - val_accuracy: 0.7466\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5446 - accuracy: 0.7313 - val_loss: 0.5180 - val_accuracy: 0.7532\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5457 - accuracy: 0.7321 - val_loss: 0.5198 - val_accuracy: 0.7477\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5469 - accuracy: 0.7308 - val_loss: 0.5177 - val_accuracy: 0.7570\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5476 - accuracy: 0.7288 - val_loss: 0.5191 - val_accuracy: 0.7548\n",
      "getting accuracy of participant  1\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4397435897435902\n",
      "TL to the participant :  2\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.6646 - accuracy: 0.6135 - val_loss: 0.5766 - val_accuracy: 0.7163\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5953 - accuracy: 0.6921 - val_loss: 0.5567 - val_accuracy: 0.7284\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5738 - accuracy: 0.7122 - val_loss: 0.5405 - val_accuracy: 0.7383\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5632 - accuracy: 0.7201 - val_loss: 0.5408 - val_accuracy: 0.7405\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 2s 9ms/step - loss: 0.5574 - accuracy: 0.7257 - val_loss: 0.5326 - val_accuracy: 0.7421\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5519 - accuracy: 0.7271 - val_loss: 0.5351 - val_accuracy: 0.7515\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5481 - accuracy: 0.7301 - val_loss: 0.5334 - val_accuracy: 0.7438\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5463 - accuracy: 0.7291 - val_loss: 0.5360 - val_accuracy: 0.7477\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5455 - accuracy: 0.7315 - val_loss: 0.5242 - val_accuracy: 0.7488\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5424 - accuracy: 0.7342 - val_loss: 0.5253 - val_accuracy: 0.7499\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5380 - accuracy: 0.7394 - val_loss: 0.5221 - val_accuracy: 0.7576\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 2s 9ms/step - loss: 0.5403 - accuracy: 0.7361 - val_loss: 0.5247 - val_accuracy: 0.7521\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 2s 9ms/step - loss: 0.5365 - accuracy: 0.7372 - val_loss: 0.5215 - val_accuracy: 0.7587\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5389 - accuracy: 0.7352 - val_loss: 0.5193 - val_accuracy: 0.7581\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5358 - accuracy: 0.7397 - val_loss: 0.5200 - val_accuracy: 0.7543\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5348 - accuracy: 0.7396 - val_loss: 0.5191 - val_accuracy: 0.7587\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5365 - accuracy: 0.7383 - val_loss: 0.5188 - val_accuracy: 0.7625\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5352 - accuracy: 0.7421 - val_loss: 0.5191 - val_accuracy: 0.7493\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5344 - accuracy: 0.7405 - val_loss: 0.5174 - val_accuracy: 0.7570\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5298 - accuracy: 0.7453 - val_loss: 0.5158 - val_accuracy: 0.7603\n",
      "getting accuracy of participant  2\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4724358974358975\n",
      "TL to the participant :  3\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 10ms/step - loss: 0.6617 - accuracy: 0.6162 - val_loss: 0.5828 - val_accuracy: 0.6992\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5973 - accuracy: 0.6860 - val_loss: 0.5636 - val_accuracy: 0.7157\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5814 - accuracy: 0.7008 - val_loss: 0.5578 - val_accuracy: 0.7306\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5743 - accuracy: 0.7088 - val_loss: 0.5573 - val_accuracy: 0.7355\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5704 - accuracy: 0.7105 - val_loss: 0.5546 - val_accuracy: 0.7333\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5663 - accuracy: 0.7171 - val_loss: 0.5589 - val_accuracy: 0.7278\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5608 - accuracy: 0.7225 - val_loss: 0.5509 - val_accuracy: 0.7322\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5638 - accuracy: 0.7187 - val_loss: 0.5541 - val_accuracy: 0.7366\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5531 - accuracy: 0.7261 - val_loss: 0.5440 - val_accuracy: 0.7416\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5564 - accuracy: 0.7270 - val_loss: 0.5488 - val_accuracy: 0.7416\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5534 - accuracy: 0.7281 - val_loss: 0.5489 - val_accuracy: 0.7388\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5534 - accuracy: 0.7279 - val_loss: 0.5463 - val_accuracy: 0.7366\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5510 - accuracy: 0.7282 - val_loss: 0.5415 - val_accuracy: 0.7416\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5490 - accuracy: 0.7296 - val_loss: 0.5404 - val_accuracy: 0.7438\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5493 - accuracy: 0.7264 - val_loss: 0.5447 - val_accuracy: 0.7399\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5511 - accuracy: 0.7302 - val_loss: 0.5413 - val_accuracy: 0.7405\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5445 - accuracy: 0.7323 - val_loss: 0.5394 - val_accuracy: 0.7455\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5478 - accuracy: 0.7320 - val_loss: 0.5415 - val_accuracy: 0.7416\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5432 - accuracy: 0.7357 - val_loss: 0.5362 - val_accuracy: 0.7433\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5446 - accuracy: 0.7347 - val_loss: 0.5405 - val_accuracy: 0.7471\n",
      "getting accuracy of participant  3\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4535087719298245\n",
      "TL to the participant :  4\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 11ms/step - loss: 0.6624 - accuracy: 0.6154 - val_loss: 0.5790 - val_accuracy: 0.6959\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5891 - accuracy: 0.6982 - val_loss: 0.5648 - val_accuracy: 0.7129\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5752 - accuracy: 0.7121 - val_loss: 0.5578 - val_accuracy: 0.7201\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5661 - accuracy: 0.7152 - val_loss: 0.5505 - val_accuracy: 0.7240\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5621 - accuracy: 0.7213 - val_loss: 0.5483 - val_accuracy: 0.7212\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5573 - accuracy: 0.7234 - val_loss: 0.5479 - val_accuracy: 0.7267\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5555 - accuracy: 0.7296 - val_loss: 0.5486 - val_accuracy: 0.7218\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5540 - accuracy: 0.7271 - val_loss: 0.5482 - val_accuracy: 0.7245\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5511 - accuracy: 0.7267 - val_loss: 0.5421 - val_accuracy: 0.7289\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5487 - accuracy: 0.7292 - val_loss: 0.5456 - val_accuracy: 0.7234\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5480 - accuracy: 0.7288 - val_loss: 0.5438 - val_accuracy: 0.7251\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5487 - accuracy: 0.7304 - val_loss: 0.5441 - val_accuracy: 0.7328\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5472 - accuracy: 0.7335 - val_loss: 0.5426 - val_accuracy: 0.7355\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5465 - accuracy: 0.7340 - val_loss: 0.5400 - val_accuracy: 0.7284\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5437 - accuracy: 0.7351 - val_loss: 0.5400 - val_accuracy: 0.7278\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5464 - accuracy: 0.7326 - val_loss: 0.5357 - val_accuracy: 0.7388\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5448 - accuracy: 0.7321 - val_loss: 0.5384 - val_accuracy: 0.7300\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5451 - accuracy: 0.7332 - val_loss: 0.5414 - val_accuracy: 0.7350\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 2s 10ms/step - loss: 0.5420 - accuracy: 0.7365 - val_loss: 0.5346 - val_accuracy: 0.7328\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5404 - accuracy: 0.7367 - val_loss: 0.5389 - val_accuracy: 0.7267\n",
      "getting accuracy of participant  4\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4266666666666667\n",
      "TL to the participant :  5\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 12ms/step - loss: 0.6770 - accuracy: 0.5968 - val_loss: 0.5962 - val_accuracy: 0.7074\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.6044 - accuracy: 0.6821 - val_loss: 0.5688 - val_accuracy: 0.7245\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5871 - accuracy: 0.6958 - val_loss: 0.5613 - val_accuracy: 0.7350\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5712 - accuracy: 0.7135 - val_loss: 0.5540 - val_accuracy: 0.7350\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5680 - accuracy: 0.7179 - val_loss: 0.5549 - val_accuracy: 0.7355\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5672 - accuracy: 0.7149 - val_loss: 0.5528 - val_accuracy: 0.7366\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5628 - accuracy: 0.7228 - val_loss: 0.5541 - val_accuracy: 0.7328\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5588 - accuracy: 0.7240 - val_loss: 0.5492 - val_accuracy: 0.7372\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5601 - accuracy: 0.7206 - val_loss: 0.5490 - val_accuracy: 0.7339\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5601 - accuracy: 0.7226 - val_loss: 0.5484 - val_accuracy: 0.7383\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5515 - accuracy: 0.7251 - val_loss: 0.5496 - val_accuracy: 0.7366\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5515 - accuracy: 0.7239 - val_loss: 0.5459 - val_accuracy: 0.7427\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5548 - accuracy: 0.7261 - val_loss: 0.5473 - val_accuracy: 0.7399\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5485 - accuracy: 0.7309 - val_loss: 0.5434 - val_accuracy: 0.7410\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5488 - accuracy: 0.7296 - val_loss: 0.5426 - val_accuracy: 0.7438\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5519 - accuracy: 0.7287 - val_loss: 0.5466 - val_accuracy: 0.7438\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5448 - accuracy: 0.7362 - val_loss: 0.5438 - val_accuracy: 0.7421\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5453 - accuracy: 0.7353 - val_loss: 0.5412 - val_accuracy: 0.7410\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5480 - accuracy: 0.7323 - val_loss: 0.5442 - val_accuracy: 0.7410\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5449 - accuracy: 0.7327 - val_loss: 0.5459 - val_accuracy: 0.7410\n",
      "getting accuracy of participant  5\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4378787878787878\n",
      "TL to the participant :  6\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 10ms/step - loss: 0.6742 - accuracy: 0.6015 - val_loss: 0.5965 - val_accuracy: 0.6854\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.6071 - accuracy: 0.6820 - val_loss: 0.5634 - val_accuracy: 0.7179\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5827 - accuracy: 0.7021 - val_loss: 0.5590 - val_accuracy: 0.7311\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5771 - accuracy: 0.7093 - val_loss: 0.5499 - val_accuracy: 0.7157\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5686 - accuracy: 0.7141 - val_loss: 0.5496 - val_accuracy: 0.7234\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5653 - accuracy: 0.7182 - val_loss: 0.5403 - val_accuracy: 0.7284\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5593 - accuracy: 0.7200 - val_loss: 0.5421 - val_accuracy: 0.7355\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5592 - accuracy: 0.7235 - val_loss: 0.5408 - val_accuracy: 0.7295\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5566 - accuracy: 0.7227 - val_loss: 0.5366 - val_accuracy: 0.7333\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5538 - accuracy: 0.7272 - val_loss: 0.5432 - val_accuracy: 0.7284\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5573 - accuracy: 0.7221 - val_loss: 0.5326 - val_accuracy: 0.7328\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5498 - accuracy: 0.7317 - val_loss: 0.5347 - val_accuracy: 0.7377\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5499 - accuracy: 0.7319 - val_loss: 0.5339 - val_accuracy: 0.7361\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5514 - accuracy: 0.7264 - val_loss: 0.5325 - val_accuracy: 0.7339\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5507 - accuracy: 0.7268 - val_loss: 0.5321 - val_accuracy: 0.7372\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5500 - accuracy: 0.7269 - val_loss: 0.5304 - val_accuracy: 0.7449\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5473 - accuracy: 0.7310 - val_loss: 0.5300 - val_accuracy: 0.7405\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5448 - accuracy: 0.7335 - val_loss: 0.5270 - val_accuracy: 0.7427\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5455 - accuracy: 0.7301 - val_loss: 0.5312 - val_accuracy: 0.7421\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5427 - accuracy: 0.7374 - val_loss: 0.5299 - val_accuracy: 0.7361\n",
      "getting accuracy of participant  6\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4129166666666666\n",
      "TL to the participant :  7\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 10ms/step - loss: 0.6697 - accuracy: 0.6058 - val_loss: 0.5844 - val_accuracy: 0.6970\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5983 - accuracy: 0.6949 - val_loss: 0.5604 - val_accuracy: 0.7300\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5820 - accuracy: 0.7024 - val_loss: 0.5528 - val_accuracy: 0.7361\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5751 - accuracy: 0.7058 - val_loss: 0.5480 - val_accuracy: 0.7416\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5682 - accuracy: 0.7178 - val_loss: 0.5447 - val_accuracy: 0.7317\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5652 - accuracy: 0.7134 - val_loss: 0.5455 - val_accuracy: 0.7339\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5638 - accuracy: 0.7189 - val_loss: 0.5415 - val_accuracy: 0.7444\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5600 - accuracy: 0.7186 - val_loss: 0.5411 - val_accuracy: 0.7388\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5582 - accuracy: 0.7217 - val_loss: 0.5393 - val_accuracy: 0.7438\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5548 - accuracy: 0.7257 - val_loss: 0.5365 - val_accuracy: 0.7444\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5550 - accuracy: 0.7274 - val_loss: 0.5365 - val_accuracy: 0.7460\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5528 - accuracy: 0.7269 - val_loss: 0.5386 - val_accuracy: 0.7383\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5535 - accuracy: 0.7285 - val_loss: 0.5343 - val_accuracy: 0.7477\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5498 - accuracy: 0.7291 - val_loss: 0.5382 - val_accuracy: 0.7399\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5508 - accuracy: 0.7263 - val_loss: 0.5281 - val_accuracy: 0.7521\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5500 - accuracy: 0.7270 - val_loss: 0.5329 - val_accuracy: 0.7460\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5484 - accuracy: 0.7313 - val_loss: 0.5306 - val_accuracy: 0.7532\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5493 - accuracy: 0.7306 - val_loss: 0.5308 - val_accuracy: 0.7504\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 13ms/step - loss: 0.5461 - accuracy: 0.7312 - val_loss: 0.5308 - val_accuracy: 0.7499\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5465 - accuracy: 0.7312 - val_loss: 0.5308 - val_accuracy: 0.7499\n",
      "getting accuracy of participant  7\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4083333333333334\n",
      "TL to the participant :  8\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 10ms/step - loss: 0.6666 - accuracy: 0.6102 - val_loss: 0.6019 - val_accuracy: 0.6860\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.6012 - accuracy: 0.6840 - val_loss: 0.5969 - val_accuracy: 0.6860\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5847 - accuracy: 0.7029 - val_loss: 0.5844 - val_accuracy: 0.6948\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5752 - accuracy: 0.7124 - val_loss: 0.5770 - val_accuracy: 0.7063\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5674 - accuracy: 0.7163 - val_loss: 0.5740 - val_accuracy: 0.7085\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5638 - accuracy: 0.7168 - val_loss: 0.5726 - val_accuracy: 0.7058\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5560 - accuracy: 0.7252 - val_loss: 0.5688 - val_accuracy: 0.7096\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5541 - accuracy: 0.7253 - val_loss: 0.5704 - val_accuracy: 0.7030\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5517 - accuracy: 0.7288 - val_loss: 0.5647 - val_accuracy: 0.7113\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5507 - accuracy: 0.7272 - val_loss: 0.5696 - val_accuracy: 0.7041\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5510 - accuracy: 0.7277 - val_loss: 0.5666 - val_accuracy: 0.7085\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5468 - accuracy: 0.7284 - val_loss: 0.5680 - val_accuracy: 0.7102\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5454 - accuracy: 0.7306 - val_loss: 0.5638 - val_accuracy: 0.7113\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5451 - accuracy: 0.7310 - val_loss: 0.5628 - val_accuracy: 0.7146\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5462 - accuracy: 0.7343 - val_loss: 0.5654 - val_accuracy: 0.7058\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5432 - accuracy: 0.7361 - val_loss: 0.5621 - val_accuracy: 0.7163\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5434 - accuracy: 0.7322 - val_loss: 0.5602 - val_accuracy: 0.7129\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5408 - accuracy: 0.7343 - val_loss: 0.5642 - val_accuracy: 0.7113\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5373 - accuracy: 0.7351 - val_loss: 0.5637 - val_accuracy: 0.7129\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5400 - accuracy: 0.7359 - val_loss: 0.5665 - val_accuracy: 0.7102\n",
      "getting accuracy of participant  8\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4172222222222224\n",
      "TL to the participant :  9\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.6432 - accuracy: 0.6401 - val_loss: 0.5970 - val_accuracy: 0.6981\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5832 - accuracy: 0.7026 - val_loss: 0.5710 - val_accuracy: 0.7102\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5644 - accuracy: 0.7132 - val_loss: 0.5689 - val_accuracy: 0.7163\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5632 - accuracy: 0.7163 - val_loss: 0.5677 - val_accuracy: 0.7218\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5598 - accuracy: 0.7223 - val_loss: 0.5600 - val_accuracy: 0.7190\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5574 - accuracy: 0.7256 - val_loss: 0.5646 - val_accuracy: 0.7190\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5580 - accuracy: 0.7214 - val_loss: 0.5608 - val_accuracy: 0.7218\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5508 - accuracy: 0.7255 - val_loss: 0.5653 - val_accuracy: 0.7262\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5517 - accuracy: 0.7245 - val_loss: 0.5570 - val_accuracy: 0.7207\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5455 - accuracy: 0.7326 - val_loss: 0.5530 - val_accuracy: 0.7284\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5480 - accuracy: 0.7294 - val_loss: 0.5547 - val_accuracy: 0.7245\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5484 - accuracy: 0.7284 - val_loss: 0.5520 - val_accuracy: 0.7218\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5467 - accuracy: 0.7297 - val_loss: 0.5515 - val_accuracy: 0.7317\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5474 - accuracy: 0.7336 - val_loss: 0.5517 - val_accuracy: 0.7273\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5445 - accuracy: 0.7295 - val_loss: 0.5500 - val_accuracy: 0.7372\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5432 - accuracy: 0.7342 - val_loss: 0.5505 - val_accuracy: 0.7306\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5427 - accuracy: 0.7337 - val_loss: 0.5515 - val_accuracy: 0.7289\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5443 - accuracy: 0.7294 - val_loss: 0.5483 - val_accuracy: 0.7317\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5416 - accuracy: 0.7339 - val_loss: 0.5478 - val_accuracy: 0.7284\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5392 - accuracy: 0.7361 - val_loss: 0.5490 - val_accuracy: 0.7218\n",
      "getting accuracy of participant  9\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4455882352941178\n",
      "TL to the participant :  10\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.6770 - accuracy: 0.6026 - val_loss: 0.5961 - val_accuracy: 0.7008\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.6061 - accuracy: 0.6794 - val_loss: 0.5797 - val_accuracy: 0.7273\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5866 - accuracy: 0.7017 - val_loss: 0.5604 - val_accuracy: 0.7234\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5757 - accuracy: 0.7071 - val_loss: 0.5540 - val_accuracy: 0.7306\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5721 - accuracy: 0.7089 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5638 - accuracy: 0.7170 - val_loss: 0.5426 - val_accuracy: 0.7372\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5624 - accuracy: 0.7182 - val_loss: 0.5392 - val_accuracy: 0.7466\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5609 - accuracy: 0.7187 - val_loss: 0.5435 - val_accuracy: 0.7344\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5598 - accuracy: 0.7202 - val_loss: 0.5350 - val_accuracy: 0.7416\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5549 - accuracy: 0.7277 - val_loss: 0.5305 - val_accuracy: 0.7526\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5547 - accuracy: 0.7258 - val_loss: 0.5319 - val_accuracy: 0.7510\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5508 - accuracy: 0.7237 - val_loss: 0.5244 - val_accuracy: 0.7521\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5513 - accuracy: 0.7276 - val_loss: 0.5235 - val_accuracy: 0.7515\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5461 - accuracy: 0.7340 - val_loss: 0.5282 - val_accuracy: 0.7482\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5476 - accuracy: 0.7296 - val_loss: 0.5249 - val_accuracy: 0.7570\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5462 - accuracy: 0.7312 - val_loss: 0.5236 - val_accuracy: 0.7543\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5463 - accuracy: 0.7297 - val_loss: 0.5235 - val_accuracy: 0.7570\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5452 - accuracy: 0.7309 - val_loss: 0.5269 - val_accuracy: 0.7499\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5454 - accuracy: 0.7313 - val_loss: 0.5227 - val_accuracy: 0.7570\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5461 - accuracy: 0.7290 - val_loss: 0.5182 - val_accuracy: 0.7609\n",
      "getting accuracy of participant  10\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4010416666666665\n",
      "TL to the participant :  11\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 10ms/step - loss: 0.6554 - accuracy: 0.6285 - val_loss: 0.5742 - val_accuracy: 0.6986\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5942 - accuracy: 0.6952 - val_loss: 0.5549 - val_accuracy: 0.7234\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5748 - accuracy: 0.7064 - val_loss: 0.5362 - val_accuracy: 0.7361\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5709 - accuracy: 0.7078 - val_loss: 0.5396 - val_accuracy: 0.7306\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5660 - accuracy: 0.7153 - val_loss: 0.5330 - val_accuracy: 0.7427\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5614 - accuracy: 0.7221 - val_loss: 0.5384 - val_accuracy: 0.7433\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5584 - accuracy: 0.7253 - val_loss: 0.5302 - val_accuracy: 0.7466\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5567 - accuracy: 0.7225 - val_loss: 0.5386 - val_accuracy: 0.7416\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5521 - accuracy: 0.7307 - val_loss: 0.5237 - val_accuracy: 0.7433\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5529 - accuracy: 0.7248 - val_loss: 0.5260 - val_accuracy: 0.7532\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5473 - accuracy: 0.7319 - val_loss: 0.5215 - val_accuracy: 0.7504\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5439 - accuracy: 0.7375 - val_loss: 0.5209 - val_accuracy: 0.7504\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5474 - accuracy: 0.7336 - val_loss: 0.5199 - val_accuracy: 0.7515\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5457 - accuracy: 0.7346 - val_loss: 0.5223 - val_accuracy: 0.7515\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5455 - accuracy: 0.7346 - val_loss: 0.5176 - val_accuracy: 0.7532\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5390 - accuracy: 0.7369 - val_loss: 0.5183 - val_accuracy: 0.7576\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5443 - accuracy: 0.7321 - val_loss: 0.5176 - val_accuracy: 0.7554\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5367 - accuracy: 0.7355 - val_loss: 0.5148 - val_accuracy: 0.7543\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5375 - accuracy: 0.7342 - val_loss: 0.5126 - val_accuracy: 0.7592\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5398 - accuracy: 0.7334 - val_loss: 0.5163 - val_accuracy: 0.7576\n",
      "getting accuracy of participant  11\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.407333333333333\n",
      "TL to the participant :  12\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 10ms/step - loss: 0.6526 - accuracy: 0.6335 - val_loss: 0.5912 - val_accuracy: 0.6860\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5903 - accuracy: 0.6962 - val_loss: 0.5712 - val_accuracy: 0.7003\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5802 - accuracy: 0.7025 - val_loss: 0.5633 - val_accuracy: 0.7113\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5741 - accuracy: 0.7078 - val_loss: 0.5655 - val_accuracy: 0.7113\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5653 - accuracy: 0.7198 - val_loss: 0.5497 - val_accuracy: 0.7223\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5639 - accuracy: 0.7164 - val_loss: 0.5600 - val_accuracy: 0.7157\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5603 - accuracy: 0.7187 - val_loss: 0.5538 - val_accuracy: 0.7223\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5563 - accuracy: 0.7200 - val_loss: 0.5511 - val_accuracy: 0.7273\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5520 - accuracy: 0.7269 - val_loss: 0.5482 - val_accuracy: 0.7234\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5546 - accuracy: 0.7240 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5506 - accuracy: 0.7270 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5479 - accuracy: 0.7305 - val_loss: 0.5436 - val_accuracy: 0.7251\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5496 - accuracy: 0.7261 - val_loss: 0.5456 - val_accuracy: 0.7196\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5462 - accuracy: 0.7334 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5473 - accuracy: 0.7296 - val_loss: 0.5376 - val_accuracy: 0.7333\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5466 - accuracy: 0.7329 - val_loss: 0.5411 - val_accuracy: 0.7328\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5431 - accuracy: 0.7321 - val_loss: 0.5407 - val_accuracy: 0.7322\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5440 - accuracy: 0.7326 - val_loss: 0.5439 - val_accuracy: 0.7306\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5439 - accuracy: 0.7349 - val_loss: 0.5383 - val_accuracy: 0.7295\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5431 - accuracy: 0.7336 - val_loss: 0.5383 - val_accuracy: 0.7328\n",
      "getting accuracy of participant  12\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4346153846153848\n",
      "TL to the participant :  13\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 11ms/step - loss: 0.6548 - accuracy: 0.6281 - val_loss: 0.5757 - val_accuracy: 0.7152\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5957 - accuracy: 0.6941 - val_loss: 0.5527 - val_accuracy: 0.7306\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5790 - accuracy: 0.7119 - val_loss: 0.5546 - val_accuracy: 0.7295\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5699 - accuracy: 0.7133 - val_loss: 0.5480 - val_accuracy: 0.7339\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5691 - accuracy: 0.7193 - val_loss: 0.5448 - val_accuracy: 0.7361\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5586 - accuracy: 0.7195 - val_loss: 0.5425 - val_accuracy: 0.7322\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5590 - accuracy: 0.7236 - val_loss: 0.5372 - val_accuracy: 0.7405\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5565 - accuracy: 0.7264 - val_loss: 0.5358 - val_accuracy: 0.7444\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5532 - accuracy: 0.7292 - val_loss: 0.5298 - val_accuracy: 0.7427\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5540 - accuracy: 0.7299 - val_loss: 0.5351 - val_accuracy: 0.7421\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5534 - accuracy: 0.7250 - val_loss: 0.5359 - val_accuracy: 0.7421\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5498 - accuracy: 0.7298 - val_loss: 0.5272 - val_accuracy: 0.7488\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5496 - accuracy: 0.7287 - val_loss: 0.5364 - val_accuracy: 0.7388\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5475 - accuracy: 0.7293 - val_loss: 0.5321 - val_accuracy: 0.7377\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5482 - accuracy: 0.7306 - val_loss: 0.5279 - val_accuracy: 0.7460\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5463 - accuracy: 0.7336 - val_loss: 0.5267 - val_accuracy: 0.7433\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5479 - accuracy: 0.7332 - val_loss: 0.5265 - val_accuracy: 0.7372\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5470 - accuracy: 0.7305 - val_loss: 0.5282 - val_accuracy: 0.7361\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5481 - accuracy: 0.7323 - val_loss: 0.5271 - val_accuracy: 0.7455\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5475 - accuracy: 0.7336 - val_loss: 0.5286 - val_accuracy: 0.7405\n",
      "getting accuracy of participant  13\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4350877192982459\n",
      "TL to the participant :  14\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 11ms/step - loss: 0.6452 - accuracy: 0.6388 - val_loss: 0.5594 - val_accuracy: 0.7240\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5849 - accuracy: 0.6998 - val_loss: 0.5409 - val_accuracy: 0.7383\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5664 - accuracy: 0.7147 - val_loss: 0.5359 - val_accuracy: 0.7405\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5573 - accuracy: 0.7222 - val_loss: 0.5384 - val_accuracy: 0.7515\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5552 - accuracy: 0.7243 - val_loss: 0.5281 - val_accuracy: 0.7499\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5529 - accuracy: 0.7278 - val_loss: 0.5247 - val_accuracy: 0.7603\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5521 - accuracy: 0.7301 - val_loss: 0.5251 - val_accuracy: 0.7526\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5479 - accuracy: 0.7305 - val_loss: 0.5241 - val_accuracy: 0.7521\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5435 - accuracy: 0.7346 - val_loss: 0.5249 - val_accuracy: 0.7510\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5451 - accuracy: 0.7339 - val_loss: 0.5280 - val_accuracy: 0.7521\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5401 - accuracy: 0.7386 - val_loss: 0.5212 - val_accuracy: 0.7543\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5410 - accuracy: 0.7364 - val_loss: 0.5217 - val_accuracy: 0.7526\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5379 - accuracy: 0.7375 - val_loss: 0.5204 - val_accuracy: 0.7466\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5359 - accuracy: 0.7373 - val_loss: 0.5189 - val_accuracy: 0.7521\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5396 - accuracy: 0.7372 - val_loss: 0.5209 - val_accuracy: 0.7482\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5347 - accuracy: 0.7413 - val_loss: 0.5253 - val_accuracy: 0.7504\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5364 - accuracy: 0.7378 - val_loss: 0.5200 - val_accuracy: 0.7510\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5366 - accuracy: 0.7375 - val_loss: 0.5173 - val_accuracy: 0.7543\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5310 - accuracy: 0.7410 - val_loss: 0.5241 - val_accuracy: 0.7521\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5327 - accuracy: 0.7412 - val_loss: 0.5266 - val_accuracy: 0.7482\n",
      "getting accuracy of participant  14\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4333333333333333\n",
      "TL to the participant :  15\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 11ms/step - loss: 0.6662 - accuracy: 0.6118 - val_loss: 0.5788 - val_accuracy: 0.7102\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5950 - accuracy: 0.6934 - val_loss: 0.5516 - val_accuracy: 0.7295\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5765 - accuracy: 0.7035 - val_loss: 0.5557 - val_accuracy: 0.7333\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5702 - accuracy: 0.7159 - val_loss: 0.5455 - val_accuracy: 0.7399\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5674 - accuracy: 0.7129 - val_loss: 0.5441 - val_accuracy: 0.7394\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5608 - accuracy: 0.7224 - val_loss: 0.5415 - val_accuracy: 0.7388\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5557 - accuracy: 0.7244 - val_loss: 0.5382 - val_accuracy: 0.7410\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5558 - accuracy: 0.7283 - val_loss: 0.5352 - val_accuracy: 0.7405\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5529 - accuracy: 0.7257 - val_loss: 0.5339 - val_accuracy: 0.7366\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5533 - accuracy: 0.7265 - val_loss: 0.5347 - val_accuracy: 0.7410\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5497 - accuracy: 0.7319 - val_loss: 0.5383 - val_accuracy: 0.7383\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5488 - accuracy: 0.7293 - val_loss: 0.5312 - val_accuracy: 0.7427\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5473 - accuracy: 0.7336 - val_loss: 0.5339 - val_accuracy: 0.7388\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5479 - accuracy: 0.7313 - val_loss: 0.5322 - val_accuracy: 0.7383\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5456 - accuracy: 0.7313 - val_loss: 0.5316 - val_accuracy: 0.7377\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5450 - accuracy: 0.7310 - val_loss: 0.5292 - val_accuracy: 0.7421\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5453 - accuracy: 0.7323 - val_loss: 0.5362 - val_accuracy: 0.7410\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5445 - accuracy: 0.7325 - val_loss: 0.5338 - val_accuracy: 0.7361\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5426 - accuracy: 0.7360 - val_loss: 0.5288 - val_accuracy: 0.7466\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5407 - accuracy: 0.7375 - val_loss: 0.5261 - val_accuracy: 0.7421\n",
      "getting accuracy of participant  15\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4011363636363638\n",
      "TL to the participant :  16\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 10ms/step - loss: 0.6577 - accuracy: 0.6211 - val_loss: 0.5872 - val_accuracy: 0.6876\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5875 - accuracy: 0.6974 - val_loss: 0.5658 - val_accuracy: 0.7063\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5731 - accuracy: 0.7078 - val_loss: 0.5588 - val_accuracy: 0.7174\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5658 - accuracy: 0.7164 - val_loss: 0.5538 - val_accuracy: 0.7157\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5589 - accuracy: 0.7201 - val_loss: 0.5487 - val_accuracy: 0.7212\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5603 - accuracy: 0.7178 - val_loss: 0.5474 - val_accuracy: 0.7300\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5527 - accuracy: 0.7273 - val_loss: 0.5431 - val_accuracy: 0.7311\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5510 - accuracy: 0.7250 - val_loss: 0.5454 - val_accuracy: 0.7273\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5501 - accuracy: 0.7299 - val_loss: 0.5438 - val_accuracy: 0.7300\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5459 - accuracy: 0.7304 - val_loss: 0.5395 - val_accuracy: 0.7300\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5459 - accuracy: 0.7296 - val_loss: 0.5394 - val_accuracy: 0.7273\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5437 - accuracy: 0.7316 - val_loss: 0.5360 - val_accuracy: 0.7339\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5424 - accuracy: 0.7337 - val_loss: 0.5327 - val_accuracy: 0.7355\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5420 - accuracy: 0.7346 - val_loss: 0.5414 - val_accuracy: 0.7317\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5431 - accuracy: 0.7362 - val_loss: 0.5367 - val_accuracy: 0.7328\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5391 - accuracy: 0.7371 - val_loss: 0.5327 - val_accuracy: 0.7410\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5417 - accuracy: 0.7370 - val_loss: 0.5335 - val_accuracy: 0.7361\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5407 - accuracy: 0.7364 - val_loss: 0.5297 - val_accuracy: 0.7416\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5407 - accuracy: 0.7359 - val_loss: 0.5303 - val_accuracy: 0.7355\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5385 - accuracy: 0.7378 - val_loss: 0.5334 - val_accuracy: 0.7344\n",
      "getting accuracy of participant  16\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4089743589743593\n",
      "TL to the participant :  17\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 10ms/step - loss: 0.6801 - accuracy: 0.5944 - val_loss: 0.5894 - val_accuracy: 0.7102\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.6042 - accuracy: 0.6807 - val_loss: 0.5716 - val_accuracy: 0.7245\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5859 - accuracy: 0.7020 - val_loss: 0.5727 - val_accuracy: 0.7185\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5775 - accuracy: 0.7092 - val_loss: 0.5677 - val_accuracy: 0.7223\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5718 - accuracy: 0.7131 - val_loss: 0.5594 - val_accuracy: 0.7311\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5649 - accuracy: 0.7169 - val_loss: 0.5575 - val_accuracy: 0.7350\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5627 - accuracy: 0.7184 - val_loss: 0.5530 - val_accuracy: 0.7344\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5606 - accuracy: 0.7193 - val_loss: 0.5511 - val_accuracy: 0.7372\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5542 - accuracy: 0.7241 - val_loss: 0.5524 - val_accuracy: 0.7300\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5562 - accuracy: 0.7218 - val_loss: 0.5476 - val_accuracy: 0.7361\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5546 - accuracy: 0.7247 - val_loss: 0.5476 - val_accuracy: 0.7355\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5517 - accuracy: 0.7266 - val_loss: 0.5459 - val_accuracy: 0.7377\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5519 - accuracy: 0.7292 - val_loss: 0.5428 - val_accuracy: 0.7388\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5486 - accuracy: 0.7313 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5472 - accuracy: 0.7301 - val_loss: 0.5442 - val_accuracy: 0.7306\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5510 - accuracy: 0.7297 - val_loss: 0.5389 - val_accuracy: 0.7366\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5494 - accuracy: 0.7290 - val_loss: 0.5410 - val_accuracy: 0.7366\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5448 - accuracy: 0.7337 - val_loss: 0.5372 - val_accuracy: 0.7361\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5469 - accuracy: 0.7293 - val_loss: 0.5413 - val_accuracy: 0.7361\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5469 - accuracy: 0.7294 - val_loss: 0.5372 - val_accuracy: 0.7433\n",
      "getting accuracy of participant  17\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4311111111111112\n",
      "TL to the participant :  18\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 11ms/step - loss: 0.6582 - accuracy: 0.6176 - val_loss: 0.5562 - val_accuracy: 0.7410\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5920 - accuracy: 0.6943 - val_loss: 0.5422 - val_accuracy: 0.7366\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5691 - accuracy: 0.7168 - val_loss: 0.5330 - val_accuracy: 0.7394\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 13ms/step - loss: 0.5611 - accuracy: 0.7232 - val_loss: 0.5209 - val_accuracy: 0.7438\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5559 - accuracy: 0.7308 - val_loss: 0.5223 - val_accuracy: 0.7477\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5531 - accuracy: 0.7264 - val_loss: 0.5160 - val_accuracy: 0.7504\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5513 - accuracy: 0.7282 - val_loss: 0.5219 - val_accuracy: 0.7499\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5447 - accuracy: 0.7330 - val_loss: 0.5174 - val_accuracy: 0.7482\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5452 - accuracy: 0.7332 - val_loss: 0.5186 - val_accuracy: 0.7521\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5420 - accuracy: 0.7332 - val_loss: 0.5153 - val_accuracy: 0.7526\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5387 - accuracy: 0.7372 - val_loss: 0.5146 - val_accuracy: 0.7587\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5371 - accuracy: 0.7374 - val_loss: 0.5139 - val_accuracy: 0.7526\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5387 - accuracy: 0.7371 - val_loss: 0.5117 - val_accuracy: 0.7499\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5356 - accuracy: 0.7410 - val_loss: 0.5131 - val_accuracy: 0.7526\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5341 - accuracy: 0.7404 - val_loss: 0.5123 - val_accuracy: 0.7460\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5335 - accuracy: 0.7426 - val_loss: 0.5095 - val_accuracy: 0.7532\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5336 - accuracy: 0.7394 - val_loss: 0.5136 - val_accuracy: 0.7554\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5313 - accuracy: 0.7429 - val_loss: 0.5069 - val_accuracy: 0.7537\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5339 - accuracy: 0.7408 - val_loss: 0.5100 - val_accuracy: 0.7504\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5335 - accuracy: 0.7433 - val_loss: 0.5066 - val_accuracy: 0.7559\n",
      "getting accuracy of participant  18\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4240740740740738\n",
      "TL to the participant :  19\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 12ms/step - loss: 0.6562 - accuracy: 0.6249 - val_loss: 0.5690 - val_accuracy: 0.7284\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5947 - accuracy: 0.6937 - val_loss: 0.5458 - val_accuracy: 0.7372\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5768 - accuracy: 0.7078 - val_loss: 0.5366 - val_accuracy: 0.7526\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5686 - accuracy: 0.7189 - val_loss: 0.5360 - val_accuracy: 0.7493\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5669 - accuracy: 0.7184 - val_loss: 0.5366 - val_accuracy: 0.7603\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5593 - accuracy: 0.7179 - val_loss: 0.5300 - val_accuracy: 0.7565\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5589 - accuracy: 0.7237 - val_loss: 0.5318 - val_accuracy: 0.7499\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5574 - accuracy: 0.7260 - val_loss: 0.5325 - val_accuracy: 0.7471\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5576 - accuracy: 0.7240 - val_loss: 0.5279 - val_accuracy: 0.7565\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5523 - accuracy: 0.7270 - val_loss: 0.5202 - val_accuracy: 0.7565\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5550 - accuracy: 0.7266 - val_loss: 0.5254 - val_accuracy: 0.7504\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5471 - accuracy: 0.7345 - val_loss: 0.5221 - val_accuracy: 0.7598\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5466 - accuracy: 0.7323 - val_loss: 0.5289 - val_accuracy: 0.7543\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5463 - accuracy: 0.7320 - val_loss: 0.5175 - val_accuracy: 0.7614\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5458 - accuracy: 0.7365 - val_loss: 0.5162 - val_accuracy: 0.7598\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5472 - accuracy: 0.7324 - val_loss: 0.5175 - val_accuracy: 0.7653\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5449 - accuracy: 0.7302 - val_loss: 0.5158 - val_accuracy: 0.7631\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5439 - accuracy: 0.7313 - val_loss: 0.5169 - val_accuracy: 0.7592\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5446 - accuracy: 0.7326 - val_loss: 0.5124 - val_accuracy: 0.7609\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5418 - accuracy: 0.7358 - val_loss: 0.5193 - val_accuracy: 0.7581\n",
      "getting accuracy of participant  19\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4457264957264961\n",
      "TL to the participant :  20\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 11ms/step - loss: 0.6658 - accuracy: 0.6165 - val_loss: 0.5863 - val_accuracy: 0.7074\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5980 - accuracy: 0.6891 - val_loss: 0.5645 - val_accuracy: 0.7295\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5768 - accuracy: 0.7100 - val_loss: 0.5641 - val_accuracy: 0.7234\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5666 - accuracy: 0.7135 - val_loss: 0.5577 - val_accuracy: 0.7295\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5622 - accuracy: 0.7182 - val_loss: 0.5497 - val_accuracy: 0.7322\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5536 - accuracy: 0.7258 - val_loss: 0.5594 - val_accuracy: 0.7284\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5530 - accuracy: 0.7271 - val_loss: 0.5517 - val_accuracy: 0.7278\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5530 - accuracy: 0.7260 - val_loss: 0.5470 - val_accuracy: 0.7350\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5480 - accuracy: 0.7291 - val_loss: 0.5450 - val_accuracy: 0.7355\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5469 - accuracy: 0.7281 - val_loss: 0.5445 - val_accuracy: 0.7372\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5483 - accuracy: 0.7299 - val_loss: 0.5477 - val_accuracy: 0.7328\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5451 - accuracy: 0.7303 - val_loss: 0.5442 - val_accuracy: 0.7339\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5416 - accuracy: 0.7339 - val_loss: 0.5434 - val_accuracy: 0.7344\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5454 - accuracy: 0.7340 - val_loss: 0.5412 - val_accuracy: 0.7361\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5401 - accuracy: 0.7320 - val_loss: 0.5428 - val_accuracy: 0.7350\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5387 - accuracy: 0.7354 - val_loss: 0.5413 - val_accuracy: 0.7361\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5412 - accuracy: 0.7340 - val_loss: 0.5404 - val_accuracy: 0.7361\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5369 - accuracy: 0.7357 - val_loss: 0.5413 - val_accuracy: 0.7383\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5411 - accuracy: 0.7304 - val_loss: 0.5412 - val_accuracy: 0.7355\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 13ms/step - loss: 0.5384 - accuracy: 0.7380 - val_loss: 0.5457 - val_accuracy: 0.7306\n",
      "getting accuracy of participant  20\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4103448275862074\n",
      "TL to the participant :  21\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 12ms/step - loss: 0.6439 - accuracy: 0.6395 - val_loss: 0.5549 - val_accuracy: 0.7322\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5868 - accuracy: 0.6979 - val_loss: 0.5413 - val_accuracy: 0.7355\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5667 - accuracy: 0.7159 - val_loss: 0.5370 - val_accuracy: 0.7377\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5692 - accuracy: 0.7141 - val_loss: 0.5403 - val_accuracy: 0.7295\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5566 - accuracy: 0.7296 - val_loss: 0.5349 - val_accuracy: 0.7416\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5523 - accuracy: 0.7251 - val_loss: 0.5267 - val_accuracy: 0.7433\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5539 - accuracy: 0.7269 - val_loss: 0.5278 - val_accuracy: 0.7427\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5489 - accuracy: 0.7277 - val_loss: 0.5269 - val_accuracy: 0.7421\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5484 - accuracy: 0.7307 - val_loss: 0.5213 - val_accuracy: 0.7455\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5488 - accuracy: 0.7308 - val_loss: 0.5251 - val_accuracy: 0.7438\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5476 - accuracy: 0.7321 - val_loss: 0.5213 - val_accuracy: 0.7444\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5457 - accuracy: 0.7349 - val_loss: 0.5260 - val_accuracy: 0.7427\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5431 - accuracy: 0.7377 - val_loss: 0.5211 - val_accuracy: 0.7488\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5429 - accuracy: 0.7320 - val_loss: 0.5187 - val_accuracy: 0.7449\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5398 - accuracy: 0.7349 - val_loss: 0.5236 - val_accuracy: 0.7455\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5377 - accuracy: 0.7365 - val_loss: 0.5211 - val_accuracy: 0.7449\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5394 - accuracy: 0.7387 - val_loss: 0.5196 - val_accuracy: 0.7444\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 10ms/step - loss: 0.5392 - accuracy: 0.7357 - val_loss: 0.5210 - val_accuracy: 0.7399\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5410 - accuracy: 0.7363 - val_loss: 0.5256 - val_accuracy: 0.7416\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5401 - accuracy: 0.7359 - val_loss: 0.5197 - val_accuracy: 0.7466\n",
      "getting accuracy of participant  21\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4131944444444444\n",
      "TL to the participant :  22\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 5s 13ms/step - loss: 0.6663 - accuracy: 0.6108 - val_loss: 0.5630 - val_accuracy: 0.7355\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5959 - accuracy: 0.6910 - val_loss: 0.5500 - val_accuracy: 0.7322\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5748 - accuracy: 0.7097 - val_loss: 0.5405 - val_accuracy: 0.7510\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5658 - accuracy: 0.7165 - val_loss: 0.5363 - val_accuracy: 0.7565\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5583 - accuracy: 0.7225 - val_loss: 0.5299 - val_accuracy: 0.7477\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5540 - accuracy: 0.7263 - val_loss: 0.5345 - val_accuracy: 0.7466\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5566 - accuracy: 0.7229 - val_loss: 0.5316 - val_accuracy: 0.7488\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5523 - accuracy: 0.7259 - val_loss: 0.5253 - val_accuracy: 0.7499\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5500 - accuracy: 0.7282 - val_loss: 0.5232 - val_accuracy: 0.7510\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5515 - accuracy: 0.7288 - val_loss: 0.5283 - val_accuracy: 0.7421\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5461 - accuracy: 0.7323 - val_loss: 0.5230 - val_accuracy: 0.7504\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5491 - accuracy: 0.7269 - val_loss: 0.5193 - val_accuracy: 0.7482\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5423 - accuracy: 0.7334 - val_loss: 0.5183 - val_accuracy: 0.7532\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5423 - accuracy: 0.7320 - val_loss: 0.5173 - val_accuracy: 0.7515\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5401 - accuracy: 0.7342 - val_loss: 0.5192 - val_accuracy: 0.7499\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5410 - accuracy: 0.7340 - val_loss: 0.5151 - val_accuracy: 0.7526\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5359 - accuracy: 0.7367 - val_loss: 0.5142 - val_accuracy: 0.7576\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5397 - accuracy: 0.7335 - val_loss: 0.5165 - val_accuracy: 0.7554\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5365 - accuracy: 0.7396 - val_loss: 0.5135 - val_accuracy: 0.7576\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5380 - accuracy: 0.7376 - val_loss: 0.5145 - val_accuracy: 0.7543\n",
      "getting accuracy of participant  22\n",
      "196/196 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4729166666666664\n",
      "TL to the participant :  23\n",
      "(198930, 1, 8, 150)\n",
      "(198930,)\n",
      "(6270, 1, 8, 150)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 4s 12ms/step - loss: 0.6605 - accuracy: 0.6178 - val_loss: 0.5680 - val_accuracy: 0.7157\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5957 - accuracy: 0.6942 - val_loss: 0.5527 - val_accuracy: 0.7317\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5787 - accuracy: 0.7078 - val_loss: 0.5556 - val_accuracy: 0.7234\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5724 - accuracy: 0.7103 - val_loss: 0.5525 - val_accuracy: 0.7295\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5672 - accuracy: 0.7163 - val_loss: 0.5475 - val_accuracy: 0.7295\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5612 - accuracy: 0.7203 - val_loss: 0.5430 - val_accuracy: 0.7383\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5599 - accuracy: 0.7223 - val_loss: 0.5349 - val_accuracy: 0.7421\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5638 - accuracy: 0.7181 - val_loss: 0.5356 - val_accuracy: 0.7438\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5566 - accuracy: 0.7219 - val_loss: 0.5378 - val_accuracy: 0.7410\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5535 - accuracy: 0.7304 - val_loss: 0.5343 - val_accuracy: 0.7399\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5533 - accuracy: 0.7265 - val_loss: 0.5337 - val_accuracy: 0.7355\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5526 - accuracy: 0.7234 - val_loss: 0.5393 - val_accuracy: 0.7460\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5488 - accuracy: 0.7290 - val_loss: 0.5369 - val_accuracy: 0.7394\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5487 - accuracy: 0.7277 - val_loss: 0.5294 - val_accuracy: 0.7427\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5476 - accuracy: 0.7288 - val_loss: 0.5368 - val_accuracy: 0.7416\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 3s 13ms/step - loss: 0.5490 - accuracy: 0.7294 - val_loss: 0.5294 - val_accuracy: 0.7482\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 3s 11ms/step - loss: 0.5467 - accuracy: 0.7314 - val_loss: 0.5299 - val_accuracy: 0.7548\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5458 - accuracy: 0.7296 - val_loss: 0.5348 - val_accuracy: 0.7366\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5466 - accuracy: 0.7312 - val_loss: 0.5300 - val_accuracy: 0.7499\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 3s 12ms/step - loss: 0.5444 - accuracy: 0.7342 - val_loss: 0.5300 - val_accuracy: 0.7377\n",
      "getting accuracy of participant  23\n",
      "196/196 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4453703703703704\n",
      "[0.76743753 0.81321344 0.54254294 0.80159271 0.78166778 0.80307744\n",
      " 0.79203517 0.84033705 0.73240179 0.72362839 0.74495449 0.69885078\n",
      " 0.74353404 0.77642945 0.64462927 0.83024604 0.77464264 0.81418398\n",
      " 0.49464598 0.77076049 0.72038256 0.61433695 0.61343711 0.80222902]\n",
      "[54.19235396 52.70392394 50.4161098  53.76426458 55.44946575 53.82242489\n",
      " 52.68940234 54.33451772 52.54643345 55.43786716 57.10425735 52.66216135\n",
      " 52.87757325 53.54565787 53.39688706 53.20648432 52.90767074 52.67421675\n",
      " 60.10132408 57.16043615 61.47292638 60.96316409 62.77214384 61.87880111]\n",
      "[1.69488263 1.46725988 1.5176878  1.45989132 1.46072507 1.50206327\n",
      " 1.45160103 1.71130753 1.49902606 1.51563931 1.51041675 1.52603197\n",
      " 1.46912599 1.46905065 1.69897151 1.42761397 1.45739841 1.41648889\n",
      " 1.76424098 1.56209755 1.80318689 1.72958732 2.11791015 1.76056933]\n",
      "[0.89 0.91 0.31 0.89 0.93 0.93 0.87 1.   0.78 0.84 0.84 0.71 0.85 0.95\n",
      " 0.53 0.96 0.87 0.96 0.16 0.87 0.8  0.38 0.51 0.95]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_cal = 4\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "CNN_accuracy_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_train_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_test_code_perso = np.zeros(nb_part)\n",
    "CNN_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*60)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "    ind2take = [j for j in range(nb_part) if j!=i]\n",
    "\n",
    "    X_train = np.expand_dims(np.concatenate([X[ind2take].reshape(-1,X.shape[-2],X.shape[-1]),X[i][:nb_samples_windows]]).reshape(-1,X.shape[-2],X.shape[-1]),1)\n",
    "    Y_train = np.concatenate([y[ind2take].reshape(-1),y[i][:nb_samples_windows]]).reshape(-1)\n",
    "    domains_train = np.concatenate([domains[ind2take].reshape(-1),domains[i][:nb_samples_windows]]).reshape(-1)\n",
    "    X_test = np.expand_dims(X[i][nb_samples_windows:],1)\n",
    "    Y_test = np.vstack((y[i][nb_samples_windows:],np.abs(1-y[i][nb_samples_windows:]))).T\n",
    "    labels_code_test = labels_code_list[i][n_cal*n_class:]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    X_std = X_train.std(axis=0)\n",
    "    X_train /= X_std + 1e-8\n",
    "    X_std = X_test.std(axis=0)\n",
    "    X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    X_train,Y_train,domains_train = balance(X_train,Y_train,domains_train)\n",
    "    Y_train = np.vstack((Y_train,np.abs(1-Y_train))).T\n",
    "    n_samples_windows = X_train.shape[-1]\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = basearchi(windows_size = n_samples_windows, n_channel_input = X_train.shape[2])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr, amsgrad=True)\n",
    "    clf.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "    history_list.append(clf.fit(np.array(x_train), y_train,\n",
    "                    batch_size=batchsize, epochs=epochs,\n",
    "                    validation_data=(np.array(x_val), y_val), shuffle=True))\n",
    "    CNN_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)[:,0]\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([0 if y[0] == 0 else 1 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    CNN_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, fps=60, consecutive=50, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    CNN_tps_test_code_perso[i] = time.time() - start\n",
    "    CNN_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(CNN_accuracy_perso)\n",
    "print(CNN_tps_train_code_perso)\n",
    "print(CNN_tps_test_code_perso)\n",
    "print(CNN_accuracy_code_perso)\n",
    "# pd.DataFrame(CNN_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score/DA_score.csv\")\n",
    "# pd.DataFrame(CNN_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score_code/DA_score_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_train_code/DA_tps_train_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_test_code/DA_tps_test_code.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.77875\n",
      "with 0.25s 0.74625\n"
     ]
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([0.89, 0.91, 0.31, 0.89, 0.93, 0.93, 0.87, 1,   0.78, 0.84, 0.84, 0.71, 0.85, 0.95,\n",
    " 0.53, 0.96, 0.87, 0.96, 0.16, 0.87, 0.8,  0.38, 0.51, 0.95]))\n",
    "print(\"with 0.25s\",np.mean([0.78, 0.91, 0.29, 0.91, 0.78, 0.82, 0.91, 0.95, 0.82, 0.8,  0.8,  0.85, 0.73, 0.87,\n",
    " 0.55, 0.93, 0.85, 0.93, 0.16, 0.71, 0.82, 0.45, 0.36, 0.93]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XDAWn + TS + LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XTL SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  0\n",
      "meannnnnn long 1.3257575757575757\n",
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:277: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "TL to the participant :  1\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  1\n",
      "meannnnnn long 1.3326666666666669\n",
      "TL to the participant :  2\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.457638888888889\n",
      "TL to the participant :  3\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  3\n",
      "meannnnnn long 1.344949494949495\n",
      "TL to the participant :  4\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.392361111111111\n",
      "TL to the participant :  5\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.447222222222222\n",
      "TL to the participant :  6\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  6\n",
      "meannnnnn long 1.3576923076923075\n",
      "TL to the participant :  7\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3408602150537632\n",
      "TL to the participant :  8\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  8\n",
      "meannnnnn long 1.3659999999999999\n",
      "TL to the participant :  9\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.59\n",
      "TL to the participant :  10\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  10\n",
      "meannnnnn long 1.3862318840579708\n",
      "TL to the participant :  11\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  11\n",
      "meannnnnn long 1.329444444444444\n",
      "TL to the participant :  12\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  12\n",
      "meannnnnn long 1.366666666666667\n",
      "TL to the participant :  13\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  13\n",
      "meannnnnn long 1.3499999999999992\n",
      "TL to the participant :  14\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  14\n",
      "meannnnnn long 1.4108333333333334\n",
      "TL to the participant :  15\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3878205128205126\n",
      "TL to the participant :  16\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  16\n",
      "meannnnnn long 1.3212121212121213\n",
      "TL to the participant :  17\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.355952380952381\n",
      "TL to the participant :  18\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  18\n",
      "meannnnnn long 1.33763440860215\n",
      "TL to the participant :  19\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4513333333333334\n",
      "TL to the participant :  20\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  20\n",
      "meannnnnn long 1.4294117647058824\n",
      "TL to the participant :  21\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  21\n",
      "meannnnnn long 1.427450980392157\n",
      "TL to the participant :  22\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  22\n",
      "meannnnnn long 1.34469696969697\n",
      "TL to the participant :  23\n",
      "balancing the number of ones and zeros\n",
      "(1456, 8, 60)\n",
      "(18720, 8, 60)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  23\n",
      "meannnnnn long 1.3554054054054052\n",
      "[0.72928779 0.66954103 0.62741782 0.70062332 0.68527784 0.72074855\n",
      " 0.68826867 0.7429981  0.5908011  0.54180177 0.6348949  0.69451588\n",
      " 0.62416145 0.67640318 0.55531641 0.71686326 0.72079047 0.69342576\n",
      " 0.68325134 0.64425872 0.74130702 0.69267106 0.54575693 0.78623938]\n",
      "[2.04206657 2.11654067 2.06249452 2.15300012 2.16206026 2.12363029\n",
      " 2.16735506 2.16375422 2.19917178 2.0739398  2.19908857 2.18056321\n",
      " 2.11883569 2.14422655 2.39101481 2.20192981 2.08629942 2.32958984\n",
      " 2.08345604 2.16635966 2.22047281 2.25666237 2.19004726 2.21074438]\n",
      "[6.86904216 6.91060209 6.73421335 6.60975599 6.84811354 6.6425209\n",
      " 6.81897879 6.99467206 6.692729   7.2119987  6.94045973 6.93348503\n",
      " 6.76539326 7.09999704 7.21368408 6.75954866 6.82654762 6.72636795\n",
      " 6.75110412 6.7336452  6.94306827 6.97156048 7.06159234 6.7215395 ]\n",
      "[0.78 0.6  0.5  0.82 0.75 0.78 0.75 0.78 0.52 0.32 0.65 0.85 0.52 0.72\n",
      " 0.42 0.78 0.8  0.78 0.7  0.55 0.9  0.85 0.38 0.88]\n",
      "0.6825\n"
     ]
    }
   ],
   "source": [
    "n_cal = 7\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "CNN_accuracy_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_train_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_test_code_perso = np.zeros(nb_part)\n",
    "CNN_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*sfreq)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "\n",
    "    X_train = X[i][:nb_samples_windows]\n",
    "    Y_train = y[i][:nb_samples_windows]\n",
    "    # Y_train = np.vstack((Y_train,np.abs(1-Y_train))).T\n",
    "    domains_train = domains[i][:nb_samples_windows]\n",
    "    X_test = X[i][nb_samples_windows:]\n",
    "    Y_test = y[i][nb_samples_windows:]\n",
    "    labels_code_test = labels_code_list[i][n_cal*n_class:]\n",
    "\n",
    "    X_std = X_train.std(axis=0)\n",
    "    X_train /= X_std + 1e-8\n",
    "    X_std = X_test.std(axis=0)\n",
    "    X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    rus = RandomUnderSampler()\n",
    "    counter=np.array(range(0,len(Y_train))).reshape(-1,1)\n",
    "    index,_ = rus.fit_resample(counter,Y_train[:])\n",
    "    X_train = np.squeeze(X_train[index,:,:], axis=1)\n",
    "    Y_train = np.squeeze(Y_train[index])\n",
    "    n_samples_windows = X_train.shape[-1]\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = make_pipeline(XdawnCovariances(nfilter=8, estimator=\"lwf\", xdawn_estimator=\"lwf\",classes=[1]),\n",
    "                        TangentSpace(), LDA(solver=\"lsqr\", shrinkage=\"auto\"))\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    # optimizer = keras.optimizers.Adam(learning_rate=lr, amsgrad=True)\n",
    "    # clf.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "    history_list.append(clf.fit(np.array(x_train), y_train))#,\n",
    "                    # batch_size=batchsize, epochs=epochs,\n",
    "                    # validation_data=(np.array(x_val), y_val), shuffle=True))\n",
    "    CNN_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([0 if y == 0 else 1 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    CNN_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, sfreq=sfreq, consecutive=40, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    CNN_tps_test_code_perso[i] = time.time() - start\n",
    "    CNN_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(CNN_accuracy_perso)\n",
    "print(CNN_tps_train_code_perso)\n",
    "print(CNN_tps_test_code_perso)\n",
    "print(CNN_accuracy_code_perso)\n",
    "print(np.mean(CNN_accuracy_code_perso))\n",
    "# pd.DataFrame(CNN_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score/SS_score.csv\")\n",
    "# pd.DataFrame(CNN_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score_code/SS_score_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_train_code/SS_tps_train_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_test_code/SS_tps_test_code.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.8700000000000001\n",
      "with 0.25s 0.8379166666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([1, 0.98, 0.85, 0.92, 0.98, 0.95, 0.82, 0.98, 0.9,  0.2,  0.9,  0.88, 0.8,  0.95,\n",
    " 0.78, 0.92, 0.98, 0.95, 0.7,  0.88, 1,   0.88, 0.68, 1  ]))\n",
    "print(\"with 0.25s\",np.mean([0.92 ,0.92, 0.85, 0.92, 0.98, 0.88, 0.65, 0.98, 0.75, 0.22, 0.85, 0.92, 0.78, 0.88,\n",
    " 0.57, 1,   0.98, 0.9,  0.78, 0.75, 1,   0.98 ,0.65, 1  ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XTL DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  0\n",
      "meannnnnn long 1.4072916666666666\n",
      "TL to the participant :  1\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  1\n",
      "meannnnnn long 1.4546099290780141\n",
      "TL to the participant :  2\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  2\n",
      "meannnnnn long 1.4912037037037038\n",
      "TL to the participant :  3\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  3\n",
      "meannnnnn long 1.4608024691358024\n",
      "TL to the participant :  4\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  4\n",
      "meannnnnn long 1.4456666666666667\n",
      "TL to the participant :  5\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  5\n",
      "meannnnnn long 1.4493710691823893\n",
      "TL to the participant :  6\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  6\n",
      "meannnnnn long 1.5063063063063065\n",
      "TL to the participant :  7\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  7\n",
      "meannnnnn long 1.4551075268817204\n",
      "TL to the participant :  8\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  8\n",
      "meannnnnn long 1.4461805555555554\n",
      "TL to the participant :  9\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4939393939393937\n",
      "TL to the participant :  10\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  10\n",
      "meannnnnn long 1.388095238095238\n",
      "TL to the participant :  11\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  11\n",
      "meannnnnn long 1.4722222222222225\n",
      "TL to the participant :  12\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  12\n",
      "meannnnnn long 1.4231481481481483\n",
      "TL to the participant :  13\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  13\n",
      "meannnnnn long 1.4160377358490563\n",
      "TL to the participant :  14\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  14\n",
      "meannnnnn long 1.5142857142857142\n",
      "TL to the participant :  15\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  15\n",
      "meannnnnn long 1.414285714285714\n",
      "TL to the participant :  16\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  16\n",
      "meannnnnn long 1.4510416666666668\n",
      "TL to the participant :  17\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  17\n",
      "meannnnnn long 1.4124293785310733\n",
      "TL to the participant :  18\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  18\n",
      "meannnnnn long 1.4136904761904763\n",
      "TL to the participant :  19\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  19\n",
      "meannnnnn long 1.419767441860465\n",
      "TL to the participant :  20\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4308176100628927\n",
      "TL to the participant :  21\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  21\n",
      "meannnnnn long 1.4462499999999998\n",
      "TL to the participant :  22\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  22\n",
      "meannnnnn long 1.4557471264367818\n",
      "TL to the participant :  23\n",
      "(201825, 8, 125)\n",
      "(201825,)\n",
      "(8775, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  23\n",
      "meannnnnn long 1.3948717948717948\n",
      "[0.74740608 0.76973763 0.55456172 0.78729875 0.74519976 0.78008348\n",
      " 0.74230769 0.82242099 0.71362552 0.64648181 0.68950507 0.65104353\n",
      " 0.68416816 0.75986881 0.60387597 0.81487776 0.72593918 0.79007156\n",
      " 0.48273703 0.71815742 0.70721527 0.66138939 0.57042338 0.82429934]\n",
      "[45.87342191 45.59355545 45.70195389 45.49592137 45.3637054  45.39643788\n",
      " 45.29981995 45.39389873 45.49970555 45.33609939 45.33996749 45.35162354\n",
      " 45.38713765 45.54726744 45.55826092 45.56781912 45.65565538 45.87393856\n",
      " 45.76630402 45.83097982 45.61161518 45.50204921 45.72950673 45.6718154 ]\n",
      "[7.18155813 7.28059888 7.44174981 7.33435225 7.31069779 7.25466347\n",
      " 7.40162063 7.11008883 7.25555992 7.54451036 7.29378271 7.47736263\n",
      " 7.53489733 7.20220423 7.5570085  7.26365256 7.31542754 7.10016418\n",
      " 7.5498631  7.33071494 7.35191417 7.49304724 7.63379622 7.0383873 ]\n",
      "[0.85 0.88 0.36 0.91 0.83 0.81 0.88 0.96 0.83 0.63 0.63 0.63 0.65 0.92\n",
      " 0.47 0.92 0.77 0.93 0.19 0.81 0.71 0.57 0.4  0.96]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_cal = 4\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "CNN_accuracy_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_train_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_test_code_perso = np.zeros(nb_part)\n",
    "CNN_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*60)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "    ind2take = [j for j in range(nb_part) if j!=i]\n",
    "\n",
    "    X_train = np.concatenate(X[ind2take]).reshape(-1,X.shape[-2],X.shape[-1])\n",
    "    Y_train = np.concatenate(y[ind2take]).reshape(-1)\n",
    "    domains_train = np.concatenate(domains[ind2take]).reshape(-1)\n",
    "    X_test = X[i]\n",
    "    Y_test = y[i]\n",
    "    labels_code_test = labels_code_list[i]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    X_std = X_train.std(axis=0)\n",
    "    X_train /= X_std + 1e-8\n",
    "    X_std = X_test.std(axis=0)\n",
    "    X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    X_train,Y_train,domains_train = balance(X_train,Y_train,domains_train)\n",
    "    n_samples_windows = X_train.shape[-1]\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = make_pipeline(XdawnCovariances(nfilter=16, estimator=\"lwf\", xdawn_estimator=\"lwf\",classes=[1]),\n",
    "                        TangentSpace(), LDA(solver=\"lsqr\", shrinkage=\"auto\"))\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr, amsgrad=True)\n",
    "    # clf.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "    history_list.append(clf.fit(np.array(x_train), y_train))#,\n",
    "                    # batch_size=batchsize, epochs=epochs,\n",
    "                    # validation_data=(np.array(x_val), y_val), shuffle=True))\n",
    "    CNN_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([0 if y == 0 else 1 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    CNN_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, fps=60, consecutive=50, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    CNN_tps_test_code_perso[i] = time.time() - start\n",
    "    CNN_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(CNN_accuracy_perso)\n",
    "print(CNN_tps_train_code_perso)\n",
    "print(CNN_tps_test_code_perso)\n",
    "print(CNN_accuracy_code_perso)\n",
    "# pd.DataFrame(CNN_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score/DG_score.csv\")\n",
    "# pd.DataFrame(CNN_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score_code/DG_score_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_train_code/DG_tps_train_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_test_code/DG_tps_test_code.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.7683333333333332\n",
      "with 0.25s 0.7362500000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([0.81, 0.88, 0.29, 0.97, 0.91, 0.88, 0.83, 0.97, 0.89, 0.71, 0.8, 0.67, 0.83, 0.93,\n",
    " 0.61, 0.93, 0.83, 0.89, 0.15, 0.88, 0.75, 0.6,  0.51, 0.92]))\n",
    "print(\"with 0.25s\",np.mean([0.87, 0.91 ,0.37, 0.92, 0.83, 0.77, 0.8,  0.96, 0.84, 0.63, 0.65, 0.65, 0.72, 0.96,\n",
    " 0.48, 0.93, 0.84 ,0.93 ,0.16, 0.85, 0.75, 0.52, 0.41, 0.92]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XTL DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  0\n",
      "meannnnnn long 1.4237499999999998\n",
      "TL to the participant :  1\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  1\n",
      "meannnnnn long 1.4864035087719298\n",
      "TL to the participant :  2\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  2\n",
      "meannnnnn long 1.4613333333333332\n",
      "TL to the participant :  3\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  3\n",
      "meannnnnn long 1.47280701754386\n",
      "TL to the participant :  4\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  4\n",
      "meannnnnn long 1.4421052631578948\n",
      "TL to the participant :  5\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  5\n",
      "meannnnnn long 1.4341666666666666\n",
      "TL to the participant :  6\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  6\n",
      "meannnnnn long 1.4777777777777779\n",
      "TL to the participant :  7\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  7\n",
      "meannnnnn long 1.4515873015873015\n",
      "TL to the participant :  8\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  8\n",
      "meannnnnn long 1.4495495495495498\n",
      "TL to the participant :  9\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  9\n",
      "meannnnnn long 1.4963541666666667\n",
      "TL to the participant :  10\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  10\n",
      "meannnnnn long 1.395402298850575\n",
      "TL to the participant :  11\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  11\n",
      "meannnnnn long 1.4688172043010757\n",
      "TL to the participant :  12\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  12\n",
      "meannnnnn long 1.4506410256410258\n",
      "TL to the participant :  13\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  13\n",
      "meannnnnn long 1.3964912280701756\n",
      "TL to the participant :  14\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  14\n",
      "meannnnnn long 1.4614583333333333\n",
      "TL to the participant :  15\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  15\n",
      "meannnnnn long 1.4125\n",
      "TL to the participant :  16\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  16\n",
      "meannnnnn long 1.421078431372549\n",
      "TL to the participant :  17\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4102272727272729\n",
      "TL to the participant :  18\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  18\n",
      "meannnnnn long 1.5224637681159423\n",
      "TL to the participant :  19\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  19\n",
      "meannnnnn long 1.4333333333333331\n",
      "TL to the participant :  20\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.406910569105691\n",
      "TL to the participant :  21\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  21\n",
      "meannnnnn long 1.4014492753623187\n",
      "TL to the participant :  22\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  22\n",
      "meannnnnn long 1.4717948717948721\n",
      "TL to the participant :  23\n",
      "(204165, 8, 125)\n",
      "(204165,)\n",
      "(6435, 8, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  23\n",
      "meannnnnn long 1.3967391304347827\n",
      "[0.75390307 0.77845991 0.56285575 0.7856562  0.74247845 0.79081965\n",
      " 0.73227354 0.81541714 0.7123516  0.66014799 0.70434217 0.66299398\n",
      " 0.67193853 0.76638478 0.62554887 0.81651488 0.74398276 0.79130753\n",
      " 0.50215482 0.72528053 0.75764352 0.66181493 0.57163766 0.83180192]\n",
      "[31.848665   31.73069596 33.48490167 33.02137995 33.75795889 32.97428322\n",
      " 32.26563525 43.35709286 45.66925526 44.45794725 33.5382266  33.56677127\n",
      " 32.1323173  32.96130943 31.72201228 30.89583111 30.50048399 30.37707615\n",
      " 31.73551798 32.57638836 31.37151408 33.03920102 34.18147326 39.88342428]\n",
      "[2.91330862 3.03534555 3.10537219 3.46248388 3.43620658 3.01354885\n",
      " 3.24874377 5.28959084 5.2068038  3.39247608 3.13800144 3.31460834\n",
      " 3.20900059 3.05713463 3.23921943 2.99228954 3.01764655 2.97288179\n",
      " 3.41703558 3.09966707 3.05881429 3.22798538 3.56038284 5.37594962]\n",
      "[0.89 0.91 0.36 0.85 0.91 0.82 0.76 0.91 0.84 0.69 0.73 0.62 0.67 0.93\n",
      " 0.56 0.96 0.84 0.95 0.2  0.8  0.82 0.62 0.42 0.95]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_cal = 4\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "CNN_accuracy_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_train_code_perso = np.zeros(nb_part)\n",
    "CNN_tps_test_code_perso = np.zeros(nb_part)\n",
    "CNN_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*60)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "    ind2take = [j for j in range(nb_part) if j!=i]\n",
    "\n",
    "    X_train = np.concatenate([X[ind2take].reshape(-1,X.shape[-2],X.shape[-1]),X[i][:nb_samples_windows]]).reshape(-1,X.shape[-2],X.shape[-1])\n",
    "    Y_train = np.concatenate([y[ind2take].reshape(-1),y[i][:nb_samples_windows]]).reshape(-1)\n",
    "    domains_train = np.concatenate([domains[ind2take].reshape(-1),domains[i][:nb_samples_windows]]).reshape(-1)\n",
    "    X_test = X[i][nb_samples_windows:]\n",
    "    Y_test = y[i][nb_samples_windows:]\n",
    "    labels_code_test = labels_code_list[i][n_cal*n_class:]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    X_std = X_train.std(axis=0)\n",
    "    X_train /= X_std + 1e-8\n",
    "    X_std = X_test.std(axis=0)\n",
    "    X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    X_train,Y_train,domains_train = balance(X_train,Y_train,domains_train)\n",
    "    n_samples_windows = X_train.shape[-1]\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = make_pipeline(XdawnCovariances(nfilter=8, estimator=\"lwf\", xdawn_estimator=\"lwf\",classes=[1]),\n",
    "                        TangentSpace(), LDA(solver=\"lsqr\", shrinkage=\"auto\"))\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    # optimizer = keras.optimizers.Adam(learning_rate=lr, amsgrad=True)\n",
    "    # clf.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "    history_list.append(clf.fit(np.array(x_train), y_train))#,\n",
    "                    # batch_size=batchsize, epochs=epochs,\n",
    "                    # validation_data=(np.array(x_val), y_val), shuffle=True))\n",
    "    CNN_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([0 if y == 0 else 1 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    CNN_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, fps=60, consecutive=50, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    CNN_tps_test_code_perso[i] = time.time() - start\n",
    "    CNN_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(CNN_accuracy_perso)\n",
    "print(CNN_tps_train_code_perso)\n",
    "print(CNN_tps_test_code_perso)\n",
    "print(CNN_accuracy_code_perso)\n",
    "# pd.DataFrame(CNN_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score/DA_score.csv\")\n",
    "# pd.DataFrame(CNN_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/score_code/DA_score_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_train_code/DA_tps_train_code.csv\")\n",
    "# pd.DataFrame(CNN_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/CNN/temps_test_code/DA_tps_test_code.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7504166666666666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(CNN_accuracy_code_perso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.7937500000000001\n",
      "with 0.25s 0.7533333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([0.85, 0.85, 0.24, 0.96, 0.95, 0.95, 0.87, 0.91, 0.87, 0.8, 0.85, 0.69 ,0.84, 0.96,\n",
    " 0.65, 0.96, 0.91, 0.96 ,0.11 ,0.87 ,0.8,  0.6,  0.65, 0.95]))\n",
    "print(\"with 0.25s\",np.mean([0.84, 0.85, 0.35, 0.93 ,0.91 ,0.8,  0.82, 0.95, 0.82, 0.73 ,0.73 ,0.73, 0.58, 0.95,\n",
    " 0.51, 0.93, 0.87, 0.89, 0.27, 0.76, 0.85, 0.58, 0.45, 0.98]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n",
      "Used Annotations descriptions: ['0', '1']\n",
      "{'0': 1, '1': 2}\n",
      "Not setting metadata\n",
      "8775 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 8775 events and 126 original time points ...\n",
      "0 bad epochs dropped\n",
      "(8775, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "X_riem = np.zeros((X.shape[0],X.shape[1],16,16))\n",
    "y_riem = np.zeros((X.shape[0],X.shape[1]))\n",
    "for ind_i,i in enumerate(participants):\n",
    "    events, event_id = mne.events_from_annotations(raw_eeglab[ind_i])\n",
    "    print(event_id)\n",
    "    epochs = mne.Epochs(raw_eeglab[ind_i],events,event_id,tmin=0.0,tmax=window_size,baseline=(0,0))\n",
    "    temp_X = epochs.get_data()[:,:,:-1]\n",
    "    \n",
    "    y_riem[ind_i] = epochs.events[...,-1]-1\n",
    "    # print(temp_X.shape)\n",
    "    # X_riem[ind_i] = compute_riemannian_alignment(Euc2SPD(X[ind_i],y[ind_i]), mean=None, dtype='covmat')\n",
    "    X_riem[ind_i] = compute_riemannian_alignment(Euc2SPD(temp_X,y_riem[ind_i]), mean=None, dtype='covmat')\n",
    "    print(X_riem[ind_i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 73125, 16, 16)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_riem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPD SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  0\n",
      "147/147 [==============================] - 0s 3ms/step\n",
      "meannnnnn long 1.4197916666666666\n",
      "TL to the participant :  1\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  1\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3933333333333335\n",
      "TL to the participant :  2\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  2\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.413793103448276\n",
      "TL to the participant :  3\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  3\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4483870967741936\n",
      "TL to the participant :  4\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  4\n",
      "147/147 [==============================] - 0s 3ms/step\n",
      "meannnnnn long 1.5076388888888888\n",
      "TL to the participant :  5\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  5\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.460144927536232\n",
      "TL to the participant :  6\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  6\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4660256410256414\n",
      "TL to the participant :  7\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  7\n",
      "147/147 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4580000000000002\n",
      "TL to the participant :  8\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  8\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4980392156862745\n",
      "TL to the participant :  9\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  9\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.564705882352941\n",
      "TL to the participant :  10\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  10\n",
      "147/147 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4433333333333338\n",
      "TL to the participant :  11\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  11\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4736842105263157\n",
      "TL to the participant :  12\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  12\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3625\n",
      "TL to the participant :  13\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  13\n",
      "147/147 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.488888888888889\n",
      "TL to the participant :  14\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  14\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.6314814814814815\n",
      "TL to the participant :  15\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  15\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4782051282051283\n",
      "TL to the participant :  16\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  16\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4460317460317458\n",
      "TL to the participant :  17\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  17\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.5142857142857142\n",
      "TL to the participant :  18\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  18\n",
      "147/147 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4958333333333336\n",
      "TL to the participant :  19\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  19\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.508888888888889\n",
      "TL to the participant :  20\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  20\n",
      "147/147 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4063063063063062\n",
      "TL to the participant :  21\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  21\n",
      "147/147 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.482051282051282\n",
      "TL to the participant :  22\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  22\n",
      "147/147 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4396825396825395\n",
      "TL to the participant :  23\n",
      "(4095, 16, 16)\n",
      "(4095,)\n",
      "(4680, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "getting accuracy of participant  23\n",
      "147/147 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.3905405405405409\n",
      "[0.81853757 0.72260733 0.78052326 0.76453488 0.72299866 0.6644678\n",
      " 0.75067084 0.77454159 0.6168381  0.64859123 0.77224955 0.65373435\n",
      " 0.67285331 0.72188059 0.57368068 0.76660331 0.65256038 0.68246869\n",
      " 0.74038462 0.63422406 0.88841682 0.64663462 0.64652281 0.86454606]\n",
      "[2.62521029 2.66488528 2.72515559 2.79110098 2.70616341 2.74036551\n",
      " 2.71781492 2.68130207 2.7036953  2.71204877 2.80227184 2.92185116\n",
      " 2.89627576 3.43702626 2.78142452 2.77372026 2.75059628 2.81315088\n",
      " 2.84060216 2.73768139 2.86200404 2.71010113 2.72553205 2.73495054]\n",
      "[1.06039619 1.1365304  1.14583111 1.14773989 1.15574932 1.18074441\n",
      " 1.16809416 1.17156625 1.21177197 1.23048544 1.28271151 1.27872229\n",
      " 1.26153469 1.18341517 1.32216358 1.21099544 1.2492764  1.33214998\n",
      " 1.20471859 1.29852581 1.08531117 1.21994209 1.19058037 1.06567574]\n",
      "[0.98 0.85 0.98 0.88 0.75 0.75 0.75 0.92 0.5  0.7  0.9  0.78 0.72 0.9\n",
      " 0.48 0.9  0.82 0.8  0.72 0.55 1.   0.6  0.48 1.  ]\n",
      "0.7795833333333334\n"
     ]
    }
   ],
   "source": [
    "n_cal = 7\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "SPD_accuracy_code_perso = np.zeros(nb_part)\n",
    "SPD_tps_train_code_perso = np.zeros(nb_part)\n",
    "SPD_tps_test_code_perso = np.zeros(nb_part)\n",
    "SPD_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*60)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "\n",
    "    X_train = X_riem[i][:nb_samples_windows]\n",
    "    Y_train = y_riem[i][:nb_samples_windows]\n",
    "    # Y_train = np.vstack((Y_train,np.abs(1-Y_train))).T\n",
    "    domains_train = domains[i][:nb_samples_windows]\n",
    "    X_test = X_riem[i][nb_samples_windows:]\n",
    "    Y_test = y_riem[i][nb_samples_windows:]\n",
    "    labels_code_test = labels_code_list[i][n_cal*n_class:]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    # X_std = X_train.std(axis=0)\n",
    "    # X_train /= X_std + 1e-8\n",
    "    # X_std = X_test.std(axis=0)\n",
    "    # X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    X_train,Y_train,domains_train = balance(X_train,Y_train,domains_train)\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = SPDNet_Tensorflow(bimap_dims=[16,8,4])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    history_list.append(clf.fit(np.array(x_train), y_train,\n",
    "                    batch_size=batchsize, epochs=epochs,\n",
    "                    validation_data=(np.array(x_val), y_val), shuffle=True,verbose=False))\n",
    "    SPD_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([1 if (y >= 0.5) else 0 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    SPD_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, sfreq=60, consecutive=50, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    SPD_tps_test_code_perso[i] = time.time() - start\n",
    "    SPD_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(SPD_accuracy_perso)\n",
    "print(SPD_tps_train_code_perso)\n",
    "print(SPD_tps_test_code_perso)\n",
    "print(SPD_accuracy_code_perso)\n",
    "print(np.mean(SPD_accuracy_code_perso))\n",
    "# pd.DataFrame(SPD_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/score/DG_score.csv\")\n",
    "# pd.DataFrame(SPD_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/score_code/DG_score_code.csv\")\n",
    "# pd.DataFrame(SPD_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/temps_train_code/DG_tps_train_code.csv\")\n",
    "# pd.DataFrame(SPD_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/temps_test_code/DG_tps_test_code.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.8595833333333335\n",
      "with 0.25s 0.9141666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"with 0.3s and filtre on 0 et 1\",np.mean([1, 0.88, 0.85, 0.88, 0.95, 0.95, 0.68, 0.92, 0.9,  0.68, 0.92, 0.75, 0.85, 0.98,\n",
    " 0.78, 0.85, 0.98, 0.92, 0.78, 0.78, 1, 0.6,  0.75, 1 ]))\n",
    "print(\"with timepoint wise 500Hz\",np.mean([1,1,0.98,0.98,0.98,1,0.85,1,0.95,0.85,0.95,0.92,0.98,1.\n",
    ",0.8,1,1,0.92,0.88,0.95,1,0.98,0.82,1]))\n",
    "print(\"with 0.25s and filter on 0 et 1\",np.mean([1, 0.92, 0.88, 0.9,  0.98, 1,   0.88, 0.95, 0.92, 0.82, 0.9,  0.85, 0.92, 0.95,\n",
    " 0.8,  0.98, 0.98, 0.98, 0.85, 0.8,  0.98, 0.95, 0.75, 1  ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPD DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 13ms/step - loss: 0.5955 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.4988 - val_sparse_categorical_accuracy: 0.7781\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4785 - sparse_categorical_accuracy: 0.7849 - val_loss: 0.4553 - val_sparse_categorical_accuracy: 0.7804\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4602 - sparse_categorical_accuracy: 0.7915 - val_loss: 0.4447 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4541 - sparse_categorical_accuracy: 0.7903 - val_loss: 0.4410 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4522 - sparse_categorical_accuracy: 0.7935 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8088\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4501 - sparse_categorical_accuracy: 0.7953 - val_loss: 0.4374 - val_sparse_categorical_accuracy: 0.8032\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4497 - sparse_categorical_accuracy: 0.7959 - val_loss: 0.4382 - val_sparse_categorical_accuracy: 0.8071\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4480 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.4430 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4481 - sparse_categorical_accuracy: 0.7965 - val_loss: 0.4418 - val_sparse_categorical_accuracy: 0.7982\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4470 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.4492 - val_sparse_categorical_accuracy: 0.7982\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4475 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4400 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4465 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4466 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.4389 - val_sparse_categorical_accuracy: 0.8038\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4464 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4427 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4463 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.4406 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4466 - sparse_categorical_accuracy: 0.7966 - val_loss: 0.4507 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4457 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.4398 - val_sparse_categorical_accuracy: 0.8038\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4459 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.4429 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4454 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.4413 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4458 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.4459 - val_sparse_categorical_accuracy: 0.8010\n",
      "getting accuracy of participant  0\n",
      "275/275 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3564444444444446\n",
      "TL to the participant :  1\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.6088 - sparse_categorical_accuracy: 0.6810 - val_loss: 0.5291 - val_sparse_categorical_accuracy: 0.7687\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4931 - sparse_categorical_accuracy: 0.7775 - val_loss: 0.4743 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4682 - sparse_categorical_accuracy: 0.7902 - val_loss: 0.4764 - val_sparse_categorical_accuracy: 0.7781\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4629 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.4739 - val_sparse_categorical_accuracy: 0.7832\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4596 - sparse_categorical_accuracy: 0.7985 - val_loss: 0.4692 - val_sparse_categorical_accuracy: 0.7860\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4572 - sparse_categorical_accuracy: 0.7998 - val_loss: 0.4675 - val_sparse_categorical_accuracy: 0.7821\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4569 - sparse_categorical_accuracy: 0.7968 - val_loss: 0.4649 - val_sparse_categorical_accuracy: 0.7921\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4557 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.4654 - val_sparse_categorical_accuracy: 0.7848\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4557 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.4621 - val_sparse_categorical_accuracy: 0.7854\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.4621 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4547 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.4668 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4544 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.4646 - val_sparse_categorical_accuracy: 0.7893\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4535 - sparse_categorical_accuracy: 0.7983 - val_loss: 0.4620 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4537 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4650 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4534 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4673 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4529 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4624 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4525 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.4642 - val_sparse_categorical_accuracy: 0.7915\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4527 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.4648 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4520 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4695 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4516 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.4608 - val_sparse_categorical_accuracy: 0.7982\n",
      "getting accuracy of participant  1\n",
      "275/275 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4787878787878788\n",
      "TL to the participant :  2\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7352 - val_loss: 0.4893 - val_sparse_categorical_accuracy: 0.7837\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4688 - sparse_categorical_accuracy: 0.7877 - val_loss: 0.4864 - val_sparse_categorical_accuracy: 0.7815\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4591 - sparse_categorical_accuracy: 0.7905 - val_loss: 0.4769 - val_sparse_categorical_accuracy: 0.7893\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4541 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.4729 - val_sparse_categorical_accuracy: 0.7915\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4486 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.4652 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4435 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.4633 - val_sparse_categorical_accuracy: 0.7982\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4402 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.4604 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4374 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.4593 - val_sparse_categorical_accuracy: 0.7971\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4358 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.4556 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4347 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.4577 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4342 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.4544 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4338 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.4483 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4323 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.4474 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4327 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.4471 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.4458 - val_sparse_categorical_accuracy: 0.8038\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4317 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.4530 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.4563 - val_sparse_categorical_accuracy: 0.7982\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4308 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4505 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.4506 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4308 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.4505 - val_sparse_categorical_accuracy: 0.8049\n",
      "getting accuracy of participant  2\n",
      "275/275 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.422012578616352\n",
      "TL to the participant :  3\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 13ms/step - loss: 0.6399 - sparse_categorical_accuracy: 0.6426 - val_loss: 0.5749 - val_sparse_categorical_accuracy: 0.7068\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.5301 - sparse_categorical_accuracy: 0.7463 - val_loss: 0.5214 - val_sparse_categorical_accuracy: 0.7531\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4741 - sparse_categorical_accuracy: 0.7825 - val_loss: 0.5065 - val_sparse_categorical_accuracy: 0.7620\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4644 - sparse_categorical_accuracy: 0.7894 - val_loss: 0.5019 - val_sparse_categorical_accuracy: 0.7726\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4617 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.5051 - val_sparse_categorical_accuracy: 0.7642\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4600 - sparse_categorical_accuracy: 0.7957 - val_loss: 0.5006 - val_sparse_categorical_accuracy: 0.7670\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4594 - sparse_categorical_accuracy: 0.7959 - val_loss: 0.4996 - val_sparse_categorical_accuracy: 0.7715\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4587 - sparse_categorical_accuracy: 0.7953 - val_loss: 0.5065 - val_sparse_categorical_accuracy: 0.7659\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4577 - sparse_categorical_accuracy: 0.7969 - val_loss: 0.5092 - val_sparse_categorical_accuracy: 0.7592\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4574 - sparse_categorical_accuracy: 0.7962 - val_loss: 0.5003 - val_sparse_categorical_accuracy: 0.7765\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4576 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.4997 - val_sparse_categorical_accuracy: 0.7698\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4569 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.4998 - val_sparse_categorical_accuracy: 0.7709\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4565 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.4967 - val_sparse_categorical_accuracy: 0.7776\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4567 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.5016 - val_sparse_categorical_accuracy: 0.7687\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4565 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.4980 - val_sparse_categorical_accuracy: 0.7754\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4563 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.5020 - val_sparse_categorical_accuracy: 0.7664\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4567 - sparse_categorical_accuracy: 0.7968 - val_loss: 0.5012 - val_sparse_categorical_accuracy: 0.7715\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4561 - sparse_categorical_accuracy: 0.7985 - val_loss: 0.4997 - val_sparse_categorical_accuracy: 0.7737\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4556 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.7681\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4554 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.4962 - val_sparse_categorical_accuracy: 0.7765\n",
      "getting accuracy of participant  3\n",
      "275/275 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4187830687830683\n",
      "TL to the participant :  4\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.5649 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.5088 - val_sparse_categorical_accuracy: 0.7464\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4734 - sparse_categorical_accuracy: 0.7874 - val_loss: 0.4884 - val_sparse_categorical_accuracy: 0.7553\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4593 - sparse_categorical_accuracy: 0.7958 - val_loss: 0.4815 - val_sparse_categorical_accuracy: 0.7670\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4527 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.4741 - val_sparse_categorical_accuracy: 0.7765\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4482 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.4776 - val_sparse_categorical_accuracy: 0.7720\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4459 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.4729 - val_sparse_categorical_accuracy: 0.7843\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4452 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.4838 - val_sparse_categorical_accuracy: 0.7698\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4444 - sparse_categorical_accuracy: 0.8041 - val_loss: 0.4840 - val_sparse_categorical_accuracy: 0.7748\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4437 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4764 - val_sparse_categorical_accuracy: 0.7787\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4435 - sparse_categorical_accuracy: 0.8032 - val_loss: 0.4704 - val_sparse_categorical_accuracy: 0.7798\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4430 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.4702 - val_sparse_categorical_accuracy: 0.7843\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4428 - sparse_categorical_accuracy: 0.8021 - val_loss: 0.4757 - val_sparse_categorical_accuracy: 0.7821\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4426 - sparse_categorical_accuracy: 0.8042 - val_loss: 0.4747 - val_sparse_categorical_accuracy: 0.7742\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4427 - sparse_categorical_accuracy: 0.8035 - val_loss: 0.4700 - val_sparse_categorical_accuracy: 0.7787\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4427 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.4694 - val_sparse_categorical_accuracy: 0.7837\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4422 - sparse_categorical_accuracy: 0.8025 - val_loss: 0.4722 - val_sparse_categorical_accuracy: 0.7809\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4414 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.4710 - val_sparse_categorical_accuracy: 0.7837\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4423 - sparse_categorical_accuracy: 0.8035 - val_loss: 0.4698 - val_sparse_categorical_accuracy: 0.7832\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4416 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.4742 - val_sparse_categorical_accuracy: 0.7804\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4419 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4715 - val_sparse_categorical_accuracy: 0.7826\n",
      "getting accuracy of participant  4\n",
      "275/275 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.3863888888888884\n",
      "TL to the participant :  5\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 15ms/step - loss: 0.5479 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.4867 - val_sparse_categorical_accuracy: 0.7787\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4841 - sparse_categorical_accuracy: 0.7795 - val_loss: 0.4921 - val_sparse_categorical_accuracy: 0.7742\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4770 - sparse_categorical_accuracy: 0.7838 - val_loss: 0.4761 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4728 - sparse_categorical_accuracy: 0.7861 - val_loss: 0.4764 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4680 - sparse_categorical_accuracy: 0.7891 - val_loss: 0.4685 - val_sparse_categorical_accuracy: 0.7815\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4629 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.4553 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4586 - sparse_categorical_accuracy: 0.7946 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4551 - sparse_categorical_accuracy: 0.7970 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.8010\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.7964 - val_loss: 0.4458 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4523 - sparse_categorical_accuracy: 0.7972 - val_loss: 0.4407 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4506 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.4443 - val_sparse_categorical_accuracy: 0.8071\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4488 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4479 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.4384 - val_sparse_categorical_accuracy: 0.8077\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4476 - sparse_categorical_accuracy: 0.8016 - val_loss: 0.4483 - val_sparse_categorical_accuracy: 0.8010\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4470 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.4416 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4461 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4441 - val_sparse_categorical_accuracy: 0.8021\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4467 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.4507 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4456 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4544 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4453 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4464 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4443 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.4409 - val_sparse_categorical_accuracy: 0.8027\n",
      "getting accuracy of participant  5\n",
      "275/275 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.437222222222222\n",
      "TL to the participant :  6\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 14ms/step - loss: 0.5833 - sparse_categorical_accuracy: 0.7038 - val_loss: 0.5064 - val_sparse_categorical_accuracy: 0.7570\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4767 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.4752 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4626 - sparse_categorical_accuracy: 0.7926 - val_loss: 0.4646 - val_sparse_categorical_accuracy: 0.7882\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4603 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.4692 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4587 - sparse_categorical_accuracy: 0.7970 - val_loss: 0.4687 - val_sparse_categorical_accuracy: 0.7893\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4578 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.4656 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4569 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.4719 - val_sparse_categorical_accuracy: 0.7809\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4561 - sparse_categorical_accuracy: 0.7985 - val_loss: 0.4710 - val_sparse_categorical_accuracy: 0.7837\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4543 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.4651 - val_sparse_categorical_accuracy: 0.7893\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4524 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.4621 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4504 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.4646 - val_sparse_categorical_accuracy: 0.7854\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4470 - sparse_categorical_accuracy: 0.8038 - val_loss: 0.4680 - val_sparse_categorical_accuracy: 0.7854\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4455 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.4574 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4437 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.4509 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4429 - sparse_categorical_accuracy: 0.8021 - val_loss: 0.4519 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4411 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.4510 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4415 - sparse_categorical_accuracy: 0.8034 - val_loss: 0.4577 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4411 - sparse_categorical_accuracy: 0.8039 - val_loss: 0.4625 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4406 - sparse_categorical_accuracy: 0.8057 - val_loss: 0.4473 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4402 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.4451 - val_sparse_categorical_accuracy: 0.8004\n",
      "getting accuracy of participant  6\n",
      "275/275 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4054545454545448\n",
      "TL to the participant :  7\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 13ms/step - loss: 0.5673 - sparse_categorical_accuracy: 0.7160 - val_loss: 0.4941 - val_sparse_categorical_accuracy: 0.7882\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4809 - sparse_categorical_accuracy: 0.7815 - val_loss: 0.4779 - val_sparse_categorical_accuracy: 0.7798\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4708 - sparse_categorical_accuracy: 0.7871 - val_loss: 0.4745 - val_sparse_categorical_accuracy: 0.7809\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4661 - sparse_categorical_accuracy: 0.7894 - val_loss: 0.4720 - val_sparse_categorical_accuracy: 0.7910\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4639 - sparse_categorical_accuracy: 0.7915 - val_loss: 0.4695 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4625 - sparse_categorical_accuracy: 0.7945 - val_loss: 0.4666 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4609 - sparse_categorical_accuracy: 0.7923 - val_loss: 0.4653 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4598 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.4611 - val_sparse_categorical_accuracy: 0.7893\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4574 - sparse_categorical_accuracy: 0.7925 - val_loss: 0.4639 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4541 - sparse_categorical_accuracy: 0.7934 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4499 - sparse_categorical_accuracy: 0.7956 - val_loss: 0.4502 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4456 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4472 - val_sparse_categorical_accuracy: 0.7971\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4435 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.4435 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4422 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4467 - val_sparse_categorical_accuracy: 0.8010\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4407 - sparse_categorical_accuracy: 0.8016 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4408 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.4434 - val_sparse_categorical_accuracy: 0.8021\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4398 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4442 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4392 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.4434 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4392 - sparse_categorical_accuracy: 0.8032 - val_loss: 0.4410 - val_sparse_categorical_accuracy: 0.8066\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4390 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.8021\n",
      "getting accuracy of participant  7\n",
      "275/275 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.371980676328502\n",
      "TL to the participant :  8\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 16ms/step - loss: 0.5513 - sparse_categorical_accuracy: 0.7320 - val_loss: 0.4734 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4688 - sparse_categorical_accuracy: 0.7907 - val_loss: 0.4508 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4534 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.4350 - val_sparse_categorical_accuracy: 0.8088\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4439 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.4383 - val_sparse_categorical_accuracy: 0.8144\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4396 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8194\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4377 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.4221 - val_sparse_categorical_accuracy: 0.8166\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4361 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.4227 - val_sparse_categorical_accuracy: 0.8177\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4358 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4215 - val_sparse_categorical_accuracy: 0.8144\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4345 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4212 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4341 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4287 - val_sparse_categorical_accuracy: 0.8149\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4336 - sparse_categorical_accuracy: 0.8092 - val_loss: 0.4207 - val_sparse_categorical_accuracy: 0.8138\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4326 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.4221 - val_sparse_categorical_accuracy: 0.8144\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4325 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.4395 - val_sparse_categorical_accuracy: 0.8088\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4320 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.4215 - val_sparse_categorical_accuracy: 0.8122\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4321 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.4244 - val_sparse_categorical_accuracy: 0.8161\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.4221 - val_sparse_categorical_accuracy: 0.8094\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4319 - sparse_categorical_accuracy: 0.8092 - val_loss: 0.4237 - val_sparse_categorical_accuracy: 0.8094\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.4190 - val_sparse_categorical_accuracy: 0.8116\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.8097 - val_loss: 0.4220 - val_sparse_categorical_accuracy: 0.8166\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4308 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.4282 - val_sparse_categorical_accuracy: 0.8088\n",
      "getting accuracy of participant  8\n",
      "275/275 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.509259259259259\n",
      "TL to the participant :  9\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 14ms/step - loss: 0.5984 - sparse_categorical_accuracy: 0.6753 - val_loss: 0.4825 - val_sparse_categorical_accuracy: 0.7837\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4781 - sparse_categorical_accuracy: 0.7814 - val_loss: 0.4606 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4674 - sparse_categorical_accuracy: 0.7908 - val_loss: 0.4518 - val_sparse_categorical_accuracy: 0.8021\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4606 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.4480 - val_sparse_categorical_accuracy: 0.8038\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4553 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.4475 - val_sparse_categorical_accuracy: 0.8082\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4485 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.4361 - val_sparse_categorical_accuracy: 0.8099\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4424 - sparse_categorical_accuracy: 0.8045 - val_loss: 0.4412 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4388 - sparse_categorical_accuracy: 0.8045 - val_loss: 0.4324 - val_sparse_categorical_accuracy: 0.8082\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4351 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.4322 - val_sparse_categorical_accuracy: 0.8122\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4326 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.4289 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.4234 - val_sparse_categorical_accuracy: 0.8155\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4295 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.4256 - val_sparse_categorical_accuracy: 0.8155\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4290 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.4270 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4280 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.4282 - val_sparse_categorical_accuracy: 0.8094\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4276 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.4247 - val_sparse_categorical_accuracy: 0.8205\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4273 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.4232 - val_sparse_categorical_accuracy: 0.8227\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4267 - sparse_categorical_accuracy: 0.8119 - val_loss: 0.4250 - val_sparse_categorical_accuracy: 0.8144\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4273 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.4277 - val_sparse_categorical_accuracy: 0.8144\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4265 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.4250 - val_sparse_categorical_accuracy: 0.8200\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4259 - sparse_categorical_accuracy: 0.8121 - val_loss: 0.4268 - val_sparse_categorical_accuracy: 0.8227\n",
      "getting accuracy of participant  9\n",
      "275/275 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.48015873015873\n",
      "TL to the participant :  10\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 13ms/step - loss: 0.5576 - sparse_categorical_accuracy: 0.7193 - val_loss: 0.4842 - val_sparse_categorical_accuracy: 0.7793\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4834 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.4692 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4766 - sparse_categorical_accuracy: 0.7821 - val_loss: 0.4642 - val_sparse_categorical_accuracy: 0.7860\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4736 - sparse_categorical_accuracy: 0.7846 - val_loss: 0.4641 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4732 - sparse_categorical_accuracy: 0.7857 - val_loss: 0.4642 - val_sparse_categorical_accuracy: 0.7860\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4724 - sparse_categorical_accuracy: 0.7832 - val_loss: 0.4587 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4714 - sparse_categorical_accuracy: 0.7874 - val_loss: 0.4623 - val_sparse_categorical_accuracy: 0.7837\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4711 - sparse_categorical_accuracy: 0.7865 - val_loss: 0.4611 - val_sparse_categorical_accuracy: 0.7915\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4701 - sparse_categorical_accuracy: 0.7856 - val_loss: 0.4837 - val_sparse_categorical_accuracy: 0.7670\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4697 - sparse_categorical_accuracy: 0.7848 - val_loss: 0.4598 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4676 - sparse_categorical_accuracy: 0.7885 - val_loss: 0.4641 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4675 - sparse_categorical_accuracy: 0.7885 - val_loss: 0.4550 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4663 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.4546 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4648 - sparse_categorical_accuracy: 0.7897 - val_loss: 0.4553 - val_sparse_categorical_accuracy: 0.7971\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4635 - sparse_categorical_accuracy: 0.7913 - val_loss: 0.4535 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 13ms/step - loss: 0.4630 - sparse_categorical_accuracy: 0.7928 - val_loss: 0.4592 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4626 - sparse_categorical_accuracy: 0.7926 - val_loss: 0.4558 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4616 - sparse_categorical_accuracy: 0.7926 - val_loss: 0.4535 - val_sparse_categorical_accuracy: 0.7932\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4614 - sparse_categorical_accuracy: 0.7953 - val_loss: 0.4554 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4611 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.4535 - val_sparse_categorical_accuracy: 0.7999\n",
      "getting accuracy of participant  10\n",
      "275/275 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4255208333333336\n",
      "TL to the participant :  11\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 16ms/step - loss: 0.6397 - sparse_categorical_accuracy: 0.6413 - val_loss: 0.5089 - val_sparse_categorical_accuracy: 0.7581\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4890 - sparse_categorical_accuracy: 0.7752 - val_loss: 0.4745 - val_sparse_categorical_accuracy: 0.7915\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4754 - sparse_categorical_accuracy: 0.7817 - val_loss: 0.4691 - val_sparse_categorical_accuracy: 0.7821\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4703 - sparse_categorical_accuracy: 0.7836 - val_loss: 0.4662 - val_sparse_categorical_accuracy: 0.7832\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4676 - sparse_categorical_accuracy: 0.7864 - val_loss: 0.4502 - val_sparse_categorical_accuracy: 0.7982\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4659 - sparse_categorical_accuracy: 0.7877 - val_loss: 0.4521 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4647 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.4510 - val_sparse_categorical_accuracy: 0.8122\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4627 - sparse_categorical_accuracy: 0.7904 - val_loss: 0.4671 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4601 - sparse_categorical_accuracy: 0.7949 - val_loss: 0.4444 - val_sparse_categorical_accuracy: 0.8066\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4584 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.4445 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4552 - sparse_categorical_accuracy: 0.7950 - val_loss: 0.4389 - val_sparse_categorical_accuracy: 0.8094\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4530 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4408 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4515 - sparse_categorical_accuracy: 0.8004 - val_loss: 0.4330 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4500 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.4314 - val_sparse_categorical_accuracy: 0.8082\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4486 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.4277 - val_sparse_categorical_accuracy: 0.8161\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4482 - sparse_categorical_accuracy: 0.8014 - val_loss: 0.4280 - val_sparse_categorical_accuracy: 0.8161\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4476 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.4281 - val_sparse_categorical_accuracy: 0.8122\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4471 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4247 - val_sparse_categorical_accuracy: 0.8138\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4468 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.4280 - val_sparse_categorical_accuracy: 0.8177\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4456 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4249 - val_sparse_categorical_accuracy: 0.8094\n",
      "getting accuracy of participant  11\n",
      "275/275 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4448484848484842\n",
      "TL to the participant :  12\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 14ms/step - loss: 0.6051 - sparse_categorical_accuracy: 0.6700 - val_loss: 0.5105 - val_sparse_categorical_accuracy: 0.7637\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4862 - sparse_categorical_accuracy: 0.7735 - val_loss: 0.4681 - val_sparse_categorical_accuracy: 0.7832\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4688 - sparse_categorical_accuracy: 0.7881 - val_loss: 0.4547 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4644 - sparse_categorical_accuracy: 0.7914 - val_loss: 0.4530 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4630 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.4510 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4609 - sparse_categorical_accuracy: 0.7942 - val_loss: 0.4459 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4605 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.4483 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4602 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.4487 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4596 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.4484 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4594 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.4533 - val_sparse_categorical_accuracy: 0.8010\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4591 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.4477 - val_sparse_categorical_accuracy: 0.8066\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4587 - sparse_categorical_accuracy: 0.7933 - val_loss: 0.4484 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4586 - sparse_categorical_accuracy: 0.7966 - val_loss: 0.4496 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4584 - sparse_categorical_accuracy: 0.7953 - val_loss: 0.4562 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4582 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.4513 - val_sparse_categorical_accuracy: 0.8038\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4582 - sparse_categorical_accuracy: 0.7949 - val_loss: 0.4496 - val_sparse_categorical_accuracy: 0.8032\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4582 - sparse_categorical_accuracy: 0.7956 - val_loss: 0.4553 - val_sparse_categorical_accuracy: 0.8010\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4580 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.4477 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4574 - sparse_categorical_accuracy: 0.7969 - val_loss: 0.4492 - val_sparse_categorical_accuracy: 0.8071\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4576 - sparse_categorical_accuracy: 0.7946 - val_loss: 0.4570 - val_sparse_categorical_accuracy: 0.7988\n",
      "getting accuracy of participant  12\n",
      "275/275 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4241496598639456\n",
      "TL to the participant :  13\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 14ms/step - loss: 0.5823 - sparse_categorical_accuracy: 0.6981 - val_loss: 0.4944 - val_sparse_categorical_accuracy: 0.7737\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4844 - sparse_categorical_accuracy: 0.7795 - val_loss: 0.4703 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4658 - sparse_categorical_accuracy: 0.7892 - val_loss: 0.4498 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4573 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.4426 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4540 - sparse_categorical_accuracy: 0.7975 - val_loss: 0.4430 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4519 - sparse_categorical_accuracy: 0.7975 - val_loss: 0.4402 - val_sparse_categorical_accuracy: 0.8010\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4505 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.4393 - val_sparse_categorical_accuracy: 0.8032\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4490 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.4388 - val_sparse_categorical_accuracy: 0.7971\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4479 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4380 - val_sparse_categorical_accuracy: 0.8032\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4476 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4470 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4458 - sparse_categorical_accuracy: 0.8009 - val_loss: 0.4461 - val_sparse_categorical_accuracy: 0.7893\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4457 - sparse_categorical_accuracy: 0.8004 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8021\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4450 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4343 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4449 - sparse_categorical_accuracy: 0.7998 - val_loss: 0.4392 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4451 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4448 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4384 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.4448 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4701 - val_sparse_categorical_accuracy: 0.7848\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4445 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.4369 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4444 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.7899\n",
      "getting accuracy of participant  13\n",
      "275/275 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.4044270833333334\n",
      "TL to the participant :  14\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 14ms/step - loss: 0.5385 - sparse_categorical_accuracy: 0.7420 - val_loss: 0.4781 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4689 - sparse_categorical_accuracy: 0.7895 - val_loss: 0.4516 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.8020 - val_loss: 0.4372 - val_sparse_categorical_accuracy: 0.8177\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4415 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.4333 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4361 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.4261 - val_sparse_categorical_accuracy: 0.8144\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4352 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4291 - val_sparse_categorical_accuracy: 0.8161\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4344 - sparse_categorical_accuracy: 0.8128 - val_loss: 0.4267 - val_sparse_categorical_accuracy: 0.8155\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4346 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.4267 - val_sparse_categorical_accuracy: 0.8122\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4343 - sparse_categorical_accuracy: 0.8116 - val_loss: 0.4315 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4331 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.4274 - val_sparse_categorical_accuracy: 0.8122\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4337 - sparse_categorical_accuracy: 0.8112 - val_loss: 0.4290 - val_sparse_categorical_accuracy: 0.8144\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4324 - sparse_categorical_accuracy: 0.8122 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4335 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.4308 - val_sparse_categorical_accuracy: 0.8116\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4330 - sparse_categorical_accuracy: 0.8128 - val_loss: 0.4247 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8131 - val_loss: 0.4259 - val_sparse_categorical_accuracy: 0.8088\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4320 - sparse_categorical_accuracy: 0.8144 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4320 - sparse_categorical_accuracy: 0.8119 - val_loss: 0.4259 - val_sparse_categorical_accuracy: 0.8166\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4322 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.4265 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8122 - val_loss: 0.4270 - val_sparse_categorical_accuracy: 0.8155\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4317 - sparse_categorical_accuracy: 0.8157 - val_loss: 0.4261 - val_sparse_categorical_accuracy: 0.8127\n",
      "getting accuracy of participant  14\n",
      "275/275 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4730158730158731\n",
      "TL to the participant :  15\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 15ms/step - loss: 0.6126 - sparse_categorical_accuracy: 0.6737 - val_loss: 0.5042 - val_sparse_categorical_accuracy: 0.7648\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4873 - sparse_categorical_accuracy: 0.7766 - val_loss: 0.4729 - val_sparse_categorical_accuracy: 0.7837\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4748 - sparse_categorical_accuracy: 0.7864 - val_loss: 0.4685 - val_sparse_categorical_accuracy: 0.7932\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4718 - sparse_categorical_accuracy: 0.7877 - val_loss: 0.4624 - val_sparse_categorical_accuracy: 0.7882\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4701 - sparse_categorical_accuracy: 0.7911 - val_loss: 0.4585 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4687 - sparse_categorical_accuracy: 0.7930 - val_loss: 0.4597 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4686 - sparse_categorical_accuracy: 0.7902 - val_loss: 0.4670 - val_sparse_categorical_accuracy: 0.7971\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4671 - sparse_categorical_accuracy: 0.7925 - val_loss: 0.4541 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4669 - sparse_categorical_accuracy: 0.7928 - val_loss: 0.4571 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4672 - sparse_categorical_accuracy: 0.7918 - val_loss: 0.4603 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4661 - sparse_categorical_accuracy: 0.7938 - val_loss: 0.4585 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4663 - sparse_categorical_accuracy: 0.7943 - val_loss: 0.4583 - val_sparse_categorical_accuracy: 0.7971\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4655 - sparse_categorical_accuracy: 0.7925 - val_loss: 0.4564 - val_sparse_categorical_accuracy: 0.7982\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4658 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.4556 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.7952 - val_loss: 0.4563 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4651 - sparse_categorical_accuracy: 0.7930 - val_loss: 0.4598 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4648 - sparse_categorical_accuracy: 0.7943 - val_loss: 0.4570 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4639 - sparse_categorical_accuracy: 0.7923 - val_loss: 0.4667 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4643 - sparse_categorical_accuracy: 0.7943 - val_loss: 0.4589 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4640 - sparse_categorical_accuracy: 0.7923 - val_loss: 0.4555 - val_sparse_categorical_accuracy: 0.8027\n",
      "getting accuracy of participant  15\n",
      "275/275 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3792349726775952\n",
      "TL to the participant :  16\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 15ms/step - loss: 0.6035 - sparse_categorical_accuracy: 0.6735 - val_loss: 0.5282 - val_sparse_categorical_accuracy: 0.7453\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4844 - sparse_categorical_accuracy: 0.7754 - val_loss: 0.4857 - val_sparse_categorical_accuracy: 0.7759\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4574 - sparse_categorical_accuracy: 0.7928 - val_loss: 0.4844 - val_sparse_categorical_accuracy: 0.7759\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.4505 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.4980 - val_sparse_categorical_accuracy: 0.7692\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4476 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.4796 - val_sparse_categorical_accuracy: 0.7809\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4470 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4782 - val_sparse_categorical_accuracy: 0.7781\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4455 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.4774 - val_sparse_categorical_accuracy: 0.7759\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4446 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.4758 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4439 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.4808 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4443 - sparse_categorical_accuracy: 0.8014 - val_loss: 0.4759 - val_sparse_categorical_accuracy: 0.7860\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4430 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4748 - val_sparse_categorical_accuracy: 0.7848\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4439 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.4767 - val_sparse_categorical_accuracy: 0.7815\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4431 - sparse_categorical_accuracy: 0.8017 - val_loss: 0.4777 - val_sparse_categorical_accuracy: 0.7848\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4425 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4755 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4419 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.4741 - val_sparse_categorical_accuracy: 0.7921\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.4716 - val_sparse_categorical_accuracy: 0.7932\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4420 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4750 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4423 - sparse_categorical_accuracy: 0.8021 - val_loss: 0.4761 - val_sparse_categorical_accuracy: 0.7815\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4415 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.4725 - val_sparse_categorical_accuracy: 0.7910\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4415 - sparse_categorical_accuracy: 0.8018 - val_loss: 0.4782 - val_sparse_categorical_accuracy: 0.7804\n",
      "getting accuracy of participant  16\n",
      "275/275 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.3680952380952378\n",
      "TL to the participant :  17\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 16ms/step - loss: 0.5919 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4732 - sparse_categorical_accuracy: 0.7871 - val_loss: 0.4504 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4553 - sparse_categorical_accuracy: 0.7950 - val_loss: 0.4497 - val_sparse_categorical_accuracy: 0.8010\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4499 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8077\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4465 - sparse_categorical_accuracy: 0.7999 - val_loss: 0.4398 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.4454 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.4521 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.4443 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.4412 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 5s 18ms/step - loss: 0.4428 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.4437 - val_sparse_categorical_accuracy: 0.8010\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.4424 - sparse_categorical_accuracy: 0.8038 - val_loss: 0.4425 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.4419 - sparse_categorical_accuracy: 0.8045 - val_loss: 0.4496 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.4415 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.4364 - val_sparse_categorical_accuracy: 0.8066\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4407 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.4392 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4404 - sparse_categorical_accuracy: 0.8056 - val_loss: 0.4461 - val_sparse_categorical_accuracy: 0.8038\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 17ms/step - loss: 0.4399 - sparse_categorical_accuracy: 0.8050 - val_loss: 0.4417 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4399 - sparse_categorical_accuracy: 0.8034 - val_loss: 0.4407 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4393 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.4388 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4394 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4389 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4395 - val_sparse_categorical_accuracy: 0.8094\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4392 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4369 - val_sparse_categorical_accuracy: 0.8088\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4392 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.4574 - val_sparse_categorical_accuracy: 0.7893\n",
      "getting accuracy of participant  17\n",
      "275/275 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4962962962962962\n",
      "TL to the participant :  18\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 16ms/step - loss: 0.5742 - sparse_categorical_accuracy: 0.7057 - val_loss: 0.4905 - val_sparse_categorical_accuracy: 0.7826\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4764 - sparse_categorical_accuracy: 0.7797 - val_loss: 0.4741 - val_sparse_categorical_accuracy: 0.7826\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4684 - sparse_categorical_accuracy: 0.7850 - val_loss: 0.4714 - val_sparse_categorical_accuracy: 0.7893\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4643 - sparse_categorical_accuracy: 0.7886 - val_loss: 0.4659 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4612 - sparse_categorical_accuracy: 0.7930 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4567 - sparse_categorical_accuracy: 0.7934 - val_loss: 0.4717 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4505 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.4563 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4423 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.4509 - val_sparse_categorical_accuracy: 0.8099\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4369 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.4491 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4338 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.4432 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4325 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.4521 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4308 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4458 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4427 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4292 - sparse_categorical_accuracy: 0.8083 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4290 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.4459 - val_sparse_categorical_accuracy: 0.8021\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4293 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4290 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4460 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4287 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.4427 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4282 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.4385 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4281 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4379 - val_sparse_categorical_accuracy: 0.8099\n",
      "getting accuracy of participant  18\n",
      "275/275 [==============================] - 1s 4ms/step\n",
      "meannnnnn long 1.42156862745098\n",
      "TL to the participant :  19\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 16ms/step - loss: 0.5885 - sparse_categorical_accuracy: 0.6900 - val_loss: 0.4757 - val_sparse_categorical_accuracy: 0.7787\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4670 - sparse_categorical_accuracy: 0.7889 - val_loss: 0.4473 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4494 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.4453 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4448 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.4403 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 16ms/step - loss: 0.4431 - sparse_categorical_accuracy: 0.8027 - val_loss: 0.4415 - val_sparse_categorical_accuracy: 0.8021\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4410 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.4425 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4404 - sparse_categorical_accuracy: 0.8057 - val_loss: 0.4390 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4396 - sparse_categorical_accuracy: 0.8042 - val_loss: 0.4496 - val_sparse_categorical_accuracy: 0.7915\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4382 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4482 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4379 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.4407 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4367 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.4382 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4367 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4449 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4360 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.4396 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4360 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.4397 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4353 - sparse_categorical_accuracy: 0.8093 - val_loss: 0.4434 - val_sparse_categorical_accuracy: 0.8038\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.4392 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.4541 - val_sparse_categorical_accuracy: 0.7910\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4345 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.4404 - val_sparse_categorical_accuracy: 0.8038\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4348 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.4379 - val_sparse_categorical_accuracy: 0.8077\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4343 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.4421 - val_sparse_categorical_accuracy: 0.7999\n",
      "getting accuracy of participant  19\n",
      "275/275 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4866666666666661\n",
      "TL to the participant :  20\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 5s 15ms/step - loss: 0.5398 - sparse_categorical_accuracy: 0.7379 - val_loss: 0.4868 - val_sparse_categorical_accuracy: 0.7832\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4822 - sparse_categorical_accuracy: 0.7802 - val_loss: 0.4724 - val_sparse_categorical_accuracy: 0.7910\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4754 - sparse_categorical_accuracy: 0.7851 - val_loss: 0.4688 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4726 - sparse_categorical_accuracy: 0.7887 - val_loss: 0.4658 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4720 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.4633 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4707 - sparse_categorical_accuracy: 0.7889 - val_loss: 0.4588 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4703 - sparse_categorical_accuracy: 0.7908 - val_loss: 0.4583 - val_sparse_categorical_accuracy: 0.8077\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4695 - sparse_categorical_accuracy: 0.7927 - val_loss: 0.4572 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4687 - sparse_categorical_accuracy: 0.7917 - val_loss: 0.4576 - val_sparse_categorical_accuracy: 0.7971\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4684 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.4642 - val_sparse_categorical_accuracy: 0.7860\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4677 - sparse_categorical_accuracy: 0.7908 - val_loss: 0.4585 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4672 - sparse_categorical_accuracy: 0.7892 - val_loss: 0.4556 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4666 - sparse_categorical_accuracy: 0.7913 - val_loss: 0.4550 - val_sparse_categorical_accuracy: 0.7915\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4659 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.4587 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4656 - sparse_categorical_accuracy: 0.7918 - val_loss: 0.4540 - val_sparse_categorical_accuracy: 0.8082\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4652 - sparse_categorical_accuracy: 0.7909 - val_loss: 0.4555 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4646 - sparse_categorical_accuracy: 0.7907 - val_loss: 0.4551 - val_sparse_categorical_accuracy: 0.7971\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4647 - sparse_categorical_accuracy: 0.7905 - val_loss: 0.4545 - val_sparse_categorical_accuracy: 0.8021\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4646 - sparse_categorical_accuracy: 0.7897 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4641 - sparse_categorical_accuracy: 0.7892 - val_loss: 0.4558 - val_sparse_categorical_accuracy: 0.8032\n",
      "getting accuracy of participant  20\n",
      "275/275 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3628378378378379\n",
      "TL to the participant :  21\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.5282 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.4807 - val_sparse_categorical_accuracy: 0.7776\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4595 - sparse_categorical_accuracy: 0.7923 - val_loss: 0.4664 - val_sparse_categorical_accuracy: 0.7809\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4467 - sparse_categorical_accuracy: 0.7972 - val_loss: 0.4526 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.4457 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4395 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.4476 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4380 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.4465 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4383 - sparse_categorical_accuracy: 0.8055 - val_loss: 0.4457 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4374 - sparse_categorical_accuracy: 0.8041 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.7860\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4365 - sparse_categorical_accuracy: 0.8058 - val_loss: 0.4437 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4368 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.4476 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4364 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.4428 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4359 - sparse_categorical_accuracy: 0.8072 - val_loss: 0.4477 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4359 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4561 - val_sparse_categorical_accuracy: 0.7882\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4355 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4428 - val_sparse_categorical_accuracy: 0.8032\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4352 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.4419 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4347 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.4430 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4352 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.4420 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.8083 - val_loss: 0.4438 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4339 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.4505 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4348 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.4412 - val_sparse_categorical_accuracy: 0.8027\n",
      "getting accuracy of participant  21\n",
      "275/275 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4374149659863944\n",
      "TL to the participant :  22\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.5601 - sparse_categorical_accuracy: 0.7273 - val_loss: 0.5027 - val_sparse_categorical_accuracy: 0.7648\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4784 - sparse_categorical_accuracy: 0.7779 - val_loss: 0.4842 - val_sparse_categorical_accuracy: 0.7676\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4665 - sparse_categorical_accuracy: 0.7881 - val_loss: 0.4829 - val_sparse_categorical_accuracy: 0.7787\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4601 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.4692 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4562 - sparse_categorical_accuracy: 0.7962 - val_loss: 0.4677 - val_sparse_categorical_accuracy: 0.7921\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4540 - sparse_categorical_accuracy: 0.7974 - val_loss: 0.4622 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4522 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.4590 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4514 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4506 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4590 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4502 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.4561 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4501 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.4598 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4495 - sparse_categorical_accuracy: 0.8017 - val_loss: 0.4568 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4499 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.4571 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4493 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.4576 - val_sparse_categorical_accuracy: 0.7932\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4492 - sparse_categorical_accuracy: 0.8020 - val_loss: 0.4611 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4485 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4579 - val_sparse_categorical_accuracy: 0.7932\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4482 - sparse_categorical_accuracy: 0.8039 - val_loss: 0.4576 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4483 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.4572 - val_sparse_categorical_accuracy: 0.7971\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4485 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.4570 - val_sparse_categorical_accuracy: 0.7982\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4486 - sparse_categorical_accuracy: 0.8009 - val_loss: 0.4581 - val_sparse_categorical_accuracy: 0.7949\n",
      "getting accuracy of participant  22\n",
      "275/275 [==============================] - 1s 3ms/step\n",
      "meannnnnn long 1.4329268292682926\n",
      "TL to the participant :  23\n",
      "(201825, 16, 16)\n",
      "(201825,)\n",
      "(8775, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.5944 - sparse_categorical_accuracy: 0.6838 - val_loss: 0.5025 - val_sparse_categorical_accuracy: 0.7687\n",
      "Epoch 2/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4721 - sparse_categorical_accuracy: 0.7834 - val_loss: 0.4792 - val_sparse_categorical_accuracy: 0.7781\n",
      "Epoch 3/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4615 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.4747 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 4/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4572 - sparse_categorical_accuracy: 0.7905 - val_loss: 0.4742 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 5/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4543 - sparse_categorical_accuracy: 0.7933 - val_loss: 0.4691 - val_sparse_categorical_accuracy: 0.7915\n",
      "Epoch 6/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4525 - sparse_categorical_accuracy: 0.7943 - val_loss: 0.4705 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 7/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4522 - sparse_categorical_accuracy: 0.7935 - val_loss: 0.4661 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 8/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4514 - sparse_categorical_accuracy: 0.7962 - val_loss: 0.4655 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 9/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4511 - sparse_categorical_accuracy: 0.7963 - val_loss: 0.4670 - val_sparse_categorical_accuracy: 0.7915\n",
      "Epoch 10/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4500 - sparse_categorical_accuracy: 0.7956 - val_loss: 0.4656 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 11/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4503 - sparse_categorical_accuracy: 0.7962 - val_loss: 0.4664 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 12/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4499 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.4650 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 13/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4495 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.4642 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 14/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4496 - sparse_categorical_accuracy: 0.7964 - val_loss: 0.4671 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 15/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4498 - sparse_categorical_accuracy: 0.7964 - val_loss: 0.4657 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 16/20\n",
      "253/253 [==============================] - 4s 15ms/step - loss: 0.4492 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.4650 - val_sparse_categorical_accuracy: 0.7977\n",
      "Epoch 17/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4489 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.4624 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 18/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4483 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.4723 - val_sparse_categorical_accuracy: 0.7848\n",
      "Epoch 19/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4489 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.4656 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 20/20\n",
      "253/253 [==============================] - 4s 14ms/step - loss: 0.4482 - sparse_categorical_accuracy: 0.7951 - val_loss: 0.4663 - val_sparse_categorical_accuracy: 0.7943\n",
      "getting accuracy of participant  23\n",
      "275/275 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3655092592592595\n",
      "[0.91216458 0.67438879 0.73962433 0.84159213 0.81753131 0.83205128\n",
      " 0.80578414 0.88363148 0.70730471 0.69293381 0.82104949 0.77122838\n",
      " 0.76007752 0.8245975  0.70026834 0.83008348 0.88419797 0.72802624\n",
      " 0.77602862 0.73315444 0.90286225 0.77400119 0.69060823 0.90745379]\n",
      "[68.90085959 74.82860589 71.10506964 66.93248701 68.04010344 69.07430387\n",
      " 70.47576642 66.59381413 70.49327922 70.82116604 70.07322288 73.27170658\n",
      " 71.62636089 71.58326411 75.94529629 78.78629732 80.35693336 83.98412776\n",
      " 77.79184031 76.91834998 75.9222157  74.54997492 73.76206207 74.37730289]\n",
      "[1.8823154  2.24804831 3.17404246 3.04600167 2.98578763 3.1433022\n",
      " 3.15248537 3.47751951 3.39072967 3.42717719 2.00916481 3.28504443\n",
      " 3.32829642 3.11451459 2.33289337 2.15232849 2.08214951 2.3092761\n",
      " 2.27099681 2.31841135 2.04596019 2.17342353 2.24336386 1.97573876]\n",
      "[1.   0.87 0.89 0.99 0.99 0.99 0.93 0.96 0.81 0.79 0.99 0.93 0.92 0.99\n",
      " 0.73 0.89 0.95 0.8  0.81 0.84 1.   0.91 0.77 0.99]\n"
     ]
    }
   ],
   "source": [
    "n_cal = 4\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "SPD_accuracy_code_perso = np.zeros(nb_part)\n",
    "SPD_tps_train_code_perso = np.zeros(nb_part)\n",
    "SPD_tps_test_code_perso = np.zeros(nb_part)\n",
    "SPD_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*60)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "    ind2take = [j for j in range(nb_part) if j!=i]\n",
    "\n",
    "    X_train = np.concatenate(X_riem[ind2take]).reshape(-1,X_riem.shape[-2],X_riem.shape[-1])\n",
    "    Y_train = np.concatenate(y_riem[ind2take]).reshape(-1)\n",
    "    domains_train = np.concatenate(domains[ind2take]).reshape(-1)\n",
    "    X_test = X_riem[i]\n",
    "    Y_test = y_riem[i]\n",
    "    labels_code_test = labels_code_list[i]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    # X_std = X_train.std(axis=0)\n",
    "    # X_train /= X_std + 1e-8\n",
    "    # X_std = X_test.std(axis=0)\n",
    "    # X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    X_train,Y_train,domains_train = balance(X_train,Y_train,domains_train)\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = SPDNet_Tensorflow(bimap_dims=[16,8,4])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    history_list.append(clf.fit(np.array(x_train), y_train,\n",
    "                    batch_size=batchsize, epochs=epochs,\n",
    "                    validation_data=(np.array(x_val), y_val), shuffle=True))\n",
    "    SPD_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([1 if (y >= 0.5) else 0 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    SPD_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, sfreq=60, consecutive=50, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    SPD_tps_test_code_perso[i] = time.time() - start\n",
    "    SPD_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(SPD_accuracy_perso)\n",
    "print(SPD_tps_train_code_perso)\n",
    "print(SPD_tps_test_code_perso)\n",
    "print(SPD_accuracy_code_perso)\n",
    "# pd.DataFrame(SPD_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/score/DG_score.csv\")\n",
    "# pd.DataFrame(SPD_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/score_code/DG_score_code.csv\")\n",
    "# pd.DataFrame(SPD_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/temps_train_code/DG_tps_train_code.csv\")\n",
    "# pd.DataFrame(SPD_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/temps_test_code/DG_tps_test_code.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.9020833333333332\n",
      "with timepoint wise 500HZ 0.9291666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9125"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([1, 0.96, 0.88, 1,   1,   0.99, 0.92, 0.99, 0.84, 0.27, 0.97, 0.89, 0.95, 0.99,\n",
    " 0.73, 0.95, 0.97, 0.89 ,0.85, 0.91, 1, 0.93, 0.8 , 0.97]))\n",
    "print(\"with timepoint wise 500HZ\",np.mean([0.99,0.92,0.93,0.99,0.99,0.99,0.95,0.97,0.89,0.79,0.97,0.93,0.96,0.97\n",
    ",0.81,0.97,0.97,0.81,0.8,0.89,1.,  0.97,0.85,0.99]))\n",
    "np.mean([1, 0.93, 0.89 ,0.99, 0.96, 0.96, 0.91 ,0.95 ,0.89 ,0.72, 0.96, 0.96 ,0.89, 0.93,\n",
    " 0.71, 0.99, 0.99, 0.89, 0.88, 0.81, 1, 0.92, 0.77, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPD DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 25s 11ms/step - loss: 0.4806 - sparse_categorical_accuracy: 0.7802 - val_loss: 0.4593 - val_sparse_categorical_accuracy: 0.7923\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4519 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.4383 - val_sparse_categorical_accuracy: 0.8044\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4396 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.4312 - val_sparse_categorical_accuracy: 0.8102\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4379 - sparse_categorical_accuracy: 0.8050 - val_loss: 0.4304 - val_sparse_categorical_accuracy: 0.8096\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4373 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.4369 - val_sparse_categorical_accuracy: 0.8047\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4367 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4364 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4366 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.4325 - val_sparse_categorical_accuracy: 0.8102\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4363 - sparse_categorical_accuracy: 0.8059 - val_loss: 0.4302 - val_sparse_categorical_accuracy: 0.8081\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4362 - sparse_categorical_accuracy: 0.8064 - val_loss: 0.4298 - val_sparse_categorical_accuracy: 0.8116\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4358 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.4305 - val_sparse_categorical_accuracy: 0.8103\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 31s 14ms/step - loss: 0.4357 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.4282 - val_sparse_categorical_accuracy: 0.8124\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4357 - sparse_categorical_accuracy: 0.8064 - val_loss: 0.4268 - val_sparse_categorical_accuracy: 0.8128\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4354 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.4265 - val_sparse_categorical_accuracy: 0.8138\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4356 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.4312 - val_sparse_categorical_accuracy: 0.8104\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4354 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.4295 - val_sparse_categorical_accuracy: 0.8078\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4352 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.4262 - val_sparse_categorical_accuracy: 0.8116\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4351 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.4425 - val_sparse_categorical_accuracy: 0.7992\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4352 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.4304 - val_sparse_categorical_accuracy: 0.8114\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4349 - sparse_categorical_accuracy: 0.8072 - val_loss: 0.4278 - val_sparse_categorical_accuracy: 0.8097\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8107\n",
      "getting accuracy of participant  0\n",
      "1676/1676 [==============================] - 5s 3ms/step\n",
      "meannnnnn long 1.380128205128205\n",
      "TL to the participant :  1\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 23s 10ms/step - loss: 0.4777 - sparse_categorical_accuracy: 0.7807 - val_loss: 0.4585 - val_sparse_categorical_accuracy: 0.7986\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.4576 - val_sparse_categorical_accuracy: 0.7979\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4529 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.4580 - val_sparse_categorical_accuracy: 0.7972\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4522 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.7959\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 22s 11ms/step - loss: 0.4520 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.4559 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4515 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.4553 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4513 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.7968\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4510 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4557 - val_sparse_categorical_accuracy: 0.7968\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4508 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.4654 - val_sparse_categorical_accuracy: 0.7898\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4509 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.4556 - val_sparse_categorical_accuracy: 0.7991\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4507 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.4594 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4507 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4561 - val_sparse_categorical_accuracy: 0.7974\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4505 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.4583 - val_sparse_categorical_accuracy: 0.7961\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4505 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4612 - val_sparse_categorical_accuracy: 0.7917\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4502 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4611 - val_sparse_categorical_accuracy: 0.7921\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4504 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.4623 - val_sparse_categorical_accuracy: 0.7897\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 28s 13ms/step - loss: 0.4503 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.4547 - val_sparse_categorical_accuracy: 0.7980\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4502 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4669 - val_sparse_categorical_accuracy: 0.7957\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 22s 11ms/step - loss: 0.4502 - sparse_categorical_accuracy: 0.7998 - val_loss: 0.4541 - val_sparse_categorical_accuracy: 0.7995\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4501 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.7949\n",
      "getting accuracy of participant  1\n",
      "1676/1676 [==============================] - 5s 3ms/step\n",
      "meannnnnn long 1.4833333333333334\n",
      "TL to the participant :  2\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4643 - sparse_categorical_accuracy: 0.7914 - val_loss: 0.4680 - val_sparse_categorical_accuracy: 0.7870\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4540 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.4518 - val_sparse_categorical_accuracy: 0.8002\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 27s 13ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4543 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4525 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4515 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4518 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.4522 - val_sparse_categorical_accuracy: 0.7991\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4515 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.4529 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4515 - sparse_categorical_accuracy: 0.7998 - val_loss: 0.4511 - val_sparse_categorical_accuracy: 0.8006\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4510 - sparse_categorical_accuracy: 0.7999 - val_loss: 0.4518 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4507 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.4613 - val_sparse_categorical_accuracy: 0.7916\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4509 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.4604 - val_sparse_categorical_accuracy: 0.7922\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4506 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.8013\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4504 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4512 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4503 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4588 - val_sparse_categorical_accuracy: 0.7915\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4505 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.4591 - val_sparse_categorical_accuracy: 0.7921\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4501 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4532 - val_sparse_categorical_accuracy: 0.7976\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4500 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.4513 - val_sparse_categorical_accuracy: 0.8018\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4500 - sparse_categorical_accuracy: 0.8004 - val_loss: 0.4515 - val_sparse_categorical_accuracy: 0.7998\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4497 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.4591 - val_sparse_categorical_accuracy: 0.7914\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4498 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.4537 - val_sparse_categorical_accuracy: 0.7994\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4494 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.4503 - val_sparse_categorical_accuracy: 0.8001\n",
      "getting accuracy of participant  2\n",
      "1676/1676 [==============================] - 5s 3ms/step\n",
      "meannnnnn long 1.4109848484848486\n",
      "TL to the participant :  3\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 23s 10ms/step - loss: 0.4899 - sparse_categorical_accuracy: 0.7716 - val_loss: 0.4664 - val_sparse_categorical_accuracy: 0.7919\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4586 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.4628 - val_sparse_categorical_accuracy: 0.7932\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4565 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.4583 - val_sparse_categorical_accuracy: 0.7989\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4556 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4553 - sparse_categorical_accuracy: 0.7972 - val_loss: 0.4600 - val_sparse_categorical_accuracy: 0.7984\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4549 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.7953\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4545 - sparse_categorical_accuracy: 0.7981 - val_loss: 0.4638 - val_sparse_categorical_accuracy: 0.7928\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4545 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.7995\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4543 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.4637 - val_sparse_categorical_accuracy: 0.7967\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4582 - val_sparse_categorical_accuracy: 0.8003\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4540 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.4573 - val_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4626 - val_sparse_categorical_accuracy: 0.7976\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4538 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.4580 - val_sparse_categorical_accuracy: 0.7992\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4540 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8002\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4537 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.4565 - val_sparse_categorical_accuracy: 0.8006\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4535 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.4589 - val_sparse_categorical_accuracy: 0.8015\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4536 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4574 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4535 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4582 - val_sparse_categorical_accuracy: 0.7986\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4535 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.4564 - val_sparse_categorical_accuracy: 0.8017\n",
      "getting accuracy of participant  3\n",
      "1676/1676 [==============================] - 6s 3ms/step\n",
      "meannnnnn long 1.4135416666666665\n",
      "TL to the participant :  4\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 23s 10ms/step - loss: 0.4748 - sparse_categorical_accuracy: 0.7833 - val_loss: 0.4642 - val_sparse_categorical_accuracy: 0.7884\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4569 - sparse_categorical_accuracy: 0.7965 - val_loss: 0.4605 - val_sparse_categorical_accuracy: 0.7941\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4558 - sparse_categorical_accuracy: 0.7968 - val_loss: 0.4604 - val_sparse_categorical_accuracy: 0.7934\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4553 - sparse_categorical_accuracy: 0.7968 - val_loss: 0.4598 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 27s 13ms/step - loss: 0.4549 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4652 - val_sparse_categorical_accuracy: 0.7924\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4548 - sparse_categorical_accuracy: 0.7965 - val_loss: 0.4683 - val_sparse_categorical_accuracy: 0.7872\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4546 - sparse_categorical_accuracy: 0.7972 - val_loss: 0.4644 - val_sparse_categorical_accuracy: 0.7922\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4544 - sparse_categorical_accuracy: 0.7974 - val_loss: 0.4641 - val_sparse_categorical_accuracy: 0.7945\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4545 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4585 - val_sparse_categorical_accuracy: 0.7945\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.7972 - val_loss: 0.4614 - val_sparse_categorical_accuracy: 0.7956\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4543 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4581 - val_sparse_categorical_accuracy: 0.7984\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4541 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.4618 - val_sparse_categorical_accuracy: 0.7924\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4538 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.4622 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.7981 - val_loss: 0.4607 - val_sparse_categorical_accuracy: 0.7923\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4538 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4582 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4586 - val_sparse_categorical_accuracy: 0.7948\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4538 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.4587 - val_sparse_categorical_accuracy: 0.7964\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4536 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4640 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4537 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.4595 - val_sparse_categorical_accuracy: 0.7956\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4537 - sparse_categorical_accuracy: 0.7984 - val_loss: 0.4573 - val_sparse_categorical_accuracy: 0.7953\n",
      "getting accuracy of participant  4\n",
      "1676/1676 [==============================] - 4s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.398888888888889\n",
      "TL to the participant :  5\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4823 - sparse_categorical_accuracy: 0.7748 - val_loss: 0.4478 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 22s 11ms/step - loss: 0.4410 - sparse_categorical_accuracy: 0.8038 - val_loss: 0.4390 - val_sparse_categorical_accuracy: 0.8040\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 22s 11ms/step - loss: 0.4367 - sparse_categorical_accuracy: 0.8059 - val_loss: 0.4355 - val_sparse_categorical_accuracy: 0.8057\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4355 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.4377 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4349 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.4402 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4345 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.4419 - val_sparse_categorical_accuracy: 0.8019\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4343 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.4399 - val_sparse_categorical_accuracy: 0.8077\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4343 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.4360 - val_sparse_categorical_accuracy: 0.8046\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4339 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.4426 - val_sparse_categorical_accuracy: 0.8047\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4340 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.4426 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 27s 13ms/step - loss: 0.4337 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.4360 - val_sparse_categorical_accuracy: 0.8033\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4335 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8068\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4333 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.8057\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4334 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.4368 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4332 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4375 - val_sparse_categorical_accuracy: 0.8012\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.4343 - val_sparse_categorical_accuracy: 0.8061\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4330 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.4368 - val_sparse_categorical_accuracy: 0.8029\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4327 - sparse_categorical_accuracy: 0.8083 - val_loss: 0.4374 - val_sparse_categorical_accuracy: 0.8037\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4328 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4505 - val_sparse_categorical_accuracy: 0.7996\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4327 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.4352 - val_sparse_categorical_accuracy: 0.8070\n",
      "getting accuracy of participant  5\n",
      "1676/1676 [==============================] - 5s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4427083333333333\n",
      "TL to the participant :  6\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 25s 11ms/step - loss: 0.4676 - sparse_categorical_accuracy: 0.7871 - val_loss: 0.4410 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4469 - sparse_categorical_accuracy: 0.8020 - val_loss: 0.4404 - val_sparse_categorical_accuracy: 0.8035\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4440 - sparse_categorical_accuracy: 0.8036 - val_loss: 0.4336 - val_sparse_categorical_accuracy: 0.8048\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4417 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.4451 - val_sparse_categorical_accuracy: 0.7979\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4406 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4305 - val_sparse_categorical_accuracy: 0.8090\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4400 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.4303 - val_sparse_categorical_accuracy: 0.8084\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4396 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.4485 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4393 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.4288 - val_sparse_categorical_accuracy: 0.8079\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4391 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4304 - val_sparse_categorical_accuracy: 0.8069\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4386 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4310 - val_sparse_categorical_accuracy: 0.8090\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4388 - sparse_categorical_accuracy: 0.8064 - val_loss: 0.4318 - val_sparse_categorical_accuracy: 0.8076\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4385 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.4350 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4382 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.4301 - val_sparse_categorical_accuracy: 0.8081\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4383 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.4281 - val_sparse_categorical_accuracy: 0.8095\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4380 - sparse_categorical_accuracy: 0.8072 - val_loss: 0.4310 - val_sparse_categorical_accuracy: 0.8073\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4379 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.4277 - val_sparse_categorical_accuracy: 0.8097\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4379 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.4528 - val_sparse_categorical_accuracy: 0.7913\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4378 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.4272 - val_sparse_categorical_accuracy: 0.8081\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4376 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.4290 - val_sparse_categorical_accuracy: 0.8086\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4377 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.4297 - val_sparse_categorical_accuracy: 0.8079\n",
      "getting accuracy of participant  6\n",
      "1676/1676 [==============================] - 5s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3728682170542637\n",
      "TL to the participant :  7\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 25s 11ms/step - loss: 0.4744 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.4576 - val_sparse_categorical_accuracy: 0.7911\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4590 - sparse_categorical_accuracy: 0.7945 - val_loss: 0.4657 - val_sparse_categorical_accuracy: 0.7855\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4576 - sparse_categorical_accuracy: 0.7952 - val_loss: 0.4583 - val_sparse_categorical_accuracy: 0.7894\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4515 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4400 - sparse_categorical_accuracy: 0.8033 - val_loss: 0.4413 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4379 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.8032\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4372 - sparse_categorical_accuracy: 0.8044 - val_loss: 0.4388 - val_sparse_categorical_accuracy: 0.8010\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4362 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.4387 - val_sparse_categorical_accuracy: 0.8018\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4363 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.4415 - val_sparse_categorical_accuracy: 0.8005\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4360 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.4385 - val_sparse_categorical_accuracy: 0.8033\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4356 - sparse_categorical_accuracy: 0.8055 - val_loss: 0.4403 - val_sparse_categorical_accuracy: 0.8031\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4357 - sparse_categorical_accuracy: 0.8059 - val_loss: 0.4389 - val_sparse_categorical_accuracy: 0.8029\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4354 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.4331 - val_sparse_categorical_accuracy: 0.8067\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4351 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.4368 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4353 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.4337 - val_sparse_categorical_accuracy: 0.8051\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4520 - val_sparse_categorical_accuracy: 0.7970\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.4382 - val_sparse_categorical_accuracy: 0.8025\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4349 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.4332 - val_sparse_categorical_accuracy: 0.8065\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.4450 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4346 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.4415 - val_sparse_categorical_accuracy: 0.8010\n",
      "getting accuracy of participant  7\n",
      "1676/1676 [==============================] - 5s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3606918238993706\n",
      "TL to the participant :  8\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4540 - sparse_categorical_accuracy: 0.7956 - val_loss: 0.4451 - val_sparse_categorical_accuracy: 0.8029\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4347 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.4471 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4320 - sparse_categorical_accuracy: 0.8093 - val_loss: 0.4394 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 24s 12ms/step - loss: 0.4309 - sparse_categorical_accuracy: 0.8100 - val_loss: 0.4369 - val_sparse_categorical_accuracy: 0.8054\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4303 - sparse_categorical_accuracy: 0.8099 - val_loss: 0.4379 - val_sparse_categorical_accuracy: 0.8040\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4298 - sparse_categorical_accuracy: 0.8099 - val_loss: 0.4379 - val_sparse_categorical_accuracy: 0.8048\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4295 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8090\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4293 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.4391 - val_sparse_categorical_accuracy: 0.8024\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4290 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4379 - val_sparse_categorical_accuracy: 0.8029\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4289 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8081\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 24s 12ms/step - loss: 0.4289 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4430 - val_sparse_categorical_accuracy: 0.8047\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4286 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8083\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4286 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.4361 - val_sparse_categorical_accuracy: 0.8051\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4288 - sparse_categorical_accuracy: 0.8109 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8057\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4286 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.4372 - val_sparse_categorical_accuracy: 0.8065\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4283 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.8075\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4284 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.4374 - val_sparse_categorical_accuracy: 0.8028\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 27s 13ms/step - loss: 0.4286 - sparse_categorical_accuracy: 0.8100 - val_loss: 0.4408 - val_sparse_categorical_accuracy: 0.8012\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 27s 13ms/step - loss: 0.4285 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.8083\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4284 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.4463 - val_sparse_categorical_accuracy: 0.8045\n",
      "getting accuracy of participant  8\n",
      "1676/1676 [==============================] - 5s 3ms/step\n",
      "meannnnnn long 1.4449074074074075\n",
      "TL to the participant :  9\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4590 - sparse_categorical_accuracy: 0.7912 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.8014\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4354 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.4318 - val_sparse_categorical_accuracy: 0.8041\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4339 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.4376 - val_sparse_categorical_accuracy: 0.8008\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4327 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4339 - val_sparse_categorical_accuracy: 0.8084\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.4284 - val_sparse_categorical_accuracy: 0.8054\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4309 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8061\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 24s 12ms/step - loss: 0.4300 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.4252 - val_sparse_categorical_accuracy: 0.8081\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4293 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.4358 - val_sparse_categorical_accuracy: 0.8067\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4287 - sparse_categorical_accuracy: 0.8109 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8041\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4283 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.4320 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4281 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.4318 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4281 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.4237 - val_sparse_categorical_accuracy: 0.8114\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4278 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.4250 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4277 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.4246 - val_sparse_categorical_accuracy: 0.8109\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 22s 11ms/step - loss: 0.4277 - sparse_categorical_accuracy: 0.8116 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.8116\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4274 - sparse_categorical_accuracy: 0.8121 - val_loss: 0.4237 - val_sparse_categorical_accuracy: 0.8083\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4275 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.4231 - val_sparse_categorical_accuracy: 0.8099\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4275 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4272 - val_sparse_categorical_accuracy: 0.8058\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4274 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.4227 - val_sparse_categorical_accuracy: 0.8135\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4275 - sparse_categorical_accuracy: 0.8121 - val_loss: 0.4242 - val_sparse_categorical_accuracy: 0.8110\n",
      "getting accuracy of participant  9\n",
      "1676/1676 [==============================] - 5s 3ms/step\n",
      "meannnnnn long 1.5409722222222222\n",
      "TL to the participant :  10\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 23s 10ms/step - loss: 0.4702 - sparse_categorical_accuracy: 0.7868 - val_loss: 0.4467 - val_sparse_categorical_accuracy: 0.8028\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4566 - sparse_categorical_accuracy: 0.7955 - val_loss: 0.4444 - val_sparse_categorical_accuracy: 0.8037\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4554 - sparse_categorical_accuracy: 0.7966 - val_loss: 0.4437 - val_sparse_categorical_accuracy: 0.8031\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4545 - sparse_categorical_accuracy: 0.7970 - val_loss: 0.4653 - val_sparse_categorical_accuracy: 0.7896\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4541 - sparse_categorical_accuracy: 0.7975 - val_loss: 0.4497 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4535 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.4517 - val_sparse_categorical_accuracy: 0.7970\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.4513 - val_sparse_categorical_accuracy: 0.7973\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4529 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4447 - val_sparse_categorical_accuracy: 0.8015\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4526 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.4510 - val_sparse_categorical_accuracy: 0.7980\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4525 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4431 - val_sparse_categorical_accuracy: 0.8017\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4524 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4420 - val_sparse_categorical_accuracy: 0.8045\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4521 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4448 - val_sparse_categorical_accuracy: 0.8021\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4518 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.4415 - val_sparse_categorical_accuracy: 0.8040\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 20s 10ms/step - loss: 0.4517 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.4573 - val_sparse_categorical_accuracy: 0.7923\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4515 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.8028\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4515 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.4434 - val_sparse_categorical_accuracy: 0.8042\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 20s 10ms/step - loss: 0.4513 - sparse_categorical_accuracy: 0.7998 - val_loss: 0.4453 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 20s 10ms/step - loss: 0.4511 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.4483 - val_sparse_categorical_accuracy: 0.7987\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 20s 10ms/step - loss: 0.4512 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.8039\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 20s 10ms/step - loss: 0.4508 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.4465 - val_sparse_categorical_accuracy: 0.8022\n",
      "getting accuracy of participant  10\n",
      "1676/1676 [==============================] - 5s 3ms/step\n",
      "meannnnnn long 1.404421768707483\n",
      "TL to the participant :  11\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4773 - sparse_categorical_accuracy: 0.7813 - val_loss: 0.4598 - val_sparse_categorical_accuracy: 0.7925\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4566 - sparse_categorical_accuracy: 0.7969 - val_loss: 0.4536 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4549 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4588 - val_sparse_categorical_accuracy: 0.7898\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.4539 - val_sparse_categorical_accuracy: 0.7950\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4537 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.7914\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4530 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4521 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4526 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4590 - val_sparse_categorical_accuracy: 0.7914\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4522 - sparse_categorical_accuracy: 0.7983 - val_loss: 0.4516 - val_sparse_categorical_accuracy: 0.7946\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4523 - sparse_categorical_accuracy: 0.7984 - val_loss: 0.4498 - val_sparse_categorical_accuracy: 0.7982\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4519 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.4492 - val_sparse_categorical_accuracy: 0.7991\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4515 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4511 - sparse_categorical_accuracy: 0.7984 - val_loss: 0.4499 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4506 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4502 - val_sparse_categorical_accuracy: 0.7972\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4459 - sparse_categorical_accuracy: 0.8018 - val_loss: 0.4371 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4386 - sparse_categorical_accuracy: 0.8050 - val_loss: 0.4350 - val_sparse_categorical_accuracy: 0.8048\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 22s 11ms/step - loss: 0.4366 - sparse_categorical_accuracy: 0.8058 - val_loss: 0.4322 - val_sparse_categorical_accuracy: 0.8074\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4353 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.4292 - val_sparse_categorical_accuracy: 0.8096\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4344 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.4280 - val_sparse_categorical_accuracy: 0.8091\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4341 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.4334 - val_sparse_categorical_accuracy: 0.8071\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4336 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.4341 - val_sparse_categorical_accuracy: 0.8085\n",
      "getting accuracy of participant  11\n",
      "1676/1676 [==============================] - 7s 4ms/step\n",
      "meannnnnn long 1.438425925925926\n",
      "TL to the participant :  12\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4721 - sparse_categorical_accuracy: 0.7848 - val_loss: 0.4537 - val_sparse_categorical_accuracy: 0.8025\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4521 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4523 - val_sparse_categorical_accuracy: 0.8015\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4510 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4520 - val_sparse_categorical_accuracy: 0.8035\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4503 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.4510 - val_sparse_categorical_accuracy: 0.8032\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 21s 10ms/step - loss: 0.4499 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.4513 - val_sparse_categorical_accuracy: 0.8012\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4496 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.4499 - val_sparse_categorical_accuracy: 0.8022\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4492 - sparse_categorical_accuracy: 0.7998 - val_loss: 0.4503 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 22s 11ms/step - loss: 0.4493 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.4552 - val_sparse_categorical_accuracy: 0.7972\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4489 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.4553 - val_sparse_categorical_accuracy: 0.7979\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4486 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4493 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4484 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.4512 - val_sparse_categorical_accuracy: 0.8008\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4483 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.4589 - val_sparse_categorical_accuracy: 0.7994\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4482 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.4487 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4479 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4519 - val_sparse_categorical_accuracy: 0.7996\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4474 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4488 - val_sparse_categorical_accuracy: 0.8014\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4472 - sparse_categorical_accuracy: 0.8016 - val_loss: 0.4562 - val_sparse_categorical_accuracy: 0.7981\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4467 - sparse_categorical_accuracy: 0.8020 - val_loss: 0.4540 - val_sparse_categorical_accuracy: 0.7985\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4452 - sparse_categorical_accuracy: 0.8034 - val_loss: 0.4491 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 22s 10ms/step - loss: 0.4390 - sparse_categorical_accuracy: 0.8056 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4334 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.4412 - val_sparse_categorical_accuracy: 0.8037\n",
      "getting accuracy of participant  12\n",
      "1676/1676 [==============================] - 5s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4467479674796748\n",
      "TL to the participant :  13\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4836 - sparse_categorical_accuracy: 0.7786 - val_loss: 0.4570 - val_sparse_categorical_accuracy: 0.7959\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4566 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.4533 - val_sparse_categorical_accuracy: 0.7956\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4554 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.4516 - val_sparse_categorical_accuracy: 0.8012\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4550 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.4509 - val_sparse_categorical_accuracy: 0.7998\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4544 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.4548 - val_sparse_categorical_accuracy: 0.7984\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4504 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4534 - val_sparse_categorical_accuracy: 0.7972\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.4503 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.4529 - val_sparse_categorical_accuracy: 0.7996\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4537 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4510 - val_sparse_categorical_accuracy: 0.7980\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4535 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4517 - val_sparse_categorical_accuracy: 0.7984\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4536 - sparse_categorical_accuracy: 0.7985 - val_loss: 0.4508 - val_sparse_categorical_accuracy: 0.7996\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4537 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.4513 - val_sparse_categorical_accuracy: 0.7989\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4534 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4559 - val_sparse_categorical_accuracy: 0.7979\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4534 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.4511 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4520 - val_sparse_categorical_accuracy: 0.7980\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4499 - val_sparse_categorical_accuracy: 0.7997\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4767 - val_sparse_categorical_accuracy: 0.7812\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4530 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.4499 - val_sparse_categorical_accuracy: 0.7980\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 23s 11ms/step - loss: 0.4530 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4514 - val_sparse_categorical_accuracy: 0.7977\n",
      "getting accuracy of participant  13\n",
      "1676/1676 [==============================] - 5s 3ms/step\n",
      "meannnnnn long 1.4187074829931972\n",
      "TL to the participant :  14\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 25s 11ms/step - loss: 0.4614 - sparse_categorical_accuracy: 0.7883 - val_loss: 0.4439 - val_sparse_categorical_accuracy: 0.8003\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4335 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.4349 - val_sparse_categorical_accuracy: 0.8074\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.4376 - val_sparse_categorical_accuracy: 0.8061\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.4306 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.4346 - val_sparse_categorical_accuracy: 0.8076\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4300 - sparse_categorical_accuracy: 0.8098 - val_loss: 0.4345 - val_sparse_categorical_accuracy: 0.8075\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4295 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4357 - val_sparse_categorical_accuracy: 0.8075\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4295 - sparse_categorical_accuracy: 0.8098 - val_loss: 0.4343 - val_sparse_categorical_accuracy: 0.8065\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4292 - sparse_categorical_accuracy: 0.8097 - val_loss: 0.4427 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4291 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.4338 - val_sparse_categorical_accuracy: 0.8070\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4289 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4430 - val_sparse_categorical_accuracy: 0.8057\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4288 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.4340 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4285 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.4327 - val_sparse_categorical_accuracy: 0.8098\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4285 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.4352 - val_sparse_categorical_accuracy: 0.8039\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4284 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.4328 - val_sparse_categorical_accuracy: 0.8090\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4284 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.4319 - val_sparse_categorical_accuracy: 0.8083\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 28s 13ms/step - loss: 0.4282 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.4366 - val_sparse_categorical_accuracy: 0.8091\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4283 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.4336 - val_sparse_categorical_accuracy: 0.8076\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 25s 12ms/step - loss: 0.4281 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.4406 - val_sparse_categorical_accuracy: 0.8017\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 27s 13ms/step - loss: 0.4278 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.4334 - val_sparse_categorical_accuracy: 0.8076\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 24s 11ms/step - loss: 0.4280 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.4382 - val_sparse_categorical_accuracy: 0.8019\n",
      "getting accuracy of participant  14\n",
      "1676/1676 [==============================] - 5s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4539473684210529\n",
      "TL to the participant :  15\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 39s 16ms/step - loss: 0.4619 - sparse_categorical_accuracy: 0.7903 - val_loss: 0.4389 - val_sparse_categorical_accuracy: 0.8085\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4414 - sparse_categorical_accuracy: 0.8041 - val_loss: 0.4469 - val_sparse_categorical_accuracy: 0.7979\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4390 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.4522 - val_sparse_categorical_accuracy: 0.8008\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4378 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.4483 - val_sparse_categorical_accuracy: 0.8035\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4372 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.8101\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4366 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.4384 - val_sparse_categorical_accuracy: 0.8041\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4360 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.4388 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4360 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.4322 - val_sparse_categorical_accuracy: 0.8104\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4355 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.4433 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4353 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4376 - val_sparse_categorical_accuracy: 0.8090\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4353 - sparse_categorical_accuracy: 0.8083 - val_loss: 0.4369 - val_sparse_categorical_accuracy: 0.8095\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4353 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.4333 - val_sparse_categorical_accuracy: 0.8125\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4349 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4498 - val_sparse_categorical_accuracy: 0.7948\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4333 - val_sparse_categorical_accuracy: 0.8090\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4349 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4513 - val_sparse_categorical_accuracy: 0.7934\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4346 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.4432 - val_sparse_categorical_accuracy: 0.8075\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4348 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.4351 - val_sparse_categorical_accuracy: 0.8073\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4346 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.4323 - val_sparse_categorical_accuracy: 0.8118\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4345 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.4362 - val_sparse_categorical_accuracy: 0.8065\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4343 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.4352 - val_sparse_categorical_accuracy: 0.8101\n",
      "getting accuracy of participant  15\n",
      "1676/1676 [==============================] - 6s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4109929078014183\n",
      "TL to the participant :  16\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 33s 15ms/step - loss: 0.4886 - sparse_categorical_accuracy: 0.7713 - val_loss: 0.4694 - val_sparse_categorical_accuracy: 0.7876\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 33s 16ms/step - loss: 0.4644 - sparse_categorical_accuracy: 0.7885 - val_loss: 0.4561 - val_sparse_categorical_accuracy: 0.7936\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 33s 16ms/step - loss: 0.4509 - sparse_categorical_accuracy: 0.7972 - val_loss: 0.4428 - val_sparse_categorical_accuracy: 0.8003\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 33s 16ms/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4375 - val_sparse_categorical_accuracy: 0.8031\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 34s 16ms/step - loss: 0.4402 - sparse_categorical_accuracy: 0.8027 - val_loss: 0.4441 - val_sparse_categorical_accuracy: 0.8042\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 34s 16ms/step - loss: 0.4396 - sparse_categorical_accuracy: 0.8024 - val_loss: 0.4386 - val_sparse_categorical_accuracy: 0.8037\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 33s 16ms/step - loss: 0.4392 - sparse_categorical_accuracy: 0.8031 - val_loss: 0.4362 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 34s 16ms/step - loss: 0.4388 - sparse_categorical_accuracy: 0.8039 - val_loss: 0.4358 - val_sparse_categorical_accuracy: 0.8067\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 34s 16ms/step - loss: 0.4385 - sparse_categorical_accuracy: 0.8046 - val_loss: 0.4361 - val_sparse_categorical_accuracy: 0.8046\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 38s 18ms/step - loss: 0.4384 - sparse_categorical_accuracy: 0.8042 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8050\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 34s 16ms/step - loss: 0.4383 - sparse_categorical_accuracy: 0.8034 - val_loss: 0.4379 - val_sparse_categorical_accuracy: 0.8055\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 35s 16ms/step - loss: 0.4378 - sparse_categorical_accuracy: 0.8046 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8063\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 34s 16ms/step - loss: 0.4378 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8045\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 34s 16ms/step - loss: 0.4376 - sparse_categorical_accuracy: 0.8046 - val_loss: 0.4355 - val_sparse_categorical_accuracy: 0.8071\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 34s 16ms/step - loss: 0.4376 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.4353 - val_sparse_categorical_accuracy: 0.8059\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 33s 16ms/step - loss: 0.4374 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.4494 - val_sparse_categorical_accuracy: 0.8007\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4375 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.4351 - val_sparse_categorical_accuracy: 0.8063\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4373 - sparse_categorical_accuracy: 0.8044 - val_loss: 0.4367 - val_sparse_categorical_accuracy: 0.8074\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4372 - sparse_categorical_accuracy: 0.8051 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8074\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4370 - sparse_categorical_accuracy: 0.8042 - val_loss: 0.4353 - val_sparse_categorical_accuracy: 0.8043\n",
      "getting accuracy of participant  16\n",
      "1676/1676 [==============================] - 6s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3606918238993704\n",
      "TL to the participant :  17\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4906 - sparse_categorical_accuracy: 0.7713 - val_loss: 0.4545 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4462 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.8047\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4363 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.4394 - val_sparse_categorical_accuracy: 0.8023\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4337 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.4320 - val_sparse_categorical_accuracy: 0.8079\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4331 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.4305 - val_sparse_categorical_accuracy: 0.8086\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4323 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.4320 - val_sparse_categorical_accuracy: 0.8084\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4319 - sparse_categorical_accuracy: 0.8085 - val_loss: 0.4397 - val_sparse_categorical_accuracy: 0.8050\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8097 - val_loss: 0.4319 - val_sparse_categorical_accuracy: 0.8102\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4313 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.4308 - val_sparse_categorical_accuracy: 0.8083\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4310 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.4294 - val_sparse_categorical_accuracy: 0.8102\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4309 - sparse_categorical_accuracy: 0.8100 - val_loss: 0.4378 - val_sparse_categorical_accuracy: 0.8013\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4309 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.4345 - val_sparse_categorical_accuracy: 0.8104\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4303 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4319 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4303 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.4295 - val_sparse_categorical_accuracy: 0.8115\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4304 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.4272 - val_sparse_categorical_accuracy: 0.8128\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4303 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.4266 - val_sparse_categorical_accuracy: 0.8129\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4302 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.4272 - val_sparse_categorical_accuracy: 0.8127\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4297 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.4426 - val_sparse_categorical_accuracy: 0.8003\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4300 - sparse_categorical_accuracy: 0.8112 - val_loss: 0.4341 - val_sparse_categorical_accuracy: 0.8098\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4297 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.4286 - val_sparse_categorical_accuracy: 0.8100\n",
      "getting accuracy of participant  17\n",
      "1676/1676 [==============================] - 6s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.5286458333333333\n",
      "TL to the participant :  18\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 31s 14ms/step - loss: 0.4555 - sparse_categorical_accuracy: 0.7945 - val_loss: 0.4426 - val_sparse_categorical_accuracy: 0.7980\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4357 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.4357 - val_sparse_categorical_accuracy: 0.8037\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4338 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.4374 - val_sparse_categorical_accuracy: 0.8025\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4327 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.4311 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.4295 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4303 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.4368 - val_sparse_categorical_accuracy: 0.8012\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4298 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4318 - val_sparse_categorical_accuracy: 0.8035\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4296 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.4289 - val_sparse_categorical_accuracy: 0.8051\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4291 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.4379 - val_sparse_categorical_accuracy: 0.8030\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4292 - sparse_categorical_accuracy: 0.8083 - val_loss: 0.4297 - val_sparse_categorical_accuracy: 0.8059\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4289 - sparse_categorical_accuracy: 0.8083 - val_loss: 0.4314 - val_sparse_categorical_accuracy: 0.8058\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4288 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.4309 - val_sparse_categorical_accuracy: 0.8073\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4287 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4319 - val_sparse_categorical_accuracy: 0.8037\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4286 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4303 - val_sparse_categorical_accuracy: 0.8061\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4283 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.4292 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4284 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4341 - val_sparse_categorical_accuracy: 0.8020\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4283 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4317 - val_sparse_categorical_accuracy: 0.8041\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4282 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.4372 - val_sparse_categorical_accuracy: 0.8043\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4281 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.4282 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4282 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.4280 - val_sparse_categorical_accuracy: 0.8058\n",
      "getting accuracy of participant  18\n",
      "1676/1676 [==============================] - 6s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4379166666666665\n",
      "TL to the participant :  19\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 31s 14ms/step - loss: 0.4643 - sparse_categorical_accuracy: 0.7906 - val_loss: 0.4431 - val_sparse_categorical_accuracy: 0.7974\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4385 - sparse_categorical_accuracy: 0.8041 - val_loss: 0.4266 - val_sparse_categorical_accuracy: 0.8092\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4344 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.4265 - val_sparse_categorical_accuracy: 0.8108\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4334 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.4458 - val_sparse_categorical_accuracy: 0.8014\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4326 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.4216 - val_sparse_categorical_accuracy: 0.8128\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4323 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4342 - val_sparse_categorical_accuracy: 0.8019\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4320 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.4219 - val_sparse_categorical_accuracy: 0.8118\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.4218 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4301 - val_sparse_categorical_accuracy: 0.8061\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4310 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.4202 - val_sparse_categorical_accuracy: 0.8126\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4312 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8089\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4310 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.4203 - val_sparse_categorical_accuracy: 0.8136\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.4310 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.4243 - val_sparse_categorical_accuracy: 0.8087\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.4209 - val_sparse_categorical_accuracy: 0.8121\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4306 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.4224 - val_sparse_categorical_accuracy: 0.8106\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.4202 - val_sparse_categorical_accuracy: 0.8144\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4306 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.4213 - val_sparse_categorical_accuracy: 0.8126\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4303 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.4257 - val_sparse_categorical_accuracy: 0.8118\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4302 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.4202 - val_sparse_categorical_accuracy: 0.8135\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4303 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.4216 - val_sparse_categorical_accuracy: 0.8113\n",
      "getting accuracy of participant  19\n",
      "1676/1676 [==============================] - 6s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4162962962962964\n",
      "TL to the participant :  20\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4716 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.4600 - val_sparse_categorical_accuracy: 0.7927\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4490 - sparse_categorical_accuracy: 0.7983 - val_loss: 0.4624 - val_sparse_categorical_accuracy: 0.7850\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4466 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4463 - val_sparse_categorical_accuracy: 0.8014\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4446 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.4434 - val_sparse_categorical_accuracy: 0.8010\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4428 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.4456 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.4403 - val_sparse_categorical_accuracy: 0.8037\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4413 - sparse_categorical_accuracy: 0.8020 - val_loss: 0.4397 - val_sparse_categorical_accuracy: 0.8034\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4406 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.4403 - val_sparse_categorical_accuracy: 0.8045\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4403 - sparse_categorical_accuracy: 0.8024 - val_loss: 0.4391 - val_sparse_categorical_accuracy: 0.8039\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4400 - sparse_categorical_accuracy: 0.8020 - val_loss: 0.4410 - val_sparse_categorical_accuracy: 0.8048\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4398 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.4403 - val_sparse_categorical_accuracy: 0.8031\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4398 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.4438 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4396 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.4461 - val_sparse_categorical_accuracy: 0.8005\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4393 - sparse_categorical_accuracy: 0.8030 - val_loss: 0.4509 - val_sparse_categorical_accuracy: 0.7906\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4392 - sparse_categorical_accuracy: 0.8030 - val_loss: 0.4458 - val_sparse_categorical_accuracy: 0.7942\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4392 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.4386 - val_sparse_categorical_accuracy: 0.8019\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4392 - sparse_categorical_accuracy: 0.8034 - val_loss: 0.4384 - val_sparse_categorical_accuracy: 0.8045\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4391 - sparse_categorical_accuracy: 0.8032 - val_loss: 0.4491 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4390 - sparse_categorical_accuracy: 0.8031 - val_loss: 0.4408 - val_sparse_categorical_accuracy: 0.7996\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.4390 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.4401 - val_sparse_categorical_accuracy: 0.8008\n",
      "getting accuracy of participant  20\n",
      "1676/1676 [==============================] - 6s 4ms/step\n",
      "meannnnnn long 1.383636363636363\n",
      "TL to the participant :  21\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 31s 14ms/step - loss: 0.4778 - sparse_categorical_accuracy: 0.7801 - val_loss: 0.4571 - val_sparse_categorical_accuracy: 0.7937\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4502 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.4577 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 31s 14ms/step - loss: 0.4385 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.4385 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.4348 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.8006\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4335 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.4347 - val_sparse_categorical_accuracy: 0.8097\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4322 - val_sparse_categorical_accuracy: 0.8088\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4323 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4362 - val_sparse_categorical_accuracy: 0.8080\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4322 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.4401 - val_sparse_categorical_accuracy: 0.8057\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4338 - val_sparse_categorical_accuracy: 0.8071\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4326 - val_sparse_categorical_accuracy: 0.8114\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.4363 - val_sparse_categorical_accuracy: 0.8030\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.8075 - val_loss: 0.4340 - val_sparse_categorical_accuracy: 0.8077\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4313 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4316 - val_sparse_categorical_accuracy: 0.8107\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4463 - val_sparse_categorical_accuracy: 0.7962\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4309 - sparse_categorical_accuracy: 0.8092 - val_loss: 0.4316 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4308 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.4337 - val_sparse_categorical_accuracy: 0.8067\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4306 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8108\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4305 - sparse_categorical_accuracy: 0.8093 - val_loss: 0.4327 - val_sparse_categorical_accuracy: 0.8118\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4306 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.4311 - val_sparse_categorical_accuracy: 0.8106\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4302 - sparse_categorical_accuracy: 0.8099 - val_loss: 0.4318 - val_sparse_categorical_accuracy: 0.8122\n",
      "getting accuracy of participant  21\n",
      "1676/1676 [==============================] - 6s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4352380952380952\n",
      "TL to the participant :  22\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 31s 14ms/step - loss: 0.4543 - sparse_categorical_accuracy: 0.7954 - val_loss: 0.4529 - val_sparse_categorical_accuracy: 0.7958\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4353 - sparse_categorical_accuracy: 0.8072 - val_loss: 0.4364 - val_sparse_categorical_accuracy: 0.8037\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4325 - sparse_categorical_accuracy: 0.8093 - val_loss: 0.4337 - val_sparse_categorical_accuracy: 0.8073\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.8100 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8092\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4303 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4332 - val_sparse_categorical_accuracy: 0.8087\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4299 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.4332 - val_sparse_categorical_accuracy: 0.8063\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4295 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.4333 - val_sparse_categorical_accuracy: 0.8069\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4294 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.4330 - val_sparse_categorical_accuracy: 0.8079\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4290 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4319 - val_sparse_categorical_accuracy: 0.8083\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4288 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.8052\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4290 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.7992\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4288 - sparse_categorical_accuracy: 0.8099 - val_loss: 0.4312 - val_sparse_categorical_accuracy: 0.8101\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4288 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.4337 - val_sparse_categorical_accuracy: 0.8084\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4284 - sparse_categorical_accuracy: 0.8109 - val_loss: 0.4292 - val_sparse_categorical_accuracy: 0.8106\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4286 - sparse_categorical_accuracy: 0.8109 - val_loss: 0.4316 - val_sparse_categorical_accuracy: 0.8075\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4283 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.4312 - val_sparse_categorical_accuracy: 0.8071\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4283 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.4324 - val_sparse_categorical_accuracy: 0.8069\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 31s 14ms/step - loss: 0.4281 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.4284 - val_sparse_categorical_accuracy: 0.8102\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4283 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4298 - val_sparse_categorical_accuracy: 0.8104\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4281 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4324 - val_sparse_categorical_accuracy: 0.8067\n",
      "getting accuracy of participant  22\n",
      "1676/1676 [==============================] - 6s 4ms/step\n",
      "meannnnnn long 1.4166666666666665\n",
      "TL to the participant :  23\n",
      "(1701375, 16, 16)\n",
      "(1701375,)\n",
      "(53625, 16, 16)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1/20\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.4794 - sparse_categorical_accuracy: 0.7797 - val_loss: 0.4647 - val_sparse_categorical_accuracy: 0.7897\n",
      "Epoch 2/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4610 - sparse_categorical_accuracy: 0.7921 - val_loss: 0.4612 - val_sparse_categorical_accuracy: 0.7914\n",
      "Epoch 3/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4590 - sparse_categorical_accuracy: 0.7930 - val_loss: 0.4686 - val_sparse_categorical_accuracy: 0.7860\n",
      "Epoch 4/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4576 - sparse_categorical_accuracy: 0.7946 - val_loss: 0.4643 - val_sparse_categorical_accuracy: 0.7919\n",
      "Epoch 5/20\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.4569 - sparse_categorical_accuracy: 0.7962 - val_loss: 0.4576 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 6/20\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.4566 - sparse_categorical_accuracy: 0.7963 - val_loss: 0.4582 - val_sparse_categorical_accuracy: 0.7956\n",
      "Epoch 7/20\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.4564 - sparse_categorical_accuracy: 0.7957 - val_loss: 0.4622 - val_sparse_categorical_accuracy: 0.7933\n",
      "Epoch 8/20\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.4563 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.4588 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 9/20\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.4560 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.7939\n",
      "Epoch 10/20\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.4558 - sparse_categorical_accuracy: 0.7965 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.7947\n",
      "Epoch 11/20\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.4558 - sparse_categorical_accuracy: 0.7969 - val_loss: 0.4616 - val_sparse_categorical_accuracy: 0.7931\n",
      "Epoch 12/20\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.4557 - sparse_categorical_accuracy: 0.7966 - val_loss: 0.4567 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 13/20\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.4556 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.4637 - val_sparse_categorical_accuracy: 0.7908\n",
      "Epoch 14/20\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.4554 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.4568 - val_sparse_categorical_accuracy: 0.7957\n",
      "Epoch 15/20\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.4554 - sparse_categorical_accuracy: 0.7962 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 16/20\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.4552 - sparse_categorical_accuracy: 0.7964 - val_loss: 0.4597 - val_sparse_categorical_accuracy: 0.7921\n",
      "Epoch 17/20\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.4551 - sparse_categorical_accuracy: 0.7964 - val_loss: 0.4570 - val_sparse_categorical_accuracy: 0.7936\n",
      "Epoch 18/20\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.4551 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.4630 - val_sparse_categorical_accuracy: 0.7916\n",
      "Epoch 19/20\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.4551 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.4568 - val_sparse_categorical_accuracy: 0.7965\n",
      "Epoch 20/20\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.4549 - sparse_categorical_accuracy: 0.7964 - val_loss: 0.4629 - val_sparse_categorical_accuracy: 0.7903\n",
      "getting accuracy of participant  23\n",
      "1676/1676 [==============================] - 7s 4ms/step\n",
      "meannnnnn long 1.3722222222222218\n",
      "[0.88857195 0.71747403 0.78410148 0.83794941 0.82130966 0.84869231\n",
      " 0.8118798  0.87470054 0.73298544 0.70031529 0.80218801 0.7852057\n",
      " 0.75017331 0.78577035 0.69140252 0.84131587 0.90613814 0.73903827\n",
      " 0.762223   0.74762394 0.904764   0.74639221 0.68351008 0.88067708]\n",
      "[503.20483351 489.85496449 465.88841772 470.60084915 478.58809066\n",
      " 487.80942702 491.26875782 496.13854122 499.55355263 469.94071174\n",
      " 419.27478981 434.32132125 461.80690169 466.54241657 497.78440404\n",
      " 699.89249659 666.71875286 588.68586469 606.52254367 602.59827662\n",
      " 590.33201671 604.77840662 605.44120145 626.90757585]\n",
      "[7.35604477 6.43475199 5.74636889 8.04238629 5.6088953  6.02047372\n",
      " 6.13631296 5.83059025 6.35037112 5.8900106  7.19230175 9.89318705\n",
      " 5.96460605 5.66911936 5.76945257 6.96020269 8.12322211 8.68248606\n",
      " 8.47688556 8.36482787 8.20388794 8.59011793 8.79020023 8.55515885]\n",
      "[0.98 0.84 0.96 0.98 0.98 1.   0.95 1.   0.78 0.82 1.   0.91 0.91 0.96\n",
      " 0.91 0.98 0.96 0.87 0.76 0.91 1.   0.89 0.85 1.  ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_cal = 4\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "SPD_accuracy_code_perso = np.zeros(nb_part)\n",
    "SPD_tps_train_code_perso = np.zeros(nb_part)\n",
    "SPD_tps_test_code_perso = np.zeros(nb_part)\n",
    "SPD_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*500)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "    ind2take = [j for j in range(nb_part) if j!=i]\n",
    "\n",
    "    X_train = np.concatenate([X_riem[ind2take].reshape(-1,X_riem.shape[-2],X_riem.shape[-1]),X_riem[i][:nb_samples_windows]]).reshape(-1,X_riem.shape[-2],X_riem.shape[-1])\n",
    "    Y_train = np.concatenate([y[ind2take].reshape(-1),y[i][:nb_samples_windows]]).reshape(-1)\n",
    "    domains_train = np.concatenate([domains[ind2take].reshape(-1),domains[i][:nb_samples_windows]]).reshape(-1)\n",
    "    X_test = X_riem[i][nb_samples_windows:]\n",
    "    Y_test = y[i][nb_samples_windows:]\n",
    "    labels_code_test = labels_code_list[i][n_cal*n_class:]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    # X_std = X_train.std(axis=0)\n",
    "    # X_train /= X_std + 1e-8\n",
    "    # X_std = X_test.std(axis=0)\n",
    "    # X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    X_train,Y_train,domains_train = balance(X_train,Y_train,domains_train)\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = SPDNet_Tensorflow(bimap_dims=[16,8,4])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    history_list.append(clf.fit(np.array(x_train), y_train,\n",
    "                    batch_size=batchsize, epochs=epochs,\n",
    "                    validation_data=(np.array(x_val), y_val), shuffle=True))\n",
    "    SPD_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([1 if (y >= 0.5) else 0 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    SPD_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, fps=500, consecutive=50, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    SPD_tps_test_code_perso[i] = time.time() - start\n",
    "    SPD_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(SPD_accuracy_perso)\n",
    "print(SPD_tps_train_code_perso)\n",
    "print(SPD_tps_test_code_perso)\n",
    "print(SPD_accuracy_code_perso)\n",
    "# pd.DataFrame(SPD_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/score/DA_score.csv\")\n",
    "# pd.DataFrame(SPD_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/score_code/DA_score_code.csv\")\n",
    "# pd.DataFrame(SPD_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/temps_train_code/DA_tps_train_code.csv\")\n",
    "# pd.DataFrame(SPD_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPD/temps_test_code/DA_tps_test_code.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\s.velut\\Documents\\These\\Protheus_PHD\\Scripts\\test_new_dataset.ipynb Cell 68\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y124sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwith 0.3s\u001b[39m\u001b[39m\"\u001b[39m,np\u001b[39m.\u001b[39mmean([\u001b[39m1\u001b[39m,  \u001b[39m0.95\u001b[39m, \u001b[39m0.8\u001b[39m,  \u001b[39m1\u001b[39m,   \u001b[39m0.96\u001b[39m, \u001b[39m0.96\u001b[39m, \u001b[39m0.89\u001b[39m, \u001b[39m0.98\u001b[39m, \u001b[39m0.91\u001b[39m, \u001b[39m0.42\u001b[39m, \u001b[39m0.96\u001b[39m, \u001b[39m0.91\u001b[39m, \u001b[39m0.93\u001b[39m, \u001b[39m1\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y124sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m  \u001b[39m0.82\u001b[39m, \u001b[39m0.91\u001b[39m, \u001b[39m0.98\u001b[39m, \u001b[39m0.85\u001b[39m, \u001b[39m0.8\u001b[39m , \u001b[39m0.91\u001b[39m, \u001b[39m1\u001b[39m,   \u001b[39m0.89\u001b[39m, \u001b[39m0.84\u001b[39m, \u001b[39m1\u001b[39m  ]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y124sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwith timepoint wise\u001b[39m\u001b[39m\"\u001b[39m,np\u001b[39m.\u001b[39mmean([\u001b[39m0.98\u001b[39m,\u001b[39m0.84\u001b[39m,\u001b[39m0.96\u001b[39m,\u001b[39m0.98\u001b[39m,\u001b[39m0.98\u001b[39m,\u001b[39m1.\u001b[39m,  \u001b[39m0.95\u001b[39m,\u001b[39m1.\u001b[39m,  \u001b[39m0.78\u001b[39m ,\u001b[39m0.82\u001b[39m,\u001b[39m1.\u001b[39m,\u001b[39m0.91\u001b[39m,\u001b[39m0.91\u001b[39m,\u001b[39m0.96\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y124sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ,\u001b[39m0.91\u001b[39m,\u001b[39m0.98\u001b[39m,\u001b[39m0.96\u001b[39m,\u001b[39m0.87\u001b[39m,\u001b[39m0.76\u001b[39m,\u001b[39m0.91\u001b[39m,\u001b[39m1.\u001b[39m,  \u001b[39m0.89\u001b[39m,\u001b[39m0.85\u001b[39m,\u001b[39m1.\u001b[39m ]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y124sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m np\u001b[39m.\u001b[39mmean([\u001b[39m1\u001b[39m,\u001b[39m0.96\u001b[39m, \u001b[39m0.95\u001b[39m, \u001b[39m0.98\u001b[39m, \u001b[39m0.98\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0.84\u001b[39m, \u001b[39m0.93\u001b[39m, \u001b[39m0.82\u001b[39m, \u001b[39m0.64\u001b[39m, \u001b[39m0.91\u001b[39m, \u001b[39m0.85\u001b[39m, \u001b[39m0.91\u001b[39m, \u001b[39m0.98\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y124sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m  \u001b[39m0.85\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0.96\u001b[39m, \u001b[39m0.87\u001b[39m, \u001b[39m0.87\u001b[39m, \u001b[39m0.98\u001b[39m, \u001b[39m0.96\u001b[39m, \u001b[39m0.82\u001b[39m, \u001b[39m0.95\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([1,  0.95, 0.8,  1,   0.96, 0.96, 0.89, 0.98, 0.91, 0.42, 0.96, 0.91, 0.93, 1,\n",
    " 0.82, 0.91, 0.98, 0.85, 0.8 , 0.91, 1,   0.89, 0.84, 1  ]))\n",
    "print(\"with timepoint wise 500HZ\",np.mean([0.98,0.84,0.96,0.98,0.98,1.,  0.95,1.,  0.78 ,0.82,1.,0.91,0.91,0.96\n",
    ",0.91,0.98,0.96,0.87,0.76,0.91,1.,  0.89,0.85,1. ]))\n",
    "np.mean([1,0.96, 0.95, 0.98, 0.98, 1, 0.84, 0.93, 0.82, 0.64, 0.91, 0.85, 0.91, 0.98,\n",
    " 0.85, 1, 1, 0.96, 0.87, 0.87, 0.98, 0.96, 0.82, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPDBN SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6670618156592051\n",
      "Epoch 2, Loss: 0.6376577218373617\n",
      "Epoch 3, Loss: 0.6176846325397491\n",
      "Epoch 4, Loss: 0.5814136366049448\n",
      "Epoch 5, Loss: 0.5619668165842692\n",
      "Epoch 6, Loss: 0.5250597645839056\n",
      "Epoch 7, Loss: 0.5162107646465302\n",
      "Epoch 8, Loss: 0.4504903306563695\n",
      "Epoch 9, Loss: 0.4838244865338008\n",
      "Epoch 10, Loss: 0.4249913344780604\n",
      "Epoch 11, Loss: 0.3987770775953929\n",
      "Epoch 12, Loss: 0.4462998112042745\n",
      "Epoch 13, Loss: 0.36260150372982025\n",
      "Epoch 14, Loss: 0.3328579639395078\n",
      "Epoch 15, Loss: 0.3641149302323659\n",
      "Epoch 16, Loss: 0.33864765365918476\n",
      "Epoch 17, Loss: 0.3215875178575516\n",
      "Epoch 18, Loss: 0.3105337123076121\n",
      "Epoch 19, Loss: 0.30432985971371335\n",
      "Epoch 20, Loss: 0.31580693026383716\n",
      "Validation Accuracy: 0.4864864864864865\n",
      "getting accuracy of participant  0\n",
      "Test Accuracy: 0.5421203337104072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  1\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6924769977728525\n",
      "Epoch 2, Loss: 0.6832739611466726\n",
      "Epoch 3, Loss: 0.6779614090919495\n",
      "Epoch 4, Loss: 0.665468821922938\n",
      "Epoch 5, Loss: 0.6554269989331564\n",
      "Epoch 6, Loss: 0.6437441408634186\n",
      "Epoch 7, Loss: 0.6249582668145498\n",
      "Epoch 8, Loss: 0.608268012603124\n",
      "Epoch 9, Loss: 0.5883064866065979\n",
      "Epoch 10, Loss: 0.5593211352825165\n",
      "Epoch 11, Loss: 0.5167825818061829\n",
      "Epoch 12, Loss: 0.5231404105822245\n",
      "Epoch 13, Loss: 0.47932080427805585\n",
      "Epoch 14, Loss: 0.47347629566987354\n",
      "Epoch 15, Loss: 0.44129058718681335\n",
      "Epoch 16, Loss: 0.43466027081012726\n",
      "Epoch 17, Loss: 0.41506027181943256\n",
      "Epoch 18, Loss: 0.37452515214681625\n",
      "Epoch 19, Loss: 0.39177773396174115\n",
      "Epoch 20, Loss: 0.3533770640691121\n",
      "Validation Accuracy: 0.7567567567567568\n",
      "getting accuracy of participant  1\n",
      "Test Accuracy: 0.6083763433257918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  2\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7005536953608195\n",
      "Epoch 2, Loss: 0.7020728985468546\n",
      "Epoch 3, Loss: 0.6691405475139618\n",
      "Epoch 4, Loss: 0.653730571269989\n",
      "Epoch 5, Loss: 0.6470721960067749\n",
      "Epoch 6, Loss: 0.6161286234855652\n",
      "Epoch 7, Loss: 0.6374632815519968\n",
      "Epoch 8, Loss: 0.6339979767799377\n",
      "Epoch 9, Loss: 0.6328570942083994\n",
      "Epoch 10, Loss: 0.595938632885615\n",
      "Epoch 11, Loss: 0.5801632503668467\n",
      "Epoch 12, Loss: 0.5921085377534231\n",
      "Epoch 13, Loss: 0.5850401918093363\n",
      "Epoch 14, Loss: 0.5756156543890635\n",
      "Epoch 15, Loss: 0.569974958896637\n",
      "Epoch 16, Loss: 0.5381475587685903\n",
      "Epoch 17, Loss: 0.5520534366369247\n",
      "Epoch 18, Loss: 0.5388025641441345\n",
      "Epoch 19, Loss: 0.5198117047548294\n",
      "Epoch 20, Loss: 0.5436254243055979\n",
      "Validation Accuracy: 0.8108108108108109\n",
      "getting accuracy of participant  2\n",
      "Test Accuracy: 0.7242912188914028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  3\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7083195547262827\n",
      "Epoch 2, Loss: 0.6789823273817698\n",
      "Epoch 3, Loss: 0.6661817828814188\n",
      "Epoch 4, Loss: 0.6637639800707499\n",
      "Epoch 5, Loss: 0.6265649398167928\n",
      "Epoch 6, Loss: 0.5937163879474004\n",
      "Epoch 7, Loss: 0.5951827565828959\n",
      "Epoch 8, Loss: 0.5576122005780538\n",
      "Epoch 9, Loss: 0.5456113815307617\n",
      "Epoch 10, Loss: 0.5058676153421402\n",
      "Epoch 11, Loss: 0.4971475899219513\n",
      "Epoch 12, Loss: 0.46719544132550556\n",
      "Epoch 13, Loss: 0.47409968574841815\n",
      "Epoch 14, Loss: 0.44872989257176715\n",
      "Epoch 15, Loss: 0.43131497502326965\n",
      "Epoch 16, Loss: 0.4238361914952596\n",
      "Epoch 17, Loss: 0.40606555839379627\n",
      "Epoch 18, Loss: 0.44534865518411\n",
      "Epoch 19, Loss: 0.45664752026398975\n",
      "Epoch 20, Loss: 0.4320615231990814\n",
      "Validation Accuracy: 0.6486486486486487\n",
      "getting accuracy of participant  3\n",
      "Test Accuracy: 0.5314709417420814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  4\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6955934564272562\n",
      "Epoch 2, Loss: 0.6741494437058767\n",
      "Epoch 3, Loss: 0.6794755061467489\n",
      "Epoch 4, Loss: 0.6692448357741038\n",
      "Epoch 5, Loss: 0.6551612913608551\n",
      "Epoch 6, Loss: 0.6381776829560598\n",
      "Epoch 7, Loss: 0.6394980549812317\n",
      "Epoch 8, Loss: 0.6174748440583547\n",
      "Epoch 9, Loss: 0.5973629852135977\n",
      "Epoch 10, Loss: 0.5896676679452261\n",
      "Epoch 11, Loss: 0.5718047022819519\n",
      "Epoch 12, Loss: 0.5434511105219523\n",
      "Epoch 13, Loss: 0.5625748584667841\n",
      "Epoch 14, Loss: 0.4914872447649638\n",
      "Epoch 15, Loss: 0.4779263784488042\n",
      "Epoch 16, Loss: 0.47044507165749866\n",
      "Epoch 17, Loss: 0.4754251142342885\n",
      "Epoch 18, Loss: 0.4472843110561371\n",
      "Epoch 19, Loss: 0.4425313820441564\n",
      "Epoch 20, Loss: 0.42069367070992786\n",
      "Validation Accuracy: 0.7297297297297297\n",
      "getting accuracy of participant  4\n",
      "Test Accuracy: 0.6939603365384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  5\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6832137207190195\n",
      "Epoch 2, Loss: 0.658149003982544\n",
      "Epoch 3, Loss: 0.6294502715269724\n",
      "Epoch 4, Loss: 0.6025544106960297\n",
      "Epoch 5, Loss: 0.5742972294489542\n",
      "Epoch 6, Loss: 0.5378305017948151\n",
      "Epoch 7, Loss: 0.5861069907744726\n",
      "Epoch 8, Loss: 0.5021124482154846\n",
      "Epoch 9, Loss: 0.4700664281845093\n",
      "Epoch 10, Loss: 0.472893292705218\n",
      "Epoch 11, Loss: 0.45726343989372253\n",
      "Epoch 12, Loss: 0.45364731053511304\n",
      "Epoch 13, Loss: 0.41969502965609234\n",
      "Epoch 14, Loss: 0.41283927857875824\n",
      "Epoch 15, Loss: 0.4070187856753667\n",
      "Epoch 16, Loss: 0.3765510718027751\n",
      "Epoch 17, Loss: 0.3473640854159991\n",
      "Epoch 18, Loss: 0.4466110020875931\n",
      "Epoch 19, Loss: 0.366717204451561\n",
      "Epoch 20, Loss: 0.3704381287097931\n",
      "Validation Accuracy: 0.8108108108108109\n",
      "getting accuracy of participant  5\n",
      "Test Accuracy: 0.8695383201357466\n",
      "TL to the participant :  6\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7622817059357961\n",
      "Epoch 2, Loss: 0.731435755888621\n",
      "Epoch 3, Loss: 0.715958426396052\n",
      "Epoch 4, Loss: 0.6981886029243469\n",
      "Epoch 5, Loss: 0.6742645005385081\n",
      "Epoch 6, Loss: 0.6665477255980173\n",
      "Epoch 7, Loss: 0.6549674173196157\n",
      "Epoch 8, Loss: 0.6474782427151998\n",
      "Epoch 9, Loss: 0.6312843362490336\n",
      "Epoch 10, Loss: 0.6243446071942648\n",
      "Epoch 11, Loss: 0.5966850320498148\n",
      "Epoch 12, Loss: 0.586337129275004\n",
      "Epoch 13, Loss: 0.5744989961385727\n",
      "Epoch 14, Loss: 0.5650735100110372\n",
      "Epoch 15, Loss: 0.5371686865886053\n",
      "Epoch 16, Loss: 0.541747068365415\n",
      "Epoch 17, Loss: 0.5293087214231491\n",
      "Epoch 18, Loss: 0.5298783431450526\n",
      "Epoch 19, Loss: 0.5149366557598114\n",
      "Epoch 20, Loss: 0.507542222738266\n",
      "Validation Accuracy: 0.7567567567567568\n",
      "getting accuracy of participant  6\n",
      "Test Accuracy: 0.6473593042986425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  7\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6906291941801707\n",
      "Epoch 2, Loss: 0.6697470247745514\n",
      "Epoch 3, Loss: 0.6565148631731669\n",
      "Epoch 4, Loss: 0.6344858805338541\n",
      "Epoch 5, Loss: 0.6107913057009379\n",
      "Epoch 6, Loss: 0.5730709433555603\n",
      "Epoch 7, Loss: 0.5596966942151388\n",
      "Epoch 8, Loss: 0.5433550775051117\n",
      "Epoch 9, Loss: 0.5246802518765131\n",
      "Epoch 10, Loss: 0.50810573498408\n",
      "Epoch 11, Loss: 0.4892701009909312\n",
      "Epoch 12, Loss: 0.44510026276111603\n",
      "Epoch 13, Loss: 0.4521457999944687\n",
      "Epoch 14, Loss: 0.4401208162307739\n",
      "Epoch 15, Loss: 0.4185736725727717\n",
      "Epoch 16, Loss: 0.4323948423067729\n",
      "Epoch 17, Loss: 0.4004183014233907\n",
      "Epoch 18, Loss: 0.3878909299770991\n",
      "Epoch 19, Loss: 0.3761543581883113\n",
      "Epoch 20, Loss: 0.35942917068799335\n",
      "Validation Accuracy: 0.7027027027027027\n",
      "getting accuracy of participant  7\n",
      "Test Accuracy: 0.6987591911764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  8\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7035298645496368\n",
      "Epoch 2, Loss: 0.6984018385410309\n",
      "Epoch 3, Loss: 0.6741301218668619\n",
      "Epoch 4, Loss: 0.6756872733434042\n",
      "Epoch 5, Loss: 0.6600612004597982\n",
      "Epoch 6, Loss: 0.638954371213913\n",
      "Epoch 7, Loss: 0.6374819775422415\n",
      "Epoch 8, Loss: 0.6252842545509338\n",
      "Epoch 9, Loss: 0.6212852895259857\n",
      "Epoch 10, Loss: 0.624566008647283\n",
      "Epoch 11, Loss: 0.6201783120632172\n",
      "Epoch 12, Loss: 0.6075616578261057\n",
      "Epoch 13, Loss: 0.5846167405446371\n",
      "Epoch 14, Loss: 0.5641432752211889\n",
      "Epoch 15, Loss: 0.5725429952144623\n",
      "Epoch 16, Loss: 0.5471821079651514\n",
      "Epoch 17, Loss: 0.5688771704832712\n",
      "Epoch 18, Loss: 0.5428448716799418\n",
      "Epoch 19, Loss: 0.5580001572767893\n",
      "Epoch 20, Loss: 0.5439261347055435\n",
      "Validation Accuracy: 0.6216216216216216\n",
      "getting accuracy of participant  8\n",
      "Test Accuracy: 0.5567466770361991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  9\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.9369021455446879\n",
      "Epoch 2, Loss: 0.8585436244805654\n",
      "Epoch 3, Loss: 0.7511394818623861\n",
      "Epoch 4, Loss: 0.7582293152809143\n",
      "Epoch 5, Loss: 0.6888893246650696\n",
      "Epoch 6, Loss: 0.6801850696404775\n",
      "Epoch 7, Loss: 0.6661233703295389\n",
      "Epoch 8, Loss: 0.6738506158192953\n",
      "Epoch 9, Loss: 0.6813449859619141\n",
      "Epoch 10, Loss: 0.6569876670837402\n",
      "Epoch 11, Loss: 0.6551224788029989\n",
      "Epoch 12, Loss: 0.641269693771998\n",
      "Epoch 13, Loss: 0.6394532223542532\n",
      "Epoch 14, Loss: 0.6651347279548645\n",
      "Epoch 15, Loss: 0.6266156136989594\n",
      "Epoch 16, Loss: 0.6209832628568014\n",
      "Epoch 17, Loss: 0.6313691039880117\n",
      "Epoch 18, Loss: 0.624133457740148\n",
      "Epoch 19, Loss: 0.6201287309328715\n",
      "Epoch 20, Loss: 0.5889356831709543\n",
      "Validation Accuracy: 0.5945945945945946\n",
      "getting accuracy of participant  9\n",
      "Test Accuracy: 0.6997048218325792\n",
      "TL to the participant :  10\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7318634390830994\n",
      "Epoch 2, Loss: 0.6907330453395844\n",
      "Epoch 3, Loss: 0.6826227009296417\n",
      "Epoch 4, Loss: 0.6557540496190389\n",
      "Epoch 5, Loss: 0.6341264943281809\n",
      "Epoch 6, Loss: 0.6187897125879923\n",
      "Epoch 7, Loss: 0.6009830335776011\n",
      "Epoch 8, Loss: 0.5797057449817657\n",
      "Epoch 9, Loss: 0.5570962031682333\n",
      "Epoch 10, Loss: 0.5448955595493317\n",
      "Epoch 11, Loss: 0.5083942313989004\n",
      "Epoch 12, Loss: 0.4954129805167516\n",
      "Epoch 13, Loss: 0.47993361949920654\n",
      "Epoch 14, Loss: 0.4162977784872055\n",
      "Epoch 15, Loss: 0.43445107340812683\n",
      "Epoch 16, Loss: 0.40568001568317413\n",
      "Epoch 17, Loss: 0.38766369223594666\n",
      "Epoch 18, Loss: 0.38665064175923664\n",
      "Epoch 19, Loss: 0.3672816256682078\n",
      "Epoch 20, Loss: 0.38351787130037945\n",
      "Validation Accuracy: 0.8648648648648649\n",
      "getting accuracy of participant  10\n",
      "Test Accuracy: 0.7771051329185521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  11\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6910024483998617\n",
      "Epoch 2, Loss: 0.685071587562561\n",
      "Epoch 3, Loss: 0.6666538814703623\n",
      "Epoch 4, Loss: 0.6601722439130148\n",
      "Epoch 5, Loss: 0.639779527982076\n",
      "Epoch 6, Loss: 0.6373146871725718\n",
      "Epoch 7, Loss: 0.6135368645191193\n",
      "Epoch 8, Loss: 0.5944481690724691\n",
      "Epoch 9, Loss: 0.5854705572128296\n",
      "Epoch 10, Loss: 0.5832326213518778\n",
      "Epoch 11, Loss: 0.5446737011273702\n",
      "Epoch 12, Loss: 0.5136961042881012\n",
      "Epoch 13, Loss: 0.5148190160592397\n",
      "Epoch 14, Loss: 0.49791580935319263\n",
      "Epoch 15, Loss: 0.5219646195570627\n",
      "Epoch 16, Loss: 0.5216438919305801\n",
      "Epoch 17, Loss: 0.45632506906986237\n",
      "Epoch 18, Loss: 0.4513674775759379\n",
      "Epoch 19, Loss: 0.43503063420454663\n",
      "Epoch 20, Loss: 0.45244858662287396\n",
      "Validation Accuracy: 0.5405405405405406\n",
      "getting accuracy of participant  11\n",
      "Test Accuracy: 0.6489677601809956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  12\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7061250607172648\n",
      "Epoch 2, Loss: 0.7000903785228729\n",
      "Epoch 3, Loss: 0.6889889438947042\n",
      "Epoch 4, Loss: 0.6793537437915802\n",
      "Epoch 5, Loss: 0.6726305584112803\n",
      "Epoch 6, Loss: 0.673654834429423\n",
      "Epoch 7, Loss: 0.6501885652542114\n",
      "Epoch 8, Loss: 0.6461072067419688\n",
      "Epoch 9, Loss: 0.6269330382347107\n",
      "Epoch 10, Loss: 0.5976449350516001\n",
      "Epoch 11, Loss: 0.5836204290390015\n",
      "Epoch 12, Loss: 0.5552013715108236\n",
      "Epoch 13, Loss: 0.5387722154458364\n",
      "Epoch 14, Loss: 0.5058572789033254\n",
      "Epoch 15, Loss: 0.5024753560622534\n",
      "Epoch 16, Loss: 0.45851335922876996\n",
      "Epoch 17, Loss: 0.4478819668292999\n",
      "Epoch 18, Loss: 0.46223820745944977\n",
      "Epoch 19, Loss: 0.46592086056868237\n",
      "Epoch 20, Loss: 0.43952461580435437\n",
      "Validation Accuracy: 0.8378378378378378\n",
      "getting accuracy of participant  12\n",
      "Test Accuracy: 0.7083392251131222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  13\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6995013356208801\n",
      "Epoch 2, Loss: 0.6958648761113485\n",
      "Epoch 3, Loss: 0.6795725623766581\n",
      "Epoch 4, Loss: 0.6746053198973337\n",
      "Epoch 5, Loss: 0.6679936647415161\n",
      "Epoch 6, Loss: 0.6528759102026621\n",
      "Epoch 7, Loss: 0.6374601721763611\n",
      "Epoch 8, Loss: 0.6320512592792511\n",
      "Epoch 9, Loss: 0.62272509932518\n",
      "Epoch 10, Loss: 0.6018790205319723\n",
      "Epoch 11, Loss: 0.5771463314692179\n",
      "Epoch 12, Loss: 0.5739696820576986\n",
      "Epoch 13, Loss: 0.5351810654004415\n",
      "Epoch 14, Loss: 0.5362786004940668\n",
      "Epoch 15, Loss: 0.5159927656253179\n",
      "Epoch 16, Loss: 0.4989687999089559\n",
      "Epoch 17, Loss: 0.5021921743949255\n",
      "Epoch 18, Loss: 0.4731942415237427\n",
      "Epoch 19, Loss: 0.4555463641881943\n",
      "Epoch 20, Loss: 0.43937501311302185\n",
      "Validation Accuracy: 0.7027027027027027\n",
      "getting accuracy of participant  13\n",
      "Test Accuracy: 0.6197680995475113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  14\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6840554674466451\n",
      "Epoch 2, Loss: 0.6778593262036642\n",
      "Epoch 3, Loss: 0.6779357592264811\n",
      "Epoch 4, Loss: 0.672044058640798\n",
      "Epoch 5, Loss: 0.6671927869319916\n",
      "Epoch 6, Loss: 0.6458741128444672\n",
      "Epoch 7, Loss: 0.6654097338517507\n",
      "Epoch 8, Loss: 0.6556591888268789\n",
      "Epoch 9, Loss: 0.6360890567302704\n",
      "Epoch 10, Loss: 0.6546780665715536\n",
      "Epoch 11, Loss: 0.6416564583778381\n",
      "Epoch 12, Loss: 0.6305088599522909\n",
      "Epoch 13, Loss: 0.6489065090815226\n",
      "Epoch 14, Loss: 0.6408224105834961\n",
      "Epoch 15, Loss: 0.6325211127599081\n",
      "Epoch 16, Loss: 0.6195828119913737\n",
      "Epoch 17, Loss: 0.6227377355098724\n",
      "Epoch 18, Loss: 0.6214194397131602\n",
      "Epoch 19, Loss: 0.6311189929644266\n",
      "Epoch 20, Loss: 0.6089025437831879\n",
      "Validation Accuracy: 0.6756756756756757\n",
      "getting accuracy of participant  14\n",
      "Test Accuracy: 0.6569570135746606\n",
      "TL to the participant :  15\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6981943746407827\n",
      "Epoch 2, Loss: 0.6832656959692637\n",
      "Epoch 3, Loss: 0.6573963860670725\n",
      "Epoch 4, Loss: 0.6389163831869761\n",
      "Epoch 5, Loss: 0.6274262567361196\n",
      "Epoch 6, Loss: 0.5953742464383444\n",
      "Epoch 7, Loss: 0.5856567323207855\n",
      "Epoch 8, Loss: 0.560472697019577\n",
      "Epoch 9, Loss: 0.5332976778348287\n",
      "Epoch 10, Loss: 0.5470585525035858\n",
      "Epoch 11, Loss: 0.5171844065189362\n",
      "Epoch 12, Loss: 0.5268007119496664\n",
      "Epoch 13, Loss: 0.4866747260093689\n",
      "Epoch 14, Loss: 0.4995860556761424\n",
      "Epoch 15, Loss: 0.4706444839636485\n",
      "Epoch 16, Loss: 0.4623515208562215\n",
      "Epoch 17, Loss: 0.4334004769722621\n",
      "Epoch 18, Loss: 0.4403564929962158\n",
      "Epoch 19, Loss: 0.4612179696559906\n",
      "Epoch 20, Loss: 0.4755305697520574\n",
      "Validation Accuracy: 0.5675675675675675\n",
      "getting accuracy of participant  15\n",
      "Test Accuracy: 0.5048076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  16\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7232609987258911\n",
      "Epoch 2, Loss: 0.686131884654363\n",
      "Epoch 3, Loss: 0.6765467623869578\n",
      "Epoch 4, Loss: 0.6508347491423289\n",
      "Epoch 5, Loss: 0.6348805030186971\n",
      "Epoch 6, Loss: 0.6034064491589864\n",
      "Epoch 7, Loss: 0.5923974414666494\n",
      "Epoch 8, Loss: 0.5684544642766317\n",
      "Epoch 9, Loss: 0.522274116675059\n",
      "Epoch 10, Loss: 0.4956243981917699\n",
      "Epoch 11, Loss: 0.48874591290950775\n",
      "Epoch 12, Loss: 0.4510641445716222\n",
      "Epoch 13, Loss: 0.41553692022959393\n",
      "Epoch 14, Loss: 0.41683243711789447\n",
      "Epoch 15, Loss: 0.3800375908613205\n",
      "Epoch 16, Loss: 0.3629143536090851\n",
      "Epoch 17, Loss: 0.3681042691071828\n",
      "Epoch 18, Loss: 0.4000687499841054\n",
      "Epoch 19, Loss: 0.4361976186434428\n",
      "Epoch 20, Loss: 0.35182532171408337\n",
      "Validation Accuracy: 0.4864864864864865\n",
      "getting accuracy of participant  16\n",
      "Test Accuracy: 0.5093856052036199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  17\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6903681556383768\n",
      "Epoch 2, Loss: 0.6894292632738749\n",
      "Epoch 3, Loss: 0.6767814854780833\n",
      "Epoch 4, Loss: 0.6730556885401408\n",
      "Epoch 5, Loss: 0.6603324214617411\n",
      "Epoch 6, Loss: 0.6578564643859863\n",
      "Epoch 7, Loss: 0.6467988689740499\n",
      "Epoch 8, Loss: 0.648788700501124\n",
      "Epoch 9, Loss: 0.6224273045857748\n",
      "Epoch 10, Loss: 0.6249340275923411\n",
      "Epoch 11, Loss: 0.5930528342723846\n",
      "Epoch 12, Loss: 0.6026369829972585\n",
      "Epoch 13, Loss: 0.5638894836107889\n",
      "Epoch 14, Loss: 0.5465076466401418\n",
      "Epoch 15, Loss: 0.5702102879683176\n",
      "Epoch 16, Loss: 0.536988173921903\n",
      "Epoch 17, Loss: 0.5503954887390137\n",
      "Epoch 18, Loss: 0.5523404031991959\n",
      "Epoch 19, Loss: 0.49156346420447034\n",
      "Epoch 20, Loss: 0.509197786450386\n",
      "Validation Accuracy: 0.6756756756756757\n",
      "getting accuracy of participant  17\n",
      "Test Accuracy: 0.6114253393665159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  18\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6788915892442068\n",
      "Epoch 2, Loss: 0.6820643643538157\n",
      "Epoch 3, Loss: 0.664718747138977\n",
      "Epoch 4, Loss: 0.6640758017698923\n",
      "Epoch 5, Loss: 0.6490049461523691\n",
      "Epoch 6, Loss: 0.6479611496130625\n",
      "Epoch 7, Loss: 0.6272272368272146\n",
      "Epoch 8, Loss: 0.6160692274570465\n",
      "Epoch 9, Loss: 0.6239260137081146\n",
      "Epoch 10, Loss: 0.5731738060712814\n",
      "Epoch 11, Loss: 0.5824446479479471\n",
      "Epoch 12, Loss: 0.5402426868677139\n",
      "Epoch 13, Loss: 0.5367380082607269\n",
      "Epoch 14, Loss: 0.5487257341543833\n",
      "Epoch 15, Loss: 0.49737786253293353\n",
      "Epoch 16, Loss: 0.47129498422145844\n",
      "Epoch 17, Loss: 0.5318584591150284\n",
      "Epoch 18, Loss: 0.48822082579135895\n",
      "Epoch 19, Loss: 0.45674099524815875\n",
      "Epoch 20, Loss: 0.4845091501871745\n",
      "Validation Accuracy: 0.7567567567567568\n",
      "getting accuracy of participant  18\n",
      "Test Accuracy: 0.7260764281674208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  19\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6840300758679708\n",
      "Epoch 2, Loss: 0.6802285810311636\n",
      "Epoch 3, Loss: 0.6665790677070618\n",
      "Epoch 4, Loss: 0.6676781276861826\n",
      "Epoch 5, Loss: 0.6508406400680542\n",
      "Epoch 6, Loss: 0.64301598072052\n",
      "Epoch 7, Loss: 0.6254502832889557\n",
      "Epoch 8, Loss: 0.5963211158911387\n",
      "Epoch 9, Loss: 0.6014981071154276\n",
      "Epoch 10, Loss: 0.5730611930290858\n",
      "Epoch 11, Loss: 0.5979207754135132\n",
      "Epoch 12, Loss: 0.5657791296641032\n",
      "Epoch 13, Loss: 0.5306707322597504\n",
      "Epoch 14, Loss: 0.5050977766513824\n",
      "Epoch 15, Loss: 0.5209323763847351\n",
      "Epoch 16, Loss: 0.5290790398915609\n",
      "Epoch 17, Loss: 0.48287512362003326\n",
      "Epoch 18, Loss: 0.49955961604913074\n",
      "Epoch 19, Loss: 0.4867456555366516\n",
      "Epoch 20, Loss: 0.4525830149650574\n",
      "Validation Accuracy: 0.7297297297297297\n",
      "getting accuracy of participant  19\n",
      "Test Accuracy: 0.6852552319004526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  20\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7038761178652445\n",
      "Epoch 2, Loss: 0.673528661330541\n",
      "Epoch 3, Loss: 0.6482771734396616\n",
      "Epoch 4, Loss: 0.6258481740951538\n",
      "Epoch 5, Loss: 0.6229932904243469\n",
      "Epoch 6, Loss: 0.5838627815246582\n",
      "Epoch 7, Loss: 0.5754461089769999\n",
      "Epoch 8, Loss: 0.5443930178880692\n",
      "Epoch 9, Loss: 0.5073308944702148\n",
      "Epoch 10, Loss: 0.4953879962364833\n",
      "Epoch 11, Loss: 0.4563413659731547\n",
      "Epoch 12, Loss: 0.4627990225950877\n",
      "Epoch 13, Loss: 0.42207538584868115\n",
      "Epoch 14, Loss: 0.42351652185122174\n",
      "Epoch 15, Loss: 0.4092286080121994\n",
      "Epoch 16, Loss: 0.4277202586332957\n",
      "Epoch 17, Loss: 0.3849247644344966\n",
      "Epoch 18, Loss: 0.4124595870574315\n",
      "Epoch 19, Loss: 0.3792124191919963\n",
      "Epoch 20, Loss: 0.3425395314892133\n",
      "Validation Accuracy: 0.5945945945945946\n",
      "getting accuracy of participant  20\n",
      "Test Accuracy: 0.6299137443438914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  21\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7240143815676371\n",
      "Epoch 2, Loss: 0.7109811007976532\n",
      "Epoch 3, Loss: 0.7104895214239756\n",
      "Epoch 4, Loss: 0.68178990483284\n",
      "Epoch 5, Loss: 0.6763620475927988\n",
      "Epoch 6, Loss: 0.6809642414251963\n",
      "Epoch 7, Loss: 0.660239984591802\n",
      "Epoch 8, Loss: 0.6633412142594656\n",
      "Epoch 9, Loss: 0.6414564152558645\n",
      "Epoch 10, Loss: 0.6318655709425608\n",
      "Epoch 11, Loss: 0.6011861364046732\n",
      "Epoch 12, Loss: 0.5809033016363779\n",
      "Epoch 13, Loss: 0.5655019382635752\n",
      "Epoch 14, Loss: 0.5619863023360571\n",
      "Epoch 15, Loss: 0.5001967698335648\n",
      "Epoch 16, Loss: 0.48243070145448047\n",
      "Epoch 17, Loss: 0.4879960020383199\n",
      "Epoch 18, Loss: 0.4438073883454005\n",
      "Epoch 19, Loss: 0.48135479787985486\n",
      "Epoch 20, Loss: 0.4393821060657501\n",
      "Validation Accuracy: 0.8108108108108109\n",
      "getting accuracy of participant  21\n",
      "Test Accuracy: 0.7586785916289593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  22\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7380663653214773\n",
      "Epoch 2, Loss: 0.7275590896606445\n",
      "Epoch 3, Loss: 0.7220149437586466\n",
      "Epoch 4, Loss: 0.7005257109800974\n",
      "Epoch 5, Loss: 0.7039543489615122\n",
      "Epoch 6, Loss: 0.6819550593694051\n",
      "Epoch 7, Loss: 0.6619764467080435\n",
      "Epoch 8, Loss: 0.6589224139849345\n",
      "Epoch 9, Loss: 0.6802191535631815\n",
      "Epoch 10, Loss: 0.6320760448773702\n",
      "Epoch 11, Loss: 0.6269224584102631\n",
      "Epoch 12, Loss: 0.6037481526533762\n",
      "Epoch 13, Loss: 0.6034643650054932\n",
      "Epoch 14, Loss: 0.5901906788349152\n",
      "Epoch 15, Loss: 0.6035201847553253\n",
      "Epoch 16, Loss: 0.5842929383118948\n",
      "Epoch 17, Loss: 0.576670785744985\n",
      "Epoch 18, Loss: 0.573326845963796\n",
      "Epoch 19, Loss: 0.5562935620546341\n",
      "Epoch 20, Loss: 0.6080338060855865\n",
      "Validation Accuracy: 0.6216216216216216\n",
      "getting accuracy of participant  22\n",
      "Test Accuracy: 0.5454079468325792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  23\n",
      "(3990, 32, 32)\n",
      "(4560, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6831793189048767\n",
      "Epoch 2, Loss: 0.6435909271240234\n",
      "Epoch 3, Loss: 0.6125143865744272\n",
      "Epoch 4, Loss: 0.5654971301555634\n",
      "Epoch 5, Loss: 0.5265133529901505\n",
      "Epoch 6, Loss: 0.49308545390764874\n",
      "Epoch 7, Loss: 0.4422021806240082\n",
      "Epoch 8, Loss: 0.4443596452474594\n",
      "Epoch 9, Loss: 0.4269181787967682\n",
      "Epoch 10, Loss: 0.4194196214278539\n",
      "Epoch 11, Loss: 0.4048919677734375\n",
      "Epoch 12, Loss: 0.3777568240960439\n",
      "Epoch 13, Loss: 0.3820605476697286\n",
      "Epoch 14, Loss: 0.3731785515944163\n",
      "Epoch 15, Loss: 0.41055944561958313\n",
      "Epoch 16, Loss: 0.3706581691900889\n",
      "Epoch 17, Loss: 0.40110041201114655\n",
      "Epoch 18, Loss: 0.3501882354418437\n",
      "Epoch 19, Loss: 0.36358340084552765\n",
      "Epoch 20, Loss: 0.33483507732550305\n",
      "Validation Accuracy: 0.5945945945945946\n",
      "getting accuracy of participant  23\n",
      "Test Accuracy: 0.537657310520362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54212033 0.60837634 0.72429122 0.53147094 0.69396034 0.86953832\n",
      " 0.6473593  0.69875919 0.55674668 0.69970482 0.77710513 0.64896776\n",
      " 0.70833923 0.6197681  0.65695701 0.50480769 0.50938561 0.61142534\n",
      " 0.72607643 0.68525523 0.62991374 0.75867859 0.54540795 0.53765731]\n",
      "[18.44663453 16.28622532 15.78565598 15.71362638 15.67448139 15.76868176\n",
      " 15.55956984 15.57822871 15.52039957 15.45689154 17.08833385 15.49804115\n",
      " 16.24478412 14.94273806 16.7355566  16.01483178 16.20480704 15.73924708\n",
      " 15.38939142 15.31289315 15.20398235 15.21854758 15.21695781 15.16730237]\n",
      "[5.72324562 5.43994999 5.30060172 5.23392653 5.22808695 5.19848204\n",
      " 5.26955986 5.20366883 5.25586033 5.21971464 5.74662328 5.60907698\n",
      " 5.40477943 5.28498769 5.68034101 5.38720512 5.24848819 5.14650464\n",
      " 5.17179084 5.19780469 5.09268212 5.14444709 5.12405944 5.00490522]\n",
      "[0.42 0.8  0.95 0.38 0.9  1.   0.75 0.88 0.6  0.68 0.95 0.8  0.95 0.75\n",
      " 0.68 0.2  0.25 0.65 0.82 0.88 0.88 0.85 0.38 0.45]\n"
     ]
    }
   ],
   "source": [
    "n_cal = 7\n",
    "n_class = 5\n",
    "nb_fold = 1\n",
    "nb_part = 24\n",
    "spdbn_accuracy_code_perso = np.zeros((nb_fold,nb_part))\n",
    "spdbn_tps_train_code_perso = np.zeros((nb_fold,nb_part))\n",
    "spdbn_tps_test_code_perso = np.zeros((nb_fold,nb_part))\n",
    "spdbn_accuracy_perso = np.zeros((nb_fold,nb_part))\n",
    "\n",
    "for k in range(nb_fold):\n",
    "    for i in range(nb_part):\n",
    "        print(\"TL to the participant : \", i)\n",
    "        nb_sample_cal = int(n_class*n_cal*(2.2-window_size)*60)\n",
    "\n",
    "        X_train = X[i][:nb_sample_cal]\n",
    "        Y_train = y[i][:nb_sample_cal]\n",
    "        X_test = X[i][nb_sample_cal:]\n",
    "        Y_test = y[i][nb_sample_cal:]\n",
    "        labels_code_test = labels_code_list[i][(n_class*n_cal):]\n",
    "\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        # X_std = X_train.std(axis=0)\n",
    "        # X_train /= X_std + 1e-8\n",
    "        # X_std = X_test.std(axis=0)\n",
    "        # X_test /= X_std + 1e-8\n",
    "\n",
    "        print(\"balancing the number of ones and zeros\")\n",
    "        X_train, Y_train, domains_train = balance(X_train,Y_train,domains[i][:nb_sample_cal])\n",
    "\n",
    "        print(\"Creating the different pipelines\")\n",
    "        lr = 1e-3\n",
    "        # optimizer = riemannian_adam.RiemannianAdam(learning_rate=lr)\n",
    "        batchsize = 64 #128 # 64 for burst\n",
    "        epoch = 20 #45 # 20 for burst\n",
    "        # clf = SPDNet_AJD(n_epochs=epoch,batch_size=batchsize,valid_split=0.1)\n",
    "        clf = SPDNetBN_Module(bimap_dims=[32,28,14,7])\n",
    "\n",
    "        print(\"Fitting\")\n",
    "        start = time.time()\n",
    "        weight_decay = 1e-4\n",
    "        \n",
    "        x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "        # Convert data into PyTorch tensors\n",
    "        # X_train_tensor = torch.tensor(x_train, dtype=torch.float64)\n",
    "        # y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "        X_val_tensor = torch.tensor(x_val, dtype=torch.float64)\n",
    "        y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "        # X_test_tensor = torch.tensor(X_test, dtype=torch.float64)\n",
    "        # y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "        # Create DataLoader for train, validation, and test sets\n",
    "        # train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        # train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "        # test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        # test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch_riemannian_adam.RiemannianAdam(clf.parameters(), lr=0.001)\n",
    "\n",
    "        clf.fit(x_train,y_train)\n",
    "\n",
    "        # Train the model\n",
    "        # num_epochs = 20\n",
    "        # for epoch in range(num_epochs):\n",
    "        #     running_loss = 0.0\n",
    "        #     for inputs, labels in train_dataloader:\n",
    "        #         # Zero the parameter gradients\n",
    "        #         optimizer.zero_grad()\n",
    "\n",
    "        #         # Forward pass\n",
    "        #         # print(inputs.shape)\n",
    "        #         # print(labels.shape)\n",
    "        #         outputs = clf(inputs)\n",
    "        #         loss = criterion(outputs.float(), labels)\n",
    "\n",
    "        #         # Backward pass and optimize\n",
    "        #         loss.backward()\n",
    "        #         optimizer.step()\n",
    "\n",
    "        #         running_loss += loss.item()\n",
    "\n",
    "        #     print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_dataloader)}\")\n",
    "\n",
    "        # print(\"Training finished!\")\n",
    "        spdbn_tps_train_code_perso[k][i] = time.time() - start\n",
    "\n",
    "        # Validation\n",
    "        clf.eval()\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                outputs = clf(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / len(x_val)\n",
    "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "        # Testing\n",
    "        start = time.time()\n",
    "        # test_correct = 0\n",
    "        # y_pred= []\n",
    "        # with torch.no_grad():\n",
    "        #     for inputs, labels in test_dataloader:\n",
    "        #         outputs = clf(inputs)\n",
    "        #         _, predicted = torch.max(outputs, 1)\n",
    "        #         y_pred.append(predicted)\n",
    "        #         test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        # test_accuracy = test_correct / len(X_test)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        print(\"getting accuracy of participant \", i)\n",
    "        # y_pred = np.concatenate(y_pred)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "        y_test_norm = np.array([1 if (y >= 0.5) else 0 for y in Y_test])\n",
    "        print(f\"Test Accuracy: {balanced_accuracy_score(y_test_norm,y_pred_norm)}\")\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "        spdbn_accuracy_perso[k][i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "        labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "            y_pred_norm, codes, min_len=30, fps=60, consecutive=50, window_size=window_size\n",
    "        )\n",
    "        spdbn_tps_test_code_perso[k][i] = time.time() - start\n",
    "        spdbn_accuracy_code_perso[k][i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "spdbn_accuracy_perso = np.mean(spdbn_accuracy_perso,axis=0)\n",
    "spdbn_tps_train_code_perso = np.mean(spdbn_tps_train_code_perso,axis=0)\n",
    "spdbn_tps_test_code_perso = np.mean(spdbn_tps_test_code_perso,axis=0)\n",
    "spdbn_accuracy_code_perso = np.mean(spdbn_accuracy_code_perso,axis=0)\n",
    "\n",
    "print(spdbn_accuracy_perso)\n",
    "print(spdbn_tps_train_code_perso)\n",
    "print(spdbn_tps_test_code_perso)\n",
    "print(spdbn_accuracy_code_perso)\n",
    "# pd.DataFrame(spdbn_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/score/SS_score.csv\")\n",
    "# pd.DataFrame(spdbn_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/score_code/SS_score_code.csv\")\n",
    "# pd.DataFrame(spdbn_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/temps_train_code/SS_tps_train_code.csv\")\n",
    "# pd.DataFrame(spdbn_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/temps_test_code/SS_tps_test_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.7020833333333334\n",
      "with 0.3s 0.8187500000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([0.42, 0.8,  0.95, 0.38, 0.9,  1,   0.75, 0.88, 0.6,  0.68, 0.95, 0.8,  0.95, 0.75,\n",
    " 0.68, 0.2 , 0.25, 0.65, 0.82, 0.88, 0.88, 0.85, 0.38 ,0.45]))\n",
    "print(\"with 0.25s\",np.mean([0.52, 0.98, 0.9,  0.92, 0.85, 0.9,  0.62, 0.92, 0.75, 0.57, 0.95, 0.82, 0.8,  0.92,\n",
    " 0.57, 0.78, 0.98, 0.92, 0.68, 0.7,  0.98, 0.92, 0.72, 0.98]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPDBN DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5417503410717472\n",
      "Epoch 2, Loss: 0.4748594481498003\n",
      "Epoch 3, Loss: 0.4658820100594312\n",
      "Epoch 4, Loss: 0.4637272903928533\n",
      "Epoch 5, Loss: 0.44802139222156256\n",
      "Epoch 6, Loss: 0.441924013372045\n",
      "Epoch 7, Loss: 0.4406695463694632\n",
      "Epoch 8, Loss: 0.43488525645807385\n",
      "Epoch 9, Loss: 0.43567147210706025\n",
      "Epoch 10, Loss: 0.4336367679061368\n",
      "Epoch 11, Loss: 0.4310180840548128\n",
      "Epoch 12, Loss: 0.4312273330288008\n",
      "Epoch 13, Loss: 0.4313997090794146\n",
      "Epoch 14, Loss: 0.4285330147249624\n",
      "Epoch 15, Loss: 0.42750218213768676\n",
      "Epoch 16, Loss: 0.4282956763636321\n",
      "Epoch 17, Loss: 0.4287677133688703\n",
      "Epoch 18, Loss: 0.4256867481744848\n",
      "Epoch 19, Loss: 0.4253149752621539\n",
      "Epoch 20, Loss: 0.4271982639329508\n",
      "getting accuracy of participant  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.369444444444444\n",
      "TL to the participant :  1\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5853809227701277\n",
      "Epoch 2, Loss: 0.48300125810783356\n",
      "Epoch 3, Loss: 0.457795417169109\n",
      "Epoch 4, Loss: 0.4488656931789592\n",
      "Epoch 5, Loss: 0.4407566257286817\n",
      "Epoch 6, Loss: 0.4360110773704946\n",
      "Epoch 7, Loss: 0.43673547834623605\n",
      "Epoch 8, Loss: 0.43018756178207695\n",
      "Epoch 9, Loss: 0.4318208107724786\n",
      "Epoch 10, Loss: 0.42820839735213667\n",
      "Epoch 11, Loss: 0.4262898521265015\n",
      "Epoch 12, Loss: 0.42668063729070127\n",
      "Epoch 13, Loss: 0.4264328798162751\n",
      "Epoch 14, Loss: 0.42601174395531416\n",
      "Epoch 15, Loss: 0.42599860834889114\n",
      "Epoch 16, Loss: 0.42660940915811807\n",
      "Epoch 17, Loss: 0.42779949493706226\n",
      "Epoch 18, Loss: 0.42532186349853873\n",
      "Epoch 19, Loss: 0.424868002475705\n",
      "Epoch 20, Loss: 0.4228742041741498\n",
      "getting accuracy of participant  1\n",
      "meannnnnn long 1.4011904761904763\n",
      "TL to the participant :  2\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5592726432951167\n",
      "Epoch 2, Loss: 0.4539247308857739\n",
      "Epoch 3, Loss: 0.44630425120703876\n",
      "Epoch 4, Loss: 0.4401238894206472\n",
      "Epoch 5, Loss: 0.4395711467368528\n",
      "Epoch 6, Loss: 0.43314296944299713\n",
      "Epoch 7, Loss: 0.42919607390649617\n",
      "Epoch 8, Loss: 0.43073101295158267\n",
      "Epoch 9, Loss: 0.4279932355857454\n",
      "Epoch 10, Loss: 0.42684784322045743\n",
      "Epoch 11, Loss: 0.4290824830532074\n",
      "Epoch 12, Loss: 0.42792542022652924\n",
      "Epoch 13, Loss: 0.42692111793439835\n",
      "Epoch 14, Loss: 0.42603972798679024\n",
      "Epoch 15, Loss: 0.4236818280769512\n",
      "Epoch 16, Loss: 0.4247076415922493\n",
      "Epoch 17, Loss: 0.42386270267888904\n",
      "Epoch 18, Loss: 0.42511472932528704\n",
      "Epoch 19, Loss: 0.4249219656921923\n",
      "Epoch 20, Loss: 0.42367459851084277\n",
      "getting accuracy of participant  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4373188405797104\n",
      "TL to the participant :  3\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5548694466706365\n",
      "Epoch 2, Loss: 0.4486298034898937\n",
      "Epoch 3, Loss: 0.45020582620054483\n",
      "Epoch 4, Loss: 0.46375483518932015\n",
      "Epoch 5, Loss: 0.43712496431544423\n",
      "Epoch 6, Loss: 0.43578824505675584\n",
      "Epoch 7, Loss: 0.43229020276339725\n",
      "Epoch 8, Loss: 0.4392341764178127\n",
      "Epoch 9, Loss: 0.4353236753959209\n",
      "Epoch 10, Loss: 0.4273193086264655\n",
      "Epoch 11, Loss: 0.4280849650967866\n",
      "Epoch 12, Loss: 0.4268827982014045\n",
      "Epoch 13, Loss: 0.427269849460572\n",
      "Epoch 14, Loss: 0.4226973226759583\n",
      "Epoch 15, Loss: 0.4236743545625359\n",
      "Epoch 16, Loss: 0.42516377789434046\n",
      "Epoch 17, Loss: 0.4224509425694123\n",
      "Epoch 18, Loss: 0.4231025844346732\n",
      "Epoch 19, Loss: 0.4203831149498001\n",
      "Epoch 20, Loss: 0.4230143786408007\n",
      "getting accuracy of participant  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.511111111111111\n",
      "TL to the participant :  4\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5506535760359839\n",
      "Epoch 2, Loss: 0.45217268634587526\n",
      "Epoch 3, Loss: 0.44797301397193223\n",
      "Epoch 4, Loss: 0.45559389668051153\n",
      "Epoch 5, Loss: 0.439218194806017\n",
      "Epoch 6, Loss: 0.4435898237861693\n",
      "Epoch 7, Loss: 0.4359010044718161\n",
      "Epoch 8, Loss: 0.4350385725265369\n",
      "Epoch 9, Loss: 0.4341579846222885\n",
      "Epoch 10, Loss: 0.4329276889911853\n",
      "Epoch 11, Loss: 0.4305667552398518\n",
      "Epoch 12, Loss: 0.4286516837310046\n",
      "Epoch 13, Loss: 0.42920787644106895\n",
      "Epoch 14, Loss: 0.4282155819237232\n",
      "Epoch 15, Loss: 0.42834418173879385\n",
      "Epoch 16, Loss: 0.4279035640647635\n",
      "Epoch 17, Loss: 0.4289881627773866\n",
      "Epoch 18, Loss: 0.4274260870879516\n",
      "Epoch 19, Loss: 0.427365044481121\n",
      "Epoch 20, Loss: 0.42102401971351355\n",
      "getting accuracy of participant  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3842948717948713\n",
      "TL to the participant :  5\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5471743632806465\n",
      "Epoch 2, Loss: 0.5033700226340443\n",
      "Epoch 3, Loss: 0.46949902025517076\n",
      "Epoch 4, Loss: 0.4574008114868775\n",
      "Epoch 5, Loss: 0.4477941357763484\n",
      "Epoch 6, Loss: 0.44683003576938063\n",
      "Epoch 7, Loss: 0.4450725897331722\n",
      "Epoch 8, Loss: 0.4418365085730329\n",
      "Epoch 9, Loss: 0.43797272379742935\n",
      "Epoch 10, Loss: 0.4384133828571066\n",
      "Epoch 11, Loss: 0.4400511917192489\n",
      "Epoch 12, Loss: 0.4375048856018111\n",
      "Epoch 13, Loss: 0.439276049262844\n",
      "Epoch 14, Loss: 0.4359747702255845\n",
      "Epoch 15, Loss: 0.43468281882815063\n",
      "Epoch 16, Loss: 0.4343314728466794\n",
      "Epoch 17, Loss: 0.43533653469057754\n",
      "Epoch 18, Loss: 0.4326124244835228\n",
      "Epoch 19, Loss: 0.4336361592868343\n",
      "Epoch 20, Loss: 0.43493006273638457\n",
      "getting accuracy of participant  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3811594202898554\n",
      "TL to the participant :  6\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5386233631288633\n",
      "Epoch 2, Loss: 0.452654363703914\n",
      "Epoch 3, Loss: 0.44374098849948496\n",
      "Epoch 4, Loss: 0.4367483634268865\n",
      "Epoch 5, Loss: 0.4336859527975321\n",
      "Epoch 6, Loss: 0.4298083421308547\n",
      "Epoch 7, Loss: 0.4305466544465162\n",
      "Epoch 8, Loss: 0.430143793229945\n",
      "Epoch 9, Loss: 0.4323788857436739\n",
      "Epoch 10, Loss: 0.4302753370720893\n",
      "Epoch 11, Loss: 0.42490209941752255\n",
      "Epoch 12, Loss: 0.42367353511508554\n",
      "Epoch 13, Loss: 0.42746441770577803\n",
      "Epoch 14, Loss: 0.42872152756899595\n",
      "Epoch 15, Loss: 0.42261282133404166\n",
      "Epoch 16, Loss: 0.4217624362790957\n",
      "Epoch 17, Loss: 0.4250424026977271\n",
      "Epoch 18, Loss: 0.4255693268496543\n",
      "Epoch 19, Loss: 0.426490111858584\n",
      "Epoch 20, Loss: 0.4258217647438869\n",
      "getting accuracy of participant  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4195238095238096\n",
      "TL to the participant :  7\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5479313804535195\n",
      "Epoch 2, Loss: 0.4662253052229062\n",
      "Epoch 3, Loss: 0.4525638004997745\n",
      "Epoch 4, Loss: 0.4475136604742147\n",
      "Epoch 5, Loss: 0.44252017699182034\n",
      "Epoch 6, Loss: 0.4377564397873357\n",
      "Epoch 7, Loss: 0.4375061356695369\n",
      "Epoch 8, Loss: 0.4381102002225816\n",
      "Epoch 9, Loss: 0.4331045459257439\n",
      "Epoch 10, Loss: 0.4348292243666947\n",
      "Epoch 11, Loss: 0.4333478950429708\n",
      "Epoch 12, Loss: 0.4364089590962976\n",
      "Epoch 13, Loss: 0.43670968181686476\n",
      "Epoch 14, Loss: 0.43855692248325795\n",
      "Epoch 15, Loss: 0.4338247312698513\n",
      "Epoch 16, Loss: 0.43272681429516524\n",
      "Epoch 17, Loss: 0.43213303957600147\n",
      "Epoch 18, Loss: 0.430648724315688\n",
      "Epoch 19, Loss: 0.4345805384218693\n",
      "Epoch 20, Loss: 0.4313080149004236\n",
      "getting accuracy of participant  7\n",
      "meannnnnn long 1.513768115942029\n",
      "TL to the participant :  8\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5516650177305564\n",
      "Epoch 2, Loss: 0.4773688125424087\n",
      "Epoch 3, Loss: 0.4632065906189382\n",
      "Epoch 4, Loss: 0.45244471705518663\n",
      "Epoch 5, Loss: 0.44957702548708767\n",
      "Epoch 6, Loss: 0.44366393907694146\n",
      "Epoch 7, Loss: 0.4343888332368806\n",
      "Epoch 8, Loss: 0.4339810680830851\n",
      "Epoch 9, Loss: 0.43384517217054963\n",
      "Epoch 10, Loss: 0.43177015508990735\n",
      "Epoch 11, Loss: 0.4290123569080606\n",
      "Epoch 12, Loss: 0.4284594792407006\n",
      "Epoch 13, Loss: 0.4255725950351916\n",
      "Epoch 14, Loss: 0.4257726513897069\n",
      "Epoch 15, Loss: 0.4262651598546654\n",
      "Epoch 16, Loss: 0.42471704236231744\n",
      "Epoch 17, Loss: 0.42528583155944943\n",
      "Epoch 18, Loss: 0.4220813362044282\n",
      "Epoch 19, Loss: 0.42182078142650425\n",
      "Epoch 20, Loss: 0.4235645905137062\n",
      "getting accuracy of participant  8\n",
      "meannnnnn long 1.5355072463768118\n",
      "TL to the participant :  9\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5600537299178541\n",
      "Epoch 2, Loss: 0.4725326565094292\n",
      "Epoch 3, Loss: 0.44099163077771664\n",
      "Epoch 4, Loss: 0.42859099071938545\n",
      "Epoch 5, Loss: 0.4378098916495219\n",
      "Epoch 6, Loss: 0.46346133202314377\n",
      "Epoch 7, Loss: 0.43005949014332145\n",
      "Epoch 8, Loss: 0.42398705054074526\n",
      "Epoch 9, Loss: 0.42237125273095444\n",
      "Epoch 10, Loss: 0.42399487196234986\n",
      "Epoch 11, Loss: 0.42280898487661034\n",
      "Epoch 12, Loss: 0.4202330634579994\n",
      "Epoch 13, Loss: 0.4210333125665784\n",
      "Epoch 14, Loss: 0.42204668786143884\n",
      "Epoch 15, Loss: 0.41916590998880565\n",
      "Epoch 16, Loss: 0.4153091773041524\n",
      "Epoch 17, Loss: 0.4147928740712814\n",
      "Epoch 18, Loss: 0.4160335239721462\n",
      "Epoch 19, Loss: 0.4134675180539489\n",
      "Epoch 20, Loss: 0.41271492786472663\n",
      "getting accuracy of participant  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3489999999999998\n",
      "TL to the participant :  10\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5732751267496496\n",
      "Epoch 2, Loss: 0.46601049054879695\n",
      "Epoch 3, Loss: 0.4481460121460259\n",
      "Epoch 4, Loss: 0.4439320921082981\n",
      "Epoch 5, Loss: 0.4392757089808583\n",
      "Epoch 6, Loss: 0.4367112765321508\n",
      "Epoch 7, Loss: 0.4342101290822029\n",
      "Epoch 8, Loss: 0.43369613389950246\n",
      "Epoch 9, Loss: 0.4313875650987029\n",
      "Epoch 10, Loss: 0.42682038742350414\n",
      "Epoch 11, Loss: 0.4294629291398451\n",
      "Epoch 12, Loss: 0.4295298340730369\n",
      "Epoch 13, Loss: 0.42760051146615297\n",
      "Epoch 14, Loss: 0.42839451343752444\n",
      "Epoch 15, Loss: 0.4315597561071627\n",
      "Epoch 16, Loss: 0.4339356005657464\n",
      "Epoch 17, Loss: 0.42870374163612723\n",
      "Epoch 18, Loss: 0.43097700126236305\n",
      "Epoch 19, Loss: 0.42828515911241993\n",
      "Epoch 20, Loss: 0.4246127544902265\n",
      "getting accuracy of participant  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3666666666666663\n",
      "TL to the participant :  11\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5593288347590715\n",
      "Epoch 2, Loss: 0.4661991558969021\n",
      "Epoch 3, Loss: 0.4701118088560179\n",
      "Epoch 4, Loss: 0.4477757904678583\n",
      "Epoch 5, Loss: 0.445842016779352\n",
      "Epoch 6, Loss: 0.446488315355964\n",
      "Epoch 7, Loss: 0.4361438964260742\n",
      "Epoch 8, Loss: 0.43429780565202236\n",
      "Epoch 9, Loss: 0.43522039090748876\n",
      "Epoch 10, Loss: 0.43214414408430457\n",
      "Epoch 11, Loss: 0.4321809966932051\n",
      "Epoch 12, Loss: 0.4285592274973169\n",
      "Epoch 13, Loss: 0.4303376270690933\n",
      "Epoch 14, Loss: 0.42764441104372963\n",
      "Epoch 15, Loss: 0.4271926860092208\n",
      "Epoch 16, Loss: 0.42627085192361847\n",
      "Epoch 17, Loss: 0.42520250694360584\n",
      "Epoch 18, Loss: 0.4254564385628328\n",
      "Epoch 19, Loss: 0.4258122391765937\n",
      "Epoch 20, Loss: 0.4258274529129267\n",
      "getting accuracy of participant  11\n",
      "meannnnnn long 1.4720238095238098\n",
      "TL to the participant :  12\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5404546019854024\n",
      "Epoch 2, Loss: 0.4527283386560157\n",
      "Epoch 3, Loss: 0.440163490944542\n",
      "Epoch 4, Loss: 0.4385340658482164\n",
      "Epoch 5, Loss: 0.4324166780570522\n",
      "Epoch 6, Loss: 0.4270705154631287\n",
      "Epoch 7, Loss: 0.4295519512379542\n",
      "Epoch 8, Loss: 0.42617762624286115\n",
      "Epoch 9, Loss: 0.42632683808915317\n",
      "Epoch 10, Loss: 0.4268178978236392\n",
      "Epoch 11, Loss: 0.42605536966584623\n",
      "Epoch 12, Loss: 0.42176710994681343\n",
      "Epoch 13, Loss: 0.42417592310812324\n",
      "Epoch 14, Loss: 0.4203053076053038\n",
      "Epoch 15, Loss: 0.42142820090521127\n",
      "Epoch 16, Loss: 0.4222441896563396\n",
      "Epoch 17, Loss: 0.4234333634376526\n",
      "Epoch 18, Loss: 0.4231490383390337\n",
      "Epoch 19, Loss: 0.4224290704005398\n",
      "Epoch 20, Loss: 0.4185056956484914\n",
      "getting accuracy of participant  12\n",
      "meannnnnn long 1.4021367521367525\n",
      "TL to the participant :  13\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.555493653868325\n",
      "Epoch 2, Loss: 0.4472356667974964\n",
      "Epoch 3, Loss: 0.44356676808092743\n",
      "Epoch 4, Loss: 0.4468927439302206\n",
      "Epoch 5, Loss: 0.4400570146390237\n",
      "Epoch 6, Loss: 0.4370717710698955\n",
      "Epoch 7, Loss: 0.4372390985954553\n",
      "Epoch 8, Loss: 0.4443914412986487\n",
      "Epoch 9, Loss: 0.440214492729865\n",
      "Epoch 10, Loss: 0.4315511293243617\n",
      "Epoch 11, Loss: 0.44017295562662184\n",
      "Epoch 12, Loss: 0.43135469290427864\n",
      "Epoch 13, Loss: 0.4340494155767374\n",
      "Epoch 14, Loss: 0.43201154185226187\n",
      "Epoch 15, Loss: 0.4308515225420706\n",
      "Epoch 16, Loss: 0.42810601368546486\n",
      "Epoch 17, Loss: 0.42806882300646976\n",
      "Epoch 18, Loss: 0.4271355816745199\n",
      "Epoch 19, Loss: 0.4266375374281779\n",
      "Epoch 20, Loss: 0.43037493457086384\n",
      "getting accuracy of participant  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4071428571428573\n",
      "TL to the participant :  14\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5152182644233108\n",
      "Epoch 2, Loss: 0.43849979480728507\n",
      "Epoch 3, Loss: 0.4320471688406542\n",
      "Epoch 4, Loss: 0.4265840296866372\n",
      "Epoch 5, Loss: 0.42492697830311954\n",
      "Epoch 6, Loss: 0.4260361687047407\n",
      "Epoch 7, Loss: 0.4235171122709289\n",
      "Epoch 8, Loss: 0.4213251938344911\n",
      "Epoch 9, Loss: 0.4256276785163209\n",
      "Epoch 10, Loss: 0.42205873952480033\n",
      "Epoch 11, Loss: 0.41762985714012757\n",
      "Epoch 12, Loss: 0.41723068797728047\n",
      "Epoch 13, Loss: 0.41721214313292876\n",
      "Epoch 14, Loss: 0.4180221479618922\n",
      "Epoch 15, Loss: 0.41713638976216316\n",
      "Epoch 16, Loss: 0.4162269306834787\n",
      "Epoch 17, Loss: 0.4171494109905325\n",
      "Epoch 18, Loss: 0.41742779000196606\n",
      "Epoch 19, Loss: 0.4147562818834558\n",
      "Epoch 20, Loss: 0.41859913885127753\n",
      "getting accuracy of participant  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.375\n",
      "TL to the participant :  15\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6408979900879785\n",
      "Epoch 2, Loss: 0.5215311580104753\n",
      "Epoch 3, Loss: 0.4685168274445459\n",
      "Epoch 4, Loss: 0.4532143644755706\n",
      "Epoch 5, Loss: 0.4479915655683726\n",
      "Epoch 6, Loss: 0.4431676621316001\n",
      "Epoch 7, Loss: 0.4315933099715039\n",
      "Epoch 8, Loss: 0.43484801915474236\n",
      "Epoch 9, Loss: 0.4310206387890503\n",
      "Epoch 10, Loss: 0.43114825896918774\n",
      "Epoch 11, Loss: 0.43038179527502507\n",
      "Epoch 12, Loss: 0.427028683538083\n",
      "Epoch 13, Loss: 0.42546541785122827\n",
      "Epoch 14, Loss: 0.4255641109775752\n",
      "Epoch 15, Loss: 0.42494771513156593\n",
      "Epoch 16, Loss: 0.42455146089196205\n",
      "Epoch 17, Loss: 0.422624436148908\n",
      "Epoch 18, Loss: 0.42329924675868824\n",
      "Epoch 19, Loss: 0.41946576396003366\n",
      "Epoch 20, Loss: 0.417637184727937\n",
      "getting accuracy of participant  15\n",
      "meannnnnn long 1.4058139534883722\n",
      "TL to the participant :  16\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5384669190971181\n",
      "Epoch 2, Loss: 0.46846302645280957\n",
      "Epoch 3, Loss: 0.45395288534928113\n",
      "Epoch 4, Loss: 0.4534414713270962\n",
      "Epoch 5, Loss: 0.44432156486436725\n",
      "Epoch 6, Loss: 0.44414005358703434\n",
      "Epoch 7, Loss: 0.4438022398389876\n",
      "Epoch 8, Loss: 0.43902533466462046\n",
      "Epoch 9, Loss: 0.44114187243394554\n",
      "Epoch 10, Loss: 0.43385735974879935\n",
      "Epoch 11, Loss: 0.43650313385296613\n",
      "Epoch 12, Loss: 0.43385144835337996\n",
      "Epoch 13, Loss: 0.4308369436766952\n",
      "Epoch 14, Loss: 0.4312009899877012\n",
      "Epoch 15, Loss: 0.43449205718934536\n",
      "Epoch 16, Loss: 0.4308549826964736\n",
      "Epoch 17, Loss: 0.42984379013068974\n",
      "Epoch 18, Loss: 0.4290311108343303\n",
      "Epoch 19, Loss: 0.42283557495102286\n",
      "Epoch 20, Loss: 0.42668567987857386\n",
      "getting accuracy of participant  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.374528301886792\n",
      "TL to the participant :  17\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5480063528520986\n",
      "Epoch 2, Loss: 0.45811263390351087\n",
      "Epoch 3, Loss: 0.4444908973528072\n",
      "Epoch 4, Loss: 0.43685591919347644\n",
      "Epoch 5, Loss: 0.4316371759050526\n",
      "Epoch 6, Loss: 0.4348890952533111\n",
      "Epoch 7, Loss: 0.4274770531337708\n",
      "Epoch 8, Loss: 0.42884954944020137\n",
      "Epoch 9, Loss: 0.42409626743756235\n",
      "Epoch 10, Loss: 0.4238012525020167\n",
      "Epoch 11, Loss: 0.42244048544671386\n",
      "Epoch 12, Loss: 0.4226845216471702\n",
      "Epoch 13, Loss: 0.42274432233534753\n",
      "Epoch 14, Loss: 0.4187197870342061\n",
      "Epoch 15, Loss: 0.41981027025030926\n",
      "Epoch 16, Loss: 0.4199177668779157\n",
      "Epoch 17, Loss: 0.4193000770173967\n",
      "Epoch 18, Loss: 0.4191351239569485\n",
      "Epoch 19, Loss: 0.4197153751156293\n",
      "Epoch 20, Loss: 0.4170976273599081\n",
      "getting accuracy of participant  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.482051282051282\n",
      "TL to the participant :  18\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5387218430405483\n",
      "Epoch 2, Loss: 0.4604673850117251\n",
      "Epoch 3, Loss: 0.44539691717363894\n",
      "Epoch 4, Loss: 0.43916647078003734\n",
      "Epoch 5, Loss: 0.4377835486084223\n",
      "Epoch 6, Loss: 0.4327310196822509\n",
      "Epoch 7, Loss: 0.4313344272086397\n",
      "Epoch 8, Loss: 0.42632649012375623\n",
      "Epoch 9, Loss: 0.42605827358784154\n",
      "Epoch 10, Loss: 0.42484413541387767\n",
      "Epoch 11, Loss: 0.42326818278525025\n",
      "Epoch 12, Loss: 0.4241925544338301\n",
      "Epoch 13, Loss: 0.4242133123916574\n",
      "Epoch 14, Loss: 0.4243308719014749\n",
      "Epoch 15, Loss: 0.42206148616969585\n",
      "Epoch 16, Loss: 0.42231952340807766\n",
      "Epoch 17, Loss: 0.4203380615799688\n",
      "Epoch 18, Loss: 0.4207443587947637\n",
      "Epoch 19, Loss: 0.4192692124051973\n",
      "Epoch 20, Loss: 0.4200011528446339\n",
      "getting accuracy of participant  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.415384615384616\n",
      "TL to the participant :  19\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5595458631869406\n",
      "Epoch 2, Loss: 0.46397612034343183\n",
      "Epoch 3, Loss: 0.44159025233238935\n",
      "Epoch 4, Loss: 0.4381533821579069\n",
      "Epoch 5, Loss: 0.4374209581874311\n",
      "Epoch 6, Loss: 0.43294434883864596\n",
      "Epoch 7, Loss: 0.42911023390479386\n",
      "Epoch 8, Loss: 0.4285308613907546\n",
      "Epoch 9, Loss: 0.4271810078062117\n",
      "Epoch 10, Loss: 0.42554426891729236\n",
      "Epoch 11, Loss: 0.4257149009499699\n",
      "Epoch 12, Loss: 0.42741207440849394\n",
      "Epoch 13, Loss: 0.4261439744150266\n",
      "Epoch 14, Loss: 0.4256086219102144\n",
      "Epoch 15, Loss: 0.42331931029912084\n",
      "Epoch 16, Loss: 0.4229627216118388\n",
      "Epoch 17, Loss: 0.4270629306556657\n",
      "Epoch 18, Loss: 0.41988341469550505\n",
      "Epoch 19, Loss: 0.4232466132962145\n",
      "Epoch 20, Loss: 0.4239582996815443\n",
      "getting accuracy of participant  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3922764227642277\n",
      "TL to the participant :  20\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5473017134936526\n",
      "Epoch 2, Loss: 0.4629300682572648\n",
      "Epoch 3, Loss: 0.4567105791065842\n",
      "Epoch 4, Loss: 0.4528674747562036\n",
      "Epoch 5, Loss: 0.4478533180663362\n",
      "Epoch 6, Loss: 0.4456899323267862\n",
      "Epoch 7, Loss: 0.44079405907541513\n",
      "Epoch 8, Loss: 0.4363456925493665\n",
      "Epoch 9, Loss: 0.4392072050832212\n",
      "Epoch 10, Loss: 0.4354856200516224\n",
      "Epoch 11, Loss: 0.43449071829672903\n",
      "Epoch 12, Loss: 0.44120132620446384\n",
      "Epoch 13, Loss: 0.4342706841416657\n",
      "Epoch 14, Loss: 0.43505042261676863\n",
      "Epoch 15, Loss: 0.4321113673504442\n",
      "Epoch 16, Loss: 0.43041296885348856\n",
      "Epoch 17, Loss: 0.43086026603123173\n",
      "Epoch 18, Loss: 0.4359815197531134\n",
      "Epoch 19, Loss: 0.4302868451923132\n",
      "Epoch 20, Loss: 0.42817777761956677\n",
      "getting accuracy of participant  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3817901234567895\n",
      "TL to the participant :  21\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5423472343245521\n",
      "Epoch 2, Loss: 0.4578027534298599\n",
      "Epoch 3, Loss: 0.4457512431545183\n",
      "Epoch 4, Loss: 0.4395236726850271\n",
      "Epoch 5, Loss: 0.43695563985966146\n",
      "Epoch 6, Loss: 0.43160005018580705\n",
      "Epoch 7, Loss: 0.43112553108949214\n",
      "Epoch 8, Loss: 0.43104058504104614\n",
      "Epoch 9, Loss: 0.42957032535923645\n",
      "Epoch 10, Loss: 0.426525937858969\n",
      "Epoch 11, Loss: 0.4301814802456647\n",
      "Epoch 12, Loss: 0.4263255539117381\n",
      "Epoch 13, Loss: 0.4248453834443353\n",
      "Epoch 14, Loss: 0.42319280782248825\n",
      "Epoch 15, Loss: 0.42223922337871045\n",
      "Epoch 16, Loss: 0.4225134286098182\n",
      "Epoch 17, Loss: 0.42440417752368376\n",
      "Epoch 18, Loss: 0.42396262526744977\n",
      "Epoch 19, Loss: 0.42329002264887094\n",
      "Epoch 20, Loss: 0.4244750360958278\n",
      "getting accuracy of participant  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4059829059829063\n",
      "TL to the participant :  22\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5455517984228209\n",
      "Epoch 2, Loss: 0.46839966834522784\n",
      "Epoch 3, Loss: 0.43579488882096484\n",
      "Epoch 4, Loss: 0.4260140161495656\n",
      "Epoch 5, Loss: 0.42807291098870337\n",
      "Epoch 6, Loss: 0.4235118117649108\n",
      "Epoch 7, Loss: 0.424943171441555\n",
      "Epoch 8, Loss: 0.42385562614072114\n",
      "Epoch 9, Loss: 0.4201002477784641\n",
      "Epoch 10, Loss: 0.41764768259599805\n",
      "Epoch 11, Loss: 0.42008716822601855\n",
      "Epoch 12, Loss: 0.41822978877462447\n",
      "Epoch 13, Loss: 0.4161361383739859\n",
      "Epoch 14, Loss: 0.42046002845745534\n",
      "Epoch 15, Loss: 0.4178725676611066\n",
      "Epoch 16, Loss: 0.41497914906358346\n",
      "Epoch 17, Loss: 0.41528532176744193\n",
      "Epoch 18, Loss: 0.41715532913804054\n",
      "Epoch 19, Loss: 0.416489124414511\n",
      "Epoch 20, Loss: 0.41262819652911276\n",
      "getting accuracy of participant  22\n",
      "meannnnnn long 1.4409523809523812\n",
      "TL to the participant :  23\n",
      "(198930, 32, 32)\n",
      "(198930,)\n",
      "(6270, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5756674520671368\n",
      "Epoch 2, Loss: 0.46553696994669735\n",
      "Epoch 3, Loss: 0.4484754882287234\n",
      "Epoch 4, Loss: 0.4449790985090658\n",
      "Epoch 5, Loss: 0.44033690728247166\n",
      "Epoch 6, Loss: 0.43638161156559363\n",
      "Epoch 7, Loss: 0.4362100606667809\n",
      "Epoch 8, Loss: 0.4331459729000926\n",
      "Epoch 9, Loss: 0.4327110801823437\n",
      "Epoch 10, Loss: 0.43221518339123577\n",
      "Epoch 11, Loss: 0.431284197838977\n",
      "Epoch 12, Loss: 0.42888372915331274\n",
      "Epoch 13, Loss: 0.42725287179928273\n",
      "Epoch 14, Loss: 0.423860099632293\n",
      "Epoch 15, Loss: 0.428646226588171\n",
      "Epoch 16, Loss: 0.4245449588051997\n",
      "Epoch 17, Loss: 0.42798200546531007\n",
      "Epoch 18, Loss: 0.42525597335770726\n",
      "Epoch 19, Loss: 0.42834709788439795\n",
      "Epoch 20, Loss: 0.42674244119552895\n",
      "getting accuracy of participant  23\n",
      "meannnnnn long 1.4310810810810815\n",
      "[0.90470742 0.83178219 0.74586076 0.64432075 0.86366207 0.86260798\n",
      " 0.80201049 0.75411996 0.70207091 0.50423565 0.83556792 0.74118804\n",
      " 0.76257199 0.82011004 0.56708273 0.83871735 0.86551316 0.74667704\n",
      " 0.76962284 0.73281957 0.89863354 0.72697064 0.70971308 0.8302139 ]\n",
      "[782.87210035 773.9491291  732.26471353 725.09330201 727.29120255\n",
      " 724.31906319 724.73854184 728.53325582 723.18428159 726.59121799\n",
      " 739.8665874  734.35059643 749.67792082 735.98716927 733.97778392\n",
      " 738.10803866 732.30211568 734.26728678 736.10655046 733.78460169\n",
      " 735.94357228 731.61161327 740.70688152 733.62249684]\n",
      "[7.19900918 7.30496287 7.40869713 7.68699741 7.22709656 7.12769437\n",
      " 7.30196285 7.47901607 7.60297728 7.12819004 7.23545265 7.57835197\n",
      " 7.2752018  7.27512097 7.35524392 7.60765386 7.16597128 7.54377651\n",
      " 7.43879461 7.32719994 7.23451614 7.48404241 7.41954303 7.4064486 ]\n",
      "[1.   0.95 0.95 0.56 1.   0.95 0.93 0.85 0.78 0.2  0.98 0.89 0.87 0.96\n",
      " 0.58 0.91 1.   0.95 0.85 0.93 1.   0.85 0.85 0.93]\n"
     ]
    }
   ],
   "source": [
    "n_cal = 4\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "SPDBN_accuracy_code_perso = np.zeros(nb_part)\n",
    "SPDBN_tps_train_code_perso = np.zeros(nb_part)\n",
    "SPDBN_tps_test_code_perso = np.zeros(nb_part)\n",
    "SPDBN_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*60)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "    ind2take = [j for j in range(nb_part) if j!=i]\n",
    "    nb_sample_cal = int(n_class*n_cal*(2.2-window_size)*60)\n",
    "\n",
    "    X_train = np.concatenate([np.concatenate(X[ind2take]).reshape(-1,X.shape[-2],X.shape[-1]),X[i][:nb_sample_cal]]).reshape(-1,X.shape[-2],X.shape[-1])\n",
    "    Y_train = np.concatenate([np.concatenate(Y[ind2take]).reshape(-1),Y[i][:nb_sample_cal]]).reshape(-1)\n",
    "    domains_train = np.concatenate([np.concatenate(domains[ind2take]).reshape(-1),domains[i][:nb_sample_cal]]).reshape(-1)\n",
    "\n",
    "    X_test = X[i][nb_sample_cal:]\n",
    "    Y_test = y[i][nb_sample_cal:]\n",
    "    labels_code_test = labels_code_list[i][(n_class*n_cal):]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    # X_std = X_train.std(axis=0)\n",
    "    # X_train /= X_std + 1e-8\n",
    "    # X_std = X_test.std(axis=0)\n",
    "    # X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    X_train,Y_train,domains_train = balance(X_train,Y_train,domains_train)\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = SPDNetBN_Module(bimap_dims=[32,28,14,7])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    clf.fit(np.array(x_train), y_train,\n",
    "                    batch_size=batchsize, epochs=epochs, shuffle=True)\n",
    "    SPDBN_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([1 if (y >= 0.5) else 0 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    SPDBN_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, fps=60, consecutive=50, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    SPDBN_tps_test_code_perso[i] = time.time() - start\n",
    "    SPDBN_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(SPDBN_accuracy_perso)\n",
    "print(SPDBN_tps_train_code_perso)\n",
    "print(SPDBN_tps_test_code_perso)\n",
    "print(SPDBN_accuracy_code_perso)\n",
    "# pd.DataFrame(SPDBN_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/score/DA_score.csv\")\n",
    "# pd.DataFrame(SPDBN_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/score_code/DA_score_code.csv\")\n",
    "# pd.DataFrame(SPDBN_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/temps_train_code/DA_tps_train_code.csv\")\n",
    "# pd.DataFrame(SPDBN_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/temps_test_code/DA_tps_test_code.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.8633333333333333\n",
      "with 0.25s 0.8925000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([1,   0.95, 0.95, 0.56, 1,   0.95, 0.93 ,0.85 ,0.78, 0.2,  0.98, 0.89, 0.87, 0.96,\n",
    " 0.58, 0.91, 1,  0.95, 0.85, 0.93, 1,  0.85, 0.85, 0.93]))\n",
    "print(\"with 0.25s\",np.mean([1, 0.98, 0.93, 0.91, 0.98, 0.95, 0.87, 0.93, 0.87, 0.76, 0.98, 0.87 ,0.91, 0.96,\n",
    " 0.69 ,0.78, 0.98, 0.95, 0.84 ,0.69 ,0.96, 0.96, 0.69, 0.98]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPDBN DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5445233749542312\n",
      "Epoch 2, Loss: 0.45403583023859106\n",
      "Epoch 3, Loss: 0.44354211966039636\n",
      "Epoch 4, Loss: 0.4391560049160667\n",
      "Epoch 5, Loss: 0.4507721551793366\n",
      "Epoch 6, Loss: 0.4606000963642663\n",
      "Epoch 7, Loss: 0.4341570460513646\n",
      "Epoch 8, Loss: 0.4333368237664106\n",
      "Epoch 9, Loss: 0.43158820471744763\n",
      "Epoch 10, Loss: 0.4351811825993504\n",
      "Epoch 11, Loss: 0.42981304175297735\n",
      "Epoch 12, Loss: 0.4336275132041675\n",
      "Epoch 13, Loss: 0.43312833137191803\n",
      "Epoch 14, Loss: 0.4342232625710634\n",
      "Epoch 15, Loss: 0.429224753568295\n",
      "Epoch 16, Loss: 0.4314336686030678\n",
      "Epoch 17, Loss: 0.43290879709918506\n",
      "Epoch 18, Loss: 0.43147510190019495\n",
      "Epoch 19, Loss: 0.42978068726807245\n",
      "Epoch 20, Loss: 0.4269242602374714\n",
      "getting accuracy of participant  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3595555555555554\n",
      "TL to the participant :  1\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5367811607277911\n",
      "Epoch 2, Loss: 0.44576072268806427\n",
      "Epoch 3, Loss: 0.43451352435138385\n",
      "Epoch 4, Loss: 0.4320426723467031\n",
      "Epoch 5, Loss: 0.42791051355746423\n",
      "Epoch 6, Loss: 0.42685331386539777\n",
      "Epoch 7, Loss: 0.4253420542351342\n",
      "Epoch 8, Loss: 0.42416984702758637\n",
      "Epoch 9, Loss: 0.4229057174426294\n",
      "Epoch 10, Loss: 0.42112698974345514\n",
      "Epoch 11, Loss: 0.4291564924090276\n",
      "Epoch 12, Loss: 0.42176262256891833\n",
      "Epoch 13, Loss: 0.4220528003608756\n",
      "Epoch 14, Loss: 0.42032607789096155\n",
      "Epoch 15, Loss: 0.4245030457087656\n",
      "Epoch 16, Loss: 0.420563055298074\n",
      "Epoch 17, Loss: 0.41810995964664716\n",
      "Epoch 18, Loss: 0.419187248342122\n",
      "Epoch 19, Loss: 0.41706249612593366\n",
      "Epoch 20, Loss: 0.4143006270935413\n",
      "getting accuracy of participant  1\n",
      "meannnnnn long 1.4677083333333334\n",
      "TL to the participant :  2\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5461705233975361\n",
      "Epoch 2, Loss: 0.4417099631115382\n",
      "Epoch 3, Loss: 0.4352310508371813\n",
      "Epoch 4, Loss: 0.431230227231037\n",
      "Epoch 5, Loss: 0.4293099491021379\n",
      "Epoch 6, Loss: 0.4291218291865036\n",
      "Epoch 7, Loss: 0.42788758850380365\n",
      "Epoch 8, Loss: 0.42603610485438775\n",
      "Epoch 9, Loss: 0.42212194074755127\n",
      "Epoch 10, Loss: 0.4223594639612281\n",
      "Epoch 11, Loss: 0.4261144577514513\n",
      "Epoch 12, Loss: 0.4226466671751422\n",
      "Epoch 13, Loss: 0.4200144664572162\n",
      "Epoch 14, Loss: 0.42590129552151373\n",
      "Epoch 15, Loss: 0.4230770461644109\n",
      "Epoch 16, Loss: 0.42383962987439905\n",
      "Epoch 17, Loss: 0.4180165423234932\n",
      "Epoch 18, Loss: 0.42026562181857263\n",
      "Epoch 19, Loss: 0.4207082022084549\n",
      "Epoch 20, Loss: 0.42134016269280505\n",
      "getting accuracy of participant  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4563888888888885\n",
      "TL to the participant :  3\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5664927894654481\n",
      "Epoch 2, Loss: 0.45773267015638086\n",
      "Epoch 3, Loss: 0.4416050899170133\n",
      "Epoch 4, Loss: 0.4366694384883986\n",
      "Epoch 5, Loss: 0.4329181052008165\n",
      "Epoch 6, Loss: 0.432305971977739\n",
      "Epoch 7, Loss: 0.4300156691564402\n",
      "Epoch 8, Loss: 0.4306813112714074\n",
      "Epoch 9, Loss: 0.4312842794557805\n",
      "Epoch 10, Loss: 0.42828612259254156\n",
      "Epoch 11, Loss: 0.42419561832083075\n",
      "Epoch 12, Loss: 0.4298089576568528\n",
      "Epoch 13, Loss: 0.42418051354969916\n",
      "Epoch 14, Loss: 0.4259842431592376\n",
      "Epoch 15, Loss: 0.4275863626493296\n",
      "Epoch 16, Loss: 0.4298979094023761\n",
      "Epoch 17, Loss: 0.42506367309762555\n",
      "Epoch 18, Loss: 0.424425869708947\n",
      "Epoch 19, Loss: 0.42415308822756226\n",
      "Epoch 20, Loss: 0.4226901144849453\n",
      "getting accuracy of participant  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3737089201877932\n",
      "TL to the participant :  4\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5308940079607982\n",
      "Epoch 2, Loss: 0.459848395331575\n",
      "Epoch 3, Loss: 0.4654942443483903\n",
      "Epoch 4, Loss: 0.4797438070943704\n",
      "Epoch 5, Loss: 0.4492584000463071\n",
      "Epoch 6, Loss: 0.4364673859870481\n",
      "Epoch 7, Loss: 0.4352826199277116\n",
      "Epoch 8, Loss: 0.4323715433301662\n",
      "Epoch 9, Loss: 0.4304192328877129\n",
      "Epoch 10, Loss: 0.42945087592121167\n",
      "Epoch 11, Loss: 0.42387169328602875\n",
      "Epoch 12, Loss: 0.4234790204777548\n",
      "Epoch 13, Loss: 0.4241906974626624\n",
      "Epoch 14, Loss: 0.4242636799341134\n",
      "Epoch 15, Loss: 0.42079142501702893\n",
      "Epoch 16, Loss: 0.42055624252251483\n",
      "Epoch 17, Loss: 0.42171636824551306\n",
      "Epoch 18, Loss: 0.42253320101692743\n",
      "Epoch 19, Loss: 0.42073741779025836\n",
      "Epoch 20, Loss: 0.42293370588730445\n",
      "getting accuracy of participant  4\n",
      "meannnnnn long 1.440229885057471\n",
      "TL to the participant :  5\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5345513748792792\n",
      "Epoch 2, Loss: 0.45781945098530163\n",
      "Epoch 3, Loss: 0.4431882608431601\n",
      "Epoch 4, Loss: 0.4432170858731854\n",
      "Epoch 5, Loss: 0.44058513370427216\n",
      "Epoch 6, Loss: 0.4361909455932647\n",
      "Epoch 7, Loss: 0.43471905059022864\n",
      "Epoch 8, Loss: 0.4338309125231189\n",
      "Epoch 9, Loss: 0.43421889311475714\n",
      "Epoch 10, Loss: 0.4327193850820715\n",
      "Epoch 11, Loss: 0.43206588340842206\n",
      "Epoch 12, Loss: 0.4313762275126612\n",
      "Epoch 13, Loss: 0.42854709858479706\n",
      "Epoch 14, Loss: 0.43317986359238153\n",
      "Epoch 15, Loss: 0.430273152976168\n",
      "Epoch 16, Loss: 0.42916389386880066\n",
      "Epoch 17, Loss: 0.43270056179389654\n",
      "Epoch 18, Loss: 0.42874728708634735\n",
      "Epoch 19, Loss: 0.42654066382660694\n",
      "Epoch 20, Loss: 0.430528417877529\n",
      "getting accuracy of participant  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.401977401129943\n",
      "TL to the participant :  6\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5710013002275007\n",
      "Epoch 2, Loss: 0.46441246457250696\n",
      "Epoch 3, Loss: 0.4499613760488307\n",
      "Epoch 4, Loss: 0.44713786244392395\n",
      "Epoch 5, Loss: 0.4573864052182601\n",
      "Epoch 6, Loss: 0.4564746876243546\n",
      "Epoch 7, Loss: 0.44573638290755835\n",
      "Epoch 8, Loss: 0.4401699761628162\n",
      "Epoch 9, Loss: 0.44026836116794543\n",
      "Epoch 10, Loss: 0.4442423477238817\n",
      "Epoch 11, Loss: 0.4382857594329849\n",
      "Epoch 12, Loss: 0.4369054900798873\n",
      "Epoch 13, Loss: 0.4349314101599893\n",
      "Epoch 14, Loss: 0.43490735933243524\n",
      "Epoch 15, Loss: 0.4326309029881662\n",
      "Epoch 16, Loss: 0.43138080741105816\n",
      "Epoch 17, Loss: 0.43165218247019727\n",
      "Epoch 18, Loss: 0.4311759260449956\n",
      "Epoch 19, Loss: 0.4269142283988093\n",
      "Epoch 20, Loss: 0.42702071580726636\n",
      "getting accuracy of participant  6\n",
      "meannnnnn long 1.4251851851851853\n",
      "TL to the participant :  7\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5255117660219019\n",
      "Epoch 2, Loss: 0.4590523293602608\n",
      "Epoch 3, Loss: 0.43932866637885803\n",
      "Epoch 4, Loss: 0.44303110088755493\n",
      "Epoch 5, Loss: 0.43871061839605036\n",
      "Epoch 6, Loss: 0.4414954747371523\n",
      "Epoch 7, Loss: 0.43741535009602783\n",
      "Epoch 8, Loss: 0.43492548150036175\n",
      "Epoch 9, Loss: 0.43369738174521405\n",
      "Epoch 10, Loss: 0.430775182520448\n",
      "Epoch 11, Loss: 0.43205034296974365\n",
      "Epoch 12, Loss: 0.42915799813308264\n",
      "Epoch 13, Loss: 0.4284315747705844\n",
      "Epoch 14, Loss: 0.4310197738319518\n",
      "Epoch 15, Loss: 0.43036477014481317\n",
      "Epoch 16, Loss: 0.42790617148866766\n",
      "Epoch 17, Loss: 0.4289160365525913\n",
      "Epoch 18, Loss: 0.43037260603527777\n",
      "Epoch 19, Loss: 0.4288961899139193\n",
      "Epoch 20, Loss: 0.4277885703465684\n",
      "getting accuracy of participant  7\n",
      "meannnnnn long 1.4267973856209146\n",
      "TL to the participant :  8\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5759797906687137\n",
      "Epoch 2, Loss: 0.4612146868064941\n",
      "Epoch 3, Loss: 0.4548991788988528\n",
      "Epoch 4, Loss: 0.4431084829121239\n",
      "Epoch 5, Loss: 0.44714743228769116\n",
      "Epoch 6, Loss: 0.46549129438965686\n",
      "Epoch 7, Loss: 0.4567775314033267\n",
      "Epoch 8, Loss: 0.4485067702800389\n",
      "Epoch 9, Loss: 0.4363251065783821\n",
      "Epoch 10, Loss: 0.4332819426719379\n",
      "Epoch 11, Loss: 0.42667610943317413\n",
      "Epoch 12, Loss: 0.42606970361570123\n",
      "Epoch 13, Loss: 0.4251421108076224\n",
      "Epoch 14, Loss: 0.4252560229405113\n",
      "Epoch 15, Loss: 0.42628012191165576\n",
      "Epoch 16, Loss: 0.42389243864730414\n",
      "Epoch 17, Loss: 0.4232243950894699\n",
      "Epoch 18, Loss: 0.42115867302822974\n",
      "Epoch 19, Loss: 0.4215114413513968\n",
      "Epoch 20, Loss: 0.4194057557893836\n",
      "getting accuracy of participant  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4743589743589742\n",
      "TL to the participant :  9\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5220782905228053\n",
      "Epoch 2, Loss: 0.4502750183989408\n",
      "Epoch 3, Loss: 0.4346459781817297\n",
      "Epoch 4, Loss: 0.4259892664408024\n",
      "Epoch 5, Loss: 0.42256346639437165\n",
      "Epoch 6, Loss: 0.421942649033701\n",
      "Epoch 7, Loss: 0.42005428353788354\n",
      "Epoch 8, Loss: 0.41762335027159436\n",
      "Epoch 9, Loss: 0.42086504829730914\n",
      "Epoch 10, Loss: 0.4195639886874926\n",
      "Epoch 11, Loss: 0.42533630686315155\n",
      "Epoch 12, Loss: 0.4242960815373146\n",
      "Epoch 13, Loss: 0.41671728663764923\n",
      "Epoch 14, Loss: 0.41878526637205493\n",
      "Epoch 15, Loss: 0.43226500185346417\n",
      "Epoch 16, Loss: 0.4182823607219538\n",
      "Epoch 17, Loss: 0.41743180679945135\n",
      "Epoch 18, Loss: 0.4162013424126056\n",
      "Epoch 19, Loss: 0.41490060149916547\n",
      "Epoch 20, Loss: 0.4136600023790782\n",
      "getting accuracy of participant  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.500925925925926\n",
      "TL to the participant :  10\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5452836019248359\n",
      "Epoch 2, Loss: 0.4618734249719989\n",
      "Epoch 3, Loss: 0.45386051554453705\n",
      "Epoch 4, Loss: 0.44832723543577985\n",
      "Epoch 5, Loss: 0.4409373839617718\n",
      "Epoch 6, Loss: 0.4396253897267368\n",
      "Epoch 7, Loss: 0.4408171668118639\n",
      "Epoch 8, Loss: 0.4376939317218871\n",
      "Epoch 9, Loss: 0.4379304859478012\n",
      "Epoch 10, Loss: 0.43828923835349176\n",
      "Epoch 11, Loss: 0.43675608597254095\n",
      "Epoch 12, Loss: 0.4321714009456484\n",
      "Epoch 13, Loss: 0.43175975289269397\n",
      "Epoch 14, Loss: 0.4335726200356314\n",
      "Epoch 15, Loss: 0.4311645023318619\n",
      "Epoch 16, Loss: 0.43178567302085663\n",
      "Epoch 17, Loss: 0.431327769761029\n",
      "Epoch 18, Loss: 0.4303062198897124\n",
      "Epoch 19, Loss: 0.4330576686519879\n",
      "Epoch 20, Loss: 0.427806959557439\n",
      "getting accuracy of participant  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.3739583333333334\n",
      "TL to the participant :  11\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5856812136917717\n",
      "Epoch 2, Loss: 0.48771950025332306\n",
      "Epoch 3, Loss: 0.45508150620894\n",
      "Epoch 4, Loss: 0.449333777658553\n",
      "Epoch 5, Loss: 0.4396057991171072\n",
      "Epoch 6, Loss: 0.4355473581981282\n",
      "Epoch 7, Loss: 0.4332826653488069\n",
      "Epoch 8, Loss: 0.4341866846376728\n",
      "Epoch 9, Loss: 0.4284792227942953\n",
      "Epoch 10, Loss: 0.42410173717694793\n",
      "Epoch 11, Loss: 0.42495130344106274\n",
      "Epoch 12, Loss: 0.42249274377530743\n",
      "Epoch 13, Loss: 0.4196540833461897\n",
      "Epoch 14, Loss: 0.4215589632158694\n",
      "Epoch 15, Loss: 0.4191873616027267\n",
      "Epoch 16, Loss: 0.4212603294566686\n",
      "Epoch 17, Loss: 0.4237798804586584\n",
      "Epoch 18, Loss: 0.421049734938286\n",
      "Epoch 19, Loss: 0.4176182885886181\n",
      "Epoch 20, Loss: 0.42020618055648956\n",
      "getting accuracy of participant  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4722222222222225\n",
      "TL to the participant :  12\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6600583559675179\n",
      "Epoch 2, Loss: 0.4956708016838481\n",
      "Epoch 3, Loss: 0.4640742386047077\n",
      "Epoch 4, Loss: 0.4456196551030804\n",
      "Epoch 5, Loss: 0.44968261030822876\n",
      "Epoch 6, Loss: 0.4386411157285743\n",
      "Epoch 7, Loss: 0.43533619248819916\n",
      "Epoch 8, Loss: 0.4357469414062651\n",
      "Epoch 9, Loss: 0.43813542780197656\n",
      "Epoch 10, Loss: 0.43567586322075763\n",
      "Epoch 11, Loss: 0.4309291995089987\n",
      "Epoch 12, Loss: 0.43127373820943793\n",
      "Epoch 13, Loss: 0.4278552639390169\n",
      "Epoch 14, Loss: 0.42623389709608356\n",
      "Epoch 15, Loss: 0.42733865081085987\n",
      "Epoch 16, Loss: 0.4263240817507265\n",
      "Epoch 17, Loss: 0.4238994251715807\n",
      "Epoch 18, Loss: 0.42386766478949384\n",
      "Epoch 19, Loss: 0.42472452867643634\n",
      "Epoch 20, Loss: 0.4194319775335402\n",
      "getting accuracy of participant  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4022435897435896\n",
      "TL to the participant :  13\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5230172409606074\n",
      "Epoch 2, Loss: 0.4731261422747209\n",
      "Epoch 3, Loss: 0.4478933844170552\n",
      "Epoch 4, Loss: 0.43779878453774884\n",
      "Epoch 5, Loss: 0.4348128545190035\n",
      "Epoch 6, Loss: 0.4293549934865929\n",
      "Epoch 7, Loss: 0.4315088619827753\n",
      "Epoch 8, Loss: 0.429877146195046\n",
      "Epoch 9, Loss: 0.4261152962215333\n",
      "Epoch 10, Loss: 0.4255089781618872\n",
      "Epoch 11, Loss: 0.42569250822538446\n",
      "Epoch 12, Loss: 0.42203946700209216\n",
      "Epoch 13, Loss: 0.4194297603821095\n",
      "Epoch 14, Loss: 0.4184955809662936\n",
      "Epoch 15, Loss: 0.41965125636620954\n",
      "Epoch 16, Loss: 0.4187458371927616\n",
      "Epoch 17, Loss: 0.414253423454262\n",
      "Epoch 18, Loss: 0.4181229337873195\n",
      "Epoch 19, Loss: 0.4170251071688686\n",
      "Epoch 20, Loss: 0.4151544240505799\n",
      "getting accuracy of participant  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4056410256410254\n",
      "TL to the participant :  14\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6537392919242617\n",
      "Epoch 2, Loss: 0.4686194183562584\n",
      "Epoch 3, Loss: 0.45069974366384064\n",
      "Epoch 4, Loss: 0.446479819744472\n",
      "Epoch 5, Loss: 0.4431179715946258\n",
      "Epoch 6, Loss: 0.4396666228300027\n",
      "Epoch 7, Loss: 0.4342595674539272\n",
      "Epoch 8, Loss: 0.43196266783555975\n",
      "Epoch 9, Loss: 0.4319182977139243\n",
      "Epoch 10, Loss: 0.42842577256468445\n",
      "Epoch 11, Loss: 0.4258190838126797\n",
      "Epoch 12, Loss: 0.4253538973011047\n",
      "Epoch 13, Loss: 0.4249996403931629\n",
      "Epoch 14, Loss: 0.4272652018682759\n",
      "Epoch 15, Loss: 0.42257064828288415\n",
      "Epoch 16, Loss: 0.42163307069554157\n",
      "Epoch 17, Loss: 0.4233491939047109\n",
      "Epoch 18, Loss: 0.4225658826206041\n",
      "Epoch 19, Loss: 0.4217501637257135\n",
      "Epoch 20, Loss: 0.4201107241890647\n",
      "getting accuracy of participant  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4043859649122807\n",
      "TL to the participant :  15\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5549890014965072\n",
      "Epoch 2, Loss: 0.4504151655280072\n",
      "Epoch 3, Loss: 0.4445871531727757\n",
      "Epoch 4, Loss: 0.4410944610480734\n",
      "Epoch 5, Loss: 0.4405446864163923\n",
      "Epoch 6, Loss: 0.43379593796645227\n",
      "Epoch 7, Loss: 0.43484455629770935\n",
      "Epoch 8, Loss: 0.43098349627769983\n",
      "Epoch 9, Loss: 0.42947875434466504\n",
      "Epoch 10, Loss: 0.4305681156311111\n",
      "Epoch 11, Loss: 0.42736058791164355\n",
      "Epoch 12, Loss: 0.42801046241884644\n",
      "Epoch 13, Loss: 0.4241979690526314\n",
      "Epoch 14, Loss: 0.4244400011927714\n",
      "Epoch 15, Loss: 0.4259694639166353\n",
      "Epoch 16, Loss: 0.4255094996436311\n",
      "Epoch 17, Loss: 0.4240376763193032\n",
      "Epoch 18, Loss: 0.42112612111766345\n",
      "Epoch 19, Loss: 0.4227857268139308\n",
      "Epoch 20, Loss: 0.4214239373744241\n",
      "getting accuracy of participant  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.42636815920398\n",
      "TL to the participant :  16\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5448817641367554\n",
      "Epoch 2, Loss: 0.49237989060021203\n",
      "Epoch 3, Loss: 0.4551504977606973\n",
      "Epoch 4, Loss: 0.4464007160173574\n",
      "Epoch 5, Loss: 0.44403858771437243\n",
      "Epoch 6, Loss: 0.43940626202600275\n",
      "Epoch 7, Loss: 0.4389747650962573\n",
      "Epoch 8, Loss: 0.4347691406963371\n",
      "Epoch 9, Loss: 0.4360588917383563\n",
      "Epoch 10, Loss: 0.43162247090942774\n",
      "Epoch 11, Loss: 0.4314342892688254\n",
      "Epoch 12, Loss: 0.43261579114929016\n",
      "Epoch 13, Loss: 0.43009028922427783\n",
      "Epoch 14, Loss: 0.4321265041592564\n",
      "Epoch 15, Loss: 0.4319948493963174\n",
      "Epoch 16, Loss: 0.4294075332140263\n",
      "Epoch 17, Loss: 0.4295713260710946\n",
      "Epoch 18, Loss: 0.42795441868041345\n",
      "Epoch 19, Loss: 0.4276163787120887\n",
      "Epoch 20, Loss: 0.42684127078225964\n",
      "getting accuracy of participant  16\n",
      "meannnnnn long 1.3842857142857137\n",
      "TL to the participant :  17\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.53407028717957\n",
      "Epoch 2, Loss: 0.44670330158806604\n",
      "Epoch 3, Loss: 0.44202532339473016\n",
      "Epoch 4, Loss: 0.4308481410793636\n",
      "Epoch 5, Loss: 0.4410428380070939\n",
      "Epoch 6, Loss: 0.42618759783360327\n",
      "Epoch 7, Loss: 0.4219978234984658\n",
      "Epoch 8, Loss: 0.4214229213861609\n",
      "Epoch 9, Loss: 0.41877958390552533\n",
      "Epoch 10, Loss: 0.417626178429532\n",
      "Epoch 11, Loss: 0.41933933448178967\n",
      "Epoch 12, Loss: 0.4163734796254531\n",
      "Epoch 13, Loss: 0.4199525130831677\n",
      "Epoch 14, Loss: 0.41423478168932343\n",
      "Epoch 15, Loss: 0.4145831962819156\n",
      "Epoch 16, Loss: 0.4149677640364575\n",
      "Epoch 17, Loss: 0.41353131524423364\n",
      "Epoch 18, Loss: 0.41580828305760864\n",
      "Epoch 19, Loss: 0.4147545904981289\n",
      "Epoch 20, Loss: 0.41546613472723676\n",
      "getting accuracy of participant  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4409420289855073\n",
      "TL to the participant :  18\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5375700834475958\n",
      "Epoch 2, Loss: 0.44762688757402624\n",
      "Epoch 3, Loss: 0.43208522511565167\n",
      "Epoch 4, Loss: 0.4317995311007669\n",
      "Epoch 5, Loss: 0.4236834145817361\n",
      "Epoch 6, Loss: 0.4237237009606343\n",
      "Epoch 7, Loss: 0.42641155027118127\n",
      "Epoch 8, Loss: 0.4239568754500551\n",
      "Epoch 9, Loss: 0.4202112571995249\n",
      "Epoch 10, Loss: 0.4193235536809024\n",
      "Epoch 11, Loss: 0.42046215553057525\n",
      "Epoch 12, Loss: 0.4195119903492833\n",
      "Epoch 13, Loss: 0.4147660775853711\n",
      "Epoch 14, Loss: 0.41917242975574237\n",
      "Epoch 15, Loss: 0.4173407104646735\n",
      "Epoch 16, Loss: 0.41885123929016205\n",
      "Epoch 17, Loss: 0.4146329944312808\n",
      "Epoch 18, Loss: 0.4144564953010544\n",
      "Epoch 19, Loss: 0.4173791502186432\n",
      "Epoch 20, Loss: 0.41624880767622485\n",
      "getting accuracy of participant  18\n",
      "meannnnnn long 1.4545045045045046\n",
      "TL to the participant :  19\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5582160674064998\n",
      "Epoch 2, Loss: 0.46131274363268976\n",
      "Epoch 3, Loss: 0.44667401898048614\n",
      "Epoch 4, Loss: 0.4375768272066305\n",
      "Epoch 5, Loss: 0.4362588437649572\n",
      "Epoch 6, Loss: 0.4314426524130252\n",
      "Epoch 7, Loss: 0.43324555262275366\n",
      "Epoch 8, Loss: 0.42684381552364514\n",
      "Epoch 9, Loss: 0.4295964107329666\n",
      "Epoch 10, Loss: 0.4222637261797788\n",
      "Epoch 11, Loss: 0.4337166345166595\n",
      "Epoch 12, Loss: 0.43140965888622723\n",
      "Epoch 13, Loss: 0.4244309249131576\n",
      "Epoch 14, Loss: 0.42173293091562897\n",
      "Epoch 15, Loss: 0.4226590227703803\n",
      "Epoch 16, Loss: 0.4199261170013149\n",
      "Epoch 17, Loss: 0.41761707670603815\n",
      "Epoch 18, Loss: 0.4189252536523012\n",
      "Epoch 19, Loss: 0.4199978485408979\n",
      "Epoch 20, Loss: 0.4208826617054317\n",
      "getting accuracy of participant  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4722222222222223\n",
      "TL to the participant :  20\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.633147238153714\n",
      "Epoch 2, Loss: 0.5016833457786575\n",
      "Epoch 3, Loss: 0.46993258560127893\n",
      "Epoch 4, Loss: 0.45968460176773224\n",
      "Epoch 5, Loss: 0.45521303787533\n",
      "Epoch 6, Loss: 0.447364296719962\n",
      "Epoch 7, Loss: 0.44628304349103937\n",
      "Epoch 8, Loss: 0.43948003855854156\n",
      "Epoch 9, Loss: 0.439770209930631\n",
      "Epoch 10, Loss: 0.437536484639164\n",
      "Epoch 11, Loss: 0.4368320697616683\n",
      "Epoch 12, Loss: 0.4347381031089149\n",
      "Epoch 13, Loss: 0.43659509276684094\n",
      "Epoch 14, Loss: 0.43459114997754456\n",
      "Epoch 15, Loss: 0.4327034848363032\n",
      "Epoch 16, Loss: 0.43271684505251556\n",
      "Epoch 17, Loss: 0.43526457326685486\n",
      "Epoch 18, Loss: 0.4347704769123213\n",
      "Epoch 19, Loss: 0.43559354602583783\n",
      "Epoch 20, Loss: 0.4341752656363687\n",
      "getting accuracy of participant  20\n",
      "meannnnnn long 1.398507462686567\n",
      "TL to the participant :  21\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5464505211637897\n",
      "Epoch 2, Loss: 0.45260578441054455\n",
      "Epoch 3, Loss: 0.4416110584504991\n",
      "Epoch 4, Loss: 0.43636730525333417\n",
      "Epoch 5, Loss: 0.43582864347182715\n",
      "Epoch 6, Loss: 0.43045978183331696\n",
      "Epoch 7, Loss: 0.4269390247556061\n",
      "Epoch 8, Loss: 0.42595171881287464\n",
      "Epoch 9, Loss: 0.42797154677008453\n",
      "Epoch 10, Loss: 0.42585318821221\n",
      "Epoch 11, Loss: 0.42429111456211377\n",
      "Epoch 12, Loss: 0.4258638148015667\n",
      "Epoch 13, Loss: 0.4228286523475006\n",
      "Epoch 14, Loss: 0.42596037844895374\n",
      "Epoch 15, Loss: 0.42403185815208044\n",
      "Epoch 16, Loss: 0.42471686111608514\n",
      "Epoch 17, Loss: 0.4238893678301408\n",
      "Epoch 18, Loss: 0.42201092845130816\n",
      "Epoch 19, Loss: 0.4208278681920922\n",
      "Epoch 20, Loss: 0.4190045763027998\n",
      "getting accuracy of participant  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meannnnnn long 1.4263636363636358\n",
      "TL to the participant :  22\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5418547660465768\n",
      "Epoch 2, Loss: 0.460513880837105\n",
      "Epoch 3, Loss: 0.4495846812904117\n",
      "Epoch 4, Loss: 0.4450697929491639\n",
      "Epoch 5, Loss: 0.44242744295022235\n",
      "Epoch 6, Loss: 0.4388654462904798\n",
      "Epoch 7, Loss: 0.43752894700751477\n",
      "Epoch 8, Loss: 0.4371370984160382\n",
      "Epoch 9, Loss: 0.43354950032450934\n",
      "Epoch 10, Loss: 0.42918288578157837\n",
      "Epoch 11, Loss: 0.4289782811766085\n",
      "Epoch 12, Loss: 0.4284539773412373\n",
      "Epoch 13, Loss: 0.42704761075408093\n",
      "Epoch 14, Loss: 0.42509769692486926\n",
      "Epoch 15, Loss: 0.42293265532599134\n",
      "Epoch 16, Loss: 0.4224995953056652\n",
      "Epoch 17, Loss: 0.4230427059967056\n",
      "Epoch 18, Loss: 0.4211736549973017\n",
      "Epoch 19, Loss: 0.419315462880455\n",
      "Epoch 20, Loss: 0.4201817811713388\n",
      "getting accuracy of participant  22\n",
      "meannnnnn long 1.4421985815602836\n",
      "TL to the participant :  23\n",
      "(196650, 32, 32)\n",
      "(196650,)\n",
      "(8550, 32, 32)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5732541875876928\n",
      "Epoch 2, Loss: 0.47478273428475903\n",
      "Epoch 3, Loss: 0.4619665466278438\n",
      "Epoch 4, Loss: 0.4535638372535291\n",
      "Epoch 5, Loss: 0.44676909816594934\n",
      "Epoch 6, Loss: 0.44224769218637067\n",
      "Epoch 7, Loss: 0.43830126989264734\n",
      "Epoch 8, Loss: 0.4366593206588459\n",
      "Epoch 9, Loss: 0.43319639863939624\n",
      "Epoch 10, Loss: 0.4357681482912523\n",
      "Epoch 11, Loss: 0.4316263818458135\n",
      "Epoch 12, Loss: 0.43394727716332837\n",
      "Epoch 13, Loss: 0.4341612855200711\n",
      "Epoch 14, Loss: 0.4329968828693209\n",
      "Epoch 15, Loss: 0.4308452197449952\n",
      "Epoch 16, Loss: 0.4311553612056928\n",
      "Epoch 17, Loss: 0.4303443848262191\n",
      "Epoch 18, Loss: 0.43270530460380285\n",
      "Epoch 19, Loss: 0.43415844976430823\n",
      "Epoch 20, Loss: 0.43000276227713574\n",
      "getting accuracy of participant  23\n",
      "meannnnnn long 1.3741293532338306\n",
      "[0.91416855 0.75223416 0.77484917 0.78069382 0.80612274 0.84819947\n",
      " 0.79370287 0.80972851 0.72897813 0.54472097 0.55408183 0.74945324\n",
      " 0.7504572  0.80902149 0.70076829 0.84177036 0.86723228 0.70428922\n",
      " 0.75074001 0.76831165 0.87519796 0.75601904 0.71051565 0.89058258]\n",
      "[722.65198851 720.10140634 720.70070124 721.34407949 722.75322342\n",
      " 721.23875093 719.98032498 722.32348943 721.20552015 719.06734657\n",
      " 720.32910609 721.5493865  721.03642678 720.95547676 721.12076759\n",
      " 720.62746525 718.95952821 721.29215026 721.51319861 718.0766902\n",
      " 721.93058872 721.11853147 723.20157719 721.02663779]\n",
      "[ 9.62522244 10.18330288  9.99176502  9.63850093 10.01490235  9.84390712\n",
      " 10.00054836  9.99658489 10.05470753 10.33275318  9.77756023 10.14688301\n",
      "  9.88188958  9.81319618 10.28820133  9.73987556  9.68354988 10.0875268\n",
      " 10.05296564  9.94883919  9.86614084 10.01956511 10.08551455  9.83062434]\n",
      "[1.   0.81 0.91 0.99 0.93 0.96 0.85 0.88 0.84 0.32 0.49 0.89 0.92 0.95\n",
      " 0.85 0.95 0.95 0.89 0.76 0.91 0.97 0.88 0.8  0.97]\n"
     ]
    }
   ],
   "source": [
    "n_cal = 4\n",
    "n_class = 5\n",
    "nb_part = len(participants)\n",
    "SPDBN_accuracy_code_perso = np.zeros(nb_part)\n",
    "SPDBN_tps_train_code_perso = np.zeros(nb_part)\n",
    "SPDBN_tps_test_code_perso = np.zeros(nb_part)\n",
    "SPDBN_accuracy_perso = np.zeros(nb_part)\n",
    "nb_samples_windows = int((2.2-window_size)*n_class*n_cal*60)\n",
    "history_list = []\n",
    "\n",
    "\n",
    "for i in range(nb_part):\n",
    "    print(\"TL to the participant : \", i)\n",
    "    ind2take = [j for j in range(nb_part) if j!=i]\n",
    "\n",
    "    X_train = np.concatenate(X[ind2take]).reshape(-1,X.shape[-2],X.shape[-1])\n",
    "    Y_train = np.concatenate(y[ind2take]).reshape(-1)\n",
    "    domains_train = np.concatenate(domains[ind2take]).reshape(-1)\n",
    "    X_test = X[i]\n",
    "    Y_test = y[i]\n",
    "    labels_code_test = labels_code_list[i]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    # X_std = X_train.std(axis=0)\n",
    "    # X_train /= X_std + 1e-8\n",
    "    # X_std = X_test.std(axis=0)\n",
    "    # X_test /= X_std + 1e-8\n",
    "\n",
    "    print(\"balancing the number of ones and zeros\")\n",
    "    X_train,Y_train,domains_train = balance(X_train,Y_train,domains_train)\n",
    "\n",
    "    print(\"Creating the different pipelines\")\n",
    "    clf = SPDNetBN_Module(bimap_dims=[32,28,14,7])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    batchsize = 64 #128 # 64 for burst\n",
    "    epochs = 20 #45 # 20 for burst\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    start = time.time()\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    clf.fit(np.array(x_train), y_train,\n",
    "                    batch_size=batchsize, epochs=epochs, shuffle=True)\n",
    "    SPDBN_tps_train_code_perso[i] = time.time() - start\n",
    "\n",
    "    print(\"getting accuracy of participant \", i)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "    y_test_norm = np.array([1 if (y >= 0.5) else 0 for y in Y_test])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "    SPDBN_accuracy_perso[i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "    labels_pred_accumul, _, mean_long_accumul = mpaa(\n",
    "        y_pred_norm, codes, min_len=30, fps=60, consecutive=50, window_size=window_size\n",
    "    )\n",
    "    print(\"meannnnnn long\",np.mean(mean_long_accumul))\n",
    "    SPDBN_tps_test_code_perso[i] = time.time() - start\n",
    "    SPDBN_accuracy_code_perso[i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "print(SPDBN_accuracy_perso)\n",
    "print(SPDBN_tps_train_code_perso)\n",
    "print(SPDBN_tps_test_code_perso)\n",
    "print(SPDBN_accuracy_code_perso)\n",
    "# pd.DataFrame(SPDBN_accuracy_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/score/DG_score.csv\")\n",
    "# pd.DataFrame(SPDBN_accuracy_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/score_code/DG_score_code.csv\")\n",
    "# pd.DataFrame(SPDBN_tps_train_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/temps_train_code/DG_tps_train_code.csv\")\n",
    "# pd.DataFrame(SPDBN_tps_test_code_perso).to_csv(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/new_dataset/Score_TF/SPDBN/temps_test_code/DG_tps_test_code.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 0.3s 0.8612500000000001\n",
      "with 0.25s 0.8929166666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"with 0.3s\",np.mean([1, 0.81 ,0.91, 0.99 ,0.93 ,0.96 ,0.85 ,0.88, 0.84, 0.32, 0.49, 0.89 ,0.92, 0.95,\n",
    " 0.85, 0.95, 0.95, 0.89, 0.76, 0.91, 0.97 ,0.88, 0.8,  0.97]))\n",
    "print(\"with 0.25s\",np.mean([1, 0.93, 0.92, 0.99, 0.95, 1 ,0.91, 0.92, 0.75, 0.64, 0.96, 0.88, 0.84, 0.93,\n",
    " 0.8,  0.91, 0.99 ,0.87, 0.85, 0.85, 0.99, 0.92, 0.63, 1 ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37542174-788c-4128-ae21-94cf344b15d1",
   "metadata": {},
   "source": [
    "### Pick an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0727580-c7d6-498a-a90c-467e07da91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  clf = basearchi_patchembedding(windows_size = n_samples_windows, n_channel_input = n_channels) # other stim\n",
    "# clf = basearchi_patchembeddingdilation(windows_size = n_samples_windows, n_channel_input = n_channels) # burst\n",
    "# clf = vanilliaEEG2Code(windows_size = n_samples_windows, n_channel_input = n_channels) # burst\n",
    "# clf = trueVanilliaEEG2Code(windows_size = n_samples_windows, n_channel_input = n_channels) # burst\n",
    "# clf = basearchitest(windows_size = n_samples_windows, n_channel_input = n_channels)\n",
    "#c lf = basearchitest_batchnorm(windows_size = n_samples_windows, n_channel_input = n_channels)\n",
    "# clf = EEGnet_Inception(windows_size = n_samples_windows, n_channel_input = n_channels)\n",
    "# clf = basearchi(windows_size = n_samples_windows, n_channel_input = n_channels)\n",
    "\n",
    "clf = make_pipeline(XdawnCovariances(nfilter=8, estimator=\"oas\", xdawn_estimator=\"lwf\"),MDM())\n",
    "clf2 = make_pipeline(XdawnCovariances(nfilter=8, estimator=\"lwf\", xdawn_estimator=\"lwf\"),\n",
    "    TangentSpace(),\n",
    "    LDA(solver=\"lsqr\", shrinkage=\"auto\"))\n",
    "clf3 = make_pipeline(XdawnCovariances(nfilter=8, estimator=\"oas\", xdawn_estimator=\"lwf\"),\n",
    "    TangentSpace(),\n",
    "    svm.SVC())\n",
    "clf4 = make_pipeline(Xdawn(nfilter=8, estimator=\"lwf\"),Vectorizer(),LDA(solver=\"lsqr\", shrinkage=\"auto\"))\n",
    "# clf5 = basearchi(windows_size = n_samples_windows, n_channel_input = n_channels)\n",
    "\n",
    "\n",
    "# xdawn = XdawnCovariances(nfilter=3, estimator=\"lwf\", xdawn_estimator=\"scm\")\n",
    "# clf = MDM()\n",
    "\n",
    "\n",
    "# clf.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a2512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 8, 125)\n",
      "(364,)\n",
      "(4680, 8, 125)\n",
      "(4680,)\n",
      "4095\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "n_cal = 7\n",
    "n_class = 5\n",
    "window_size = 0.25\n",
    "nb_samples_windows = int((2.2-window_size)*n_cal*n_class*60)\n",
    "X_train = X[i][:nb_samples_windows]\n",
    "Y_train = Y[i][:nb_samples_windows]\n",
    "domains_train = domains[i][:nb_samples_windows]\n",
    "X_test = X[i][nb_samples_windows:]\n",
    "Y_test = Y[i][nb_samples_windows:]\n",
    "labels_code_test = labels_code_list[i][n_cal*n_class:]\n",
    "\n",
    "X_std = X_train.std(axis=0)\n",
    "X_train /= X_std + 1e-8\n",
    "X_std = X_test.std(axis=0)\n",
    "X_test /= X_std + 1e-8\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "counter=np.array(range(0,len(Y_train))).reshape(-1,1)\n",
    "index,_ = rus.fit_resample(counter,Y_train[:])\n",
    "X_train = np.squeeze(X_train[index,:,:], axis=1)\n",
    "Y_train = np.squeeze(Y_train[index])\n",
    "# rus = RandomUnderSampler()\n",
    "# counter=np.array(range(0,len(Y_test))).reshape(-1,1)\n",
    "# index,_ = rus.fit_resample(counter,Y_test[:])\n",
    "# X_test = np.squeeze(X_test[index,:,:], axis=1)\n",
    "# Y_test = np.squeeze(Y_test[index])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(nb_samples_windows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5099b32-1a52-4758-a20b-0a2c759d9cbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cut the train in train and valid\n",
    "Also set some HP of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a5ecf-8400-4722-86bc-317d15a2b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "batchsize = 128 #128 # 64 for burst\n",
    "epochs = 45 #45 # 20 for burst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ad9011-e499-4c2a-9163-d968ba4d0153",
   "metadata": {},
   "source": [
    "### Attach an optimizer and train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3bb97b",
   "metadata": {},
   "source": [
    "res_X_train=[]\n",
    "for i in range(len(X_train)):\n",
    "    res_X_train.append(np.array(X_train[i:i+1]).reshape(n_samples_windows, n_channels, 1))\n",
    "res_X_val=[]\n",
    "for i in range(len(x_val)):\n",
    "    res_X_val.append(np.array(x_val[i:i+1]).reshape(n_samples_windows, n_channels, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1a142",
   "metadata": {},
   "source": [
    "np.array(res_X_val).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9861b",
   "metadata": {},
   "source": [
    "np.array(res_X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29716ea1-43fe-4060-b7e2-7685be9c2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 1e-3\n",
    "# weight_decay = 1e-4\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=lr, amsgrad=True)\n",
    "# clf5.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "# X_trainp = xdawn.fit_transform(X_train,y_train)\n",
    "# X_valp = xdawn.fit_transform(x_val,y_val)\n",
    "# X_testp = xdawn.fit_transform(X_test,Y_test)>\n",
    "history = clf.fit(np.array(x_train), y_train)\n",
    "history2 = clf2.fit(np.array(x_train), y_train)\n",
    "history3 = clf3.fit(np.array(x_train), y_train)\n",
    "history4 = clf4.fit(np.array(x_train), y_train)\n",
    "\n",
    "history_list = [history,history2,history3,history4]\n",
    "\n",
    "reg_x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "# history_r1 = rm.fit(np.array(reg_x_train), y_train)\n",
    "keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm.score(X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2]),Y_test)\n",
    "# pred = rm.predict(X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2]))\n",
    "# y_pred = [1 if (Y >= 0.5) else 0 for Y in pred]\n",
    "# print(np.count_nonzero(y_pred==Y_test)/len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RG\n",
      "0.5291922531884743\n",
      "0.5484234234234234\n",
      "0.5054785330948122\n",
      "RG+LDA\n",
      "0.8179263108171941\n",
      "0.46621621621621623\n",
      "0.5024038461538461\n",
      "RG+SVC\n",
      "0.7182569674067076\n",
      "0.47935435435435436\n",
      "0.509559481216458\n",
      "Xdw+LDA\n",
      "0.7423948984411903\n",
      "0.5352852852852853\n",
      "0.5254919499105546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "\n",
    "print(\"RG\")\n",
    "print(balanced_accuracy_score(y_train,history.predict(x_train)))\n",
    "print(balanced_accuracy_score(y_val,history.predict(x_val)))\n",
    "print(balanced_accuracy_score(Y_test,history.predict(X_test)))\n",
    "\n",
    "print(\"RG+LDA\")\n",
    "print(balanced_accuracy_score(y_train,history2.predict(x_train)))\n",
    "print(balanced_accuracy_score(y_val,history2.predict(x_val)))\n",
    "print(balanced_accuracy_score(Y_test,history2.predict(X_test)))\n",
    "\n",
    "print(\"RG+SVC\")\n",
    "print(balanced_accuracy_score(y_train,history3.predict(x_train)))\n",
    "print(balanced_accuracy_score(y_val,history3.predict(x_val)))\n",
    "print(balanced_accuracy_score(Y_test,history3.predict(X_test)))\n",
    "\n",
    "print(\"Xdw+LDA\")\n",
    "print(balanced_accuracy_score(y_train,history4.predict(x_train)))\n",
    "print(balanced_accuracy_score(y_val,history4.predict(x_val)))\n",
    "print(balanced_accuracy_score(Y_test,history4.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b597e6e-6eb6-4314-bfcf-a4f405d6d0f1",
   "metadata": {},
   "source": [
    "### Model and accuracy and loss\n",
    "Just check that the model learnt something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a1b07-b67d-4557-9406-2cd1bde805e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\s.velut\\Documents\\These\\Protheus_PHD\\Scripts\\test_new_dataset.ipynb Cell 62\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y115sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# summarize history for accuracy\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y115sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y115sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history_list[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y115sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history_list[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/test_new_dataset.ipynb#Y115sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mmodel accuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "p=2\n",
    "plt.figure(figsize=(12,12))\n",
    "# summarize history for accuracy\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history_list[0].history['accuracy'])\n",
    "plt.plot(history_list[0].history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# summarize history for loss\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history_list[p].history['loss'])\n",
    "plt.plot(history_list[p].history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "print()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c91070-aab2-451f-b011-4ad2eb23f0ca",
   "metadata": {},
   "source": [
    "filename = ''\n",
    "np.save(filename + \"std_from_calibration\", X_std)\n",
    "model_filename = os.path.join(os.getcwd(), filename + '0.7' + \"trainedmodel\")\n",
    "# Save the model if calibration was done\n",
    "clf.save(model_filename)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2ae4c-9865-42a3-bc95-45ad496308c4",
   "metadata": {},
   "source": [
    "## Vizualize learned filters\n",
    "### Raw vizualiation of 1D convolutinal kernel of the first layer --> spatial filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58fd505-5745-43ae-8ef2-cd9045e945e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We first visualize the learned patch embeddings.\n",
    "# patch_embeddings = clf.layers[0].get_weights()[0]\n",
    "# weights = patch_embeddings\n",
    "# # First, apply min-max normalization to the\n",
    "# # given weights to avoid isotrophic scaling.\n",
    "# p_min, p_max = weights.min(), weights.max()\n",
    "# weights = (weights - p_min) / (p_max - p_min)\n",
    "\n",
    "# # Visualize all the filters.\n",
    "# num_filters = 10\n",
    "# plt.figure(figsize=(16, 2))\n",
    "# idx = 1\n",
    "# for i in range(num_filters):\n",
    "#     current_weight = weights[:, :, :, i]\n",
    "#     if current_weight.shape[-1] == 1:\n",
    "#         current_weight = current_weight.squeeze()\n",
    "#     ax = plt.subplot(1, 10, idx)\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_yticks([])\n",
    "#     plt.plot(current_weight)\n",
    "#     idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be1554-eb6d-4001-8c2d-a421db9a5841",
   "metadata": {},
   "source": [
    "### Viz of the corresponding topo maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b89198-1321-418a-a322-6251c4d46da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spatialfilts = clf.get_layer(\"conv2d\").get_weights()[0]\n",
    "# spatialfilts = np.squeeze(spatialfilts)\n",
    "# spatialfilts = np.swapaxes(spatialfilts, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ca7e0-dd11-40e9-90e6-f162e290aa06",
   "metadata": {},
   "source": [
    "### Predict on the test set\n",
    "The predictions are made on windows to regress the code.  \n",
    "Here we divide the prediction in 10 fold to avoid OOM from the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f599ad-7a5f-469d-9680-876e7438cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "y_pred = history4.predict(X_test)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aefccb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf375061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "# y_test_norm = np.array([0 if y == 0 else 1 for y in Y_test])\n",
    "y_pred_norm = y_pred\n",
    "y_test_norm = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c1d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 407\n",
      "True negatives: 3545\n",
      "False positives: 335\n",
      "False negatives: 393\n",
      "Accuracy: 0.8444444444444444\n",
      "Sensitivity: 0.50875\n",
      "Precision: 0.5485175202156334\n",
      "Fowlkes-Mallows: 0.5282596789550604\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "import math\n",
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "print(\"True positives:\", tp)\n",
    "print(\"True negatives:\", tn)\n",
    "print(\"False positives:\", fp)\n",
    "print(\"False negatives:\", fn)\n",
    "print(\"Accuracy:\", (tp+tn)/len(y_test_norm))\n",
    "print(\"Sensitivity:\", sen:=tp/(tp+fn))\n",
    "print(\"Precision:\", pre:=tp/(tp+fp))\n",
    "print(\"Fowlkes-Mallows:\", math.sqrt(sen*pre))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6b90c-103f-4762-8d56-c820dfbf9129",
   "metadata": {},
   "source": [
    "### Convert prediction on windows (regressed code) to label prediction\n",
    "\n",
    "It is offline and synchronous, so we will:\n",
    "1. First create a `code_buffer` that contains the regressed code on the full epoch (2.2s - the last window)\n",
    "    - The refresh rate of the EEG device (500 Hz) is faster than the refress rate of the screen (60Hz), so we average predictions (500/60~8 samples) so they correspond to each flip of the screen.\n",
    "2. Starting from `min_len` (in number of samples), we compute Pearson correalation with the bank of templates code to find the closest one\n",
    "    - If the most correlated code has a significantely bigger correlation compared to the second one (50% bigger) and the p_value is significative then the trial is classified and we move to the next one\n",
    "    - If the thresholds are not reached, then we add samples (with a step of 3) to have a longer trial and re-do the computation\n",
    "    - The thresholds can never been reached in 2.2s, then the trial is not classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4dff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_best_score = 0\n",
    "# p_best_ratio = 0\n",
    "# p_best_acc = 0\n",
    "# p_best_values = ()\n",
    "\n",
    "# for p in np.logspace(0,-5, 6):\n",
    "#     for dr in np.linspace(0.2, 0.8, 7):\n",
    "#         labels_pred, _, mean_long = make_preds_pvalue(y_pred, codes, min_len=70, sfreq=sfreq, obj_p=p)\n",
    "#         ratio = len(labels_pred[labels_pred != -1])/len(labels_pred)\n",
    "#         accuracy = accuracy_score(labels_test[labels_pred != -1], labels_pred[labels_pred != -1])\n",
    "#         score = ratio*accuracy\n",
    "#         if ratio >= p_best_ratio:\n",
    "#             p_best_score = score\n",
    "#             p_best_acc = accuracy\n",
    "#             p_best_ratio = ratio\n",
    "#             p_best_values = (p, dr)\n",
    "#         print(\"==========\", p, \"+\", dr,':',ratio,'--',accuracy,'--',score, '--', np.mean(mean_long))\n",
    "# print(\"Best score\", p_best_score)\n",
    "# print(\"Best values\", p_best_values)            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d7e07-f107-48dd-9530-0d58f533aafd",
   "metadata": {},
   "source": [
    "### Compute accuracy score and accuracy score when a prediction is made (discard not classified trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c000d2-8ad2-4fce-8519-3197a7397513",
   "metadata": {},
   "source": [
    "### Other classification method\n",
    "Same as before but the classification method is different. Instead of thresholds to reach, if when increasing trial lengt a code correllated the most 40 times in a row then the trial is labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8663d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(_utils)\n",
    "# from _utils import make_preds_accumul_aggresive, make_preds_pvalue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd82787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 3 1 2 2 1 0 1 3 3 2 2 0 0 3 1 1 3 2 1 1 2 1 3 2 1 3 2 0 2 2 2 2 2\n",
      " 1 3 2]\n",
      "[0 2 1 3 3 2 0 1 1 0 2 3 3 1 2 0 0 3 1 2 3 2 1 0 2 0 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "========== 15 : 1.0 -- 0.68 -- 0.68 -- 0.8083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 3 2 2 1 1 0 1 3 3 2 2 0 0 3 1 1 3 2 1 0 2 1 3 2 1 3 2 0 0 2 3 2 2\n",
      " 1 3 2]\n",
      "[0 2 1 3 3 2 0 1 1 0 2 3 3 1 2 0 0 3 1 2 3 2 1 0 2 0 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "========== 20 : 1.0 -- 0.8 -- 0.8 -- 0.9483333333333335\n",
      "[0 2 1 3 3 2 2 1 1 0 1 3 3 2 2 0 0 3 1 1 3 2 1 0 2 1 3 2 1 3 2 0 0 2 3 2 2\n",
      " 1 3 2]\n",
      "[0 2 1 3 3 2 0 1 1 0 2 3 3 1 2 0 0 3 1 2 3 2 1 0 2 0 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "========== 25 : 1.0 -- 0.8 -- 0.8 -- 1.0316666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 3 1 2 1 1 0 1 3 3 2 2 0 0 3 1 1 3 2 1 0 2 1 3 2 1 3 2 0 0 2 3 2 2\n",
      " 1 3 2]\n",
      "[0 2 1 3 3 2 0 1 1 0 2 3 3 1 2 0 0 3 1 2 3 2 1 0 2 0 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "========== 30 : 1.0 -- 0.78 -- 0.78 -- 1.105128205128205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 3 1 2 1 1 0 1 3 3 2 2 0 0 3 1 1 3 2 1 0 2 1 3 2 1 3 2 0 0 1 3 2 2\n",
      " 1 3 2]\n",
      "[0 2 1 3 3 2 0 1 1 0 2 3 3 1 2 0 0 3 1 2 3 2 1 0 2 0 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "========== 35 : 1.0 -- 0.8 -- 0.8 -- 1.191228070175439\n",
      "[0 2 1 3 3 1 2 1 1 0 1 3 3 2 2 0 0 3 1 1 3 2 1 0 2 1 3 2 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "[0 2 1 3 3 2 0 1 1 0 2 3 3 1 2 0 0 3 1 2 3 2 1 0 2 0 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "========== 40 : 1.0 -- 0.82 -- 0.82 -- 1.2903508771929821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 3 1 2 1 1 0 1 3 3 2 2 0 0 3 1 2 3 2 1 0 2 1 3 2 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "[0 2 1 3 3 2 0 1 1 0 2 3 3 1 2 0 0 3 1 2 3 2 1 0 2 0 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "========== 45 : 1.0 -- 0.85 -- 0.85 -- 1.362037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 3 1 2 1 1 0 1 3 3 2 2 0 0 3 1 2 3 2 1 0 2 1 3 2 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "[0 2 1 3 3 2 0 1 1 0 2 3 3 1 2 0 0 3 1 2 3 2 1 0 2 0 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "========== 50 : 1.0 -- 0.85 -- 0.85 -- 1.4171568627450981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 3 1 2 1 1 0 1 3 3 1 2 0 0 3 1 2 3 2 1 0 2 1 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "[0 2 1 3 3 2 0 1 1 0 2 3 3 1 2 0 0 3 1 2 3 2 1 0 2 0 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "========== 55 : 1.0 -- 0.9 -- 0.9 -- 1.5086021505376344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 3 1 2 1 1 0 1 3 3 1 2 0 0 3 1 2 3 2 1 0 2 1 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "[0 2 1 3 3 2 0 1 1 0 2 3 3 1 2 0 0 3 1 2 3 2 1 0 2 0 3 1 1 3 2 0 0 1 3 2 0\n",
      " 1 3 2]\n",
      "========== 60 : 1.0 -- 0.9 -- 0.9 -- 1.5811111111111107\n",
      "Best accuracy 0.9\n",
      "Best ratio 1.0\n",
      "Best score 0.9\n",
      "Best values 55\n"
     ]
    }
   ],
   "source": [
    "acc_best_score=0\n",
    "acc_best_ratio=0\n",
    "acc_best_acc=0\n",
    "acc_best_value = 0\n",
    "# for minlen in np.linspace(10, 60, 10):\n",
    "for cons in [15, 20, 25, 30, 35, 40, 45, 50, 55, 60]:\n",
    "    \n",
    "    labels_pred_accumul, _, mean_long_accumul = make_preds_accumul_aggresive(\n",
    "        y_pred_norm, codes, min_len=30, sfreq=60, consecutive=cons, window_size=window_size\n",
    "    )\n",
    "    print(labels_pred_accumul)\n",
    "    print(labels_test)\n",
    "    ratio = np.round(len(labels_pred_accumul[labels_pred_accumul != -1])/len(labels_pred_accumul), 2)\n",
    "    accuracy = np.round(accuracy_score(labels_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    score = np.round(ratio*accuracy,2)\n",
    "    print(\"==========\", cons, ':', ratio, '--', accuracy,\n",
    "        '--', score, '--', np.mean(mean_long_accumul))\n",
    "    if accuracy > acc_best_acc:\n",
    "        acc_best_score = score\n",
    "        acc_best_value = cons\n",
    "        acc_best_acc = accuracy\n",
    "        acc_best_ratio = ratio\n",
    "\n",
    "print(\"Best accuracy\", acc_best_acc)\n",
    "print(\"Best ratio\", acc_best_ratio)\n",
    "print(\"Best score\", acc_best_score)\n",
    "print(\"Best values\", acc_best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ab636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d2fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "labels_pred_accumul, aaaaa, mean_long_accumul = make_preds_accumul_aggresive(\n",
    "        y_pred_norm, codes, min_len=30, sfreq=sfreq, consecutive=15, window_size=window_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f451353",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_pred_accumul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb4b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5269678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ac3a953833c090f146e4ba605ec310f853a691b325db82e974886e3abb928d6"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
