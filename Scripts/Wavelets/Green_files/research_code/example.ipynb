{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import sys\n",
    "sys.path.append('C:/Users/s.velut/Documents/These/Protheus_PHD/Scripts')\n",
    "from Wavelets.Green_files.green.data_utils import EpochsDataset\n",
    "from Wavelets.Green_files.green.wavelet_layers import RealCovariance, PW_PLV\n",
    "import torch\n",
    "\n",
    "from Wavelets.Green_files.research_code.pl_utils import get_green, GreenClassifierLM\n",
    "from Wavelets.Green_files.research_code.crossval_utils import pl_crossval\n",
    "from Wavelets.Green_files.tests.conftest import make_one_dummy_epoch\n",
    "\n",
    "mne.set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import get_BVEP_data, prepare_data, balance\n",
    "from _utils import make_preds_accumul_aggresive\n",
    "sys.path.append('C:/Users/s.velut/Documents/These/Protheus_PHD/Scripts/Wavelets/Jade/')\n",
    "sys.path.insert(0,\"C:\\\\Users\\\\s.velut\\\\Documents\\\\These\\\\moabb\\\\moabb\\\\datasets\")\n",
    "sys.path.insert(0,\"C:\\\\Users\\\\s.velut\\\\Documents\\\\These\\\\moabb\\\\moabb\\\\paradigms\")\n",
    "import numpy as np\n",
    "import time\n",
    "from pyriemann.estimation import Xdawn\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from SPDNet.torch.optimizers import riemannian_adam as torch_riemannian_adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from castillos2023 import CasitllosBurstVEP100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avec MOABB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing the first None classes from all possible events.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "[1, 2, 3]\n",
      "[1, 2, 3]\n",
      "['Fp1', 'Fz', 'F3', 'F7', 'F9', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'P9', 'O1', 'Oz', 'O2', 'P10', 'P8', 'P4', 'CP2', 'CP6', 'T8', 'C4', 'Cz', 'FC2', 'FC6', 'F10', 'F8', 'F4', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 7020, 32, 251)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "\n",
    "subjects = [1,2,3]\n",
    "# subjects = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "nb_subject = len(subjects)\n",
    "moabb_ds = CasitllosBurstVEP100()\n",
    "\n",
    "on_frame = True\n",
    "recenter = False\n",
    "window_size=0.5\n",
    "\n",
    "raw_data,labels,codes,labels_codes = get_BVEP_data(subjects,on_frame,to_keep=None,moabb_ds=moabb_ds,window_size=window_size)\n",
    "X_parent,Y_parent,domains_parent = prepare_data(subjects,raw_data,labels,on_frame,False,recenter,codes,window_size=window_size)\n",
    "X_parent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7020, 32, 126)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_parent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 126])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "n_epochs = 10\n",
    "dataset = EpochsDataset(\n",
    "    epochs=[make_one_dummy_epoch(n_epochs) for i in range(n)],\n",
    "    targets=torch.Tensor([[0,1], [0,1],[0,1], [0,1],[0,1], [0,1],[0,1], [0,1],[0,1], [0,1]] * n).to(torch.float64),\n",
    "    subjects=[f'subject_{i}' for i in range(n)],\n",
    "    n_epochs=n_epochs,\n",
    ")\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[0,1], [0,1],[0,1], [0,1],[0,1], [0,1],[0,1], [0,1],[0,1], [0,1]] * n).to(torch.float64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EpochsDataset\n",
       "=====================\n",
       "len: 21060\n",
       "n_epochs/sample: 7020\n",
       "num_channels/sample: 32\n",
       "sampling frequency: 500.0\n",
       "epoch duration (s): 0.5\n",
       "padding: repeat\n",
       "shuffle: False\n",
       "random_state: Generator(PCG64)\n",
       "use age: None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = X_parent.shape[1]\n",
    "Y = np.concatenate(np.array([[[0,1] if (y >= 0.5) else [1,0] for y in Y_parent[j]] for j in range(len(subjects))]))\n",
    "\n",
    "dataset = EpochsDataset(\n",
    "    epochs=mne.EpochsArray(np.concatenate(X_parent),info=mne.create_info(\n",
    "                                        ch_names=[str(i) for i in range(32)],\n",
    "                                        sfreq=500,\n",
    "                                        ch_types='eeg')),\n",
    "    targets=torch.Tensor(Y).to(torch.float64),\n",
    "    subjects=subjects,\n",
    "    n_epochs=n,\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21060, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_green(\n",
    "#     n_freqs=2,\n",
    "#     kernel_width_s=.5,\n",
    "#     n_ch=3,\n",
    "#     sfreq=500,\n",
    "#     orth_weights=True,\n",
    "#     dropout=.5,\n",
    "#     hidden_dim=[8],\n",
    "#     logref='logeuclid',\n",
    "#     pool_layer=PW_PLV(),\n",
    "#     bi_out=[2],\n",
    "#     dtype=torch.float32,\n",
    "#     use_age=False,\n",
    "#     out_dim=2\n",
    "# )\n",
    "# model_pl = GreenClassifierLM(model=model,)\n",
    "# model_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreenClassifierLM(\n",
       "  (model): Green(\n",
       "    (conv_layers): Sequential(\n",
       "      (0): ComplexWavelet(kernel_width_s=0.25, sfreq=500, n_wavelets=4, stride=5, padding=0, scaling=oct)\n",
       "    )\n",
       "    (pooling_layers): PW_PLV()\n",
       "    (spd_layers): Sequential(\n",
       "      (0): LedoitWold(n_freqs=4, init_shrinkage=-3.0, learnable=True)\n",
       "      (1): BiMap(d_in=32, d_out=4, n_freqs=4\n",
       "    )\n",
       "    (proj): LogEig(ref=logeuclid, reg=0.0001, n_freqs=4, size=4\n",
       "    (head): Sequential(\n",
       "      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=64, out_features=8, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=8, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_green(\n",
    "    n_freqs=4,\n",
    "    kernel_width_s=.25,\n",
    "    n_ch=32,\n",
    "    sfreq=500,\n",
    "    orth_weights=False,\n",
    "    dropout=.5,\n",
    "    hidden_dim=[8],\n",
    "    logref='logeuclid',\n",
    "    pool_layer=PW_PLV(),\n",
    "    bi_out=[4],\n",
    "    dtype=torch.float32,\n",
    "    out_dim=2,\n",
    "    use_age=False,\n",
    ")\n",
    "model_pl = GreenClassifierLM(model=model,\n",
    "                            criterion=torch.nn.CrossEntropyLoss(),)\n",
    "model_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A1000 6GB Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation 0\n",
      "shape ypred et ytrue torch.Size([1, 2]) torch.Size([1, 2])\n",
      "ypred et ytrue tensor([[-0.7690,  0.2440]], device='cuda:0') tensor([[1., 0.]], device='cuda:0', dtype=torch.float64)\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "Finding best initial lr:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr:   5%|▌         | 1/20 [00:25<08:10, 25.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation 0\n",
      "shape ypred et ytrue torch.Size([1, 2]) torch.Size([1, 2])\n",
      "ypred et ytrue tensor([[-0.6825,  0.2094]], device='cuda:0') tensor([[1., 0.]], device='cuda:0', dtype=torch.float64)\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr:  10%|█         | 2/20 [01:19<12:40, 42.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation 0\n",
      "shape ypred et ytrue torch.Size([1, 2]) torch.Size([1, 2])\n",
      "ypred et ytrue tensor([[-0.5910,  0.1727]], device='cuda:0') tensor([[1., 0.]], device='cuda:0', dtype=torch.float64)\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_acc =  0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.146393060684204\n",
      "       test_score                   0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "pl_crossval_output, _ = pl_crossval(\n",
    "    model, \n",
    "    dataset=dataset,\n",
    "    n_epochs=25,\n",
    "    save_preds=True,\n",
    "    ckpt_prefix='checkpoints/test',\n",
    "    train_splits=[[0,1,2,3,4,5,6,7]],\n",
    "    test_splits=[[8]],\n",
    "    batch_size=64,\n",
    "    pl_module=GreenClassifierLM,\n",
    "    num_workers=0, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>21060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>1: 21060</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>0.000 – 0.250 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<EpochsArray |  21060 events (all good), 0 – 0.25 s, baseline off, ~647.9 MB, data loaded,\n",
       " '1': 21060>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moabb.evaluations import WithinSessionEvaluation, CrossSubjectEvaluation\n",
    "from moabb.paradigms import CVEP\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.models import EEGNetv4\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from skorch.callbacks import EarlyStopping, EpochScoring\n",
    "from skorch.dataset import ValidSplit\n",
    "\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.evaluations import CrossSessionEvaluation\n",
    "from moabb.paradigms import MotorImagery\n",
    "from moabb.utils import setup_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed to be able to reproduce results\n",
    "seed = 42\n",
    "setup_seed(seed)\n",
    "\n",
    "# Hyperparameter\n",
    "LEARNING_RATE = 0.0625 * 0.01  # parameter taken from Braindecode\n",
    "WEIGHT_DECAY = 0  # parameter taken from Braindecode\n",
    "BATCH_SIZE = 64  # parameter taken from BrainDecode\n",
    "EPOCH = 10\n",
    "PATIENCE = 3\n",
    "fmin = 4\n",
    "fmax = 100\n",
    "tmin = 0\n",
    "tmax = None\n",
    "\n",
    "# Define a Skorch classifier\n",
    "clf = EEGClassifier(\n",
    "    module=model,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer__lr=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_epochs=EPOCH,\n",
    "    train_split=ValidSplit(0.2, random_state=seed),\n",
    "    device=\"cuda\",\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"valid_loss\", patience=PATIENCE),\n",
    "        EpochScoring(\n",
    "            scoring=\"accuracy\", on_train=True, name=\"train_acc\", lower_is_better=False\n",
    "        ),\n",
    "        EpochScoring(\n",
    "            scoring=\"accuracy\", on_train=False, name=\"valid_acc\", lower_is_better=False\n",
    "        ),\n",
    "    ],\n",
    "    verbose=1,  # Not printing the results for each epoch\n",
    ")\n",
    "\n",
    "# Create the pipelines\n",
    "pipes = {}\n",
    "pipes[\"Green\"] = make_pipeline(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing the first None classes from all possible events.\n",
      "CasitllosBurstVEP100-WithinSession:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le sujet est 1\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3538\u001b[0m        \u001b[32m0.7697\u001b[0m       \u001b[35m0.8221\u001b[0m        \u001b[31m7.6826\u001b[0m  5.0076\n",
      "      2       \u001b[36m0.5192\u001b[0m        \u001b[32m0.6922\u001b[0m       0.8221      229.0211  0.5524\n",
      "      3       \u001b[36m0.7154\u001b[0m        \u001b[32m0.6172\u001b[0m       0.8221      868.0827  0.5497\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3275\u001b[0m        \u001b[32m0.7706\u001b[0m       \u001b[35m0.1842\u001b[0m       \u001b[31m10.8679\u001b[0m  0.5259\n",
      "      2       \u001b[36m0.5116\u001b[0m        \u001b[32m0.6938\u001b[0m       0.1842      410.2107  0.5242\n",
      "      3       \u001b[36m0.7098\u001b[0m        \u001b[32m0.6135\u001b[0m       0.1842     3756.7553  0.5267\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3281\u001b[0m        \u001b[32m0.7697\u001b[0m       \u001b[35m0.8327\u001b[0m       \u001b[31m13.9326\u001b[0m  0.5256\n",
      "      2       \u001b[36m0.5011\u001b[0m        \u001b[32m0.6944\u001b[0m       0.8327       46.9018  0.5167\n",
      "      3       \u001b[36m0.7098\u001b[0m        \u001b[32m0.6185\u001b[0m       0.1673      798.2114  0.5246\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3263\u001b[0m        \u001b[32m0.7671\u001b[0m       \u001b[35m0.1744\u001b[0m       \u001b[31m46.8029\u001b[0m  0.5202\n",
      "      2       \u001b[36m0.5100\u001b[0m        \u001b[32m0.6936\u001b[0m       \u001b[35m0.8256\u001b[0m     1363.7185  0.5194\n",
      "      3       \u001b[36m0.7179\u001b[0m        \u001b[32m0.6112\u001b[0m       0.1744     1214.7687  0.5245\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3411\u001b[0m        \u001b[32m0.7666\u001b[0m       \u001b[35m0.1566\u001b[0m        \u001b[31m3.3126\u001b[0m  0.5215\n",
      "      2       \u001b[36m0.5179\u001b[0m        \u001b[32m0.6909\u001b[0m       0.1566      596.3057  0.5279\n",
      "      3       \u001b[36m0.7094\u001b[0m        \u001b[32m0.6176\u001b[0m       \u001b[35m0.8434\u001b[0m      105.8198  0.5253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:   8%|▊         | 1/12 [00:26<04:46, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n",
      "le sujet est 2\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3484\u001b[0m        \u001b[32m0.7681\u001b[0m       \u001b[35m0.1779\u001b[0m       \u001b[31m35.4138\u001b[0m  0.8176\n",
      "      2       \u001b[36m0.5301\u001b[0m        \u001b[32m0.6902\u001b[0m       \u001b[35m0.8221\u001b[0m      182.2675  0.5290\n",
      "      3       \u001b[36m0.7094\u001b[0m        \u001b[32m0.6143\u001b[0m       0.8221      112.5674  0.5260\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3283\u001b[0m        \u001b[32m0.7697\u001b[0m       \u001b[35m0.8247\u001b[0m        \u001b[31m7.4649\u001b[0m  0.5494\n",
      "      2       \u001b[36m0.5221\u001b[0m        \u001b[32m0.6906\u001b[0m       0.1753     3602.7817  0.5276\n",
      "      3       \u001b[36m0.7237\u001b[0m        \u001b[32m0.6163\u001b[0m       0.8247       25.5686  0.5372\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3297\u001b[0m        \u001b[32m0.7710\u001b[0m       \u001b[35m0.8141\u001b[0m        \u001b[31m8.7434\u001b[0m  0.5525\n",
      "      2       \u001b[36m0.5308\u001b[0m        \u001b[32m0.6907\u001b[0m       0.8141      180.4255  0.5397\n",
      "      3       \u001b[36m0.7205\u001b[0m        \u001b[32m0.6151\u001b[0m       0.1859       27.7432  0.5327\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3261\u001b[0m        \u001b[32m0.7721\u001b[0m       \u001b[35m0.8078\u001b[0m        \u001b[31m1.3672\u001b[0m  0.5281\n",
      "      2       \u001b[36m0.5297\u001b[0m        \u001b[32m0.6907\u001b[0m       0.8078       13.8009  0.5372\n",
      "      3       \u001b[36m0.7315\u001b[0m        \u001b[32m0.6146\u001b[0m       0.8078       25.4013  0.5320\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3440\u001b[0m        \u001b[32m0.7700\u001b[0m       \u001b[35m0.1779\u001b[0m       \u001b[31m26.3414\u001b[0m  0.5292\n",
      "      2       \u001b[36m0.5219\u001b[0m        \u001b[32m0.6920\u001b[0m       0.1779     3064.4718  0.5365\n",
      "      3       \u001b[36m0.7205\u001b[0m        \u001b[32m0.6154\u001b[0m       \u001b[35m0.8221\u001b[0m      144.9129  0.5369\n",
      "      4       \u001b[36m0.7917\u001b[0m        \u001b[32m0.5567\u001b[0m       0.8221       \u001b[31m19.9097\u001b[0m  0.5407\n",
      "      5       \u001b[36m0.8259\u001b[0m        \u001b[32m0.5176\u001b[0m       0.1779      429.2058  0.5403\n",
      "      6       \u001b[36m0.8288\u001b[0m        \u001b[32m0.4937\u001b[0m       0.8221      255.9084  0.5760\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:  17%|█▋        | 2/12 [00:45<03:41, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le sujet est 3\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3475\u001b[0m        \u001b[32m0.7678\u001b[0m       \u001b[35m0.1548\u001b[0m       \u001b[31m21.1013\u001b[0m  0.7922\n",
      "      2       \u001b[36m0.5304\u001b[0m        \u001b[32m0.6900\u001b[0m       0.1548     1135.9080  0.5928\n",
      "      3       \u001b[36m0.7040\u001b[0m        \u001b[32m0.6218\u001b[0m       0.1548      211.9135  0.6252\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3388\u001b[0m        \u001b[32m0.7671\u001b[0m       \u001b[35m0.1601\u001b[0m       \u001b[31m14.4414\u001b[0m  0.7222\n",
      "      2       \u001b[36m0.5388\u001b[0m        \u001b[32m0.6864\u001b[0m       0.1601      301.8501  0.7338\n",
      "      3       \u001b[36m0.7092\u001b[0m        \u001b[32m0.6194\u001b[0m       \u001b[35m0.8399\u001b[0m     1377.3352  0.7674\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3326\u001b[0m        \u001b[32m0.7699\u001b[0m       \u001b[35m0.8292\u001b[0m       \u001b[31m14.1315\u001b[0m  0.7619\n",
      "      2       \u001b[36m0.5223\u001b[0m        \u001b[32m0.6898\u001b[0m       0.8292      614.3822  0.7415\n",
      "      3       \u001b[36m0.7172\u001b[0m        \u001b[32m0.6164\u001b[0m       0.1708     1229.4463  0.7088\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3482\u001b[0m        \u001b[32m0.7655\u001b[0m       \u001b[35m0.1779\u001b[0m       \u001b[31m14.0972\u001b[0m  0.7179\n",
      "      2       \u001b[36m0.5254\u001b[0m        \u001b[32m0.6926\u001b[0m       \u001b[35m0.8221\u001b[0m      730.8244  0.7464\n",
      "      3       \u001b[36m0.7165\u001b[0m        \u001b[32m0.6178\u001b[0m       0.8221      194.5955  0.6733\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3404\u001b[0m        \u001b[32m0.7687\u001b[0m       \u001b[35m0.1664\u001b[0m       \u001b[31m18.3403\u001b[0m  0.6513\n",
      "      2       \u001b[36m0.5241\u001b[0m        \u001b[32m0.6927\u001b[0m       0.1664      392.7893  0.5768\n",
      "      3       \u001b[36m0.7123\u001b[0m        \u001b[32m0.6163\u001b[0m       \u001b[35m0.8336\u001b[0m      395.0478  0.6695\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:  25%|██▌       | 3/12 [01:06<03:16, 21.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le sujet est 4\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3413\u001b[0m        \u001b[32m0.7682\u001b[0m       \u001b[35m0.1797\u001b[0m        \u001b[31m2.0585\u001b[0m  0.7043\n",
      "      2       \u001b[36m0.5237\u001b[0m        \u001b[32m0.6926\u001b[0m       \u001b[35m0.8203\u001b[0m        6.1535  0.6138\n",
      "      3       \u001b[36m0.7147\u001b[0m        \u001b[32m0.6179\u001b[0m       0.1797      335.0947  0.6186\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3498\u001b[0m        \u001b[32m0.7679\u001b[0m       \u001b[35m0.8319\u001b[0m        \u001b[31m2.0918\u001b[0m  0.5597\n",
      "      2       \u001b[36m0.5150\u001b[0m        \u001b[32m0.6913\u001b[0m       0.1681     1336.6867  0.5831\n",
      "      3       \u001b[36m0.7051\u001b[0m        \u001b[32m0.6149\u001b[0m       0.8319      182.9739  0.6088\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3259\u001b[0m        \u001b[32m0.7703\u001b[0m       \u001b[35m0.1637\u001b[0m       \u001b[31m29.5080\u001b[0m  0.7064\n",
      "      2       \u001b[36m0.5203\u001b[0m        \u001b[32m0.6925\u001b[0m       \u001b[35m0.8363\u001b[0m      136.4204  0.6132\n",
      "      3       \u001b[36m0.7076\u001b[0m        \u001b[32m0.6174\u001b[0m       0.1637      947.6609  0.5960\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3337\u001b[0m        \u001b[32m0.7673\u001b[0m       \u001b[35m0.1931\u001b[0m       \u001b[31m44.3812\u001b[0m  0.5413\n",
      "      2       \u001b[36m0.5371\u001b[0m        \u001b[32m0.6876\u001b[0m       \u001b[35m0.8069\u001b[0m      176.3701  0.5444\n",
      "      3       \u001b[36m0.7386\u001b[0m        \u001b[32m0.6127\u001b[0m       0.8069       79.8793  0.5466\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3321\u001b[0m        \u001b[32m0.7700\u001b[0m       \u001b[35m0.1566\u001b[0m        \u001b[31m6.0929\u001b[0m  0.6207\n",
      "      2       \u001b[36m0.5121\u001b[0m        \u001b[32m0.6946\u001b[0m       0.1566      402.2316  0.5703\n",
      "      3       \u001b[36m0.7042\u001b[0m        \u001b[32m0.6216\u001b[0m       0.1566       76.7098  0.5454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:  33%|███▎      | 4/12 [01:25<02:45, 20.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n",
      "le sujet est 5\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3172\u001b[0m        \u001b[32m0.7720\u001b[0m       \u001b[35m0.1797\u001b[0m       \u001b[31m20.0817\u001b[0m  0.7892\n",
      "      2       \u001b[36m0.5201\u001b[0m        \u001b[32m0.6901\u001b[0m       \u001b[35m0.8203\u001b[0m      105.4492  0.5668\n",
      "      3       \u001b[36m0.7219\u001b[0m        \u001b[32m0.6110\u001b[0m       0.1797      747.9804  0.5663\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3420\u001b[0m        \u001b[32m0.7692\u001b[0m       \u001b[35m0.1779\u001b[0m       \u001b[31m24.5045\u001b[0m  0.5362\n",
      "      2       \u001b[36m0.5241\u001b[0m        \u001b[32m0.6905\u001b[0m       \u001b[35m0.8221\u001b[0m      744.1621  0.5568\n",
      "      3       \u001b[36m0.7230\u001b[0m        \u001b[32m0.6141\u001b[0m       0.1779      778.7651  0.5605\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3478\u001b[0m        \u001b[32m0.7698\u001b[0m       \u001b[35m0.1681\u001b[0m        \u001b[31m6.8120\u001b[0m  0.5686\n",
      "      2       \u001b[36m0.5109\u001b[0m        \u001b[32m0.6925\u001b[0m       0.1681      205.3872  0.5900\n",
      "      3       \u001b[36m0.7069\u001b[0m        \u001b[32m0.6191\u001b[0m       \u001b[35m0.8319\u001b[0m      256.6643  0.5970\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3263\u001b[0m        \u001b[32m0.7683\u001b[0m       \u001b[35m0.1717\u001b[0m       \u001b[31m35.1206\u001b[0m  0.5453\n",
      "      2       \u001b[36m0.5172\u001b[0m        \u001b[32m0.6943\u001b[0m       0.1717     1422.8389  0.5402\n",
      "      3       \u001b[36m0.7371\u001b[0m        \u001b[32m0.6136\u001b[0m       \u001b[35m0.8283\u001b[0m      521.3980  0.5454\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3411\u001b[0m        \u001b[32m0.7661\u001b[0m       \u001b[35m0.1655\u001b[0m       \u001b[31m32.4301\u001b[0m  0.5503\n",
      "      2       \u001b[36m0.5217\u001b[0m        \u001b[32m0.6906\u001b[0m       0.1655     3584.1310  0.5539\n",
      "      3       \u001b[36m0.7163\u001b[0m        \u001b[32m0.6188\u001b[0m       0.1655      620.6509  0.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:  42%|████▏     | 5/12 [01:44<02:19, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n",
      "le sujet est 6\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\Documents\\These\\moabb\\moabb\\datasets\\castillos2023.py:129: RuntimeWarning: Data file name in EEG.data (P13_burst100.fdt) is incorrect, the file name must have changed on disk, using the correct file name (P6_burst100.fdt).\n",
      "  raw = mne.io.read_raw_eeglab(file_path_list[0], preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3275\u001b[0m        \u001b[32m0.7686\u001b[0m       \u001b[35m0.1877\u001b[0m        \u001b[31m7.7937\u001b[0m  0.7882\n",
      "      2       \u001b[36m0.5297\u001b[0m        \u001b[32m0.6873\u001b[0m       0.1877     3815.1727  0.5676\n",
      "      3       \u001b[36m0.7252\u001b[0m        \u001b[32m0.6105\u001b[0m       0.1877     2086.8965  0.5791\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3625\u001b[0m        \u001b[32m0.7657\u001b[0m       \u001b[35m0.1601\u001b[0m        \u001b[31m1.4006\u001b[0m  0.5533\n",
      "      2       \u001b[36m0.5145\u001b[0m        \u001b[32m0.6917\u001b[0m       \u001b[35m0.8399\u001b[0m      284.2771  0.5545\n",
      "      3       \u001b[36m0.7036\u001b[0m        \u001b[32m0.6187\u001b[0m       0.8399      319.2554  0.6246\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3295\u001b[0m        \u001b[32m0.7691\u001b[0m       \u001b[35m0.8310\u001b[0m        \u001b[31m9.3264\u001b[0m  0.5486\n",
      "      2       \u001b[36m0.5208\u001b[0m        \u001b[32m0.6894\u001b[0m       0.1690     1212.8300  0.5591\n",
      "      3       \u001b[36m0.7266\u001b[0m        \u001b[32m0.6143\u001b[0m       0.1690      128.7654  0.5443\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3326\u001b[0m        \u001b[32m0.7711\u001b[0m       \u001b[35m0.1708\u001b[0m        \u001b[31m2.9288\u001b[0m  0.5439\n",
      "      2       \u001b[36m0.5248\u001b[0m        \u001b[32m0.6912\u001b[0m       \u001b[35m0.8292\u001b[0m       23.0209  0.5505\n",
      "      3       \u001b[36m0.7112\u001b[0m        \u001b[32m0.6154\u001b[0m       0.8292      700.8555  0.5491\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3350\u001b[0m        \u001b[32m0.7709\u001b[0m       \u001b[35m0.8238\u001b[0m        \u001b[31m0.4687\u001b[0m  0.5586\n",
      "      2       \u001b[36m0.5083\u001b[0m        \u001b[32m0.6934\u001b[0m       0.8238      224.1422  0.5425\n",
      "      3       \u001b[36m0.7158\u001b[0m        \u001b[32m0.6164\u001b[0m       0.8238      208.9979  0.5547\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:  50%|█████     | 6/12 [02:03<01:56, 19.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le sujet est 7\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3355\u001b[0m        \u001b[32m0.7698\u001b[0m       \u001b[35m0.8203\u001b[0m        \u001b[31m6.4873\u001b[0m  0.7715\n",
      "      2       \u001b[36m0.5217\u001b[0m        \u001b[32m0.6934\u001b[0m       0.1797     1648.9735  0.5384\n",
      "      3       \u001b[36m0.7181\u001b[0m        \u001b[32m0.6131\u001b[0m       0.1797     3951.8921  0.5458\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3408\u001b[0m        \u001b[32m0.7683\u001b[0m       \u001b[35m0.1610\u001b[0m       \u001b[31m49.3810\u001b[0m  0.5657\n",
      "      2       \u001b[36m0.5179\u001b[0m        \u001b[32m0.6923\u001b[0m       0.1610     1429.8317  0.5476\n",
      "      3       \u001b[36m0.7078\u001b[0m        \u001b[32m0.6200\u001b[0m       \u001b[35m0.8390\u001b[0m      182.5405  0.5598\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3400\u001b[0m        \u001b[32m0.7697\u001b[0m       \u001b[35m0.8265\u001b[0m       \u001b[31m16.9543\u001b[0m  0.6770\n",
      "      2       \u001b[36m0.5237\u001b[0m        \u001b[32m0.6906\u001b[0m       0.8265       54.7920  0.6656\n",
      "      3       \u001b[36m0.7161\u001b[0m        \u001b[32m0.6172\u001b[0m       0.1735     3048.6472  0.6771\n",
      "      4       \u001b[36m0.7955\u001b[0m        \u001b[32m0.5560\u001b[0m       0.8265       \u001b[31m13.6497\u001b[0m  0.6749\n",
      "      5       \u001b[36m0.8212\u001b[0m        \u001b[32m0.5175\u001b[0m       0.8265      170.4877  0.6832\n",
      "      6       \u001b[36m0.8272\u001b[0m        \u001b[32m0.4941\u001b[0m       0.8265       19.5780  0.6912\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3406\u001b[0m        \u001b[32m0.7661\u001b[0m       \u001b[35m0.1601\u001b[0m        \u001b[31m2.3160\u001b[0m  0.7018\n",
      "      2       \u001b[36m0.5203\u001b[0m        \u001b[32m0.6935\u001b[0m       \u001b[35m0.8399\u001b[0m      213.7575  0.6791\n",
      "      3       \u001b[36m0.7121\u001b[0m        \u001b[32m0.6174\u001b[0m       0.1601     1940.6721  0.6767\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3438\u001b[0m        \u001b[32m0.7708\u001b[0m       \u001b[35m0.1824\u001b[0m       \u001b[31m26.9783\u001b[0m  0.7180\n",
      "      2       \u001b[36m0.5263\u001b[0m        \u001b[32m0.6923\u001b[0m       0.1824     2310.2077  0.6861\n",
      "      3       \u001b[36m0.7054\u001b[0m        \u001b[32m0.6162\u001b[0m       0.1824      776.4621  0.6757\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:  58%|█████▊    | 7/12 [02:25<01:42, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le sujet est 8\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3406\u001b[0m        \u001b[32m0.7686\u001b[0m       \u001b[35m0.8212\u001b[0m        \u001b[31m3.6106\u001b[0m  0.7736\n",
      "      2       \u001b[36m0.5270\u001b[0m        \u001b[32m0.6921\u001b[0m       0.1788     1105.8186  0.5768\n",
      "      3       \u001b[36m0.7225\u001b[0m        \u001b[32m0.6190\u001b[0m       0.8212       96.8083  0.5810\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3478\u001b[0m        \u001b[32m0.7670\u001b[0m       \u001b[35m0.1646\u001b[0m       \u001b[31m23.3157\u001b[0m  0.5750\n",
      "      2       \u001b[36m0.5165\u001b[0m        \u001b[32m0.6927\u001b[0m       0.1646     2168.4011  0.5873\n",
      "      3       \u001b[36m0.7069\u001b[0m        \u001b[32m0.6187\u001b[0m       0.1646     1689.2294  0.5903\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3627\u001b[0m        \u001b[32m0.7678\u001b[0m       \u001b[35m0.8381\u001b[0m        \u001b[31m1.6787\u001b[0m  0.6111\n",
      "      2       \u001b[36m0.5306\u001b[0m        \u001b[32m0.6917\u001b[0m       0.8381      272.6654  0.5881\n",
      "      3       \u001b[36m0.7045\u001b[0m        \u001b[32m0.6211\u001b[0m       0.1619     1677.1084  0.6113\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3333\u001b[0m        \u001b[32m0.7678\u001b[0m       \u001b[35m0.1593\u001b[0m       \u001b[31m14.6431\u001b[0m  0.6034\n",
      "      2       \u001b[36m0.5228\u001b[0m        \u001b[32m0.6900\u001b[0m       \u001b[35m0.8407\u001b[0m      508.0159  0.6324\n",
      "      3       \u001b[36m0.7109\u001b[0m        \u001b[32m0.6166\u001b[0m       0.1593     1783.0318  0.6231\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3286\u001b[0m        \u001b[32m0.7721\u001b[0m       \u001b[35m0.8194\u001b[0m       \u001b[31m13.4500\u001b[0m  0.6607\n",
      "      2       \u001b[36m0.5246\u001b[0m        \u001b[32m0.6915\u001b[0m       0.8194      485.5589  0.6312\n",
      "      3       \u001b[36m0.7190\u001b[0m        \u001b[32m0.6172\u001b[0m       0.1806      536.5041  0.6494\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:  67%|██████▋   | 8/12 [02:45<01:21, 20.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le sujet est 9\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3393\u001b[0m        \u001b[32m0.7690\u001b[0m       \u001b[35m0.8443\u001b[0m        \u001b[31m1.6905\u001b[0m  0.7493\n",
      "      2       \u001b[36m0.5143\u001b[0m        \u001b[32m0.6929\u001b[0m       0.1557      658.8522  0.5723\n",
      "      3       \u001b[36m0.7172\u001b[0m        \u001b[32m0.6190\u001b[0m       0.1557     1925.6755  0.5685\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3446\u001b[0m        \u001b[32m0.7682\u001b[0m       \u001b[35m0.1699\u001b[0m        \u001b[31m9.2919\u001b[0m  0.5801\n",
      "      2       \u001b[36m0.5165\u001b[0m        \u001b[32m0.6932\u001b[0m       \u001b[35m0.8301\u001b[0m      207.5981  0.5534\n",
      "      3       \u001b[36m0.7071\u001b[0m        \u001b[32m0.6224\u001b[0m       0.1699      242.7426  0.5620\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3480\u001b[0m        \u001b[32m0.7685\u001b[0m       \u001b[35m0.1797\u001b[0m       \u001b[31m17.8096\u001b[0m  0.5784\n",
      "      2       \u001b[36m0.5246\u001b[0m        \u001b[32m0.6917\u001b[0m       0.1797      796.5170  0.6022\n",
      "      3       \u001b[36m0.7190\u001b[0m        \u001b[32m0.6168\u001b[0m       0.1797      379.2073  0.5626\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3290\u001b[0m        \u001b[32m0.7710\u001b[0m       \u001b[35m0.1868\u001b[0m       \u001b[31m26.7216\u001b[0m  0.5950\n",
      "      2       \u001b[36m0.5054\u001b[0m        \u001b[32m0.6926\u001b[0m       0.1868     1155.6313  0.5832\n",
      "      3       \u001b[36m0.7172\u001b[0m        \u001b[32m0.6146\u001b[0m       0.1868     1432.0032  0.5998\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3426\u001b[0m        \u001b[32m0.7651\u001b[0m       \u001b[35m0.8390\u001b[0m        \u001b[31m4.9479\u001b[0m  0.6051\n",
      "      2       \u001b[36m0.5210\u001b[0m        \u001b[32m0.6924\u001b[0m       0.8390      482.4699  0.6144\n",
      "      3       \u001b[36m0.7116\u001b[0m        \u001b[32m0.6186\u001b[0m       0.8390       53.6311  0.5995\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:  75%|███████▌  | 9/12 [03:04<00:59, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le sujet est 10\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3230\u001b[0m        \u001b[32m0.7680\u001b[0m       \u001b[35m0.8123\u001b[0m        \u001b[31m3.7347\u001b[0m  0.7927\n",
      "      2       \u001b[36m0.5234\u001b[0m        \u001b[32m0.6920\u001b[0m       0.8123      741.0393  0.5556\n",
      "      3       \u001b[36m0.7270\u001b[0m        \u001b[32m0.6122\u001b[0m       0.1877     1809.0810  0.5456\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3326\u001b[0m        \u001b[32m0.7699\u001b[0m       \u001b[35m0.1690\u001b[0m       \u001b[31m19.0549\u001b[0m  0.5814\n",
      "      2       \u001b[36m0.5308\u001b[0m        \u001b[32m0.6885\u001b[0m       \u001b[35m0.8310\u001b[0m       82.6642  0.5480\n",
      "      3       \u001b[36m0.7225\u001b[0m        \u001b[32m0.6146\u001b[0m       0.1690      393.8340  0.5520\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3388\u001b[0m        \u001b[32m0.7697\u001b[0m       \u001b[35m0.1619\u001b[0m       \u001b[31m12.3530\u001b[0m  0.5616\n",
      "      2       \u001b[36m0.5246\u001b[0m        \u001b[32m0.6911\u001b[0m       0.1619      994.7696  0.5639\n",
      "      3       \u001b[36m0.7163\u001b[0m        \u001b[32m0.6175\u001b[0m       0.1619     3439.6521  0.5662\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3310\u001b[0m        \u001b[32m0.7655\u001b[0m       \u001b[35m0.8319\u001b[0m        \u001b[31m0.4574\u001b[0m  0.5677\n",
      "      2       \u001b[36m0.5301\u001b[0m        \u001b[32m0.6916\u001b[0m       0.8319      289.1792  0.5813\n",
      "      3       \u001b[36m0.7257\u001b[0m        \u001b[32m0.6119\u001b[0m       0.8319       46.6833  0.5733\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3388\u001b[0m        \u001b[32m0.7695\u001b[0m       \u001b[35m0.8105\u001b[0m        \u001b[31m7.0435\u001b[0m  0.6272\n",
      "      2       \u001b[36m0.5252\u001b[0m        \u001b[32m0.6895\u001b[0m       0.8105      214.4349  0.5767\n",
      "      3       \u001b[36m0.7330\u001b[0m        \u001b[32m0.6151\u001b[0m       0.1895     1184.3382  0.5995\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:  83%|████████▎ | 10/12 [03:23<00:39, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le sujet est 11\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3326\u001b[0m        \u001b[32m0.7685\u001b[0m       \u001b[35m0.8141\u001b[0m       \u001b[31m18.3613\u001b[0m  0.7336\n",
      "      2       \u001b[36m0.5268\u001b[0m        \u001b[32m0.6881\u001b[0m       0.8141      317.1253  0.5590\n",
      "      3       \u001b[36m0.7201\u001b[0m        \u001b[32m0.6160\u001b[0m       0.8141      230.3204  0.5449\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3319\u001b[0m        \u001b[32m0.7696\u001b[0m       \u001b[35m0.8283\u001b[0m        \u001b[31m2.7670\u001b[0m  0.5633\n",
      "      2       \u001b[36m0.5194\u001b[0m        \u001b[32m0.6921\u001b[0m       0.8283       99.1806  0.5791\n",
      "      3       \u001b[36m0.7268\u001b[0m        \u001b[32m0.6173\u001b[0m       0.1717     1020.5210  0.5560\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3420\u001b[0m        \u001b[32m0.7668\u001b[0m       \u001b[35m0.1735\u001b[0m       \u001b[31m33.5174\u001b[0m  0.5799\n",
      "      2       \u001b[36m0.5223\u001b[0m        \u001b[32m0.6933\u001b[0m       \u001b[35m0.8265\u001b[0m      470.4835  0.5575\n",
      "      3       \u001b[36m0.7183\u001b[0m        \u001b[32m0.6151\u001b[0m       0.1735     2704.0528  0.5717\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3272\u001b[0m        \u001b[32m0.7703\u001b[0m       \u001b[35m0.8363\u001b[0m        \u001b[31m2.7503\u001b[0m  0.6349\n",
      "      2       \u001b[36m0.5239\u001b[0m        \u001b[32m0.6909\u001b[0m       0.1637      861.1372  0.5846\n",
      "      3       \u001b[36m0.7051\u001b[0m        \u001b[32m0.6200\u001b[0m       0.8363      288.2517  0.5910\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3308\u001b[0m        \u001b[32m0.7684\u001b[0m       \u001b[35m0.1770\u001b[0m       \u001b[31m10.7035\u001b[0m  0.6008\n",
      "      2       \u001b[36m0.5246\u001b[0m        \u001b[32m0.6888\u001b[0m       \u001b[35m0.8230\u001b[0m      218.3983  0.5941\n",
      "      3       \u001b[36m0.7163\u001b[0m        \u001b[32m0.6156\u001b[0m       0.8230      907.8921  0.5866\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession:  92%|█████████▏| 11/12 [03:42<00:19, 19.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le sujet est 12\n",
      "get the data\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "start cv\n",
      "No hdf5_path provided, models will not be saved.\n",
      "grid search start\n",
      "cv est finie\n",
      "cross validate\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3388\u001b[0m        \u001b[32m0.7673\u001b[0m       \u001b[35m0.8399\u001b[0m        \u001b[31m6.3398\u001b[0m  0.7213\n",
      "      2       \u001b[36m0.5239\u001b[0m        \u001b[32m0.6935\u001b[0m       0.1601     1373.8409  0.5530\n",
      "      3       \u001b[36m0.7063\u001b[0m        \u001b[32m0.6193\u001b[0m       0.1601     1419.7458  0.5594\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3471\u001b[0m        \u001b[32m0.7663\u001b[0m       \u001b[35m0.1619\u001b[0m       \u001b[31m25.2622\u001b[0m  0.5692\n",
      "      2       \u001b[36m0.5261\u001b[0m        \u001b[32m0.6940\u001b[0m       0.1619      764.3405  0.5834\n",
      "      3       \u001b[36m0.7089\u001b[0m        \u001b[32m0.6223\u001b[0m       \u001b[35m0.8381\u001b[0m       53.3334  0.5585\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3333\u001b[0m        \u001b[32m0.7689\u001b[0m       \u001b[35m0.8283\u001b[0m        \u001b[31m1.5458\u001b[0m  0.5701\n",
      "      2       \u001b[36m0.5270\u001b[0m        \u001b[32m0.6918\u001b[0m       0.8283       20.4483  0.5702\n",
      "      3       \u001b[36m0.7161\u001b[0m        \u001b[32m0.6150\u001b[0m       0.1717      466.9297  0.5738\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3315\u001b[0m        \u001b[32m0.7686\u001b[0m       \u001b[35m0.1708\u001b[0m        \u001b[31m1.3481\u001b[0m  0.5863\n",
      "      2       \u001b[36m0.5127\u001b[0m        \u001b[32m0.6919\u001b[0m       0.1708      243.0497  0.5817\n",
      "      3       \u001b[36m0.7121\u001b[0m        \u001b[32m0.6155\u001b[0m       0.1708     4003.5484  0.5787\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m0.3424\u001b[0m        \u001b[32m0.7697\u001b[0m       \u001b[35m0.8230\u001b[0m       \u001b[31m15.4268\u001b[0m  0.5959\n",
      "      2       \u001b[36m0.5199\u001b[0m        \u001b[32m0.6921\u001b[0m       0.1770     1271.7874  0.6115\n",
      "      3       \u001b[36m0.6996\u001b[0m        \u001b[32m0.6185\u001b[0m       0.1770     3266.5562  0.5921\n",
      "Stopping since valid_loss has not improved in the last 3 epochs.\n",
      "return res\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasitllosBurstVEP100-WithinSession: 100%|██████████| 12/12 [04:00<00:00, 20.07s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "paradigm = CVEP()\n",
    "dataset = [CasitllosBurstVEP100()]\n",
    "\n",
    "\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm, datasets=dataset, suffix=\"examples\", overwrite=False\n",
    ")\n",
    "results = evaluation.process(pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>samples</th>\n",
       "      <th>subject</th>\n",
       "      <th>session</th>\n",
       "      <th>channels</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>dataset</th>\n",
       "      <th>pipeline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.697436</td>\n",
       "      <td>7.589004</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829060</td>\n",
       "      <td>8.038203</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.829060</td>\n",
       "      <td>8.169000</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.829060</td>\n",
       "      <td>10.290387</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.829060</td>\n",
       "      <td>9.395892</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.829060</td>\n",
       "      <td>7.266255</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.829060</td>\n",
       "      <td>6.603435</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.697436</td>\n",
       "      <td>10.050620</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.829060</td>\n",
       "      <td>10.584088</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.829060</td>\n",
       "      <td>8.627160</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.697436</td>\n",
       "      <td>7.491545</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.829060</td>\n",
       "      <td>7.987654</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score       time  samples subject session  channels  n_sessions  \\\n",
       "0   0.697436   7.589004   7020.0       1       0        32           1   \n",
       "1   0.829060   8.038203   7020.0       2       0        32           1   \n",
       "2   0.829060   8.169000   7020.0       3       0        32           1   \n",
       "3   0.829060  10.290387   7020.0       4       0        32           1   \n",
       "4   0.829060   9.395892   7020.0       5       0        32           1   \n",
       "5   0.829060   7.266255   7020.0       6       0        32           1   \n",
       "6   0.829060   6.603435   7020.0       7       0        32           1   \n",
       "7   0.697436  10.050620   7020.0       8       0        32           1   \n",
       "8   0.829060  10.584088   7020.0       9       0        32           1   \n",
       "9   0.829060   8.627160   7020.0      10       0        32           1   \n",
       "10  0.697436   7.491545   7020.0      11       0        32           1   \n",
       "11  0.829060   7.987654   7020.0      12       0        32           1   \n",
       "\n",
       "                 dataset pipeline  \n",
       "0   CasitllosBurstVEP100    Green  \n",
       "1   CasitllosBurstVEP100    Green  \n",
       "2   CasitllosBurstVEP100    Green  \n",
       "3   CasitllosBurstVEP100    Green  \n",
       "4   CasitllosBurstVEP100    Green  \n",
       "5   CasitllosBurstVEP100    Green  \n",
       "6   CasitllosBurstVEP100    Green  \n",
       "7   CasitllosBurstVEP100    Green  \n",
       "8   CasitllosBurstVEP100    Green  \n",
       "9   CasitllosBurstVEP100    Green  \n",
       "10  CasitllosBurstVEP100    Green  \n",
       "11  CasitllosBurstVEP100    Green  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing the first None classes from all possible events.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\s.velut\\Documents\\These\\Protheus_PHD\\Scripts\\Wavelets\\Green_files\\research_code\\example.ipynb Cell 17\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/Wavelets/Green_files/research_code/example.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dataset \u001b[39m=\u001b[39m [CasitllosBurstVEP100()]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/Wavelets/Green_files/research_code/example.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cross_evaluation \u001b[39m=\u001b[39m CrossSubjectEvaluation(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/Wavelets/Green_files/research_code/example.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     paradigm\u001b[39m=\u001b[39mparadigm, datasets\u001b[39m=\u001b[39mdataset, suffix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexamples\u001b[39m\u001b[39m\"\u001b[39m, overwrite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/Wavelets/Green_files/research_code/example.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/s.velut/Documents/These/Protheus_PHD/Scripts/Wavelets/Green_files/research_code/example.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m cross_results \u001b[39m=\u001b[39m cross_evaluation\u001b[39m.\u001b[39;49mprocess(pipes)\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\moabb\\evaluations\\base.py:188\u001b[0m, in \u001b[0;36mBaseEvaluation.process\u001b[1;34m(self, pipelines, param_grid, postprocess_pipeline)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[39m# (we only keep the pipeline for the first frequency band, better ideas?)\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\n\u001b[0;32m    182\u001b[0m         dataset,\n\u001b[0;32m    183\u001b[0m         pipelines,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m         postprocess_pipeline\u001b[39m=\u001b[39mpostprocess_pipeline,\n\u001b[0;32m    187\u001b[0m     )\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mfor\u001b[39;49;00m res \u001b[39min\u001b[39;49;00m results:\n\u001b[0;32m    189\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpush_result(res, pipelines, process_pipeline)\n\u001b[0;32m    191\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults\u001b[39m.\u001b[39mto_dataframe(\n\u001b[0;32m    192\u001b[0m     pipelines\u001b[39m=\u001b[39mpipelines, process_pipeline\u001b[39m=\u001b[39mprocess_pipeline\n\u001b[0;32m    193\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\moabb\\evaluations\\evaluations.py:665\u001b[0m, in \u001b[0;36mCrossSubjectEvaluation.evaluate\u001b[1;34m(self, dataset, pipelines, param_grid, process_pipeline, postprocess_pipeline)\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[39m# get the data\u001b[39;00m\n\u001b[1;32m--> 665\u001b[0m X, y, metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparadigm\u001b[39m.\u001b[39;49mget_data(\n\u001b[0;32m    666\u001b[0m     dataset\u001b[39m=\u001b[39;49mdataset,\n\u001b[0;32m    667\u001b[0m     return_epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_epochs,\n\u001b[0;32m    668\u001b[0m     return_raws\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_raws,\n\u001b[0;32m    669\u001b[0m     postprocess_pipeline\u001b[39m=\u001b[39;49mpostprocess_pipeline,\n\u001b[0;32m    670\u001b[0m )\n\u001b[0;32m    672\u001b[0m \u001b[39m# encode labels\u001b[39;00m\n\u001b[0;32m    673\u001b[0m le \u001b[39m=\u001b[39m LabelEncoder()\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\moabb\\paradigms\\base.py:278\u001b[0m, in \u001b[0;36mBaseProcessing.get_data\u001b[1;34m(self, dataset, subjects, return_epochs, return_raws, cache_config, postprocess_pipeline)\u001b[0m\n\u001b[0;32m    273\u001b[0m process_pipelines \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_process_pipelines(\n\u001b[0;32m    274\u001b[0m     dataset, return_epochs, return_raws, postprocess_pipeline\n\u001b[0;32m    275\u001b[0m )\n\u001b[0;32m    276\u001b[0m labels_pipeline \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_labels_pipeline(dataset, return_epochs, return_raws)\n\u001b[1;32m--> 278\u001b[0m data \u001b[39m=\u001b[39m [\n\u001b[0;32m    279\u001b[0m     dataset\u001b[39m.\u001b[39;49mget_data(\n\u001b[0;32m    280\u001b[0m         subjects\u001b[39m=\u001b[39;49msubjects,\n\u001b[0;32m    281\u001b[0m         cache_config\u001b[39m=\u001b[39;49mcache_config,\n\u001b[0;32m    282\u001b[0m         process_pipeline\u001b[39m=\u001b[39;49mprocess_pipeline,\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m     \u001b[39mfor\u001b[39;49;00m process_pipeline \u001b[39min\u001b[39;49;00m process_pipelines\n\u001b[0;32m    285\u001b[0m ]\n\u001b[0;32m    287\u001b[0m X \u001b[39m=\u001b[39m []\n\u001b[0;32m    288\u001b[0m labels \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\moabb\\paradigms\\base.py:279\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    273\u001b[0m process_pipelines \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_process_pipelines(\n\u001b[0;32m    274\u001b[0m     dataset, return_epochs, return_raws, postprocess_pipeline\n\u001b[0;32m    275\u001b[0m )\n\u001b[0;32m    276\u001b[0m labels_pipeline \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_labels_pipeline(dataset, return_epochs, return_raws)\n\u001b[0;32m    278\u001b[0m data \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 279\u001b[0m     dataset\u001b[39m.\u001b[39;49mget_data(\n\u001b[0;32m    280\u001b[0m         subjects\u001b[39m=\u001b[39;49msubjects,\n\u001b[0;32m    281\u001b[0m         cache_config\u001b[39m=\u001b[39;49mcache_config,\n\u001b[0;32m    282\u001b[0m         process_pipeline\u001b[39m=\u001b[39;49mprocess_pipeline,\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m     \u001b[39mfor\u001b[39;00m process_pipeline \u001b[39min\u001b[39;00m process_pipelines\n\u001b[0;32m    285\u001b[0m ]\n\u001b[0;32m    287\u001b[0m X \u001b[39m=\u001b[39m []\n\u001b[0;32m    288\u001b[0m labels \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\moabb\\datasets\\base.py:342\u001b[0m, in \u001b[0;36mBaseDataset.get_data\u001b[1;34m(self, subjects, cache_config, process_pipeline)\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[39mif\u001b[39;00m subject \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubject_list:\n\u001b[0;32m    341\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid subject \u001b[39m\u001b[39m{:d}\u001b[39;00m\u001b[39m given\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(subject))\n\u001b[1;32m--> 342\u001b[0m     data[subject] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_subject_data_using_cache(\n\u001b[0;32m    343\u001b[0m         subject,\n\u001b[0;32m    344\u001b[0m         cache_config,\n\u001b[0;32m    345\u001b[0m         process_pipeline,\n\u001b[0;32m    346\u001b[0m     )\n\u001b[0;32m    347\u001b[0m check_subject_names(data)\n\u001b[0;32m    348\u001b[0m check_session_names(data)\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\moabb\\datasets\\base.py:436\u001b[0m, in \u001b[0;36mBaseDataset._get_single_subject_data_using_cache\u001b[1;34m(self, subject, cache_config, process_pipeline)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[39m# Load and eventually overwrite:\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cached_steps) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# last option: we don't use cache\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     sessions_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_subject_data(subject)\n\u001b[0;32m    437\u001b[0m     \u001b[39massert\u001b[39;00m sessions_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# should not happen\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\These\\moabb\\moabb\\datasets\\castillos2023.py:128\u001b[0m, in \u001b[0;36mBaseCastillos2023._get_single_subject_data\u001b[1;34m(self, subject)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_single_subject_data\u001b[39m(\u001b[39mself\u001b[39m, subject):\n\u001b[0;32m    127\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the data of a single subject.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     file_path_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_path(subject, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparadigm_type)\n\u001b[0;32m    129\u001b[0m     raw \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mread_raw_eeglab(file_path_list[\u001b[39m0\u001b[39m], preload\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    131\u001b[0m     \u001b[39m# Strip the annotations that were script to make them easier to process\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\These\\moabb\\moabb\\datasets\\castillos2023.py:234\u001b[0m, in \u001b[0;36mBaseCastillos2023.data_path\u001b[1;34m(self, subject, paradigm_type, path, force_update, update_path, verbose)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (osp\u001b[39m.\u001b[39misdir(path_folder \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m4Class-VEP\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m    233\u001b[0m     zip_ref \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39mZipFile(path_zip, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 234\u001b[0m     zip_ref\u001b[39m.\u001b[39;49mextractall(path_folder)\n\u001b[0;32m    236\u001b[0m subject_paths\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    237\u001b[0m     path_folder\n\u001b[0;32m    238\u001b[0m     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m4Class-CVEP/P\u001b[39m\u001b[39m{:d}\u001b[39;00m\u001b[39m/P\u001b[39m\u001b[39m{:d}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.set\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(subject, subject, paradigm_type)\n\u001b[0;32m    239\u001b[0m )\n\u001b[0;32m    241\u001b[0m \u001b[39mreturn\u001b[39;00m subject_paths\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1681\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1678\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(path)\n\u001b[0;32m   1680\u001b[0m \u001b[39mfor\u001b[39;00m zipinfo \u001b[39min\u001b[39;00m members:\n\u001b[1;32m-> 1681\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_member(zipinfo, path, pwd)\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1736\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1732\u001b[0m     \u001b[39mreturn\u001b[39;00m targetpath\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(member, pwd\u001b[39m=\u001b[39mpwd) \u001b[39mas\u001b[39;00m source, \\\n\u001b[0;32m   1735\u001b[0m      \u001b[39mopen\u001b[39m(targetpath, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m target:\n\u001b[1;32m-> 1736\u001b[0m     shutil\u001b[39m.\u001b[39;49mcopyfileobj(source, target)\n\u001b[0;32m   1738\u001b[0m \u001b[39mreturn\u001b[39;00m targetpath\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:197\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    195\u001b[0m fdst_write \u001b[39m=\u001b[39m fdst\u001b[39m.\u001b[39mwrite\n\u001b[0;32m    196\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m     buf \u001b[39m=\u001b[39m fsrc_read(length)\n\u001b[0;32m    198\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buf:\n\u001b[0;32m    199\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:955\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    954\u001b[0m \u001b[39mwhile\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n\u001b[1;32m--> 955\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read1(n)\n\u001b[0;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[0;32m    957\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readbuffer \u001b[39m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1031\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_type \u001b[39m==\u001b[39m ZIP_DEFLATED:\n\u001b[0;32m   1030\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(n, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m-> 1031\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(data, n)\n\u001b[0;32m   1032\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39meof \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m                  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_left \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m                  \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail)\n\u001b[0;32m   1035\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "paradigm = CVEP()\n",
    "dataset = [CasitllosBurstVEP100()]\n",
    "\n",
    "cross_evaluation = CrossSubjectEvaluation(\n",
    "    paradigm=paradigm, datasets=dataset, suffix=\"examples\", overwrite=False\n",
    ")\n",
    "cross_results = cross_evaluation.process(pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>samples</th>\n",
       "      <th>subject</th>\n",
       "      <th>session</th>\n",
       "      <th>channels</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>dataset</th>\n",
       "      <th>pipeline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>137.261841</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>177.490524</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>137.546021</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>144.890167</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>105.100517</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>143.653839</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>105.876099</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>101.209442</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>211.256851</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>104.882607</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>118.469406</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.82906</td>\n",
       "      <td>103.212265</td>\n",
       "      <td>77220.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>CasitllosBurstVEP100</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score        time  samples subject session  channels  n_sessions  \\\n",
       "0   0.82906  137.261841  77220.0       1       0        32           1   \n",
       "1   0.82906  177.490524  77220.0       2       0        32           1   \n",
       "2   0.82906  137.546021  77220.0       3       0        32           1   \n",
       "3   0.82906  144.890167  77220.0       4       0        32           1   \n",
       "4   0.82906  105.100517  77220.0       5       0        32           1   \n",
       "5   0.82906  143.653839  77220.0       6       0        32           1   \n",
       "6   0.82906  105.876099  77220.0       7       0        32           1   \n",
       "7   0.82906  101.209442  77220.0       8       0        32           1   \n",
       "8   0.82906  211.256851  77220.0       9       0        32           1   \n",
       "9   0.82906  104.882607  77220.0      10       0        32           1   \n",
       "10  0.82906  118.469406  77220.0      11       0        32           1   \n",
       "11  0.82906  103.212265  77220.0      12       0        32           1   \n",
       "\n",
       "                 dataset pipeline  \n",
       "0   CasitllosBurstVEP100    Green  \n",
       "1   CasitllosBurstVEP100    Green  \n",
       "2   CasitllosBurstVEP100    Green  \n",
       "3   CasitllosBurstVEP100    Green  \n",
       "4   CasitllosBurstVEP100    Green  \n",
       "5   CasitllosBurstVEP100    Green  \n",
       "6   CasitllosBurstVEP100    Green  \n",
       "7   CasitllosBurstVEP100    Green  \n",
       "8   CasitllosBurstVEP100    Green  \n",
       "9   CasitllosBurstVEP100    Green  \n",
       "10  CasitllosBurstVEP100    Green  \n",
       "11  CasitllosBurstVEP100    Green  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing the first None classes from all possible events.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\Documents\\These\\moabb\\moabb\\datasets\\castillos2023.py:129: RuntimeWarning: Data file name in EEG.data (P13_burst100.fdt) is incorrect, the file name must have changed on disk, using the correct file name (P6_burst100.fdt).\n",
      "  raw = mne.io.read_raw_eeglab(file_path_list[0], preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "C:\\Users\\s.velut\\mne_data\\MNE-4class-vep-data\\records\\8255618\\files\\\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "['Fp1', 'Fz', 'F3', 'F7', 'F9', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'P9', 'O1', 'Oz', 'O2', 'P10', 'P8', 'P4', 'CP2', 'CP6', 'T8', 'C4', 'Cz', 'FC2', 'FC6', 'F10', 'F8', 'F4', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'F9', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'P9', 'O1', 'Oz', 'O2', 'P10', 'P8', 'P4', 'CP2', 'CP6', 'T8', 'C4', 'Cz', 'FC2', 'FC6', 'F10', 'F8', 'F4', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'F9', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'P9', 'O1', 'Oz', 'O2', 'P10', 'P8', 'P4', 'CP2', 'CP6', 'T8', 'C4', 'Cz', 'FC2', 'FC6', 'F10', 'F8', 'F4', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'F9', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'P9', 'O1', 'Oz', 'O2', 'P10', 'P8', 'P4', 'CP2', 'CP6', 'T8', 'C4', 'Cz', 'FC2', 'FC6', 'F10', 'F8', 'F4', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'F9', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'P9', 'O1', 'Oz', 'O2', 'P10', 'P8', 'P4', 'CP2', 'CP6', 'T8', 'C4', 'Cz', 'FC2', 'FC6', 'F10', 'F8', 'F4', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'F9', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'P9', 'O1', 'Oz', 'O2', 'P10', 'P8', 'P4', 'CP2', 'CP6', 'T8', 'C4', 'Cz', 'FC2', 'FC6', 'F10', 'F8', 'F4', 'Fp2', 'stim_trial', 'stim_epoch']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n",
      "Recentering the matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 7020, 32, 126)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "\n",
    "# subjects = [1,2,3]\n",
    "subjects = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "nb_subject = len(subjects)\n",
    "moabb_ds = CasitllosBurstVEP100()\n",
    "\n",
    "\n",
    "on_frame = True\n",
    "recenter = True\n",
    "window_size=0.25\n",
    "\n",
    "raw_data,labels,codes,labels_codes = get_BVEP_data(subjects,on_frame,to_keep=None,moabb_ds=moabb_ds,window_size=window_size)\n",
    "X_parent,Y_parent,domains_parent = prepare_data(subjects,raw_data,labels,on_frame,False,recenter,codes,window_size=window_size)\n",
    "X_parent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreenClassifierLM(\n",
       "  (model): Green(\n",
       "    (conv_layers): Sequential(\n",
       "      (0): ComplexWavelet(kernel_width_s=0.25, sfreq=500, n_wavelets=20, stride=5, padding=0, scaling=oct)\n",
       "    )\n",
       "    (pooling_layers): RealCovariance()\n",
       "    (spd_layers): Sequential(\n",
       "      (0): LedoitWold(n_freqs=20, init_shrinkage=-3.0, learnable=True)\n",
       "      (1): BiMap(d_in=32, d_out=16, n_freqs=20\n",
       "      (2): BiMap(d_in=16, d_out=8, n_freqs=20\n",
       "    )\n",
       "    (proj): LogEig(ref=logeuclid, reg=0.0001, n_freqs=20, size=8\n",
       "    (head): Sequential(\n",
       "      (0): BatchNorm1d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.7, inplace=False)\n",
       "      (2): Linear(in_features=720, out_features=10, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.7, inplace=False)\n",
       "      (6): Linear(in_features=10, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_green(\n",
    "    n_freqs=20,\n",
    "    kernel_width_s=window_size,\n",
    "    n_ch=32,\n",
    "    sfreq=500,\n",
    "    orth_weights=False,\n",
    "    dropout=.7,\n",
    "    hidden_dim=[10],\n",
    "    logref='logeuclid',\n",
    "    pool_layer=RealCovariance(),\n",
    "    bi_out=[16,8],\n",
    "    dtype=torch.float32,\n",
    "    out_dim=2,\n",
    "    use_age=False,\n",
    ")\n",
    "model_pl = GreenClassifierLM(model=model,\n",
    "                            criterion=torch.nn.CrossEntropyLoss(),)\n",
    "model_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6374088458039544\n",
      "Epoch 2, Loss: 0.5308170996832126\n",
      "Epoch 3, Loss: 0.5198487840818636\n",
      "Epoch 4, Loss: 0.5161755153627107\n",
      "Epoch 5, Loss: 0.5105622343944781\n",
      "Epoch 6, Loss: 0.5075623751589746\n",
      "Epoch 7, Loss: 0.501397329568863\n",
      "Epoch 8, Loss: 0.4986560123436379\n",
      "Epoch 9, Loss: 0.49700562114065344\n",
      "Epoch 10, Loss: 0.4998178710540136\n",
      "Epoch 11, Loss: 0.49438112170407267\n",
      "Epoch 12, Loss: 0.4925415687488787\n",
      "Epoch 13, Loss: 0.4919468501300523\n",
      "Epoch 14, Loss: 0.4914361037088163\n",
      "Epoch 15, Loss: 0.48760880042206156\n",
      "Epoch 16, Loss: 0.4858998176726428\n",
      "Epoch 17, Loss: 0.4845502357591282\n",
      "Epoch 18, Loss: 0.48732415970527765\n",
      "Epoch 19, Loss: 0.48557239093563775\n",
      "Epoch 20, Loss: 0.48463608983791234\n",
      "Training finished!\n",
      "Training accuracy : 0.7836994152412093\n",
      "Validation Accuracy: 0.7916214137172075\n",
      "Test Accuracy: 0.8207946735395188\n",
      "TL to the participant :  1\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.4354285637086088\n",
      "Epoch 2, Loss: 0.41947733678601007\n",
      "Epoch 3, Loss: 0.40908874598416417\n",
      "Epoch 4, Loss: 0.3999271450620709\n",
      "Epoch 5, Loss: 0.389518905860005\n",
      "Epoch 6, Loss: 0.3855313470869353\n",
      "Epoch 7, Loss: 0.37488187086401564\n",
      "Epoch 8, Loss: 0.36909637609214496\n",
      "Epoch 9, Loss: 0.36177282712676306\n",
      "Epoch 10, Loss: 0.3544524646166599\n",
      "Epoch 11, Loss: 0.3468912157596964\n",
      "Epoch 12, Loss: 0.3374640381245902\n",
      "Epoch 13, Loss: 0.33379726897586476\n",
      "Epoch 14, Loss: 0.324465237512733\n",
      "Epoch 15, Loss: 0.3186822767059008\n",
      "Epoch 16, Loss: 0.3107155931266871\n",
      "Epoch 17, Loss: 0.30347726453434337\n",
      "Epoch 18, Loss: 0.2951009920826464\n",
      "Epoch 19, Loss: 0.2888161638469407\n",
      "Epoch 20, Loss: 0.279554106611194\n",
      "Training finished!\n",
      "Training accuracy : 0.8749874317877431\n",
      "Validation Accuracy: 0.8029402005085337\n",
      "Test Accuracy: 0.715451030927835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  2\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.4822502545335076\n",
      "Epoch 2, Loss: 0.42163950990546833\n",
      "Epoch 3, Loss: 0.4026604581962932\n",
      "Epoch 4, Loss: 0.38708931243780886\n",
      "Epoch 5, Loss: 0.37544187022881076\n",
      "Epoch 6, Loss: 0.36281825335639895\n",
      "Epoch 7, Loss: 0.3544424905921474\n",
      "Epoch 8, Loss: 0.3407100919521216\n",
      "Epoch 9, Loss: 0.3298031236186172\n",
      "Epoch 10, Loss: 0.32185350647478395\n",
      "Epoch 11, Loss: 0.3102333204764308\n",
      "Epoch 12, Loss: 0.3016663381547639\n",
      "Epoch 13, Loss: 0.2962322555708163\n",
      "Epoch 14, Loss: 0.28460321047089315\n",
      "Epoch 15, Loss: 0.27961734998406784\n",
      "Epoch 16, Loss: 0.2688489294413364\n",
      "Epoch 17, Loss: 0.2612505653590867\n",
      "Epoch 18, Loss: 0.25705774970578427\n",
      "Epoch 19, Loss: 0.24621955458865022\n",
      "Epoch 20, Loss: 0.23939033469015902\n",
      "Training finished!\n",
      "Training accuracy : 0.8956405005229193\n",
      "Validation Accuracy: 0.7956265805757331\n",
      "Test Accuracy: 0.7810524054982818\n",
      "TL to the participant :  3\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.5046873803391602\n",
      "Epoch 2, Loss: 0.43030924864790654\n",
      "Epoch 3, Loss: 0.4058926785534078\n",
      "Epoch 4, Loss: 0.39119127708854096\n",
      "Epoch 5, Loss: 0.37899156745636103\n",
      "Epoch 6, Loss: 0.370162760850155\n",
      "Epoch 7, Loss: 0.3574698675310973\n",
      "Epoch 8, Loss: 0.34948643987829037\n",
      "Epoch 9, Loss: 0.33915117703603975\n",
      "Epoch 10, Loss: 0.3300987330801559\n",
      "Epoch 11, Loss: 0.3207188937700156\n",
      "Epoch 12, Loss: 0.31383450202869645\n",
      "Epoch 13, Loss: 0.30840686893824376\n",
      "Epoch 14, Loss: 0.2982013547059261\n",
      "Epoch 15, Loss: 0.2909146144760377\n",
      "Epoch 16, Loss: 0.28253383365544404\n",
      "Epoch 17, Loss: 0.27605234558383623\n",
      "Epoch 18, Loss: 0.2696862887252461\n",
      "Epoch 19, Loss: 0.2646620041944764\n",
      "Epoch 20, Loss: 0.2564482553212932\n",
      "Training finished!\n",
      "Training accuracy : 0.8837754286866855\n",
      "Validation Accuracy: 0.8017343613581454\n",
      "Test Accuracy: 0.7428135738831615\n",
      "TL to the participant :  4\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.48324978333531005\n",
      "Epoch 2, Loss: 0.42332399677146565\n",
      "Epoch 3, Loss: 0.4003002767761548\n",
      "Epoch 4, Loss: 0.3838481071320447\n",
      "Epoch 5, Loss: 0.374831959650372\n",
      "Epoch 6, Loss: 0.3656144053195462\n",
      "Epoch 7, Loss: 0.35507511650071\n",
      "Epoch 8, Loss: 0.34465848722241144\n",
      "Epoch 9, Loss: 0.33751487718387085\n",
      "Epoch 10, Loss: 0.3291078985640497\n",
      "Epoch 11, Loss: 0.32583487146731577\n",
      "Epoch 12, Loss: 0.31393119209643566\n",
      "Epoch 13, Loss: 0.3061845125122504\n",
      "Epoch 14, Loss: 0.29917502890933645\n",
      "Epoch 15, Loss: 0.29396347220648417\n",
      "Epoch 16, Loss: 0.28937055951718127\n",
      "Epoch 17, Loss: 0.2793470867203944\n",
      "Epoch 18, Loss: 0.27803476202217015\n",
      "Epoch 19, Loss: 0.27059808617288417\n",
      "Epoch 20, Loss: 0.26661954700495255\n",
      "Training finished!\n",
      "Training accuracy : 0.8766074766345083\n",
      "Validation Accuracy: 0.7950719094765322\n",
      "Test Accuracy: 0.7539690721649485\n",
      "TL to the participant :  5\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.49070623778935635\n",
      "Epoch 2, Loss: 0.4383349151322336\n",
      "Epoch 3, Loss: 0.4202833393306443\n",
      "Epoch 4, Loss: 0.40900553293300396\n",
      "Epoch 5, Loss: 0.3988554860606338\n",
      "Epoch 6, Loss: 0.38818170920465933\n",
      "Epoch 7, Loss: 0.38024296647671496\n",
      "Epoch 8, Loss: 0.3693590418858962\n",
      "Epoch 9, Loss: 0.3655111619017341\n",
      "Epoch 10, Loss: 0.3555510753031933\n",
      "Epoch 11, Loss: 0.3449586471373385\n",
      "Epoch 12, Loss: 0.3369055474346334\n",
      "Epoch 13, Loss: 0.3318993906180064\n",
      "Epoch 14, Loss: 0.326324964743672\n",
      "Epoch 15, Loss: 0.3182616186864448\n",
      "Epoch 16, Loss: 0.3133995523958495\n",
      "Epoch 17, Loss: 0.3048838683601582\n",
      "Epoch 18, Loss: 0.3002487486962116\n",
      "Epoch 19, Loss: 0.2958434293667475\n",
      "Epoch 20, Loss: 0.2923337762102936\n",
      "Training finished!\n",
      "Training accuracy : 0.8655778721879686\n",
      "Validation Accuracy: 0.7949751766678472\n",
      "Test Accuracy: 0.821335910652921\n",
      "TL to the participant :  6\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.4565575635794437\n",
      "Epoch 2, Loss: 0.4079563977591919\n",
      "Epoch 3, Loss: 0.3938100477059682\n",
      "Epoch 4, Loss: 0.3777007247010867\n",
      "Epoch 5, Loss: 0.37413267452608456\n",
      "Epoch 6, Loss: 0.3602058894254945\n",
      "Epoch 7, Loss: 0.3500355609438636\n",
      "Epoch 8, Loss: 0.34193694839874905\n",
      "Epoch 9, Loss: 0.3326080143903241\n",
      "Epoch 10, Loss: 0.3313535974332781\n",
      "Epoch 11, Loss: 0.3192303115219781\n",
      "Epoch 12, Loss: 0.3118895355047602\n",
      "Epoch 13, Loss: 0.3022565894054644\n",
      "Epoch 14, Loss: 0.3014848088224729\n",
      "Epoch 15, Loss: 0.2918517694780321\n",
      "Epoch 16, Loss: 0.28532135920091106\n",
      "Epoch 17, Loss: 0.2809209558096799\n",
      "Epoch 18, Loss: 0.27781799853299605\n",
      "Epoch 19, Loss: 0.2727638029239394\n",
      "Epoch 20, Loss: 0.26681665378538044\n",
      "Training finished!\n",
      "Training accuracy : 0.8791994062406074\n",
      "Validation Accuracy: 0.8032447950841552\n",
      "Test Accuracy: 0.5928006872852234\n",
      "TL to the participant :  7\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.46652056123271135\n",
      "Epoch 2, Loss: 0.42358160642060366\n",
      "Epoch 3, Loss: 0.40903441034483184\n",
      "Epoch 4, Loss: 0.39960791956294667\n",
      "Epoch 5, Loss: 0.38852668964501585\n",
      "Epoch 6, Loss: 0.3790227045615514\n",
      "Epoch 7, Loss: 0.3708780397519921\n",
      "Epoch 8, Loss: 0.3632384293910229\n",
      "Epoch 9, Loss: 0.3552234741322922\n",
      "Epoch 10, Loss: 0.349606702002612\n",
      "Epoch 11, Loss: 0.34511115885142124\n",
      "Epoch 12, Loss: 0.33748422694025615\n",
      "Epoch 13, Loss: 0.3297663830898025\n",
      "Epoch 14, Loss: 0.32291323307788733\n",
      "Epoch 15, Loss: 0.3189883618192239\n",
      "Epoch 16, Loss: 0.31208258605364597\n",
      "Epoch 17, Loss: 0.30592432180137347\n",
      "Epoch 18, Loss: 0.2996838014234196\n",
      "Epoch 19, Loss: 0.2948684522148335\n",
      "Epoch 20, Loss: 0.2919977097348733\n",
      "Training finished!\n",
      "Training accuracy : 0.8675173240530063\n",
      "Validation Accuracy: 0.7852451769463351\n",
      "Test Accuracy: 0.8319931271477663\n",
      "TL to the participant :  8\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.4889475826964234\n",
      "Epoch 2, Loss: 0.4301790152535294\n",
      "Epoch 3, Loss: 0.4120555809952996\n",
      "Epoch 4, Loss: 0.40072076708981486\n",
      "Epoch 5, Loss: 0.38960966702663535\n",
      "Epoch 6, Loss: 0.3822324066902652\n",
      "Epoch 7, Loss: 0.3725726690256234\n",
      "Epoch 8, Loss: 0.3660326787468159\n",
      "Epoch 9, Loss: 0.3582330629681096\n",
      "Epoch 10, Loss: 0.3497222515669736\n",
      "Epoch 11, Loss: 0.3403178218187708\n",
      "Epoch 12, Loss: 0.33331920183969266\n",
      "Epoch 13, Loss: 0.3322801560163498\n",
      "Epoch 14, Loss: 0.31990156119520013\n",
      "Epoch 15, Loss: 0.3147225312211297\n",
      "Epoch 16, Loss: 0.30894516643249625\n",
      "Epoch 17, Loss: 0.30280424270666007\n",
      "Epoch 18, Loss: 0.2988547891829953\n",
      "Epoch 19, Loss: 0.2918031956661831\n",
      "Epoch 20, Loss: 0.28721004577748704\n",
      "Training finished!\n",
      "Training accuracy : 0.8695091789068532\n",
      "Validation Accuracy: 0.8040906546482754\n",
      "Test Accuracy: 0.6892396907216495\n",
      "TL to the participant :  9\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.48528921468691394\n",
      "Epoch 2, Loss: 0.44061475134257116\n",
      "Epoch 3, Loss: 0.42271037625544\n",
      "Epoch 4, Loss: 0.4114900890173334\n",
      "Epoch 5, Loss: 0.40177580438780064\n",
      "Epoch 6, Loss: 0.3922047252456347\n",
      "Epoch 7, Loss: 0.3846660894877983\n",
      "Epoch 8, Loss: 0.3780958382469235\n",
      "Epoch 9, Loss: 0.3737686013633555\n",
      "Epoch 10, Loss: 0.3655458581266981\n",
      "Epoch 11, Loss: 0.35900824187379893\n",
      "Epoch 12, Loss: 0.3519157300392787\n",
      "Epoch 13, Loss: 0.3455125579779798\n",
      "Epoch 14, Loss: 0.34495123484821033\n",
      "Epoch 15, Loss: 0.33588463149287484\n",
      "Epoch 16, Loss: 0.3304333486791813\n",
      "Epoch 17, Loss: 0.3238913352290789\n",
      "Epoch 18, Loss: 0.31930336324554504\n",
      "Epoch 19, Loss: 0.3132795056610396\n",
      "Epoch 20, Loss: 0.3086204093965617\n",
      "Training finished!\n",
      "Training accuracy : 0.859898904079023\n",
      "Validation Accuracy: 0.7871116225546605\n",
      "Test Accuracy: 0.8860094501718213\n",
      "TL to the participant :  10\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.49247273324113905\n",
      "Epoch 2, Loss: 0.43821548187371456\n",
      "Epoch 3, Loss: 0.4215002043680711\n",
      "Epoch 4, Loss: 0.408388203292182\n",
      "Epoch 5, Loss: 0.3972863695386684\n",
      "Epoch 6, Loss: 0.3899474971222155\n",
      "Epoch 7, Loss: 0.3788561694549792\n",
      "Epoch 8, Loss: 0.37042793554790093\n",
      "Epoch 9, Loss: 0.36268454884940926\n",
      "Epoch 10, Loss: 0.35574395056023744\n",
      "Epoch 11, Loss: 0.350359698768818\n",
      "Epoch 12, Loss: 0.3447939497051817\n",
      "Epoch 13, Loss: 0.33764908191832627\n",
      "Epoch 14, Loss: 0.33264629913098887\n",
      "Epoch 15, Loss: 0.3280182115507848\n",
      "Epoch 16, Loss: 0.32334077882044243\n",
      "Epoch 17, Loss: 0.31737842139872635\n",
      "Epoch 18, Loss: 0.31528456454927273\n",
      "Epoch 19, Loss: 0.310976248347398\n",
      "Epoch 20, Loss: 0.30575261626279715\n",
      "Training finished!\n",
      "Training accuracy : 0.8628983213622075\n",
      "Validation Accuracy: 0.7997676324507232\n",
      "Test Accuracy: 0.7348024054982818\n",
      "TL to the participant :  11\n",
      "balancing the number of ones and zeros\n",
      "(26400, 32, 126)\n",
      "(26400,)\n",
      "(7020, 32, 126)\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.46134163529583905\n",
      "Epoch 2, Loss: 0.41765146616733434\n",
      "Epoch 3, Loss: 0.40377331805048566\n",
      "Epoch 4, Loss: 0.3891389886989738\n",
      "Epoch 5, Loss: 0.3844132066676111\n",
      "Epoch 6, Loss: 0.3731622140064384\n",
      "Epoch 7, Loss: 0.36477362910906475\n",
      "Epoch 8, Loss: 0.3557783212625619\n",
      "Epoch 9, Loss: 0.3505217784281933\n",
      "Epoch 10, Loss: 0.3419313992966305\n",
      "Epoch 11, Loss: 0.3371646228161725\n",
      "Epoch 12, Loss: 0.3287032103448203\n",
      "Epoch 13, Loss: 0.3223350912332535\n",
      "Epoch 14, Loss: 0.31626757929722465\n",
      "Epoch 15, Loss: 0.31264292299747465\n",
      "Epoch 16, Loss: 0.30498993279355946\n",
      "Epoch 17, Loss: 0.2983274812499682\n",
      "Epoch 18, Loss: 0.2931411440173785\n",
      "Epoch 19, Loss: 0.29005255238576366\n",
      "Epoch 20, Loss: 0.28466210067272185\n",
      "Training finished!\n",
      "Training accuracy : 0.8709173105755394\n",
      "Validation Accuracy: 0.8010598499803965\n",
      "Test Accuracy: 0.70446735395189\n",
      "[[0.82079467 0.71545103 0.78105241 0.74281357 0.75396907 0.82133591\n",
      "  0.59280069 0.83199313 0.68923969 0.88600945 0.73480241 0.70446735]]\n",
      "[[396.81742024 330.49021912 329.62686777 330.96017027 331.8104744\n",
      "  339.43271923 334.94549751 329.55192208 328.37579107 329.31285882\n",
      "  342.41585159 365.34910274]]\n",
      "[[3.71236897 3.9116447  3.57160068 3.98849583 3.9431386  3.59917927\n",
      "  4.05959105 3.6279974  3.788867   3.62033057 3.98347259 3.14511776]]\n",
      "[[0.97 0.78 0.97 0.9  0.95 0.93 0.48 0.97 0.87 0.98 0.92 0.72]]\n",
      "[0.82079467 0.71545103 0.78105241 0.74281357 0.75396907 0.82133591\n",
      " 0.59280069 0.83199313 0.68923969 0.88600945 0.73480241 0.70446735]\n",
      "[396.81742024 330.49021912 329.62686777 330.96017027 331.8104744\n",
      " 339.43271923 334.94549751 329.55192208 328.37579107 329.31285882\n",
      " 342.41585159 365.34910274]\n",
      "[3.71236897 3.9116447  3.57160068 3.98849583 3.9431386  3.59917927\n",
      " 4.05959105 3.6279974  3.788867   3.62033057 3.98347259 3.14511776]\n",
      "[0.97 0.78 0.97 0.9  0.95 0.93 0.48 0.97 0.87 0.98 0.92 0.72]\n"
     ]
    }
   ],
   "source": [
    "n_cal = 7\n",
    "n_class = 4\n",
    "nb_fold = 1\n",
    "spdbn_accuracy_code_perso = np.zeros((nb_fold,nb_subject))\n",
    "spdbn_tps_train_code_perso = np.zeros((nb_fold,nb_subject))\n",
    "spdbn_tps_test_code_perso = np.zeros((nb_fold,nb_subject))\n",
    "spdbn_accuracy_perso = np.zeros((nb_fold,nb_subject))\n",
    "\n",
    "for k in range(nb_fold):\n",
    "    for i in range(nb_subject):\n",
    "        print(\"TL to the participant : \", i)\n",
    "        X = X_parent.copy()\n",
    "        Y = Y_parent.copy()\n",
    "        domains = domains_parent.copy()\n",
    "\n",
    "        ## DA\n",
    "        # n_cal = 4\n",
    "        # nb_sample_cal = int(n_class*n_cal*(2.2-window_size)*60)\n",
    "        # ind2take = [j for j in range(len(subjects)) if j!=i]\n",
    "        # X_train = np.concatenate([np.concatenate(X[ind2take]).reshape(-1,X.shape[-2],X.shape[-1]),X[i][:nb_sample_cal]]).reshape(-1,X.shape[-2],X.shape[-1])\n",
    "        # Y_train = np.concatenate([np.concatenate(Y[ind2take]).reshape(-1),Y[i][:nb_sample_cal]]).reshape(-1)\n",
    "        # X_test = X[i][nb_sample_cal:]\n",
    "        # Y_test = Y[i][nb_sample_cal:]\n",
    "        # labels_code_test = labels_codes[i][(n_class*4):]\n",
    "        # domains_train = np.concatenate([np.concatenate(domains[ind2take]).reshape(-1),domains[i][:nb_sample_cal]]).reshape(-1)\n",
    "\n",
    "        ## DG\n",
    "        ind2take = [j for j in range(len(subjects)) if j!=i]\n",
    "        X_train = np.concatenate(X[ind2take]).reshape(-1,X.shape[-2],X.shape[-1])\n",
    "        Y_train = np.concatenate(Y[ind2take]).reshape(-1)\n",
    "        X_test = X[i]\n",
    "        Y_test = Y[i]\n",
    "        labels_code_test = labels_codes[i]\n",
    "        domains_train = np.concatenate(domains[ind2take]).reshape(-1)\n",
    "\n",
    "        ## SS\n",
    "        # nb_sample_cal = int(n_class*n_cal*(2.2-window_size)*60)\n",
    "        # X_train = X[i][:nb_sample_cal]\n",
    "        # Y_train = Y[i][:nb_sample_cal]\n",
    "        # X_test = X[i][nb_sample_cal:]\n",
    "        # Y_test = Y[i][nb_sample_cal:]\n",
    "        # labels_code_test = labels_codes[i][(n_class*n_cal):]\n",
    "        # domains_train = domains[i][:nb_sample_cal]\n",
    "        \n",
    "        # X_std = X_train.std(axis=0)\n",
    "        # X_train /= X_std + 1e-8\n",
    "        # X_std = X_test.std(axis=0)\n",
    "        # X_test /= X_std + 1e-8\n",
    "\n",
    "        xdawn = Xdawn(nfilter=16,classes=[1],estimator='lwf')\n",
    "        xdawn = xdawn.fit(X_train, Y_train)\n",
    "        X_train = xdawn.transform(X_train)\n",
    "        X_test = xdawn.transform(X_test)\n",
    "        X_train = np.hstack([X_train,np.tile(xdawn.evokeds_[None,:,:],(X_train.shape[0],1,1))])\n",
    "        X_test = np.hstack([X_test,np.tile(xdawn.evokeds_[None,:,:],(X_test.shape[0],1,1))])\n",
    "\n",
    "        print(\"balancing the number of ones and zeros\")\n",
    "        X_train, Y_train, domains_train = balance(X_train,Y_train,domains_train)\n",
    "        print(X_train.shape)\n",
    "        print(Y_train.shape)\n",
    "        print(X_test.shape)\n",
    "\n",
    "        print(\"Creating the different pipelines\")\n",
    "        lr = 1e-3\n",
    "        # optimizer = riemannian_adam.RiemannianAdam(learning_rate=lr)\n",
    "        batchsize = 64 #128 # 64 for burst\n",
    "        clf = model\n",
    "\n",
    "        print(\"Fitting\")\n",
    "        start = time.time()\n",
    "        weight_decay = 1e-4\n",
    "        \n",
    "        x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "        # Convert data into PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(x_train, dtype=torch.float64)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "        X_val_tensor = torch.tensor(x_val, dtype=torch.float64)\n",
    "        y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float64)\n",
    "        y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "        # Create DataLoader for train, validation, and test sets\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch_riemannian_adam.RiemannianAdam(clf.parameters(), lr=lr)\n",
    "\n",
    "        # Train the model\n",
    "        num_epochs = 20\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            train_y_pred= []\n",
    "            y_train = []\n",
    "            for inputs, labels in train_dataloader:\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                # print(inputs.shape)\n",
    "                # print(labels.shape)\n",
    "                outputs = clf(inputs)\n",
    "                # print(outputs.get_device())\n",
    "                # print(labels.get_device())\n",
    "\n",
    "                labels = labels.to('cpu')\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_y_pred.append(predicted.to('cpu'))\n",
    "                y_train.append(labels.to('cpu'))\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_dataloader)}\")\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "        print(\"Training accuracy :\", balanced_accuracy_score(np.concatenate(y_train),np.array([1 if (y >= 0.5) else 0 for y in np.concatenate(train_y_pred)])))\n",
    "        spdbn_tps_train_code_perso[k][i] = time.time() - start\n",
    "\n",
    "        # Validation\n",
    "        clf.eval()\n",
    "        val_correct = 0\n",
    "        val_y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                outputs = clf(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predicted = predicted.to('cpu')\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_y_pred.append(predicted)\n",
    "\n",
    "\n",
    "        val_accuracy = balanced_accuracy_score(y_val,np.array([1 if (y >= 0.5) else 0 for y in np.concatenate(val_y_pred)]))#val_correct / len(x_val)\n",
    "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "        # Testing\n",
    "        start = time.time()\n",
    "        test_correct = 0\n",
    "        y_pred= []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                outputs = clf(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predicted = predicted.to('cpu')\n",
    "                y_pred.append(predicted)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        test_accuracy = test_correct / len(X_test)\n",
    "        \n",
    "        # print(\"getting accuracy of participant \", i)\n",
    "        test_y_pred = np.concatenate(y_pred)\n",
    "\n",
    "\n",
    "        # # train \n",
    "        # fitted_clf = clf.fit(x_train,y_train)\n",
    "        # train_y_pred = fitted_clf.predict(x_train)\n",
    "        # y_trainpred_norm = np.array([1 if (y >= 0.5) else 0 for y in train_y_pred])\n",
    "        # y_traintest_norm = np.array([0 if y == 0 else 1 for y in y_train])\n",
    "        # print(\"loss:\",fitted_clf.get_loss(y_trainpred_norm,y_traintest_norm))\n",
    "        # print(\"train accuracy\", balanced_accuracy_score(y_traintest_norm,y_trainpred_norm))\n",
    "\n",
    "        # # validate\n",
    "        # val_y_pred = fitted_clf.predict(x_val)\n",
    "        # y_valpred_norm = np.array([1 if (y >= 0.5) else 0 for y in val_y_pred])\n",
    "        # y_valtest_norm = np.array([0 if y == 0 else 1 for y in y_val])\n",
    "        # print(\"val accuracy\", balanced_accuracy_score(y_valtest_norm,y_valpred_norm))\n",
    "\n",
    "\n",
    "        # # y_pred = np.array(y_pred)\n",
    "        # test_y_pred = fitted_clf.pred(X_test)\n",
    "\n",
    "        y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in test_y_pred])\n",
    "        y_test_norm = np.array([0 if y == 0 else 1 for y in Y_test])\n",
    "\n",
    "        # tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "        spdbn_accuracy_perso[k][i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "        print(f\"Test Accuracy: {spdbn_accuracy_perso[k][i]}\")\n",
    "\n",
    "        labels_pred_accumul, _, mean_long_accumul = make_preds_accumul_aggresive(\n",
    "            y_pred_norm, codes, min_len=30, sfreq=60, consecutive=50, window_size=window_size\n",
    "        )\n",
    "        spdbn_tps_test_code_perso[k][i] = time.time() - start\n",
    "        spdbn_accuracy_code_perso[k][i] = np.round(balanced_accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "        # keras.backend.clear_session()\n",
    "\n",
    "\n",
    "print(spdbn_accuracy_perso)\n",
    "print(spdbn_tps_train_code_perso)\n",
    "print(spdbn_tps_test_code_perso)\n",
    "print(spdbn_accuracy_code_perso)\n",
    "\n",
    "spdbn_accuracy_perso = np.mean(spdbn_accuracy_perso,axis=0)\n",
    "spdbn_tps_train_code_perso = np.mean(spdbn_tps_train_code_perso,axis=0)\n",
    "spdbn_tps_test_code_perso = np.mean(spdbn_tps_test_code_perso,axis=0)\n",
    "spdbn_accuracy_code_perso = np.mean(spdbn_accuracy_code_perso,axis=0)\n",
    "\n",
    "print(spdbn_accuracy_perso)\n",
    "print(spdbn_tps_train_code_perso)\n",
    "print(spdbn_tps_test_code_perso)\n",
    "print(spdbn_accuracy_code_perso)\n",
    "# np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/SPDbnNet/score/WO1_score\",spdbn_accuracy_perso)\n",
    "# np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/SPDbnNet/score_code/WO1_score_code\",spdbn_accuracy_code_perso)\n",
    "# np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/SPDbnNet/temps_train_code/WO1_tps_train_code\",spdbn_tps_train_code_perso)\n",
    "# np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/SPDbnNet/temps_test_code/WO1_tps_test_code\",spdbn_tps_test_code_perso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/GREEN/score/DG_score\",spdbn_accuracy_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/GREEN/score_code/DG_score_code\",spdbn_accuracy_code_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/GREEN/temps_train_code/DG_tps_train_code\",spdbn_tps_train_code_perso)\n",
    "np.save(\"C:/Users/s.velut/Documents/These/Protheus_PHD/results/results/Score_TF/GREEN/temps_test_code/DG_tps_test_code\",spdbn_tps_test_code_perso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riemann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
