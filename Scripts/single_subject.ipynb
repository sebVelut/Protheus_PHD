{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de10f24-829d-4847-b79b-7d4d282eb5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Scripts.EEG2CodeKeras import (basearchi,\n",
    "                           basearchitest_batchnorm,\n",
    "                           basearchi_patchembedding,\n",
    "                           basearchi_patchembeddingdilation,\n",
    "                           trueVanilliaEEG2Code,\n",
    "                           vanilliaEEG2Code,\n",
    "                           vanilliaEEG2Code2,\n",
    "                           EEGnet_Inception)\n",
    "from Scripts._utils import make_preds_accumul_aggresive, make_preds_pvalue\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.classification import MDM\n",
    "from tensorflow import keras\n",
    "import mne\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbff77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "575c7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 60\n",
    "sfreq = 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e15184-3fcf-463d-89b7-97e4e6db7a95",
   "metadata": {},
   "source": [
    "## Path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c5a06b-e9fd-42d7-bf0c-83d8d68b707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 500\n",
    "\n",
    "participant = 'P12'\n",
    "path = '/'.join(['C:\\\\Users\\\\s.velut\\\\Documents\\\\These\\\\Protheus_PHD\\\\Class4', participant])\n",
    "# path = '/home/dcas/k.cabrera/Data/SETNOP2'\n",
    "n_class=4\n",
    "fps = 60\n",
    "window_size = 0.25\n",
    "\n",
    "# file_name = '_'.join([participant, 'mseq40.set'])\n",
    "# file_name = '_'.join([participant, 'mseq100.set'])\n",
    "# file_name = '_'.join([participant, 'burst40.set'])\n",
    "file_name = '_'.join([participant, 'burst100.set'])\n",
    "# file_name = '/'.join([path,  participant+'_whitemseq.set'])\n",
    "# file_name = '_'.join([participant, 'burst', 'oi_1.set'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d909114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# participant = 'P3'\n",
    "# path = '/home/dcas/k.cabrera/Data/SET'\n",
    "# n_class=11\n",
    "\n",
    "\n",
    "# file_name = '_'.join([participant, 'whitemseq.set'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f830cb-fdc0-4d83-b0e3-3107ac016368",
   "metadata": {},
   "source": [
    "#### Load channel positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ede9c-040e-4590-94b2-577a62a9b026",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the raw data and small pre-process\n",
    "1. Drop the ACC channels and the shitty channels near ears\n",
    "2. Average re-referencing\n",
    "4. Extract 2.2s epochs using events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8df747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_eeglab(os.path.join(path, file_name), preload=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e02a0323-b237-4b92-b5ed-ded4930f3cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'F9', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'P9', 'O1', 'Oz', 'O2', 'P10', 'P8', 'P4', 'CP2', 'CP6', 'T8', 'C4', 'Cz', 'FC2', 'FC6', 'F10', 'F8', 'F4', 'Fp2']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 50 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 49.90, 50.10 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Channels : 32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(raw.ch_names)\n",
    "# to_drop = [\"P9\", \"P10\", \"TP9\", \"TP10\", \"10\", \"21\"]\n",
    "# raw = raw.drop_channels([ch for ch in raw.ch_names if ch in to_drop])\n",
    "# # raw = raw.drop_channels([\"10\", \"21\"])\n",
    "# keep = [\"O1\", \"O2\", \"Oz\", \"P7\", \"P3\", \"P4\", \"P8\", \"Pz\"]\n",
    "# keep = [\"16\", \"18\", \"17\", \"15\", \"14\", \"19\", \"20\", \"13\"] # electrodes to keep\n",
    "# raw = raw.drop_channels([i for i in raw.ch_names if i not in keep])\n",
    "\n",
    "raw = raw.filter(l_freq=50.1, h_freq=49.9, method=\"iir\", verbose=True)\n",
    "# raw.resample(480, npad='auto')\n",
    "# Average re-referencing\n",
    "mne.set_eeg_reference(raw, 'average', copy=False, verbose=False)\n",
    "#raw = raw.filter(l_freq=5, h_freq=45, method=\"fir\", verbose=True)\n",
    "n_channels = len(raw.ch_names)\n",
    "print(\"Channels :\", n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e70fa4b-2e51-42fe-a41a-0b7c29ea6bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 60 events and 1101 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# Strip the annotations that were script to make them easier to process\n",
    "events, event_id = mne.events_from_annotations(raw, event_id='auto', verbose=False)\n",
    "to_remove = []\n",
    "for idx in range(len(raw.annotations.description)):\n",
    "    if (('collects' in raw.annotations.description[idx]) or\n",
    "        ('iti' in raw.annotations.description[idx]) or\n",
    "        (raw.annotations.description[idx] == '[]')):\n",
    "        to_remove.append(idx)\n",
    "    else:\n",
    "        code = raw.annotations.description[idx].split('_')[0]\n",
    "        lab = raw.annotations.description[idx].split('_')[1]\n",
    "        code = code.replace('\\n', '')\n",
    "        code = code.replace('[', '')\n",
    "        code = code.replace(']', '')\n",
    "        code = code.replace(' ', '')\n",
    "        raw.annotations.description[idx] = code + '_' + lab\n",
    "\n",
    "to_remove = np.array(to_remove)\n",
    "if len(to_remove) > 0:\n",
    "    raw.annotations.delete(to_remove)\n",
    "# Get the events\n",
    "events, event_id = mne.events_from_annotations(raw, event_id='auto', verbose=False)\n",
    "shift = 0.0\n",
    "# Epoch the data following event\n",
    "epochs = mne.Epochs(raw, events, event_id=event_id, tmin=shift, \\\n",
    "            tmax=2.2+shift, baseline=(None, None), preload=False, verbose=False)\n",
    "labels = epochs.events[..., -1]\n",
    "labels -= np.min(labels)\n",
    "data = epochs.get_data()\n",
    "info_ep = epochs.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec5d54-21ce-4a3e-9974-dff0d81efe65",
   "metadata": {},
   "source": [
    "### Transform a code in `str` to a code in np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d886a37-bc66-490c-a290-f84b2502c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code2array(code):\n",
    "    tmp = []\n",
    "    for idx, c in enumerate(code[:-2]):\n",
    "        if c == '5' or c == '.':\n",
    "            continue\n",
    "        elif c == '0':\n",
    "            if code[idx+2] == '5':\n",
    "                tmp.append(0.5)\n",
    "            else:\n",
    "                tmp.append(0)\n",
    "        else:\n",
    "            tmp.append(1)\n",
    "    if code[-1] == '.':\n",
    "        if code[-2] == '0':\n",
    "            tmp.append(0)\n",
    "        else:\n",
    "            tmp.append(1)\n",
    "    return np.array(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f02ea8-255b-4d46-9f64-8263ef253089",
   "metadata": {},
   "source": [
    "### Build a dictionnary that contains all the code in the np.array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e221464-c67a-468d-bedc-1cb4592d032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "codes = OrderedDict()\n",
    "for k, v in event_id.items():\n",
    "    code = k.split('_')[0]\n",
    "    code = code.replace('.','').replace('2','')\n",
    "    idx = k.split('_')[1]\n",
    "    if 'randomslowwhite' in file_name:\n",
    "        codes[v-1] = code2array(code) \n",
    "    else:\n",
    "        codes[v-1] = np.array(list(map(int, code)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f84de91-a554-4326-8c67-f1ad891597d5",
   "metadata": {},
   "source": [
    "### Define train/test split and windows size\n",
    "Here we use only the first 7 blocks as calibrition and 8 others would be used as testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e12df7eb-a999-4f84-8b58-6c5503e5feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = int(epochs.info['sfreq'])\n",
    "n_samples_windows = int(window_size*sfreq)\n",
    "n_trial_per_class = int(len(data)/n_class)\n",
    "\n",
    "n_cal = 7\n",
    "\n",
    "\n",
    "data_train = data[:n_class*n_cal]\n",
    "labels_train = labels[:n_class*n_cal]\n",
    "data_test = data[n_class*n_cal:]\n",
    "labels_test = labels[n_class*n_cal:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c34c29-78b0-4da1-ac2c-b18150cb175e",
   "metadata": {},
   "source": [
    "### Slice the epoch in windows\n",
    "The network is not processing full epochs but windows of 250ms. So each epoch is cut into window and the following code (`0` or `1`) is associated as label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec58decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_window_old(data, labels):\n",
    "    length = int((2.2-window_size)*sfreq)\n",
    "    X = np.empty(shape=((length)*data.shape[0], n_channels, n_samples_windows))\n",
    "    y = np.empty(shape=((length)*data.shape[0]), dtype=int)\n",
    "    print(length)\n",
    "    print(n_samples_windows)\n",
    "    count = 0\n",
    "    for trial_nb, trial in enumerate(data):\n",
    "        lab = labels[trial_nb]\n",
    "        c = codes[lab]\n",
    "        code_pos = 0\n",
    "        for idx in range(length):\n",
    "            X[count] = trial[:, idx:idx+n_samples_windows]\n",
    "            if idx/sfreq >= (code_pos+1)/fps:\n",
    "                code_pos += 1 \n",
    "            y[count] = int(c[code_pos])\n",
    "            count += 1\n",
    "\n",
    "    X = np.expand_dims(X, 1)\n",
    "    X = X.astype(np.float32)\n",
    "    y = np.vstack((y,np.abs(1-y))).T\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b888b955-2c47-4dcd-b51f-438442a0d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_window(data, labels, win_size, data_freq, code_freq, offset=0,\n",
    "              focus_rising=None, pre_rising=0, post_rising=0,\n",
    "              focus_falling=None, pre_falling=0, post_falling=0):\n",
    "    length = int((2.2-win_size)*data_freq)\n",
    "    X = np.empty(shape=((length)*data.shape[0], n_channels, n_samples_windows))\n",
    "    Y = np.empty(shape=((length)*data.shape[0]), dtype=int)\n",
    "    for trial_nb, trial in enumerate(data):\n",
    "        lab = labels[trial_nb]\n",
    "        c = codes[lab]\n",
    "        labels_upsampled = np.repeat(c, sfreq//code_freq)\n",
    "        labels_upsampled = np.concatenate((np.zeros(int(offset*data_freq), dtype=int), np.array(labels_upsampled)))\n",
    "        if (focus_rising is not None) or (focus_falling is not None):\n",
    "            hi_indices = []\n",
    "            low_indices = []\n",
    "            for idx in range(1, len(labels_upsampled)):\n",
    "                if (focus_rising is not None) and (labels_upsampled[idx-1] == 0) and (labels_upsampled[idx] == 1):\n",
    "                    hi_indices.append(idx)\n",
    "                elif (focus_falling is not None) and (labels_upsampled[idx-1] == 1) and (labels_upsampled[idx] == 0):\n",
    "                    low_indices.append(idx)\n",
    "            focused_labels = np.zeros(length)\n",
    "            pre_rising_frames = int(sfreq*pre_rising)\n",
    "            post_rising_frames = int(sfreq*post_rising)\n",
    "            pre_falling_frames = int(sfreq*pre_falling)\n",
    "            post_falling_frames = int(sfreq*post_falling)\n",
    "            for idx in hi_indices:\n",
    "                focused_labels[idx-pre_rising_frames:idx+post_rising_frames+1] = 1\n",
    "            for idx in low_indices:\n",
    "                focused_labels[idx-pre_falling_frames:idx+post_falling_frames+1] = 1\n",
    "        else:\n",
    "            focused_labels = labels_upsampled.copy()\n",
    "            \n",
    "        for idx in range(length):\n",
    "            # print('Xidx:', trial_nb*length+idx, \"Tidxm:\", idx, 'TidxM:', idx +\n",
    "            #       n_samples_windows, 'Ltrial', trial[:, idx:idx+n_samples_windows].shape)\n",
    "            X[trial_nb*length+idx] = trial[:, idx:idx+n_samples_windows]\n",
    "            Y[trial_nb*length+idx] = focused_labels[idx]\n",
    "    X = np.expand_dims(X, 1)\n",
    "    X = X.astype(np.float32)\n",
    "    Y = np.vstack((Y,np.abs(1-Y))).T\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23dc6e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 32, 1101)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50bfe6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975\n",
      "125\n",
      "975\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "window_size = 0.25\n",
    "# X, Y = to_window_old(np.array(data_train[:1]), labels_train[:1])\n",
    "# X_train, Y_train = to_window_old(data_train, labels_train)\n",
    "# X_test, Y_test = to_window_old(data_test, labels_test)\n",
    "# print(Y[:,0])\n",
    "X_train, Y_train = to_window_old(data_train, labels_train)#, 0.25, sfreq, 60)\n",
    "X_test, Y_test = to_window_old(data_test, labels_test)#, 0.25, sfreq, 60)\n",
    "# print(codes[labels_train[0]])\n",
    "# print(np.array(Y_train[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d7b89-7b58-44f9-ab45-3b1ef1ea713e",
   "metadata": {},
   "source": [
    "### Normalization using stats from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2ab8195-3775-47c4-8a16-953fac6636a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = X_train.std(axis=0)\n",
    "X_train /= X_std + 1e-8\n",
    "X_std = X_test.std(axis=0)\n",
    "X_test /= X_std + 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e1ba06-f21d-4ecf-9cd5-8387736a4508",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Balance classes\n",
    "Our classes are unbalanced, there are more `1` than `0` in the train set (the stimulation is more often ON than OFF).  \n",
    "We will use a random under sampler to make it balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "692240c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27300, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "(27300, 2)\n",
      "4676\n",
      "(31200, 2)\n",
      "5344\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(len(Y_train[Y_train[:, 0] == 1]))\n",
    "print(Y_test.shape)\n",
    "print(len(Y_test[Y_test[:, 0] == 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44030563-1570-4eb3-b112-6b630d449e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rus = RandomUnderSampler()\n",
    "counter=np.array(range(0,len(Y_train))).reshape(-1,1)\n",
    "index,_ = rus.fit_resample(counter,Y_train[:,0])\n",
    "X_train = np.squeeze(X_train[index,:,:,:], axis=1)\n",
    "Y_train = np.squeeze(Y_train[index])\n",
    "# rus = RandomUnderSampler()\n",
    "# counter=np.array(range(0,len(Y_test))).reshape(-1,1)\n",
    "# index,_ = rus.fit_resample(counter,Y_test[:,0])\n",
    "# X_test = np.squeeze(X_test[index,:,:,:], axis=1)\n",
    "# Y_test = np.squeeze(Y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44336b40-3e06-4c69-9858-2b696853ea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9352, 1, 32, 125)\n",
      "(9352, 2)\n",
      "(31200, 1, 32, 125)\n",
      "(31200, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38de3569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4676\n",
      "4676\n",
      "25856\n",
      "5344\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train[Y_train[:,0] == 0]))\n",
    "print(len(Y_train[Y_train[:,0] == 1]))\n",
    "print(len(Y_test[Y_test[:,0] == 0]))\n",
    "print(len(Y_test[Y_test[:,0] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37542174-788c-4128-ae21-94cf344b15d1",
   "metadata": {},
   "source": [
    "### Pick an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    InputLayer,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    "    Permute,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    BatchNormalization,\n",
    "    LayerNormalization,\n",
    "    Dropout,\n",
    "    LeakyReLU,\n",
    "    Activation,\n",
    "    SeparableConv2D,\n",
    "    DepthwiseConv2D,\n",
    "    SpatialDropout2D,\n",
    "    Softmax,\n",
    "    Add,\n",
    "    GlobalAveragePooling2D,\n",
    "    concatenate\n",
    ")\n",
    "from tensorflow_addons.layers import GELU, Sparsemax\n",
    "\n",
    "def basearchiTest(n_channel_input, windows_size):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(1, n_channel_input, windows_size)))\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            16,\n",
    "            kernel_size=(n_channel_input, 1),\n",
    "            padding=\"valid\",\n",
    "            strides=(1, 1),\n",
    "            data_format=\"channels_first\",\n",
    "            kernel_initializer=\"he_uniform\",\n",
    "            activation=None,\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization(axis=1, scale=True, center=False))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),\n",
    "              padding=\"same\", data_format=\"channels_first\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            8,\n",
    "            kernel_size=(1, 32),\n",
    "            dilation_rate=(1, 2),\n",
    "            data_format=\"channels_first\",\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_uniform\",\n",
    "            activation=None,\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization(axis=1, scale=True, center=False))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding=\"same\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    # model.add(\n",
    "    #     Conv2D(\n",
    "    #         4,\n",
    "    #         kernel_size=(5, 5),\n",
    "    #         dilation_rate=(2, 2),\n",
    "    #         data_format=\"channels_first\",\n",
    "    #         padding=\"same\",\n",
    "    #         kernel_initializer=\"he_uniform\",\n",
    "    #         activation=None,\n",
    "    #     )\n",
    "    # )\n",
    "    # model.add(BatchNormalization(axis=1, scale=True, center=False))\n",
    "    # model.add(LeakyReLU(alpha=0.3))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "    #           data_format=\"channels_first\", padding=\"same\"))\n",
    "    # model.add(Dropout(0.5))\n",
    "    # model.add(Flatten())\n",
    "    # model.add(Dense(int(256), activation=None))\n",
    "    # model.add(LeakyReLU(alpha=0.3))\n",
    "    # model.add(Dense(2, name=\"preds\", activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0727580-c7d6-498a-a90c-467e07da91b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "293/293 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9352, 8, 1, 63)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  clf = basearchi_patchembedding(windows_size = n_samples_windows, n_channel_input = n_channels) # other stim\n",
    "# clf = basearchi_patchembeddingdilation(windows_size = n_samples_windows, n_channel_input = n_channels) # burst\n",
    "# clf = vanilliaEEG2Code(windows_size = n_samples_windows, n_channel_input = n_channels) # burst\n",
    "# clf = trueVanilliaEEG2Code(windows_size = n_samples_windows, n_channel_input = n_channels) # burst\n",
    "# clf = basearchitest(windows_size = n_samples_windows, n_channel_input = n_channels)\n",
    "#c lf = basearchitest_batchnorm(windows_size = n_samples_windows, n_channel_input = n_channels)\n",
    "# clf = EEGnet_Inception(windows_size = n_samples_windows, n_channel_input = n_channels)\n",
    "# clf = basearchi(windows_size = n_samples_windows, n_channel_input = n_channels)\n",
    "clf = basearchiTest(windows_size = n_samples_windows, n_channel_input = n_channels)\n",
    "\n",
    "# clf.summary()\n",
    "pred = clf.predict(X_train)\n",
    "np.array(pred).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL to the participant :  0\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6800844822869156\n",
      "Epoch 2, Loss: 0.6362742722937555\n",
      "Epoch 3, Loss: 0.5920952201792689\n",
      "Epoch 4, Loss: 0.5595734462593541\n",
      "Epoch 5, Loss: 0.5291543043021\n",
      "Epoch 6, Loss: 0.5047485893874457\n",
      "Epoch 7, Loss: 0.4811313554193034\n",
      "Epoch 8, Loss: 0.4653357560887481\n",
      "Epoch 9, Loss: 0.44498562722495105\n",
      "Epoch 10, Loss: 0.43808446982593247\n",
      "Epoch 11, Loss: 0.4230556013909253\n",
      "Epoch 12, Loss: 0.42166664541670773\n",
      "Epoch 13, Loss: 0.4065099417260199\n",
      "Epoch 14, Loss: 0.41020679338411853\n",
      "Epoch 15, Loss: 0.39778093406648346\n",
      "Epoch 16, Loss: 0.3975639080233646\n",
      "Epoch 17, Loss: 0.39309776292154286\n",
      "Epoch 18, Loss: 0.38176313934452605\n",
      "Epoch 19, Loss: 0.37917667616045836\n",
      "Epoch 20, Loss: 0.38070535185662185\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8899379410325479\n",
      "Test Accuracy: 0.6263586302024664\n",
      "getting accuracy of participant  0\n",
      "TL to the participant :  1\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6848251431277304\n",
      "Epoch 2, Loss: 0.626134532419118\n",
      "Epoch 3, Loss: 0.5870462954044342\n",
      "Epoch 4, Loss: 0.5540321476080201\n",
      "Epoch 5, Loss: 0.5335737189108675\n",
      "Epoch 6, Loss: 0.513635876955408\n",
      "Epoch 7, Loss: 0.4923283552581614\n",
      "Epoch 8, Loss: 0.4809692917448102\n",
      "Epoch 9, Loss: 0.4744417319695155\n",
      "Epoch 10, Loss: 0.45341143373287085\n",
      "Epoch 11, Loss: 0.45021076082731737\n",
      "Epoch 12, Loss: 0.4387219089901809\n",
      "Epoch 13, Loss: 0.4314850747133746\n",
      "Epoch 14, Loss: 0.4276374519774408\n",
      "Epoch 15, Loss: 0.4276356046850031\n",
      "Epoch 16, Loss: 0.424710200817296\n",
      "Epoch 17, Loss: 0.41487316595333995\n",
      "Epoch 18, Loss: 0.42026812944448355\n",
      "Epoch 19, Loss: 0.4124640646305951\n",
      "Epoch 20, Loss: 0.4079293502551137\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8826321782834774\n",
      "Test Accuracy: 0.6306274363401909\n",
      "getting accuracy of participant  1\n",
      "TL to the participant :  2\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6999341452663596\n",
      "Epoch 2, Loss: 0.6405903778292916\n",
      "Epoch 3, Loss: 0.5867967777179949\n",
      "Epoch 4, Loss: 0.5518518148949652\n",
      "Epoch 5, Loss: 0.5205769782716577\n",
      "Epoch 6, Loss: 0.49683866491823486\n",
      "Epoch 7, Loss: 0.4819736239133459\n",
      "Epoch 8, Loss: 0.4770627369483312\n",
      "Epoch 9, Loss: 0.4591556387868794\n",
      "Epoch 10, Loss: 0.44937392798337067\n",
      "Epoch 11, Loss: 0.44214010306380014\n",
      "Epoch 12, Loss: 0.43605626893766\n",
      "Epoch 13, Loss: 0.4335677366365086\n",
      "Epoch 14, Loss: 0.4235778816721656\n",
      "Epoch 15, Loss: 0.41785362724101904\n",
      "Epoch 16, Loss: 0.41375177534240665\n",
      "Epoch 17, Loss: 0.40988404484409274\n",
      "Epoch 18, Loss: 0.3971046891176339\n",
      "Epoch 19, Loss: 0.39716132391582837\n",
      "Epoch 20, Loss: 0.38746594332835893\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8838646684624285\n",
      "Test Accuracy: 0.6478786702584929\n",
      "getting accuracy of participant  2\n",
      "TL to the participant :  3\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7416162138635461\n",
      "Epoch 2, Loss: 0.66614174210664\n",
      "Epoch 3, Loss: 0.6236416191765757\n",
      "Epoch 4, Loss: 0.5865876444361426\n",
      "Epoch 5, Loss: 0.551253618164496\n",
      "Epoch 6, Loss: 0.5269463509321213\n",
      "Epoch 7, Loss: 0.4996985833753239\n",
      "Epoch 8, Loss: 0.48635800431172055\n",
      "Epoch 9, Loss: 0.4731072584788005\n",
      "Epoch 10, Loss: 0.4650164174311089\n",
      "Epoch 11, Loss: 0.4450430924242193\n",
      "Epoch 12, Loss: 0.4474177234100573\n",
      "Epoch 13, Loss: 0.43615980356028583\n",
      "Epoch 14, Loss: 0.4340448332103816\n",
      "Epoch 15, Loss: 0.4250550620032079\n",
      "Epoch 16, Loss: 0.4104353352026506\n",
      "Epoch 17, Loss: 0.4170095455465895\n",
      "Epoch 18, Loss: 0.4172415848482739\n",
      "Epoch 19, Loss: 0.4122697017861135\n",
      "Epoch 20, Loss: 0.4028656223055088\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8245930953110494\n",
      "Test Accuracy: 0.633063197552914\n",
      "getting accuracy of participant  3\n",
      "TL to the participant :  4\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7100057913498445\n",
      "Epoch 2, Loss: 0.6297618250052134\n",
      "Epoch 3, Loss: 0.5941667771249106\n",
      "Epoch 4, Loss: 0.5654494356025349\n",
      "Epoch 5, Loss: 0.5348060571334579\n",
      "Epoch 6, Loss: 0.5197002106543743\n",
      "Epoch 7, Loss: 0.5081265254905729\n",
      "Epoch 8, Loss: 0.49341460181908176\n",
      "Epoch 9, Loss: 0.4835149855776267\n",
      "Epoch 10, Loss: 0.47236301614479587\n",
      "Epoch 11, Loss: 0.47013907089377893\n",
      "Epoch 12, Loss: 0.4587029959216262\n",
      "Epoch 13, Loss: 0.45037607397093915\n",
      "Epoch 14, Loss: 0.43866601970159647\n",
      "Epoch 15, Loss: 0.44789047606966714\n",
      "Epoch 16, Loss: 0.4328134179566846\n",
      "Epoch 17, Loss: 0.4270146744269313\n",
      "Epoch 18, Loss: 0.42588606092965964\n",
      "Epoch 19, Loss: 0.4182048184853612\n",
      "Epoch 20, Loss: 0.4177822888349042\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8567430246543768\n",
      "Test Accuracy: 0.6216522323545978\n",
      "getting accuracy of participant  4\n",
      "TL to the participant :  5\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6857169252453428\n",
      "Epoch 2, Loss: 0.6317159876678929\n",
      "Epoch 3, Loss: 0.59069906762152\n",
      "Epoch 4, Loss: 0.5623407551284992\n",
      "Epoch 5, Loss: 0.5402224698301518\n",
      "Epoch 6, Loss: 0.51809524654439\n",
      "Epoch 7, Loss: 0.49614630910483276\n",
      "Epoch 8, Loss: 0.4857569388819463\n",
      "Epoch 9, Loss: 0.4683920673348687\n",
      "Epoch 10, Loss: 0.4608672091906721\n",
      "Epoch 11, Loss: 0.44556288014758716\n",
      "Epoch 12, Loss: 0.4384982123067885\n",
      "Epoch 13, Loss: 0.4403201142946879\n",
      "Epoch 14, Loss: 0.43282318702249817\n",
      "Epoch 15, Loss: 0.4240593092911171\n",
      "Epoch 16, Loss: 0.43211219256574457\n",
      "Epoch 17, Loss: 0.4163490908615517\n",
      "Epoch 18, Loss: 0.399298105050217\n",
      "Epoch 19, Loss: 0.41149497935266205\n",
      "Epoch 20, Loss: 0.40368516607718036\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8254048467276128\n",
      "Test Accuracy: 0.6238496861475069\n",
      "getting accuracy of participant  5\n",
      "TL to the participant :  6\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6950732826283483\n",
      "Epoch 2, Loss: 0.6377659376823541\n",
      "Epoch 3, Loss: 0.6034128340807828\n",
      "Epoch 4, Loss: 0.5665847769740856\n",
      "Epoch 5, Loss: 0.540580555570848\n",
      "Epoch 6, Loss: 0.5224339108575474\n",
      "Epoch 7, Loss: 0.49897608522212866\n",
      "Epoch 8, Loss: 0.490558048992446\n",
      "Epoch 9, Loss: 0.4718660542910749\n",
      "Epoch 10, Loss: 0.47347106671694555\n",
      "Epoch 11, Loss: 0.47409110787239944\n",
      "Epoch 12, Loss: 0.45901605712644983\n",
      "Epoch 13, Loss: 0.46626523408022796\n",
      "Epoch 14, Loss: 0.46371691425641376\n",
      "Epoch 15, Loss: 0.45761436314293835\n",
      "Epoch 16, Loss: 0.4432002276633725\n",
      "Epoch 17, Loss: 0.4500611729242585\n",
      "Epoch 18, Loss: 0.43744119301889883\n",
      "Epoch 19, Loss: 0.42944120051282825\n",
      "Epoch 20, Loss: 0.42617859917156625\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8745215239889693\n",
      "Test Accuracy: 0.6366110600581016\n",
      "getting accuracy of participant  6\n",
      "TL to the participant :  7\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6914113493579807\n",
      "Epoch 2, Loss: 0.647908553481102\n",
      "Epoch 3, Loss: 0.6180226531895724\n",
      "Epoch 4, Loss: 0.5852713223659631\n",
      "Epoch 5, Loss: 0.5630816442496849\n",
      "Epoch 6, Loss: 0.5336007489399477\n",
      "Epoch 7, Loss: 0.5177149641694445\n",
      "Epoch 8, Loss: 0.49529536948962644\n",
      "Epoch 9, Loss: 0.4823144900076317\n",
      "Epoch 10, Loss: 0.4655599679910775\n",
      "Epoch 11, Loss: 0.45823746445504104\n",
      "Epoch 12, Loss: 0.4442043988542123\n",
      "Epoch 13, Loss: 0.44072300398891623\n",
      "Epoch 14, Loss: 0.43740482063907565\n",
      "Epoch 15, Loss: 0.42414536914139084\n",
      "Epoch 16, Loss: 0.41274570560816565\n",
      "Epoch 17, Loss: 0.40719676062916266\n",
      "Epoch 18, Loss: 0.396134117110209\n",
      "Epoch 19, Loss: 0.39604174063512776\n",
      "Epoch 20, Loss: 0.39491180364381184\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8717890086571574\n",
      "Test Accuracy: 0.6551610578348254\n",
      "getting accuracy of participant  7\n",
      "TL to the participant :  8\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7001066072420641\n",
      "Epoch 2, Loss: 0.6515601801149773\n",
      "Epoch 3, Loss: 0.6237433033459114\n",
      "Epoch 4, Loss: 0.5875710397958755\n",
      "Epoch 5, Loss: 0.5567509252013583\n",
      "Epoch 6, Loss: 0.5325890978177389\n",
      "Epoch 7, Loss: 0.5028175813230601\n",
      "Epoch 8, Loss: 0.49253475508003525\n",
      "Epoch 9, Loss: 0.4812866835431619\n",
      "Epoch 10, Loss: 0.4644601900469173\n",
      "Epoch 11, Loss: 0.44767673607125424\n",
      "Epoch 12, Loss: 0.45168509650411026\n",
      "Epoch 13, Loss: 0.4505459855903279\n",
      "Epoch 14, Loss: 0.4338558350097049\n",
      "Epoch 15, Loss: 0.4332251485550042\n",
      "Epoch 16, Loss: 0.4208822534842925\n",
      "Epoch 17, Loss: 0.42549943923950195\n",
      "Epoch 18, Loss: 0.41938709038676636\n",
      "Epoch 19, Loss: 0.41604666287700337\n",
      "Epoch 20, Loss: 0.41877841994617926\n",
      "Training finished!\n",
      "Validation Accuracy: 0.857241508622858\n",
      "Test Accuracy: 0.6269696837760124\n",
      "getting accuracy of participant  8\n",
      "TL to the participant :  9\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.681644466790286\n",
      "Epoch 2, Loss: 0.6331109092994169\n",
      "Epoch 3, Loss: 0.5911391546780412\n",
      "Epoch 4, Loss: 0.5583518086509272\n",
      "Epoch 5, Loss: 0.5266477296298201\n",
      "Epoch 6, Loss: 0.5068825104019858\n",
      "Epoch 7, Loss: 0.5004573423754085\n",
      "Epoch 8, Loss: 0.48698234083977615\n",
      "Epoch 9, Loss: 0.464207417585633\n",
      "Epoch 10, Loss: 0.46602190918091574\n",
      "Epoch 11, Loss: 0.4513118402524428\n",
      "Epoch 12, Loss: 0.4462389695373448\n",
      "Epoch 13, Loss: 0.4397324555073724\n",
      "Epoch 14, Loss: 0.4357913716724425\n",
      "Epoch 15, Loss: 0.4355453180544304\n",
      "Epoch 16, Loss: 0.42284823231624835\n",
      "Epoch 17, Loss: 0.4310612594991019\n",
      "Epoch 18, Loss: 0.41819501713369833\n",
      "Epoch 19, Loss: 0.4003151156234019\n",
      "Epoch 20, Loss: 0.4126488055017861\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8623200998797236\n",
      "Test Accuracy: 0.6292688061377245\n",
      "getting accuracy of participant  9\n",
      "TL to the participant :  10\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7343119464137338\n",
      "Epoch 2, Loss: 0.6504179189602534\n",
      "Epoch 3, Loss: 0.6037408815640392\n",
      "Epoch 4, Loss: 0.5734551122242754\n",
      "Epoch 5, Loss: 0.5474851305286089\n",
      "Epoch 6, Loss: 0.5277711349454793\n",
      "Epoch 7, Loss: 0.5140066508090857\n",
      "Epoch 8, Loss: 0.4975662628809611\n",
      "Epoch 9, Loss: 0.48650558744416095\n",
      "Epoch 10, Loss: 0.47456642330595944\n",
      "Epoch 11, Loss: 0.4669518001151807\n",
      "Epoch 12, Loss: 0.4606178163579016\n",
      "Epoch 13, Loss: 0.46239773522723804\n",
      "Epoch 14, Loss: 0.4415086451353449\n",
      "Epoch 15, Loss: 0.4405456894274914\n",
      "Epoch 16, Loss: 0.43170231061451364\n",
      "Epoch 17, Loss: 0.4309318555575429\n",
      "Epoch 18, Loss: 0.42862423238429154\n",
      "Epoch 19, Loss: 0.4223168215742617\n",
      "Epoch 20, Loss: 0.4241361125852122\n",
      "Training finished!\n",
      "Validation Accuracy: 0.7949744584131746\n",
      "Test Accuracy: 0.5753542420110275\n",
      "getting accuracy of participant  10\n",
      "TL to the participant :  11\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6838252011573676\n",
      "Epoch 2, Loss: 0.6310451577107111\n",
      "Epoch 3, Loss: 0.589816897204428\n",
      "Epoch 4, Loss: 0.5684921811475898\n",
      "Epoch 5, Loss: 0.5448128079826181\n",
      "Epoch 6, Loss: 0.5278092024452758\n",
      "Epoch 7, Loss: 0.5089824782176451\n",
      "Epoch 8, Loss: 0.4836067667964733\n",
      "Epoch 9, Loss: 0.47224584086374805\n",
      "Epoch 10, Loss: 0.46986283858617145\n",
      "Epoch 11, Loss: 0.4519101379044128\n",
      "Epoch 12, Loss: 0.4536864493380893\n",
      "Epoch 13, Loss: 0.4407981943451997\n",
      "Epoch 14, Loss: 0.4335887524666208\n",
      "Epoch 15, Loss: 0.42887662159222545\n",
      "Epoch 16, Loss: 0.41974751922217285\n",
      "Epoch 17, Loss: 0.42273462450865545\n",
      "Epoch 18, Loss: 0.4144053314671372\n",
      "Epoch 19, Loss: 0.4068461505301071\n",
      "Epoch 20, Loss: 0.40358705908963177\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8842831206011077\n",
      "Test Accuracy: 0.6431257225647715\n",
      "getting accuracy of participant  11\n",
      "TL to the participant :  0\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7006645943179275\n",
      "Epoch 2, Loss: 0.6389421080098008\n",
      "Epoch 3, Loss: 0.5934419670339787\n",
      "Epoch 4, Loss: 0.5549102565555861\n",
      "Epoch 5, Loss: 0.5208498677521041\n",
      "Epoch 6, Loss: 0.5083631272568847\n",
      "Epoch 7, Loss: 0.48242170612017315\n",
      "Epoch 8, Loss: 0.4766985796617739\n",
      "Epoch 9, Loss: 0.4540493300918377\n",
      "Epoch 10, Loss: 0.4459185767354387\n",
      "Epoch 11, Loss: 0.4362639326489333\n",
      "Epoch 12, Loss: 0.42239637763211224\n",
      "Epoch 13, Loss: 0.4277613865155162\n",
      "Epoch 14, Loss: 0.42024599196332874\n",
      "Epoch 15, Loss: 0.413991703228517\n",
      "Epoch 16, Loss: 0.41320416647376434\n",
      "Epoch 17, Loss: 0.40288866017804004\n",
      "Epoch 18, Loss: 0.39670399034565146\n",
      "Epoch 19, Loss: 0.4023093457023303\n",
      "Epoch 20, Loss: 0.3903242284149835\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8931597938380065\n",
      "Test Accuracy: 0.6240615921622102\n",
      "getting accuracy of participant  0\n",
      "TL to the participant :  1\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6885091978492159\n",
      "Epoch 2, Loss: 0.6337914525559454\n",
      "Epoch 3, Loss: 0.5888056061936148\n",
      "Epoch 4, Loss: 0.5552682659842751\n",
      "Epoch 5, Loss: 0.5252706313675101\n",
      "Epoch 6, Loss: 0.5058651182687643\n",
      "Epoch 7, Loss: 0.4847853059569995\n",
      "Epoch 8, Loss: 0.4808402086297671\n",
      "Epoch 9, Loss: 0.4592385348497015\n",
      "Epoch 10, Loss: 0.45178701344764594\n",
      "Epoch 11, Loss: 0.44027205127658264\n",
      "Epoch 12, Loss: 0.4455609554142663\n",
      "Epoch 13, Loss: 0.4329492002725601\n",
      "Epoch 14, Loss: 0.42550502582029864\n",
      "Epoch 15, Loss: 0.4161156802014871\n",
      "Epoch 16, Loss: 0.41903267891118023\n",
      "Epoch 17, Loss: 0.4144975278865207\n",
      "Epoch 18, Loss: 0.4081661400921417\n",
      "Epoch 19, Loss: 0.41084174224824616\n",
      "Epoch 20, Loss: 0.40374353550600284\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8650206024796148\n",
      "Test Accuracy: 0.6159946891489299\n",
      "getting accuracy of participant  1\n",
      "TL to the participant :  2\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6856755790385333\n",
      "Epoch 2, Loss: 0.6312731775370511\n",
      "Epoch 3, Loss: 0.58390453006282\n",
      "Epoch 4, Loss: 0.5504506864782536\n",
      "Epoch 5, Loss: 0.5256257079767458\n",
      "Epoch 6, Loss: 0.5049039992419156\n",
      "Epoch 7, Loss: 0.4868373642816688\n",
      "Epoch 8, Loss: 0.471932796366287\n",
      "Epoch 9, Loss: 0.46968147881103284\n",
      "Epoch 10, Loss: 0.447431432929906\n",
      "Epoch 11, Loss: 0.44513796868197847\n",
      "Epoch 12, Loss: 0.43493542526707507\n",
      "Epoch 13, Loss: 0.42485926187399664\n",
      "Epoch 14, Loss: 0.41885819534460705\n",
      "Epoch 15, Loss: 0.4134467607646277\n",
      "Epoch 16, Loss: 0.4127995175394145\n",
      "Epoch 17, Loss: 0.39818208009907696\n",
      "Epoch 18, Loss: 0.40712691098451614\n",
      "Epoch 19, Loss: 0.3982888793177677\n",
      "Epoch 20, Loss: 0.3947538607048266\n",
      "Training finished!\n",
      "Validation Accuracy: 0.783475027782478\n",
      "Test Accuracy: 0.5573365567750638\n",
      "getting accuracy of participant  2\n",
      "TL to the participant :  3\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6958527050235055\n",
      "Epoch 2, Loss: 0.6415343203327872\n",
      "Epoch 3, Loss: 0.6027656680706776\n",
      "Epoch 4, Loss: 0.569792597582846\n",
      "Epoch 5, Loss: 0.5428126307599472\n",
      "Epoch 6, Loss: 0.520690236353513\n",
      "Epoch 7, Loss: 0.5091321077762228\n",
      "Epoch 8, Loss: 0.4900356007344795\n",
      "Epoch 9, Loss: 0.48288760153633176\n",
      "Epoch 10, Loss: 0.4715545518380223\n",
      "Epoch 11, Loss: 0.4627596471797336\n",
      "Epoch 12, Loss: 0.45065067663337244\n",
      "Epoch 13, Loss: 0.4362630138568806\n",
      "Epoch 14, Loss: 0.4322260602405577\n",
      "Epoch 15, Loss: 0.4222516898404468\n",
      "Epoch 16, Loss: 0.43266442079435696\n",
      "Epoch 17, Loss: 0.40899449135317945\n",
      "Epoch 18, Loss: 0.4129834755352049\n",
      "Epoch 19, Loss: 0.39859003697832424\n",
      "Epoch 20, Loss: 0.4201270687309178\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8536789488848137\n",
      "Test Accuracy: 0.6218309050216398\n",
      "getting accuracy of participant  3\n",
      "TL to the participant :  4\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6819600553223581\n",
      "Epoch 2, Loss: 0.6232426500681675\n",
      "Epoch 3, Loss: 0.5904930306203438\n",
      "Epoch 4, Loss: 0.5603173293850638\n",
      "Epoch 5, Loss: 0.5264048070618601\n",
      "Epoch 6, Loss: 0.5048981135090193\n",
      "Epoch 7, Loss: 0.4900934255935929\n",
      "Epoch 8, Loss: 0.46938174375981995\n",
      "Epoch 9, Loss: 0.4523439806970683\n",
      "Epoch 10, Loss: 0.45131788673726\n",
      "Epoch 11, Loss: 0.44364697260387015\n",
      "Epoch 12, Loss: 0.44651642148241855\n",
      "Epoch 13, Loss: 0.4247934127395803\n",
      "Epoch 14, Loss: 0.417105175103202\n",
      "Epoch 15, Loss: 0.41125204052888986\n",
      "Epoch 16, Loss: 0.41330523201913544\n",
      "Epoch 17, Loss: 0.4120310043746775\n",
      "Epoch 18, Loss: 0.40708956754568854\n",
      "Epoch 19, Loss: 0.3994821209573384\n",
      "Epoch 20, Loss: 0.3933684646405957\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8781938416650279\n",
      "Test Accuracy: 0.6165488870649789\n",
      "getting accuracy of participant  4\n",
      "TL to the participant :  5\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6833195623123285\n",
      "Epoch 2, Loss: 0.634571629040169\n",
      "Epoch 3, Loss: 0.5972627423929445\n",
      "Epoch 4, Loss: 0.5600905007485187\n",
      "Epoch 5, Loss: 0.5333212038332765\n",
      "Epoch 6, Loss: 0.5159136709390264\n",
      "Epoch 7, Loss: 0.4903105269327308\n",
      "Epoch 8, Loss: 0.4727715231252439\n",
      "Epoch 9, Loss: 0.4615542263244138\n",
      "Epoch 10, Loss: 0.44892082431099634\n",
      "Epoch 11, Loss: 0.43704674618713785\n",
      "Epoch 12, Loss: 0.43291317468339746\n",
      "Epoch 13, Loss: 0.434722285379063\n",
      "Epoch 14, Loss: 0.422364511273124\n",
      "Epoch 15, Loss: 0.40932089056481014\n",
      "Epoch 16, Loss: 0.41770796635837265\n",
      "Epoch 17, Loss: 0.4088053436893405\n",
      "Epoch 18, Loss: 0.3992381309243766\n",
      "Epoch 19, Loss: 0.39420236579396506\n",
      "Epoch 20, Loss: 0.39759561825882306\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8733370529078994\n",
      "Test Accuracy: 0.6060418226047903\n",
      "getting accuracy of participant  5\n",
      "TL to the participant :  6\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6851411398613092\n",
      "Epoch 2, Loss: 0.6342507049892888\n",
      "Epoch 3, Loss: 0.5906776011441693\n",
      "Epoch 4, Loss: 0.5595784092491324\n",
      "Epoch 5, Loss: 0.5385861166498878\n",
      "Epoch 6, Loss: 0.5171414412783853\n",
      "Epoch 7, Loss: 0.5035801886609106\n",
      "Epoch 8, Loss: 0.49212071818835806\n",
      "Epoch 9, Loss: 0.4775491562305075\n",
      "Epoch 10, Loss: 0.47139860779950116\n",
      "Epoch 11, Loss: 0.4648919663194454\n",
      "Epoch 12, Loss: 0.45911263448722434\n",
      "Epoch 13, Loss: 0.494858069627574\n",
      "Epoch 14, Loss: 0.4557768991499236\n",
      "Epoch 15, Loss: 0.4556654876831806\n",
      "Epoch 16, Loss: 0.4382935324401567\n",
      "Epoch 17, Loss: 0.4290159389828191\n",
      "Epoch 18, Loss: 0.42203825441273773\n",
      "Epoch 19, Loss: 0.43071153285828506\n",
      "Epoch 20, Loss: 0.41626084110502043\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8300741323406338\n",
      "Test Accuracy: 0.6088346975603249\n",
      "getting accuracy of participant  6\n",
      "TL to the participant :  7\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.735850503950408\n",
      "Epoch 2, Loss: 0.6439936355207906\n",
      "Epoch 3, Loss: 0.5883328659516393\n",
      "Epoch 4, Loss: 0.5503679132371238\n",
      "Epoch 5, Loss: 0.5229594897140156\n",
      "Epoch 6, Loss: 0.5023336722092195\n",
      "Epoch 7, Loss: 0.48946395245465363\n",
      "Epoch 8, Loss: 0.46687939018011093\n",
      "Epoch 9, Loss: 0.4627763884085597\n",
      "Epoch 10, Loss: 0.4519675283720999\n",
      "Epoch 11, Loss: 0.4526416106205998\n",
      "Epoch 12, Loss: 0.4377869347279722\n",
      "Epoch 13, Loss: 0.4399294327154304\n",
      "Epoch 14, Loss: 0.43029663282813446\n",
      "Epoch 15, Loss: 0.4297981363805858\n",
      "Epoch 16, Loss: 0.42665877667340363\n",
      "Epoch 17, Loss: 0.4246829915227312\n",
      "Epoch 18, Loss: 0.42450113707419596\n",
      "Epoch 19, Loss: 0.4157248173247684\n",
      "Epoch 20, Loss: 0.4098111400098512\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8315650109986601\n",
      "Test Accuracy: 0.6032567059568981\n",
      "getting accuracy of participant  7\n",
      "TL to the participant :  8\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6913892680948431\n",
      "Epoch 2, Loss: 0.6291488386464842\n",
      "Epoch 3, Loss: 0.5885619259241855\n",
      "Epoch 4, Loss: 0.5579601207917387\n",
      "Epoch 5, Loss: 0.5416983463095896\n",
      "Epoch 6, Loss: 0.5235978292696404\n",
      "Epoch 7, Loss: 0.506424484605139\n",
      "Epoch 8, Loss: 0.49404537271369586\n",
      "Epoch 9, Loss: 0.484657369779818\n",
      "Epoch 10, Loss: 0.4802101597641454\n",
      "Epoch 11, Loss: 0.4679203767216567\n",
      "Epoch 12, Loss: 0.451983638559327\n",
      "Epoch 13, Loss: 0.4603403181289182\n",
      "Epoch 14, Loss: 0.44550850558461563\n",
      "Epoch 15, Loss: 0.443237318008235\n",
      "Epoch 16, Loss: 0.4510726847431876\n",
      "Epoch 17, Loss: 0.42720699084527564\n",
      "Epoch 18, Loss: 0.4509649714737227\n",
      "Epoch 19, Loss: 0.41459026142503275\n",
      "Epoch 20, Loss: 0.4206046098560998\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8570197061231211\n",
      "Test Accuracy: 0.630332736445426\n",
      "getting accuracy of participant  8\n",
      "TL to the participant :  9\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6778150431134484\n",
      "Epoch 2, Loss: 0.6257582681648659\n",
      "Epoch 3, Loss: 0.5883572871486346\n",
      "Epoch 4, Loss: 0.5612520869031097\n",
      "Epoch 5, Loss: 0.531110073129336\n",
      "Epoch 6, Loss: 0.5148118072838495\n",
      "Epoch 7, Loss: 0.49946411992564343\n",
      "Epoch 8, Loss: 0.4842770515066205\n",
      "Epoch 9, Loss: 0.4715911380269311\n",
      "Epoch 10, Loss: 0.46469784031311673\n",
      "Epoch 11, Loss: 0.4522821693257852\n",
      "Epoch 12, Loss: 0.44770726584123843\n",
      "Epoch 13, Loss: 0.4418721596399943\n",
      "Epoch 14, Loss: 0.4358205745617549\n",
      "Epoch 15, Loss: 0.42588136638655805\n",
      "Epoch 16, Loss: 0.41211887607068726\n",
      "Epoch 17, Loss: 0.41577760739759967\n",
      "Epoch 18, Loss: 0.411694833162156\n",
      "Epoch 19, Loss: 0.4050183273626096\n",
      "Epoch 20, Loss: 0.4008474176128705\n",
      "Training finished!\n",
      "Validation Accuracy: 0.882979745087189\n",
      "Test Accuracy: 0.6303428106657971\n",
      "getting accuracy of participant  9\n",
      "TL to the participant :  10\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7745049148797989\n",
      "Epoch 2, Loss: 0.649111839406418\n",
      "Epoch 3, Loss: 0.5955210000728116\n",
      "Epoch 4, Loss: 0.5531673921328603\n",
      "Epoch 5, Loss: 0.5380417442683018\n",
      "Epoch 6, Loss: 0.5117670466954057\n",
      "Epoch 7, Loss: 0.4972273307767781\n",
      "Epoch 8, Loss: 0.4796180964419336\n",
      "Epoch 9, Loss: 0.46228014068170026\n",
      "Epoch 10, Loss: 0.4555387634671096\n",
      "Epoch 11, Loss: 0.44497542015530844\n",
      "Epoch 12, Loss: 0.4440704383181803\n",
      "Epoch 13, Loss: 0.43395974419333716\n",
      "Epoch 14, Loss: 0.44046667940688855\n",
      "Epoch 15, Loss: 0.4477798035650542\n",
      "Epoch 16, Loss: 0.4240847932118358\n",
      "Epoch 17, Loss: 0.48787393578977295\n",
      "Epoch 18, Loss: 0.4486211109341997\n",
      "Epoch 19, Loss: 0.42253881151025946\n",
      "Epoch 20, Loss: 0.44012504838632815\n",
      "Training finished!\n",
      "Validation Accuracy: 0.802527176522777\n",
      "Test Accuracy: 0.6309881397477323\n",
      "getting accuracy of participant  10\n",
      "TL to the participant :  11\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6912399981961106\n",
      "Epoch 2, Loss: 0.636147217317061\n",
      "Epoch 3, Loss: 0.5934759098472018\n",
      "Epoch 4, Loss: 0.5619783132816806\n",
      "Epoch 5, Loss: 0.532985116947781\n",
      "Epoch 6, Loss: 0.5167429510391119\n",
      "Epoch 7, Loss: 0.49036776500217844\n",
      "Epoch 8, Loss: 0.482095290991393\n",
      "Epoch 9, Loss: 0.45934457580248517\n",
      "Epoch 10, Loss: 0.4616712706558632\n",
      "Epoch 11, Loss: 0.43889706514098425\n",
      "Epoch 12, Loss: 0.43204159131555847\n",
      "Epoch 13, Loss: 0.4352767704562707\n",
      "Epoch 14, Loss: 0.4289060167290948\n",
      "Epoch 15, Loss: 0.4186676223621224\n",
      "Epoch 16, Loss: 0.4164440543814139\n",
      "Epoch 17, Loss: 0.41454359753565356\n",
      "Epoch 18, Loss: 0.4086114533922889\n",
      "Epoch 19, Loss: 0.4085138180490696\n",
      "Epoch 20, Loss: 0.4088193388147788\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8423144290529261\n",
      "Test Accuracy: 0.6331638239609889\n",
      "getting accuracy of participant  11\n",
      "TL to the participant :  0\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6743461769638639\n",
      "Epoch 2, Loss: 0.6108740324323828\n",
      "Epoch 3, Loss: 0.5761510391126979\n",
      "Epoch 4, Loss: 0.5433393470717199\n",
      "Epoch 5, Loss: 0.5239000304630308\n",
      "Epoch 6, Loss: 0.5030666862924894\n",
      "Epoch 7, Loss: 0.4899176158236735\n",
      "Epoch 8, Loss: 0.4744205506462039\n",
      "Epoch 9, Loss: 0.4644620262763717\n",
      "Epoch 10, Loss: 0.44489698947379086\n",
      "Epoch 11, Loss: 0.4375194062789281\n",
      "Epoch 12, Loss: 0.4413624887890888\n",
      "Epoch 13, Loss: 0.4300562696474971\n",
      "Epoch 14, Loss: 0.4179961554931872\n",
      "Epoch 15, Loss: 0.41778706601171783\n",
      "Epoch 16, Loss: 0.412281126687021\n",
      "Epoch 17, Loss: 0.4003137092698704\n",
      "Epoch 18, Loss: 0.40311963777198934\n",
      "Epoch 19, Loss: 0.40581405049923697\n",
      "Epoch 20, Loss: 0.39666015135519433\n",
      "Training finished!\n",
      "Validation Accuracy: 0.861380297535477\n",
      "Test Accuracy: 0.6069746722520306\n",
      "getting accuracy of participant  0\n",
      "TL to the participant :  1\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7371290213230884\n",
      "Epoch 2, Loss: 0.6715490425174887\n",
      "Epoch 3, Loss: 0.6413609096498201\n",
      "Epoch 4, Loss: 0.6102728961092053\n",
      "Epoch 5, Loss: 0.5793295563621954\n",
      "Epoch 6, Loss: 0.5531801254008756\n",
      "Epoch 7, Loss: 0.5303806174885143\n",
      "Epoch 8, Loss: 0.5115863321857019\n",
      "Epoch 9, Loss: 0.4989808176954587\n",
      "Epoch 10, Loss: 0.47678899719859613\n",
      "Epoch 11, Loss: 0.4713683652155327\n",
      "Epoch 12, Loss: 0.4607048328175689\n",
      "Epoch 13, Loss: 0.4605148373679681\n",
      "Epoch 14, Loss: 0.4422593123533509\n",
      "Epoch 15, Loss: 0.4478664885867726\n",
      "Epoch 16, Loss: 0.4378352844805429\n",
      "Epoch 17, Loss: 0.4254317484570272\n",
      "Epoch 18, Loss: 0.4176958115263419\n",
      "Epoch 19, Loss: 0.4190516742792996\n",
      "Epoch 20, Loss: 0.41206220040718716\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8144976516374512\n",
      "Test Accuracy: 0.5846434837626726\n",
      "getting accuracy of participant  1\n",
      "TL to the participant :  2\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6809688671068712\n",
      "Epoch 2, Loss: 0.6160615930954615\n",
      "Epoch 3, Loss: 0.5751443062767838\n",
      "Epoch 4, Loss: 0.537397230664889\n",
      "Epoch 5, Loss: 0.5133164843375032\n",
      "Epoch 6, Loss: 0.49282858859408984\n",
      "Epoch 7, Loss: 0.4780927720395001\n",
      "Epoch 8, Loss: 0.46329016012675833\n",
      "Epoch 9, Loss: 0.449417449082389\n",
      "Epoch 10, Loss: 0.4402139342643998\n",
      "Epoch 11, Loss: 0.42844088420723425\n",
      "Epoch 12, Loss: 0.42706325379284943\n",
      "Epoch 13, Loss: 0.42129396985877643\n",
      "Epoch 14, Loss: 0.40859508514404297\n",
      "Epoch 15, Loss: 0.4060942820753112\n",
      "Epoch 16, Loss: 0.40566153214736417\n",
      "Epoch 17, Loss: 0.3977818258784034\n",
      "Epoch 18, Loss: 0.3940006589347666\n",
      "Epoch 19, Loss: 0.3881624343268799\n",
      "Epoch 20, Loss: 0.39591302609804907\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8843540059360752\n",
      "Test Accuracy: 0.6209435630595245\n",
      "getting accuracy of participant  2\n",
      "TL to the participant :  3\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6750680334640272\n",
      "Epoch 2, Loss: 0.6130829403797785\n",
      "Epoch 3, Loss: 0.5797965853954806\n",
      "Epoch 4, Loss: 0.5348813219955473\n",
      "Epoch 5, Loss: 0.5127514882972746\n",
      "Epoch 6, Loss: 0.49425927007740195\n",
      "Epoch 7, Loss: 0.478471232408827\n",
      "Epoch 8, Loss: 0.4694250654993635\n",
      "Epoch 9, Loss: 0.46338381279598584\n",
      "Epoch 10, Loss: 0.4519779169649789\n",
      "Epoch 11, Loss: 0.44573008314226614\n",
      "Epoch 12, Loss: 0.430519184831417\n",
      "Epoch 13, Loss: 0.4358084806890199\n",
      "Epoch 14, Loss: 0.41799703579057346\n",
      "Epoch 15, Loss: 0.4108011982206142\n",
      "Epoch 16, Loss: 0.4146727316758849\n",
      "Epoch 17, Loss: 0.40875924198013364\n",
      "Epoch 18, Loss: 0.39510563670685794\n",
      "Epoch 19, Loss: 0.4010744266437762\n",
      "Epoch 20, Loss: 0.39771274319200806\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8689147226554104\n",
      "Test Accuracy: 0.6606544028280074\n",
      "getting accuracy of participant  3\n",
      "TL to the participant :  4\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.677792697241812\n",
      "Epoch 2, Loss: 0.6265955048077034\n",
      "Epoch 3, Loss: 0.5846063995903189\n",
      "Epoch 4, Loss: 0.5530436163147291\n",
      "Epoch 5, Loss: 0.5341918147874601\n",
      "Epoch 6, Loss: 0.5052289648941068\n",
      "Epoch 7, Loss: 0.48807853663509543\n",
      "Epoch 8, Loss: 0.47568252637530817\n",
      "Epoch 9, Loss: 0.4574981690807776\n",
      "Epoch 10, Loss: 0.44888155117179407\n",
      "Epoch 11, Loss: 0.43787185847759247\n",
      "Epoch 12, Loss: 0.4298950743043061\n",
      "Epoch 13, Loss: 0.4182347734317635\n",
      "Epoch 14, Loss: 0.4141828706770232\n",
      "Epoch 15, Loss: 0.40468648967869353\n",
      "Epoch 16, Loss: 0.4054925780404698\n",
      "Epoch 17, Loss: 0.39829146816874994\n",
      "Epoch 18, Loss: 0.38910696655511856\n",
      "Epoch 19, Loss: 0.38849194031773193\n",
      "Epoch 20, Loss: 0.3798979517411102\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8789758669733791\n",
      "Test Accuracy: 0.5992838734659394\n",
      "getting accuracy of participant  4\n",
      "TL to the participant :  5\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6831221097346508\n",
      "Epoch 2, Loss: 0.6257372575275826\n",
      "Epoch 3, Loss: 0.5831793289292942\n",
      "Epoch 4, Loss: 0.5524873397115505\n",
      "Epoch 5, Loss: 0.5351949760859663\n",
      "Epoch 6, Loss: 0.5050041149511482\n",
      "Epoch 7, Loss: 0.49250778917110327\n",
      "Epoch 8, Loss: 0.47808141938664694\n",
      "Epoch 9, Loss: 0.4639029304186503\n",
      "Epoch 10, Loss: 0.4567439942197366\n",
      "Epoch 11, Loss: 0.44366747773054876\n",
      "Epoch 12, Loss: 0.43313937069791736\n",
      "Epoch 13, Loss: 0.4281384816223925\n",
      "Epoch 14, Loss: 0.4196011279568528\n",
      "Epoch 15, Loss: 0.41776158141367364\n",
      "Epoch 16, Loss: 0.41468580089735263\n",
      "Epoch 17, Loss: 0.4070222446638526\n",
      "Epoch 18, Loss: 0.40857247579278366\n",
      "Epoch 19, Loss: 0.3979136828671802\n",
      "Epoch 20, Loss: 0.39111576477686566\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8831695348550052\n",
      "Test Accuracy: 0.603308929788937\n",
      "getting accuracy of participant  5\n",
      "TL to the participant :  6\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7170181007999362\n",
      "Epoch 2, Loss: 0.6453519219701941\n",
      "Epoch 3, Loss: 0.6087182195800723\n",
      "Epoch 4, Loss: 0.5747194734938217\n",
      "Epoch 5, Loss: 0.5486468492132245\n",
      "Epoch 6, Loss: 0.5286269323392347\n",
      "Epoch 7, Loss: 0.5157384019006382\n",
      "Epoch 8, Loss: 0.4984729064233375\n",
      "Epoch 9, Loss: 0.48885827059998654\n",
      "Epoch 10, Loss: 0.47400781896078226\n",
      "Epoch 11, Loss: 0.4571911268162005\n",
      "Epoch 12, Loss: 0.4468037197084138\n",
      "Epoch 13, Loss: 0.4498244146957542\n",
      "Epoch 14, Loss: 0.43856836674791394\n",
      "Epoch 15, Loss: 0.4327343627810478\n",
      "Epoch 16, Loss: 0.42786961951942154\n",
      "Epoch 17, Loss: 0.4198752400098425\n",
      "Epoch 18, Loss: 0.42054350787039957\n",
      "Epoch 19, Loss: 0.41094095575990097\n",
      "Epoch 20, Loss: 0.407217029820789\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8793074274111303\n",
      "Test Accuracy: 0.6270441403702496\n",
      "getting accuracy of participant  6\n",
      "TL to the participant :  7\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6984958422906471\n",
      "Epoch 2, Loss: 0.6317679769161976\n",
      "Epoch 3, Loss: 0.5951636718078093\n",
      "Epoch 4, Loss: 0.5622569977334051\n",
      "Epoch 5, Loss: 0.5338757677060185\n",
      "Epoch 6, Loss: 0.514780900469332\n",
      "Epoch 7, Loss: 0.5015675942554618\n",
      "Epoch 8, Loss: 0.49381472937988513\n",
      "Epoch 9, Loss: 0.4767421698479941\n",
      "Epoch 10, Loss: 0.4544116563417695\n",
      "Epoch 11, Loss: 0.4448026479645209\n",
      "Epoch 12, Loss: 0.43117345305103244\n",
      "Epoch 13, Loss: 0.4348423523884831\n",
      "Epoch 14, Loss: 0.429193878038363\n",
      "Epoch 15, Loss: 0.41886204255349707\n",
      "Epoch 16, Loss: 0.4104169678281654\n",
      "Epoch 17, Loss: 0.4064713915189107\n",
      "Epoch 18, Loss: 0.4045995697379112\n",
      "Epoch 19, Loss: 0.40067358552054927\n",
      "Epoch 20, Loss: 0.39277150617404416\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8738263903815461\n",
      "Test Accuracy: 0.6376392095141401\n",
      "getting accuracy of participant  7\n",
      "TL to the participant :  8\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6988351010915005\n",
      "Epoch 2, Loss: 0.6604015908458016\n",
      "Epoch 3, Loss: 0.6330198921037443\n",
      "Epoch 4, Loss: 0.5996494677030679\n",
      "Epoch 5, Loss: 0.5668709668697733\n",
      "Epoch 6, Loss: 0.5525820248506286\n",
      "Epoch 7, Loss: 0.5266255537668864\n",
      "Epoch 8, Loss: 0.5059395138964509\n",
      "Epoch 9, Loss: 0.4891020820447893\n",
      "Epoch 10, Loss: 0.4807078434210835\n",
      "Epoch 11, Loss: 0.4738973690704866\n",
      "Epoch 12, Loss: 0.46816415746103635\n",
      "Epoch 13, Loss: 0.47302554028503824\n",
      "Epoch 14, Loss: 0.47739707520513824\n",
      "Epoch 15, Loss: 0.4465744477329832\n",
      "Epoch 16, Loss: 0.43970874561504886\n",
      "Epoch 17, Loss: 0.4622175917029381\n",
      "Epoch 18, Loss: 0.47366386663281557\n",
      "Epoch 19, Loss: 0.4882425128510504\n",
      "Epoch 20, Loss: 0.4371355478510712\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8356877935453186\n",
      "Test Accuracy: 0.6048699707639177\n",
      "getting accuracy of participant  8\n",
      "TL to the participant :  9\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.686798843922037\n",
      "Epoch 2, Loss: 0.645484086690527\n",
      "Epoch 3, Loss: 0.6072035034497579\n",
      "Epoch 4, Loss: 0.5632478100332347\n",
      "Epoch 5, Loss: 0.5354262479778492\n",
      "Epoch 6, Loss: 0.5096352798017588\n",
      "Epoch 7, Loss: 0.49009706396045105\n",
      "Epoch 8, Loss: 0.47307416299978894\n",
      "Epoch 9, Loss: 0.4634971033894654\n",
      "Epoch 10, Loss: 0.44816480283484317\n",
      "Epoch 11, Loss: 0.4408624851793954\n",
      "Epoch 12, Loss: 0.42191080500682193\n",
      "Epoch 13, Loss: 0.42141961148290924\n",
      "Epoch 14, Loss: 0.41842184441559244\n",
      "Epoch 15, Loss: 0.40688229961828754\n",
      "Epoch 16, Loss: 0.404314830786351\n",
      "Epoch 17, Loss: 0.4004434665495699\n",
      "Epoch 18, Loss: 0.3959011456957369\n",
      "Epoch 19, Loss: 0.38536307554353366\n",
      "Epoch 20, Loss: 0.391694984201229\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8949845195574926\n",
      "Test Accuracy: 0.6060508546644335\n",
      "getting accuracy of participant  9\n",
      "TL to the participant :  10\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7099705731326883\n",
      "Epoch 2, Loss: 0.635655754443371\n",
      "Epoch 3, Loss: 0.5936548502156229\n",
      "Epoch 4, Loss: 0.5587096510059906\n",
      "Epoch 5, Loss: 0.5319983126087622\n",
      "Epoch 6, Loss: 0.5115721934672558\n",
      "Epoch 7, Loss: 0.5051707521532521\n",
      "Epoch 8, Loss: 0.4875194796107032\n",
      "Epoch 9, Loss: 0.48027006378679565\n",
      "Epoch 10, Loss: 0.47243863840897876\n",
      "Epoch 11, Loss: 0.455465117187211\n",
      "Epoch 12, Loss: 0.45270428919430933\n",
      "Epoch 13, Loss: 0.4469781235763521\n",
      "Epoch 14, Loss: 0.4355719525254134\n",
      "Epoch 15, Loss: 0.4292323724790053\n",
      "Epoch 16, Loss: 0.4264501134554545\n",
      "Epoch 17, Loss: 0.4188627921270602\n",
      "Epoch 18, Loss: 0.4111603627150709\n",
      "Epoch 19, Loss: 0.4113591019854401\n",
      "Epoch 20, Loss: 0.3968723254899184\n",
      "Training finished!\n",
      "Validation Accuracy: 0.872136575460869\n",
      "Test Accuracy: 0.6660603221156697\n",
      "getting accuracy of participant  10\n",
      "TL to the participant :  11\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6765311328750668\n",
      "Epoch 2, Loss: 0.627883435198755\n",
      "Epoch 3, Loss: 0.5804890689976288\n",
      "Epoch 4, Loss: 0.5452305385560701\n",
      "Epoch 5, Loss: 0.528982782905752\n",
      "Epoch 6, Loss: 0.5111485999641996\n",
      "Epoch 7, Loss: 0.49869282656546793\n",
      "Epoch 8, Loss: 0.4811886729616107\n",
      "Epoch 9, Loss: 0.47623279510122357\n",
      "Epoch 10, Loss: 0.4592108539108074\n",
      "Epoch 11, Loss: 0.44714747008049127\n",
      "Epoch 12, Loss: 0.4437472899303292\n",
      "Epoch 13, Loss: 0.4354142417961901\n",
      "Epoch 14, Loss: 0.424859866725676\n",
      "Epoch 15, Loss: 0.4259667247533798\n",
      "Epoch 16, Loss: 0.4195815733436382\n",
      "Epoch 17, Loss: 0.42064595944953687\n",
      "Epoch 18, Loss: 0.41272491510167264\n",
      "Epoch 19, Loss: 0.4101004233640252\n",
      "Epoch 20, Loss: 0.3990017349521319\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8493915294311338\n",
      "Test Accuracy: 0.6353355711226063\n",
      "getting accuracy of participant  11\n",
      "TL to the participant :  0\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7481099710319982\n",
      "Epoch 2, Loss: 0.6808213555451595\n",
      "Epoch 3, Loss: 0.6586671543843818\n",
      "Epoch 4, Loss: 0.6457056935989496\n",
      "Epoch 5, Loss: 0.6268320476466959\n",
      "Epoch 6, Loss: 0.6063633782394005\n",
      "Epoch 7, Loss: 0.5743111022042505\n",
      "Epoch 8, Loss: 0.5342384357795571\n",
      "Epoch 9, Loss: 0.5162253842660876\n",
      "Epoch 10, Loss: 0.4915727230184006\n",
      "Epoch 11, Loss: 0.4793119694698941\n",
      "Epoch 12, Loss: 0.4657346714626659\n",
      "Epoch 13, Loss: 0.45726708390495996\n",
      "Epoch 14, Loss: 0.4419208004167586\n",
      "Epoch 15, Loss: 0.43839297263008176\n",
      "Epoch 16, Loss: 0.43684071573344146\n",
      "Epoch 17, Loss: 0.4291221984859669\n",
      "Epoch 18, Loss: 0.4271238631371296\n",
      "Epoch 19, Loss: 0.42118006628571136\n",
      "Epoch 20, Loss: 0.41252853585915134\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8856413750840335\n",
      "Test Accuracy: 0.6572116827607162\n",
      "getting accuracy of participant  0\n",
      "TL to the participant :  1\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7137976884841919\n",
      "Epoch 2, Loss: 0.637616571151849\n",
      "Epoch 3, Loss: 0.592815340694153\n",
      "Epoch 4, Loss: 0.5650644234635613\n",
      "Epoch 5, Loss: 0.5398084239074679\n",
      "Epoch 6, Loss: 0.5259676763054096\n",
      "Epoch 7, Loss: 0.506621234796264\n",
      "Epoch 8, Loss: 0.4923927307580457\n",
      "Epoch 9, Loss: 0.48530799692327325\n",
      "Epoch 10, Loss: 0.4687146052266612\n",
      "Epoch 11, Loss: 0.462271100192359\n",
      "Epoch 12, Loss: 0.44999647546898236\n",
      "Epoch 13, Loss: 0.4546300802718509\n",
      "Epoch 14, Loss: 0.45294721492312173\n",
      "Epoch 15, Loss: 0.4439316270026294\n",
      "Epoch 16, Loss: 0.42933943325823004\n",
      "Epoch 17, Loss: 0.437019877587304\n",
      "Epoch 18, Loss: 0.42618128047748044\n",
      "Epoch 19, Loss: 0.4248346948262417\n",
      "Epoch 20, Loss: 0.42019429915782175\n",
      "Training finished!\n",
      "Validation Accuracy: 0.7276654029259637\n",
      "Test Accuracy: 0.5919548202481176\n",
      "getting accuracy of participant  1\n",
      "TL to the participant :  2\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6841325561205546\n",
      "Epoch 2, Loss: 0.6317816670193817\n",
      "Epoch 3, Loss: 0.5850318069710876\n",
      "Epoch 4, Loss: 0.5609614923596382\n",
      "Epoch 5, Loss: 0.5372622385621071\n",
      "Epoch 6, Loss: 0.5171421608238509\n",
      "Epoch 7, Loss: 0.5010449723763899\n",
      "Epoch 8, Loss: 0.4794200446569558\n",
      "Epoch 9, Loss: 0.4723484337781415\n",
      "Epoch 10, Loss: 0.44854754638491257\n",
      "Epoch 11, Loss: 0.4468596318002903\n",
      "Epoch 12, Loss: 0.4418708835587357\n",
      "Epoch 13, Loss: 0.4271032999862324\n",
      "Epoch 14, Loss: 0.4227804552876588\n",
      "Epoch 15, Loss: 0.4085340730168603\n",
      "Epoch 16, Loss: 0.4117245993605166\n",
      "Epoch 17, Loss: 0.4098814624277028\n",
      "Epoch 18, Loss: 0.39212441805637244\n",
      "Epoch 19, Loss: 0.3872072978904753\n",
      "Epoch 20, Loss: 0.3883170213437442\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8790147395764258\n",
      "Test Accuracy: 0.6156261116381099\n",
      "getting accuracy of participant  2\n",
      "TL to the participant :  3\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7240776284174486\n",
      "Epoch 2, Loss: 0.6496465133898186\n",
      "Epoch 3, Loss: 0.5957995808937333\n",
      "Epoch 4, Loss: 0.5636032311753794\n",
      "Epoch 5, Loss: 0.5281877668969559\n",
      "Epoch 6, Loss: 0.5036486972010497\n",
      "Epoch 7, Loss: 0.4951146746223623\n",
      "Epoch 8, Loss: 0.4724590606761701\n",
      "Epoch 9, Loss: 0.46341298497987515\n",
      "Epoch 10, Loss: 0.4522936016772733\n",
      "Epoch 11, Loss: 0.45326699090726447\n",
      "Epoch 12, Loss: 0.4376364185503035\n",
      "Epoch 13, Loss: 0.43176068726814154\n",
      "Epoch 14, Loss: 0.4281416776956934\n",
      "Epoch 15, Loss: 0.4271060799558957\n",
      "Epoch 16, Loss: 0.4177005681576151\n",
      "Epoch 17, Loss: 0.4090518147656412\n",
      "Epoch 18, Loss: 0.41335675673502864\n",
      "Epoch 19, Loss: 0.40529623898592865\n",
      "Epoch 20, Loss: 0.41224705066644785\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8821268344438702\n",
      "Test Accuracy: 0.594743294969467\n",
      "getting accuracy of participant  3\n",
      "TL to the participant :  4\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6867981706604813\n",
      "Epoch 2, Loss: 0.6342768763953989\n",
      "Epoch 3, Loss: 0.5972502908923409\n",
      "Epoch 4, Loss: 0.564873435506315\n",
      "Epoch 5, Loss: 0.5411505064729488\n",
      "Epoch 6, Loss: 0.5222468793843732\n",
      "Epoch 7, Loss: 0.5162010671514453\n",
      "Epoch 8, Loss: 0.49434419111772016\n",
      "Epoch 9, Loss: 0.4794429518056638\n",
      "Epoch 10, Loss: 0.4674937054514885\n",
      "Epoch 11, Loss: 0.4713606879566655\n",
      "Epoch 12, Loss: 0.4561976862676216\n",
      "Epoch 13, Loss: 0.4464505775408311\n",
      "Epoch 14, Loss: 0.44147085240392975\n",
      "Epoch 15, Loss: 0.44148724909984705\n",
      "Epoch 16, Loss: 0.42947874105337897\n",
      "Epoch 17, Loss: 0.423591199472095\n",
      "Epoch 18, Loss: 0.429349949639855\n",
      "Epoch 19, Loss: 0.4189812683246352\n",
      "Epoch 20, Loss: 0.4202059509627747\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8591371196773117\n",
      "Test Accuracy: 0.6165001371020336\n",
      "getting accuracy of participant  4\n",
      "TL to the participant :  5\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6884490088983015\n",
      "Epoch 2, Loss: 0.6304465062690504\n",
      "Epoch 3, Loss: 0.5853373751495824\n",
      "Epoch 4, Loss: 0.5563788350784418\n",
      "Epoch 5, Loss: 0.5294803753495216\n",
      "Epoch 6, Loss: 0.510468666074854\n",
      "Epoch 7, Loss: 0.49486245531024353\n",
      "Epoch 8, Loss: 0.4887904134212118\n",
      "Epoch 9, Loss: 0.4712669716188402\n",
      "Epoch 10, Loss: 0.45644335448741913\n",
      "Epoch 11, Loss: 0.45748547103368875\n",
      "Epoch 12, Loss: 0.4497158053246411\n",
      "Epoch 13, Loss: 0.44352071980635327\n",
      "Epoch 14, Loss: 0.4319996732202443\n",
      "Epoch 15, Loss: 0.4291216261459119\n",
      "Epoch 16, Loss: 0.4180971964290648\n",
      "Epoch 17, Loss: 0.42453433324893314\n",
      "Epoch 18, Loss: 0.4161803135366151\n",
      "Epoch 19, Loss: 0.4050622916582859\n",
      "Epoch 20, Loss: 0.3975694635600755\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8810681276667749\n",
      "Test Accuracy: 0.5886708559983993\n",
      "getting accuracy of participant  5\n",
      "TL to the participant :  6\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6803830338246895\n",
      "Epoch 2, Loss: 0.6221676473364686\n",
      "Epoch 3, Loss: 0.5730301864219435\n",
      "Epoch 4, Loss: 0.5345118736678903\n",
      "Epoch 5, Loss: 0.5109161858757337\n",
      "Epoch 6, Loss: 0.49155533155708603\n",
      "Epoch 7, Loss: 0.47052608023990283\n",
      "Epoch 8, Loss: 0.4560263269778454\n",
      "Epoch 9, Loss: 0.44292947379025543\n",
      "Epoch 10, Loss: 0.433255723028472\n",
      "Epoch 11, Loss: 0.42552556481325265\n",
      "Epoch 12, Loss: 0.42638020781856595\n",
      "Epoch 13, Loss: 0.4150968270771431\n",
      "Epoch 14, Loss: 0.41190845903122064\n",
      "Epoch 15, Loss: 0.3989553941470204\n",
      "Epoch 16, Loss: 0.40342820051944617\n",
      "Epoch 17, Loss: 0.40110725220857246\n",
      "Epoch 18, Loss: 0.38740089795354643\n",
      "Epoch 19, Loss: 0.3797957987496347\n",
      "Epoch 20, Loss: 0.38913100799827866\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8657477488189589\n",
      "Test Accuracy: 0.6309712335848106\n",
      "getting accuracy of participant  6\n",
      "TL to the participant :  7\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6741812463962671\n",
      "Epoch 2, Loss: 0.6167587953986544\n",
      "Epoch 3, Loss: 0.58679373607491\n",
      "Epoch 4, Loss: 0.553589094768871\n",
      "Epoch 5, Loss: 0.5288321870294485\n",
      "Epoch 6, Loss: 0.5003740999734763\n",
      "Epoch 7, Loss: 0.49290162076552707\n",
      "Epoch 8, Loss: 0.47869107285232254\n",
      "Epoch 9, Loss: 0.4628526800961206\n",
      "Epoch 10, Loss: 0.45981022918766196\n",
      "Epoch 11, Loss: 0.444963390854272\n",
      "Epoch 12, Loss: 0.4397888910589796\n",
      "Epoch 13, Loss: 0.42644809231613623\n",
      "Epoch 14, Loss: 0.42543844991561136\n",
      "Epoch 15, Loss: 0.4202655107911789\n",
      "Epoch 16, Loss: 0.4113470215463277\n",
      "Epoch 17, Loss: 0.4065190673326001\n",
      "Epoch 18, Loss: 0.3949329691628615\n",
      "Epoch 19, Loss: 0.3968429510114771\n",
      "Epoch 20, Loss: 0.392221429357023\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8393601112213771\n",
      "Test Accuracy: 0.6032205777183257\n",
      "getting accuracy of participant  7\n",
      "TL to the participant :  8\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6735742281783711\n",
      "Epoch 2, Loss: 0.617564805077784\n",
      "Epoch 3, Loss: 0.5843443355777047\n",
      "Epoch 4, Loss: 0.5551493978410056\n",
      "Epoch 5, Loss: 0.5351354059847918\n",
      "Epoch 6, Loss: 0.5203803294535839\n",
      "Epoch 7, Loss: 0.4988561254559141\n",
      "Epoch 8, Loss: 0.4817652828765638\n",
      "Epoch 9, Loss: 0.47630420033678866\n",
      "Epoch 10, Loss: 0.4602819751157905\n",
      "Epoch 11, Loss: 0.4539811785022418\n",
      "Epoch 12, Loss: 0.4531800805619269\n",
      "Epoch 13, Loss: 0.4474124928767031\n",
      "Epoch 14, Loss: 0.4378660987272407\n",
      "Epoch 15, Loss: 0.42558500261017773\n",
      "Epoch 16, Loss: 0.42199961457288626\n",
      "Epoch 17, Loss: 0.411456143088413\n",
      "Epoch 18, Loss: 0.4106418664256732\n",
      "Epoch 19, Loss: 0.4095429985812216\n",
      "Epoch 20, Loss: 0.3962958100618738\n",
      "Training finished!\n",
      "Validation Accuracy: 0.9050936829733425\n",
      "Test Accuracy: 0.618563036365388\n",
      "getting accuracy of participant  8\n",
      "TL to the participant :  9\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6884596582615015\n",
      "Epoch 2, Loss: 0.6321474124084819\n",
      "Epoch 3, Loss: 0.5899644780791167\n",
      "Epoch 4, Loss: 0.5484813803976233\n",
      "Epoch 5, Loss: 0.5107170544338949\n",
      "Epoch 6, Loss: 0.49442811852151697\n",
      "Epoch 7, Loss: 0.473862114277753\n",
      "Epoch 8, Loss: 0.46086807842507505\n",
      "Epoch 9, Loss: 0.4461011884338928\n",
      "Epoch 10, Loss: 0.4377284874067162\n",
      "Epoch 11, Loss: 0.42011590866428433\n",
      "Epoch 12, Loss: 0.41793554005297745\n",
      "Epoch 13, Loss: 0.4053030400113626\n",
      "Epoch 14, Loss: 0.408536627211354\n",
      "Epoch 15, Loss: 0.40272428862976306\n",
      "Epoch 16, Loss: 0.39990362841071503\n",
      "Epoch 17, Loss: 0.3913492691336256\n",
      "Epoch 18, Loss: 0.39220249946370267\n",
      "Epoch 19, Loss: 0.38137402430628287\n",
      "Epoch 20, Loss: 0.3770203437994827\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8742608488861856\n",
      "Test Accuracy: 0.6162252382611015\n",
      "getting accuracy of participant  9\n",
      "TL to the participant :  10\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6792154185699694\n",
      "Epoch 2, Loss: 0.630332985610673\n",
      "Epoch 3, Loss: 0.5958358999906164\n",
      "Epoch 4, Loss: 0.5660022296237223\n",
      "Epoch 5, Loss: 0.541550741502733\n",
      "Epoch 6, Loss: 0.516250379383564\n",
      "Epoch 7, Loss: 0.5063503903873039\n",
      "Epoch 8, Loss: 0.48781192934874334\n",
      "Epoch 9, Loss: 0.46765918600739853\n",
      "Epoch 10, Loss: 0.4651769573489825\n",
      "Epoch 11, Loss: 0.45118172557064984\n",
      "Epoch 12, Loss: 0.43972386464928137\n",
      "Epoch 13, Loss: 0.42880998664733133\n",
      "Epoch 14, Loss: 0.4527167576280507\n",
      "Epoch 15, Loss: 0.43304757209438266\n",
      "Epoch 16, Loss: 0.4062783631185691\n",
      "Epoch 17, Loss: 0.4090708595785228\n",
      "Epoch 18, Loss: 0.4103132751629208\n",
      "Epoch 19, Loss: 0.4025669496393565\n",
      "Epoch 20, Loss: 0.40905854523633467\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8518702295312879\n",
      "Test Accuracy: 0.6054996674349321\n",
      "getting accuracy of participant  10\n",
      "TL to the participant :  11\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7125565472877387\n",
      "Epoch 2, Loss: 0.6520394217787366\n",
      "Epoch 3, Loss: 0.6070594977248799\n",
      "Epoch 4, Loss: 0.580314822946534\n",
      "Epoch 5, Loss: 0.5464031691804077\n",
      "Epoch 6, Loss: 0.5234144673202977\n",
      "Epoch 7, Loss: 0.5070733726024628\n",
      "Epoch 8, Loss: 0.49015167062029696\n",
      "Epoch 9, Loss: 0.47411153826749686\n",
      "Epoch 10, Loss: 0.4601871592528892\n",
      "Epoch 11, Loss: 0.4643201590939002\n",
      "Epoch 12, Loss: 0.44882663136178796\n",
      "Epoch 13, Loss: 0.43814562915852573\n",
      "Epoch 14, Loss: 0.43122772308010043\n",
      "Epoch 15, Loss: 0.42514781789346173\n",
      "Epoch 16, Loss: 0.4089644072633801\n",
      "Epoch 17, Loss: 0.40651821503133484\n",
      "Epoch 18, Loss: 0.4075257017305403\n",
      "Epoch 19, Loss: 0.3973649595723008\n",
      "Epoch 20, Loss: 0.3945928809769226\n",
      "Training finished!\n",
      "Validation Accuracy: 0.863157004157082\n",
      "Test Accuracy: 0.6279913486764095\n",
      "getting accuracy of participant  11\n",
      "TL to the participant :  0\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.709866514711669\n",
      "Epoch 2, Loss: 0.645289957523346\n",
      "Epoch 3, Loss: 0.605891901435274\n",
      "Epoch 4, Loss: 0.5663037257212581\n",
      "Epoch 5, Loss: 0.541599236880288\n",
      "Epoch 6, Loss: 0.524606037772063\n",
      "Epoch 7, Loss: 0.5027319730231257\n",
      "Epoch 8, Loss: 0.48679483501297055\n",
      "Epoch 9, Loss: 0.4855147550503413\n",
      "Epoch 10, Loss: 0.4711075673500697\n",
      "Epoch 11, Loss: 0.46197736037499976\n",
      "Epoch 12, Loss: 0.4502268234888713\n",
      "Epoch 13, Loss: 0.44459068120429013\n",
      "Epoch 14, Loss: 0.4519762261347337\n",
      "Epoch 15, Loss: 0.444548868320205\n",
      "Epoch 16, Loss: 0.479886735479037\n",
      "Epoch 17, Loss: 0.43547559371500305\n",
      "Epoch 18, Loss: 0.44970458858844004\n",
      "Epoch 19, Loss: 0.4265579172607624\n",
      "Epoch 20, Loss: 0.43603129143064673\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8030462401046359\n",
      "Test Accuracy: 0.5886150425016303\n",
      "getting accuracy of participant  0\n",
      "TL to the participant :  1\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.9229886044155468\n",
      "Epoch 2, Loss: 0.7179596410556273\n",
      "Epoch 3, Loss: 0.6538535622936307\n",
      "Epoch 4, Loss: 0.6298569675647852\n",
      "Epoch 5, Loss: 0.6150327636436983\n",
      "Epoch 6, Loss: 0.595640909039613\n",
      "Epoch 7, Loss: 0.5791984342715957\n",
      "Epoch 8, Loss: 0.5671228874813427\n",
      "Epoch 9, Loss: 0.555054737311421\n",
      "Epoch 10, Loss: 0.5464796222972147\n",
      "Epoch 11, Loss: 0.5339125394821167\n",
      "Epoch 12, Loss: 0.5203041359782219\n",
      "Epoch 13, Loss: 0.5018200998504957\n",
      "Epoch 14, Loss: 0.49561447695349203\n",
      "Epoch 15, Loss: 0.48659063243504724\n",
      "Epoch 16, Loss: 0.4734552739696069\n",
      "Epoch 17, Loss: 0.461502242268938\n",
      "Epoch 18, Loss: 0.44942955017992947\n",
      "Epoch 19, Loss: 0.45607237404946127\n",
      "Epoch 20, Loss: 0.452706774075826\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8140654797565203\n",
      "Test Accuracy: 0.6548723793131559\n",
      "getting accuracy of participant  1\n",
      "TL to the participant :  2\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7509311365358757\n",
      "Epoch 2, Loss: 0.6602374590707548\n",
      "Epoch 3, Loss: 0.6244496870221514\n",
      "Epoch 4, Loss: 0.5776662212429624\n",
      "Epoch 5, Loss: 0.5482073252399763\n",
      "Epoch 6, Loss: 0.5259551051439662\n",
      "Epoch 7, Loss: 0.5059572954972585\n",
      "Epoch 8, Loss: 0.4985691381223274\n",
      "Epoch 9, Loss: 0.4781816784631122\n",
      "Epoch 10, Loss: 0.4678868448192423\n",
      "Epoch 11, Loss: 0.4701600736289313\n",
      "Epoch 12, Loss: 0.4523715315894647\n",
      "Epoch 13, Loss: 0.44559437510642136\n",
      "Epoch 14, Loss: 0.44179349844202853\n",
      "Epoch 15, Loss: 0.4324931168194973\n",
      "Epoch 16, Loss: 0.4304454482414506\n",
      "Epoch 17, Loss: 0.4287637336687608\n",
      "Epoch 18, Loss: 0.41536972333084454\n",
      "Epoch 19, Loss: 0.4164982986721126\n",
      "Epoch 20, Loss: 0.405456734651869\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8571706232878905\n",
      "Test Accuracy: 0.638831209795755\n",
      "getting accuracy of participant  2\n",
      "TL to the participant :  3\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7212324038599477\n",
      "Epoch 2, Loss: 0.642436124158628\n",
      "Epoch 3, Loss: 0.6009957447196498\n",
      "Epoch 4, Loss: 0.5749391622164033\n",
      "Epoch 5, Loss: 0.5478317938519247\n",
      "Epoch 6, Loss: 0.518550118939443\n",
      "Epoch 7, Loss: 0.5122864600835424\n",
      "Epoch 8, Loss: 0.4940323211026914\n",
      "Epoch 9, Loss: 0.48841124908490613\n",
      "Epoch 10, Loss: 0.4777847955172712\n",
      "Epoch 11, Loss: 0.4662425448045586\n",
      "Epoch 12, Loss: 0.44158396215149853\n",
      "Epoch 13, Loss: 0.44519172270189633\n",
      "Epoch 14, Loss: 0.44359884614294226\n",
      "Epoch 15, Loss: 0.4395769570361484\n",
      "Epoch 16, Loss: 0.4514471610838717\n",
      "Epoch 17, Loss: 0.4411484402689067\n",
      "Epoch 18, Loss: 0.4223568064696861\n",
      "Epoch 19, Loss: 0.42859705514980084\n",
      "Epoch 20, Loss: 0.4179141629825939\n",
      "Training finished!\n",
      "Validation Accuracy: 0.7812272766768955\n",
      "Test Accuracy: 0.5991510558709314\n",
      "getting accuracy of participant  3\n",
      "TL to the participant :  4\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.696391039725506\n",
      "Epoch 2, Loss: 0.6238844457900885\n",
      "Epoch 3, Loss: 0.5698556805198843\n",
      "Epoch 4, Loss: 0.5390129333192651\n",
      "Epoch 5, Loss: 0.5085556373903246\n",
      "Epoch 6, Loss: 0.49407039898814575\n",
      "Epoch 7, Loss: 0.47561951591209933\n",
      "Epoch 8, Loss: 0.4687522408185583\n",
      "Epoch 9, Loss: 0.45276183025403455\n",
      "Epoch 10, Loss: 0.44891970740123227\n",
      "Epoch 11, Loss: 0.44651877880096436\n",
      "Epoch 12, Loss: 0.4371936072905858\n",
      "Epoch 13, Loss: 0.43779591177449084\n",
      "Epoch 14, Loss: 0.4209139035506682\n",
      "Epoch 15, Loss: 0.424480946903879\n",
      "Epoch 16, Loss: 0.4103845956199097\n",
      "Epoch 17, Loss: 0.4088061503840215\n",
      "Epoch 18, Loss: 0.39986141364682803\n",
      "Epoch 19, Loss: 0.40784409258401755\n",
      "Epoch 20, Loss: 0.39913418155276414\n",
      "Training finished!\n",
      "Validation Accuracy: 0.85952355908407\n",
      "Test Accuracy: 0.6094039489091124\n",
      "getting accuracy of participant  4\n",
      "TL to the participant :  5\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6896875947713852\n",
      "Epoch 2, Loss: 0.6289890015667136\n",
      "Epoch 3, Loss: 0.5852680240165103\n",
      "Epoch 4, Loss: 0.5515083645780882\n",
      "Epoch 5, Loss: 0.5281508711702896\n",
      "Epoch 6, Loss: 0.4987626497944196\n",
      "Epoch 7, Loss: 0.49596672256787616\n",
      "Epoch 8, Loss: 0.4682040431282737\n",
      "Epoch 9, Loss: 0.4585806770306645\n",
      "Epoch 10, Loss: 0.45419420076139044\n",
      "Epoch 11, Loss: 0.4399786496704275\n",
      "Epoch 12, Loss: 0.43895541831399454\n",
      "Epoch 13, Loss: 0.4364882745977604\n",
      "Epoch 14, Loss: 0.42560911178588867\n",
      "Epoch 15, Loss: 0.42686919100356824\n",
      "Epoch 16, Loss: 0.4107576163880753\n",
      "Epoch 17, Loss: 0.4141703911802985\n",
      "Epoch 18, Loss: 0.4116222366239085\n",
      "Epoch 19, Loss: 0.4093126424334266\n",
      "Epoch 20, Loss: 0.4076809028558659\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8645312650059681\n",
      "Test Accuracy: 0.6552664318639948\n",
      "getting accuracy of participant  5\n",
      "TL to the participant :  6\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.748288868503137\n",
      "Epoch 2, Loss: 0.6593400244459962\n",
      "Epoch 3, Loss: 0.6132189852721763\n",
      "Epoch 4, Loss: 0.5841684653000399\n",
      "Epoch 5, Loss: 0.5583850973934839\n",
      "Epoch 6, Loss: 0.547408910637552\n",
      "Epoch 7, Loss: 0.5211674148837725\n",
      "Epoch 8, Loss: 0.5105966984322576\n",
      "Epoch 9, Loss: 0.5001800195737318\n",
      "Epoch 10, Loss: 0.4866546514359387\n",
      "Epoch 11, Loss: 0.47957173283352994\n",
      "Epoch 12, Loss: 0.4627266526222229\n",
      "Epoch 13, Loss: 0.45466709701400815\n",
      "Epoch 14, Loss: 0.4470685889775103\n",
      "Epoch 15, Loss: 0.43887671647649823\n",
      "Epoch 16, Loss: 0.4432592579361164\n",
      "Epoch 17, Loss: 0.42563068776419666\n",
      "Epoch 18, Loss: 0.4220518304994612\n",
      "Epoch 19, Loss: 0.4185250819180951\n",
      "Epoch 20, Loss: 0.4265673144748717\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8401261301637679\n",
      "Test Accuracy: 0.586530026271714\n",
      "getting accuracy of participant  6\n",
      "TL to the participant :  7\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6834334473718296\n",
      "Epoch 2, Loss: 0.6437283469872042\n",
      "Epoch 3, Loss: 0.6032278361645612\n",
      "Epoch 4, Loss: 0.5698461006536628\n",
      "Epoch 5, Loss: 0.5344579018878214\n",
      "Epoch 6, Loss: 0.515040565394994\n",
      "Epoch 7, Loss: 0.49957179007205094\n",
      "Epoch 8, Loss: 0.4834277286674037\n",
      "Epoch 9, Loss: 0.47790260071104224\n",
      "Epoch 10, Loss: 0.46715178363250964\n",
      "Epoch 11, Loss: 0.4541313201189041\n",
      "Epoch 12, Loss: 0.44678232909152005\n",
      "Epoch 13, Loss: 0.4364177950403907\n",
      "Epoch 14, Loss: 0.440063745460727\n",
      "Epoch 15, Loss: 0.4159338862606973\n",
      "Epoch 16, Loss: 0.42721778334993304\n",
      "Epoch 17, Loss: 0.4167404626355027\n",
      "Epoch 18, Loss: 0.41333994630611304\n",
      "Epoch 19, Loss: 0.4027671710108266\n",
      "Epoch 20, Loss: 0.3973970718004487\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8785574148347\n",
      "Test Accuracy: 0.6188378194106836\n",
      "getting accuracy of participant  7\n",
      "TL to the participant :  8\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6953154806837891\n",
      "Epoch 2, Loss: 0.6251807795329527\n",
      "Epoch 3, Loss: 0.5856957826198954\n",
      "Epoch 4, Loss: 0.5531831627542322\n",
      "Epoch 5, Loss: 0.5256660822214503\n",
      "Epoch 6, Loss: 0.5106498422947797\n",
      "Epoch 7, Loss: 0.4927533067988627\n",
      "Epoch 8, Loss: 0.47722503700942703\n",
      "Epoch 9, Loss: 0.4653714190829884\n",
      "Epoch 10, Loss: 0.4584941173141653\n",
      "Epoch 11, Loss: 0.4539935329195225\n",
      "Epoch 12, Loss: 0.4527814135406957\n",
      "Epoch 13, Loss: 0.429838897829706\n",
      "Epoch 14, Loss: 0.440682450252952\n",
      "Epoch 15, Loss: 0.4414979908050913\n",
      "Epoch 16, Loss: 0.443994864821434\n",
      "Epoch 17, Loss: 0.42506445921731717\n",
      "Epoch 18, Loss: 0.4339622216242732\n",
      "Epoch 19, Loss: 0.4451326362111352\n",
      "Epoch 20, Loss: 0.4244484297479644\n",
      "Training finished!\n",
      "Validation Accuracy: 0.7942267324604528\n",
      "Test Accuracy: 0.6051684919146855\n",
      "getting accuracy of participant  8\n",
      "TL to the participant :  9\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.7283985610261108\n",
      "Epoch 2, Loss: 0.6453860072475491\n",
      "Epoch 3, Loss: 0.6038705697565367\n",
      "Epoch 4, Loss: 0.5581423421249245\n",
      "Epoch 5, Loss: 0.5214568861957752\n",
      "Epoch 6, Loss: 0.504495436946551\n",
      "Epoch 7, Loss: 0.4815814233187473\n",
      "Epoch 8, Loss: 0.4717503763509519\n",
      "Epoch 9, Loss: 0.45904422822323715\n",
      "Epoch 10, Loss: 0.4484275193376975\n",
      "Epoch 11, Loss: 0.43702598638606793\n",
      "Epoch 12, Loss: 0.4221494209134217\n",
      "Epoch 13, Loss: 0.4267740484439965\n",
      "Epoch 14, Loss: 0.417318092602672\n",
      "Epoch 15, Loss: 0.42345604006991244\n",
      "Epoch 16, Loss: 0.4081754253217668\n",
      "Epoch 17, Loss: 0.3936519494110888\n",
      "Epoch 18, Loss: 0.39792121596860164\n",
      "Epoch 19, Loss: 0.3930658112195405\n",
      "Epoch 20, Loss: 0.3866942439115409\n",
      "Training finished!\n",
      "Validation Accuracy: 0.890719966340899\n",
      "Test Accuracy: 0.6052314847409141\n",
      "getting accuracy of participant  9\n",
      "TL to the participant :  10\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6859512428442637\n",
      "Epoch 2, Loss: 0.6310656558383595\n",
      "Epoch 3, Loss: 0.5899605694593806\n",
      "Epoch 4, Loss: 0.5644603177453532\n",
      "Epoch 5, Loss: 0.5352170950535572\n",
      "Epoch 6, Loss: 0.5159403406309359\n",
      "Epoch 7, Loss: 0.49263595879981015\n",
      "Epoch 8, Loss: 0.47238543223250995\n",
      "Epoch 9, Loss: 0.46562020909605606\n",
      "Epoch 10, Loss: 0.455696125599471\n",
      "Epoch 11, Loss: 0.45002554018389096\n",
      "Epoch 12, Loss: 0.43411447898004996\n",
      "Epoch 13, Loss: 0.43116779106132913\n",
      "Epoch 14, Loss: 0.43388491665775125\n",
      "Epoch 15, Loss: 0.42521904115424014\n",
      "Epoch 16, Loss: 0.41512908154364786\n",
      "Epoch 17, Loss: 0.4109597864250342\n",
      "Epoch 18, Loss: 0.41247612486282986\n",
      "Epoch 19, Loss: 0.4105140760992513\n",
      "Epoch 20, Loss: 0.407172338416179\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8728545753053786\n",
      "Test Accuracy: 0.5928742376015296\n",
      "getting accuracy of participant  10\n",
      "TL to the participant :  11\n",
      "(9352, 1, 32, 125)\n",
      "(31200, 1, 32, 125)\n",
      "balancing the number of ones and zeros\n",
      "Creating the different pipelines\n",
      "Fitting\n",
      "Epoch 1, Loss: 0.6738301623951305\n",
      "Epoch 2, Loss: 0.6211362594004833\n",
      "Epoch 3, Loss: 0.5775681953086997\n",
      "Epoch 4, Loss: 0.5471411726691506\n",
      "Epoch 5, Loss: 0.5233635545680018\n",
      "Epoch 6, Loss: 0.5072526656316988\n",
      "Epoch 7, Loss: 0.49324063505187177\n",
      "Epoch 8, Loss: 0.4851596856659109\n",
      "Epoch 9, Loss: 0.46630390710902936\n",
      "Epoch 10, Loss: 0.4605404849756848\n",
      "Epoch 11, Loss: 0.4579460033864686\n",
      "Epoch 12, Loss: 0.4502824091098525\n",
      "Epoch 13, Loss: 0.43904220696651575\n",
      "Epoch 14, Loss: 0.4281760174216646\n",
      "Epoch 15, Loss: 0.43011127750981937\n",
      "Epoch 16, Loss: 0.42576919157396664\n",
      "Epoch 17, Loss: 0.4205277476346854\n",
      "Epoch 18, Loss: 0.4158003084135778\n",
      "Epoch 19, Loss: 0.42642685680678394\n",
      "Epoch 20, Loss: 0.47753565735889203\n",
      "Training finished!\n",
      "Validation Accuracy: 0.8282562664922735\n",
      "Test Accuracy: 0.6324029308338768\n",
      "getting accuracy of participant  11\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[124.12817073 124.46538692 127.4681839  135.90787129 134.67368279\n",
      " 134.95591879 123.97578406 134.85607443 134.96063709 135.51463881\n",
      " 131.93119192 132.65311656]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"C:\\\\Users\\\\s.velut\\\\Documents\\\\These\\\\Protheus_PHD\\\\Scripts\")\n",
    "from Scripts.SPDNet.torch.spd_net_bn_torch import CNNSPDNetBN_Module\n",
    "from Scripts.SPDNet.torch.optimizers import riemannian_adam as torch_riemannian_adam\n",
    "\n",
    "\n",
    "\n",
    "n_cal = 7\n",
    "n_class = 4\n",
    "nb_fold = 1\n",
    "spdbn_accuracy_code_perso = np.zeros((nb_fold,12))\n",
    "spdbn_tps_train_code_perso = np.zeros((nb_fold,12))\n",
    "spdbn_tps_test_code_perso = np.zeros((nb_fold,12))\n",
    "spdbn_accuracy_perso = np.zeros((nb_fold,12))\n",
    "\n",
    "for k in range(nb_fold):\n",
    "    for i in range(12):\n",
    "        print(\"TL to the participant : \", i)\n",
    "        # X = X_parent.copy()\n",
    "        # Y = Y_parent.copy()\n",
    "        # domains = domains_parent.copy()\n",
    "        nb_sample_cal = int(n_class*n_cal*(2.2-window_size)*60)\n",
    "\n",
    "        # X_train = X[i][:nb_sample_cal]\n",
    "        # Y_train = Y[i][:nb_sample_cal]\n",
    "        # X_test = X[i][nb_sample_cal:]\n",
    "        # Y_test = Y[i][nb_sample_cal:]\n",
    "        # labels_code_test = labels_codes[i][(n_class*n_cal):]\n",
    "\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        # X_std = X_train.std(axis=0)\n",
    "        # X_train /= X_std + 1e-8\n",
    "        # X_std = X_test.std(axis=0)\n",
    "        # X_test /= X_std + 1e-8\n",
    "\n",
    "        print(\"balancing the number of ones and zeros\")\n",
    "        # X_train, Y_train, domains_train = balance(X_train,Y_train,domains[i][:nb_sample_cal])\n",
    "\n",
    "        print(\"Creating the different pipelines\")\n",
    "        lr = 1e-3\n",
    "        # optimizer = riemannian_adam.RiemannianAdam(learning_rate=lr)\n",
    "        batchsize = 64 #128 # 64 for burst\n",
    "        epoch = 20 #45 # 20 for burst\n",
    "        # clf = SPDNet_AJD(n_epochs=epoch,batch_size=batchsize,valid_split=0.1)\n",
    "        clf = CNNSPDNetBN_Module(32,0.25)\n",
    "\n",
    "        print(\"Fitting\")\n",
    "        start = time.time()\n",
    "        weight_decay = 1e-4\n",
    "        \n",
    "        x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "        # Convert data into PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(x_train, dtype=torch.float64)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "        X_val_tensor = torch.tensor(x_val, dtype=torch.float64)\n",
    "        y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float64)\n",
    "        y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "        # Create DataLoader for train, validation, and test sets\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = torch.nn.CrossEntropyLoss().float()\n",
    "        optimizer = torch_riemannian_adam.RiemannianAdam(clf.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        num_epochs = 20\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_dataloader:\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                # print(inputs.shape)\n",
    "                # print(labels.shape)\n",
    "                outputs = clf(inputs)\n",
    "                loss = criterion(outputs.float(), labels.float())\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_dataloader)}\")\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "        spdbn_tps_train_code_perso[k][i] = time.time() - start\n",
    "\n",
    "        # Validation\n",
    "        clf.eval()\n",
    "        val_correct = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                outputs = clf(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                y_pred.append(np.array(predicted))\n",
    "                y_true.append(np.array(labels)) \n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = balanced_accuracy_score(np.concatenate(y_true),np.concatenate(y_pred))\n",
    "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "        # Testing\n",
    "        start = time.time()\n",
    "        test_correct = 0\n",
    "        y_pred= []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                outputs = clf(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                y_pred.append(np.array(predicted))\n",
    "                y_true.append(np.array(labels)) \n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        test_accuracy = balanced_accuracy_score(np.concatenate(y_true),np.concatenate(y_pred))\n",
    "        print(f\"Test Accuracy: {test_accuracy}\")\n",
    "        \n",
    "        print(\"getting accuracy of participant \", i)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "        y_test_norm = np.array([0 if y == 0 else 1 for y in np.concatenate(y_true)])\n",
    "\n",
    "        # tn, fp, fn, tp = confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "        # spdbn_accuracy_perso[k][i] = balanced_accuracy_score(y_test_norm,y_pred_norm)\n",
    "\n",
    "        # labels_pred_accumul, _, mean_long_accumul = make_preds_accumul_aggresive(\n",
    "        #     y_pred_norm, codes, min_len=30, sfreq=freq, consecutive=50, window_size=window_size\n",
    "        # )\n",
    "        # spdbn_tps_test_code_perso[k][i] = time.time() - start\n",
    "        # spdbn_accuracy_code_perso[k][i] = np.round(accuracy_score(labels_code_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "spdbn_accuracy_perso = np.mean(spdbn_accuracy_perso,axis=0)\n",
    "spdbn_tps_train_code_perso = np.mean(spdbn_tps_train_code_perso,axis=0)\n",
    "spdbn_tps_test_code_perso = np.mean(spdbn_tps_test_code_perso,axis=0)\n",
    "spdbn_accuracy_code_perso = np.mean(spdbn_accuracy_code_perso,axis=0)\n",
    "\n",
    "print(spdbn_accuracy_perso)\n",
    "print(spdbn_tps_train_code_perso)\n",
    "print(spdbn_tps_test_code_perso)\n",
    "print(spdbn_accuracy_code_perso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5099b32-1a52-4758-a20b-0a2c759d9cbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cut the train in train and valid\n",
    "Also set some HP of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a5ecf-8400-4722-86bc-317d15a2b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "batchsize = 64 #128 # 64 for burst\n",
    "epochs = 20 #45 # 20 for burst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ad9011-e499-4c2a-9163-d968ba4d0153",
   "metadata": {},
   "source": [
    "### Attach an optimizer and train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3bb97b",
   "metadata": {},
   "source": [
    "res_X_train=[]\n",
    "for i in range(len(X_train)):\n",
    "    res_X_train.append(np.array(X_train[i:i+1]).reshape(n_samples_windows, n_channels, 1))\n",
    "res_X_val=[]\n",
    "for i in range(len(x_val)):\n",
    "    res_X_val.append(np.array(x_val[i:i+1]).reshape(n_samples_windows, n_channels, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1a142",
   "metadata": {},
   "source": [
    "np.array(res_X_val).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9861b",
   "metadata": {},
   "source": [
    "np.array(res_X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29716ea1-43fe-4060-b7e2-7685be9c2804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "132/132 [==============================] - 2s 10ms/step - loss: 0.6964 - accuracy: 0.5758 - val_loss: 0.6061 - val_accuracy: 0.6944\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.6058 - accuracy: 0.6797 - val_loss: 0.5340 - val_accuracy: 0.7564\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.5533 - accuracy: 0.7245 - val_loss: 0.4972 - val_accuracy: 0.7842\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.5366 - accuracy: 0.7356 - val_loss: 0.4805 - val_accuracy: 0.7810\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.5124 - accuracy: 0.7536 - val_loss: 0.4767 - val_accuracy: 0.7895\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.5011 - accuracy: 0.7553 - val_loss: 0.4466 - val_accuracy: 0.8173\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4933 - accuracy: 0.7599 - val_loss: 0.4515 - val_accuracy: 0.8056\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4799 - accuracy: 0.7697 - val_loss: 0.4291 - val_accuracy: 0.8280\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4683 - accuracy: 0.7808 - val_loss: 0.4118 - val_accuracy: 0.8365\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4684 - accuracy: 0.7769 - val_loss: 0.4157 - val_accuracy: 0.8301\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4526 - accuracy: 0.7893 - val_loss: 0.3890 - val_accuracy: 0.8440\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4467 - accuracy: 0.7957 - val_loss: 0.3954 - val_accuracy: 0.8365\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4409 - accuracy: 0.7934 - val_loss: 0.3870 - val_accuracy: 0.8451\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4318 - accuracy: 0.8017 - val_loss: 0.3774 - val_accuracy: 0.8419\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4264 - accuracy: 0.8011 - val_loss: 0.3745 - val_accuracy: 0.8526\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4272 - accuracy: 0.8030 - val_loss: 0.3595 - val_accuracy: 0.8643\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4181 - accuracy: 0.8061 - val_loss: 0.3441 - val_accuracy: 0.8729\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.4139 - accuracy: 0.8096 - val_loss: 0.3485 - val_accuracy: 0.8739\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4105 - accuracy: 0.8137 - val_loss: 0.3356 - val_accuracy: 0.8686\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4037 - accuracy: 0.8178 - val_loss: 0.3223 - val_accuracy: 0.8782\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4087 - accuracy: 0.8140 - val_loss: 0.3344 - val_accuracy: 0.8868\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3943 - accuracy: 0.8239 - val_loss: 0.3127 - val_accuracy: 0.8932\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3885 - accuracy: 0.8256 - val_loss: 0.3148 - val_accuracy: 0.8900\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3960 - accuracy: 0.8240 - val_loss: 0.3272 - val_accuracy: 0.8846\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3814 - accuracy: 0.8288 - val_loss: 0.3191 - val_accuracy: 0.8942\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3906 - accuracy: 0.8315 - val_loss: 0.3079 - val_accuracy: 0.8921\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3833 - accuracy: 0.8316 - val_loss: 0.3113 - val_accuracy: 0.8985\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3690 - accuracy: 0.8377 - val_loss: 0.2949 - val_accuracy: 0.9017\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3773 - accuracy: 0.8331 - val_loss: 0.2936 - val_accuracy: 0.9028\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3781 - accuracy: 0.8358 - val_loss: 0.3059 - val_accuracy: 0.8964\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3657 - accuracy: 0.8397 - val_loss: 0.2963 - val_accuracy: 0.8942\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3770 - accuracy: 0.8350 - val_loss: 0.2934 - val_accuracy: 0.9124\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3703 - accuracy: 0.8358 - val_loss: 0.2916 - val_accuracy: 0.9006\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3672 - accuracy: 0.8365 - val_loss: 0.2928 - val_accuracy: 0.8996\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3673 - accuracy: 0.8386 - val_loss: 0.2895 - val_accuracy: 0.9060\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3608 - accuracy: 0.8441 - val_loss: 0.2820 - val_accuracy: 0.9049\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3534 - accuracy: 0.8460 - val_loss: 0.2750 - val_accuracy: 0.8985\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3526 - accuracy: 0.8467 - val_loss: 0.2890 - val_accuracy: 0.9071\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3547 - accuracy: 0.8424 - val_loss: 0.2781 - val_accuracy: 0.9071\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3549 - accuracy: 0.8460 - val_loss: 0.2773 - val_accuracy: 0.9006\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3569 - accuracy: 0.8470 - val_loss: 0.2715 - val_accuracy: 0.9060\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3525 - accuracy: 0.8428 - val_loss: 0.2643 - val_accuracy: 0.9135\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3489 - accuracy: 0.8485 - val_loss: 0.2723 - val_accuracy: 0.9199\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3506 - accuracy: 0.8455 - val_loss: 0.2760 - val_accuracy: 0.8974\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3506 - accuracy: 0.8495 - val_loss: 0.2642 - val_accuracy: 0.9060\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.3466 - accuracy: 0.8485 - val_loss: 0.2652 - val_accuracy: 0.9145\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3510 - accuracy: 0.8486 - val_loss: 0.2763 - val_accuracy: 0.9081\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3394 - accuracy: 0.8517 - val_loss: 0.2564 - val_accuracy: 0.9145\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3485 - accuracy: 0.8511 - val_loss: 0.2655 - val_accuracy: 0.9167\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.3387 - accuracy: 0.8574 - val_loss: 0.2623 - val_accuracy: 0.9092\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr, amsgrad=True)\n",
    "clf.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "history = clf.fit(np.array(X_train), y_train,\n",
    "                  batch_size=batchsize, epochs=50,\n",
    "                  validation_data=(np.array(x_val), y_val), shuffle=True)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 [==============================] - 3s 3ms/step - loss: 0.5361 - accuracy: 0.7330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.536074161529541, 0.7330127954483032]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b597e6e-6eb6-4314-bfcf-a4f405d6d0f1",
   "metadata": {},
   "source": [
    "### Model and accuracy and loss\n",
    "Just check that the model learnt something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a1b07-b67d-4557-9406-2cd1bde805e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "# summarize history for accuracy\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# summarize history for loss\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c91070-aab2-451f-b011-4ad2eb23f0ca",
   "metadata": {},
   "source": [
    "filename = ''\n",
    "np.save(filename + \"std_from_calibration\", X_std)\n",
    "model_filename = os.path.join(os.getcwd(), filename + '0.7' + \"trainedmodel\")\n",
    "# Save the model if calibration was done\n",
    "clf.save(model_filename)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2ae4c-9865-42a3-bc95-45ad496308c4",
   "metadata": {},
   "source": [
    "## Vizualize learned filters\n",
    "### Raw vizualiation of 1D convolutinal kernel of the first layer --> spatial filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58fd505-5745-43ae-8ef2-cd9045e945e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We first visualize the learned patch embeddings.\n",
    "# patch_embeddings = clf.layers[0].get_weights()[0]\n",
    "# weights = patch_embeddings\n",
    "# # First, apply min-max normalization to the\n",
    "# # given weights to avoid isotrophic scaling.\n",
    "# p_min, p_max = weights.min(), weights.max()\n",
    "# weights = (weights - p_min) / (p_max - p_min)\n",
    "\n",
    "# # Visualize all the filters.\n",
    "# num_filters = 10\n",
    "# plt.figure(figsize=(16, 2))\n",
    "# idx = 1\n",
    "# for i in range(num_filters):\n",
    "#     current_weight = weights[:, :, :, i]\n",
    "#     if current_weight.shape[-1] == 1:\n",
    "#         current_weight = current_weight.squeeze()\n",
    "#     ax = plt.subplot(1, 10, idx)\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_yticks([])\n",
    "#     plt.plot(current_weight)\n",
    "#     idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be1554-eb6d-4001-8c2d-a421db9a5841",
   "metadata": {},
   "source": [
    "### Viz of the corresponding topo maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b89198-1321-418a-a322-6251c4d46da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spatialfilts = clf.get_layer(\"conv2d\").get_weights()[0]\n",
    "# spatialfilts = np.squeeze(spatialfilts)\n",
    "# spatialfilts = np.swapaxes(spatialfilts, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ca7e0-dd11-40e9-90e6-f162e290aa06",
   "metadata": {},
   "source": [
    "### Predict on the test set\n",
    "The predictions are made on windows to regress the code.  \n",
    "Here we divide the prediction in 10 fold to avoid OOM from the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f599ad-7a5f-469d-9680-876e7438cf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 [==============================] - 3s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "y_pred = clf.predict(X_test)[:,0]\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aefccb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf375061",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_norm = np.array([1 if (y >= 0.5) else 0 for y in y_pred])\n",
    "y_test_norm = np.array([0 if y[0] == 0 else 1 for y in Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c1d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 2826\n",
      "True negatives: 20342\n",
      "False positives: 5514\n",
      "False negatives: 2518\n",
      "Accuracy: 0.7425641025641025\n",
      "Sensitivity: 0.5288173652694611\n",
      "Precision: 0.33884892086330937\n",
      "Fowlkes-Mallows: 0.42330744566489187\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "import math\n",
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test_norm, y_pred_norm).ravel()\n",
    "print(\"True positives:\", tp)\n",
    "print(\"True negatives:\", tn)\n",
    "print(\"False positives:\", fp)\n",
    "print(\"False negatives:\", fn)\n",
    "print(\"Accuracy:\", (tp+tn)/len(y_test_norm))\n",
    "print(\"Sensitivity:\", sen:=tp/(tp+fn))\n",
    "print(\"Precision:\", pre:=tp/(tp+fp))\n",
    "print(\"Fowlkes-Mallows:\", math.sqrt(sen*pre))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6b90c-103f-4762-8d56-c820dfbf9129",
   "metadata": {},
   "source": [
    "### Convert prediction on windows (regressed code) to label prediction\n",
    "\n",
    "It is offline and synchronous, so we will:\n",
    "1. First create a `code_buffer` that contains the regressed code on the full epoch (2.2s - the last window)\n",
    "    - The refresh rate of the EEG device (500 Hz) is faster than the refress rate of the screen (60Hz), so we average predictions (500/60~8 samples) so they correspond to each flip of the screen.\n",
    "2. Starting from `min_len` (in number of samples), we compute Pearson correalation with the bank of templates code to find the closest one\n",
    "    - If the most correlated code has a significantely bigger correlation compared to the second one (50% bigger) and the p_value is significative then the trial is classified and we move to the next one\n",
    "    - If the thresholds are not reached, then we add samples (with a step of 3) to have a longer trial and re-do the computation\n",
    "    - The thresholds can never been reached in 2.2s, then the trial is not classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4dff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_best_score = 0\n",
    "# p_best_ratio = 0\n",
    "# p_best_acc = 0\n",
    "# p_best_values = ()\n",
    "\n",
    "# for p in np.logspace(0,-5, 6):\n",
    "#     for dr in np.linspace(0.2, 0.8, 7):\n",
    "#         labels_pred, _, mean_long = make_preds_pvalue(y_pred, codes, min_len=70, sfreq=sfreq, obj_p=p)\n",
    "#         ratio = len(labels_pred[labels_pred != -1])/len(labels_pred)\n",
    "#         accuracy = accuracy_score(labels_test[labels_pred != -1], labels_pred[labels_pred != -1])\n",
    "#         score = ratio*accuracy\n",
    "#         if ratio >= p_best_ratio:\n",
    "#             p_best_score = score\n",
    "#             p_best_acc = accuracy\n",
    "#             p_best_ratio = ratio\n",
    "#             p_best_values = (p, dr)\n",
    "#         print(\"==========\", p, \"+\", dr,':',ratio,'--',accuracy,'--',score, '--', np.mean(mean_long))\n",
    "# print(\"Best score\", p_best_score)\n",
    "# print(\"Best values\", p_best_values)            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d7e07-f107-48dd-9530-0d58f533aafd",
   "metadata": {},
   "source": [
    "### Compute accuracy score and accuracy score when a prediction is made (discard not classified trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c000d2-8ad2-4fce-8519-3197a7397513",
   "metadata": {},
   "source": [
    "### Other classification method\n",
    "Same as before but the classification method is different. Instead of thresholds to reach, if when increasing trial lengt a code correllated the most 40 times in a row then the trial is labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8663d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(_utils)\n",
    "# from _utils import make_preds_accumul_aggresive, make_preds_pvalue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd82787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 15 : 1.0 -- 0.47 -- 0.47 -- 0.8161290322580645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 20 : 1.0 -- 0.5 -- 0.5 -- 0.9569892473118279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 25 : 1.0 -- 0.53 -- 0.53 -- 1.0442528735632184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 30 : 1.0 -- 0.56 -- 0.56 -- 1.1130952380952384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 35 : 1.0 -- 0.62 -- 0.62 -- 1.2586666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 40 : 1.0 -- 0.62 -- 0.62 -- 1.3763888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 45 : 1.0 -- 0.72 -- 0.72 -- 1.427450980392157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 50 : 1.0 -- 0.72 -- 0.72 -- 1.4533333333333331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 55 : 1.0 -- 0.72 -- 0.72 -- 1.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 60 : 1.0 -- 0.72 -- 0.72 -- 1.5680555555555555\n",
      "Best accuracy 0.72\n",
      "Best ratio 1.0\n",
      "Best score 0.72\n",
      "Best values 45\n"
     ]
    }
   ],
   "source": [
    "acc_best_score=0\n",
    "acc_best_ratio=0\n",
    "acc_best_acc=0\n",
    "acc_best_value = 0\n",
    "# for minlen in np.linspace(10, 60, 10):\n",
    "for cons in [15, 20, 25, 30, 35, 40, 45, 50, 55, 60]:\n",
    "    \n",
    "    labels_pred_accumul, _, mean_long_accumul = make_preds_accumul_aggresive(\n",
    "        y_pred_norm, codes, min_len=30, sfreq=sfreq, consecutive=cons, window_size=window_size\n",
    "    )\n",
    "    ratio = np.round(len(labels_pred_accumul[labels_pred_accumul != -1])/len(labels_pred_accumul), 2)\n",
    "    accuracy = np.round(accuracy_score(labels_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1]), 2)\n",
    "    score = np.round(ratio*accuracy,2)\n",
    "    print(\"==========\", cons, ':', ratio, '--', accuracy,\n",
    "        '--', score, '--', np.mean(mean_long_accumul))\n",
    "    if accuracy > acc_best_acc:\n",
    "        acc_best_score = score\n",
    "        acc_best_value = cons\n",
    "        acc_best_acc = accuracy\n",
    "        acc_best_ratio = ratio\n",
    "\n",
    "print(\"Best accuracy\", acc_best_acc)\n",
    "print(\"Best ratio\", acc_best_ratio)\n",
    "print(\"Best score\", acc_best_score)\n",
    "print(\"Best values\", acc_best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ab636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test[labels_pred_accumul!=-1], labels_pred_accumul[labels_pred_accumul!=-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d2fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\s.velut\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "labels_pred_accumul, aaaaa, mean_long_accumul = make_preds_accumul_aggresive(\n",
    "        y_pred_norm, codes, min_len=30, sfreq=sfreq, consecutive=15, window_size=window_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f451353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_pred_accumul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb4b0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0,\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "                     1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     1, 1, 1, 1, 0, 0, 0, 0])),\n",
       "             (1,\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "                     1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             (2,\n",
       "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "                     1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 1, 1, 1])),\n",
       "             (3,\n",
       "              array([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "                     1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "                     0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                     0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "                     1, 1, 1, 0, 0, 0, 0, 0]))])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5269678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ac3a953833c090f146e4ba605ec310f853a691b325db82e974886e3abb928d6"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
